# Comparing `tmp/netspresso-0.1.4-py3-none-any.whl.zip` & `tmp/netspresso-0.1.5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,25 +1,25 @@
-Zip file size: 18171 bytes, number of entries: 23
--rw-r--r--  2.0 unx       22 b- defN 23-Jun-02 08:59 netspresso/__init__.py
--rw-r--r--  2.0 unx    20173 b- defN 23-Jun-02 08:56 netspresso/compressor/__init__.py
--rw-r--r--  2.0 unx     8237 b- defN 23-Jun-01 17:47 netspresso/compressor/client/__init__.py
--rw-r--r--  2.0 unx      517 b- defN 23-Jun-02 06:03 netspresso/compressor/client/config.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-01 17:47 netspresso/compressor/client/schemas/__init__.py
--rw-r--r--  2.0 unx     2584 b- defN 23-Jun-01 17:47 netspresso/compressor/client/schemas/auth.py
--rw-r--r--  2.0 unx      466 b- defN 23-Jun-01 17:47 netspresso/compressor/client/schemas/common.py
--rw-r--r--  2.0 unx     4042 b- defN 23-Jun-01 17:47 netspresso/compressor/client/schemas/compression.py
--rw-r--r--  2.0 unx     4243 b- defN 23-Jun-01 17:47 netspresso/compressor/client/schemas/model.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-01 17:47 netspresso/compressor/client/utils/__init__.py
--rw-r--r--  2.0 unx      465 b- defN 23-Jun-01 17:47 netspresso/compressor/client/utils/common.py
--rw-r--r--  2.0 unx      694 b- defN 23-Jun-01 17:47 netspresso/compressor/client/utils/enum.py
--rw-r--r--  2.0 unx     3735 b- defN 23-Jun-01 17:47 netspresso/compressor/client/utils/validator.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-01 17:47 netspresso/compressor/core/__init__.py
--rw-r--r--  2.0 unx      551 b- defN 23-Jun-01 17:47 netspresso/compressor/core/compression.py
--rw-r--r--  2.0 unx      507 b- defN 23-Jun-01 17:47 netspresso/compressor/core/model.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-02 08:32 netspresso/compressor/utils/__init__.py
--rw-r--r--  2.0 unx      228 b- defN 23-Jun-01 17:47 netspresso/compressor/utils/token.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Jun-02 08:59 netspresso-0.1.4.dist-info/LICENSE
--rw-r--r--  2.0 unx      846 b- defN 23-Jun-02 08:59 netspresso-0.1.4.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-02 08:59 netspresso-0.1.4.dist-info/WHEEL
--rw-r--r--  2.0 unx       11 b- defN 23-Jun-02 08:59 netspresso-0.1.4.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2142 b- defN 23-Jun-02 08:59 netspresso-0.1.4.dist-info/RECORD
-23 files, 60912 bytes uncompressed, 14583 bytes compressed:  76.1%
+Zip file size: 18944 bytes, number of entries: 23
+-rw-rw-rw-  2.0 fat       23 b- defN 23-Jun-07 04:15 netspresso/__init__.py
+-rw-rw-rw-  2.0 fat    22980 b- defN 23-Jun-07 07:58 netspresso/compressor/__init__.py
+-rw-rw-rw-  2.0 fat     8456 b- defN 23-Jun-05 06:16 netspresso/compressor/client/__init__.py
+-rw-rw-rw-  2.0 fat      536 b- defN 23-Jun-05 04:34 netspresso/compressor/client/config.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-05 02:41 netspresso/compressor/client/schemas/__init__.py
+-rw-rw-rw-  2.0 fat     2644 b- defN 23-Jun-05 02:41 netspresso/compressor/client/schemas/auth.py
+-rw-rw-rw-  2.0 fat      482 b- defN 23-Jun-05 02:41 netspresso/compressor/client/schemas/common.py
+-rw-rw-rw-  2.0 fat     4141 b- defN 23-Jun-05 02:41 netspresso/compressor/client/schemas/compression.py
+-rw-rw-rw-  2.0 fat     5581 b- defN 23-Jun-07 07:58 netspresso/compressor/client/schemas/model.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-05 02:41 netspresso/compressor/client/utils/__init__.py
+-rw-rw-rw-  2.0 fat      481 b- defN 23-Jun-05 02:41 netspresso/compressor/client/utils/common.py
+-rw-rw-rw-  2.0 fat      840 b- defN 23-Jun-07 07:58 netspresso/compressor/client/utils/enum.py
+-rw-rw-rw-  2.0 fat     3814 b- defN 23-Jun-05 02:41 netspresso/compressor/client/utils/validator.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-05 02:41 netspresso/compressor/core/__init__.py
+-rw-rw-rw-  2.0 fat      563 b- defN 23-Jun-05 02:41 netspresso/compressor/core/compression.py
+-rw-rw-rw-  2.0 fat      521 b- defN 23-Jun-05 02:41 netspresso/compressor/core/model.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-05 02:41 netspresso/compressor/utils/__init__.py
+-rw-rw-rw-  2.0 fat      236 b- defN 23-Jun-05 02:41 netspresso/compressor/utils/token.py
+-rw-rw-rw-  2.0 fat    11558 b- defN 23-Jun-07 15:08 netspresso-0.1.5.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat      872 b- defN 23-Jun-07 15:08 netspresso-0.1.5.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Jun-07 15:08 netspresso-0.1.5.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       11 b- defN 23-Jun-07 15:08 netspresso-0.1.5.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     2142 b- defN 23-Jun-07 15:08 netspresso-0.1.5.dist-info/RECORD
+23 files, 65973 bytes uncompressed, 15356 bytes compressed:  76.7%
```

## zipnote {}

```diff
@@ -48,23 +48,23 @@
 
 Filename: netspresso/compressor/utils/__init__.py
 Comment: 
 
 Filename: netspresso/compressor/utils/token.py
 Comment: 
 
-Filename: netspresso-0.1.4.dist-info/LICENSE
+Filename: netspresso-0.1.5.dist-info/LICENSE
 Comment: 
 
-Filename: netspresso-0.1.4.dist-info/METADATA
+Filename: netspresso-0.1.5.dist-info/METADATA
 Comment: 
 
-Filename: netspresso-0.1.4.dist-info/WHEEL
+Filename: netspresso-0.1.5.dist-info/WHEEL
 Comment: 
 
-Filename: netspresso-0.1.4.dist-info/top_level.txt
+Filename: netspresso-0.1.5.dist-info/top_level.txt
 Comment: 
 
-Filename: netspresso-0.1.4.dist-info/RECORD
+Filename: netspresso-0.1.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## netspresso/__init__.py

```diff
@@ -1 +1 @@
-__version__ = "0.1.4"
+__version__ = "0.1.5"
```

## netspresso/compressor/__init__.py

```diff
@@ -1,513 +1,563 @@
-from functools import wraps
-from typing import Any, Dict, List, Union
-
-from urllib import request
-from loguru import logger
-
-from netspresso.compressor.client import (
-    ModelCompressorAPIClient,
-    Task,
-    Framework,
-    CompressionMethod,
-    RecommendationMethod,
-)
-from netspresso.compressor.client.schemas.auth import LoginRequest, RefreshTokenRequest
-from netspresso.compressor.client.schemas.model import UploadModelRequest
-from netspresso.compressor.client.schemas.compression import (
-    AutoCompressionRequest,
-    CompressionRequest,
-    GetAvailableLayersRequest,
-    CreateCompressionRequest,
-    RecommendationRequest,
-)
-from netspresso.compressor.core.model import CompressedModel, Model
-from netspresso.compressor.core.compression import CompressionBase, CompressionInfo
-from netspresso.compressor.utils.token import check_jwt_exp
-
-
-class ModelCompressor:
-    def __init__(self, email: str, password: str):
-        """Initialize the Model Compressor.
-
-        Args:
-            email (str): The email address for a user account.
-            password (str): The password for a user account.
-        """
-        self.email = email
-        self.password = password
-        self.client = ModelCompressorAPIClient()
-        self.__login()
-
-    def __login(self) -> None:
-        try:
-            data = LoginRequest(username=self.email, password=self.password)
-            response = self.client.login(data)
-            self.access_token = response.access_token
-            self.refresh_token = response.refresh_token
-            logger.info("Login successful")
-
-        except Exception as e:
-            logger.error(f"Login failed. Error: {e}")
-            raise e
-
-    def validate_token(func) -> None:
-        @wraps(func)
-        def wrapper(self, *args, **kwargs):
-            if not check_jwt_exp(self.access_token):
-                self.__reissue_token()
-            return func(self, *args, **kwargs)
-
-        return wrapper
-
-    def __reissue_token(self) -> None:
-        try:
-            data = RefreshTokenRequest(access_token=self.access_token, refresh_token=self.refresh_token)
-            response = self.client.refresh_token(data)
-            self.access_token = response.access_token
-            self.refresh_token = response.refresh_token
-
-        except Exception as e:
-            raise e
-
-    @validate_token
-    def get_credit(self) -> int:
-        """Get the available NetsPresso credits.
-
-        Raises:
-            e: If an error occurs while getting credit information.
-
-        Returns:
-            int: The total amount of available NetsPresso credits.
-        """
-        try:
-            credit = self.client.get_credit(access_token=self.access_token)
-            logger.info(f"Get Credit successful. Credit: {credit.total}")
-
-            return credit.total
-
-        except Exception as e:
-            logger.error(f"Get Credit failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def upload_model(
-        self, model_name: str, task: Task, framework: Framework, file_path: str, input_shape: List = []
-    ) -> Model:
-        """Upload a model for compression.
-
-        Args:
-            model_name (str): The name of the model.
-            task (Task): The task of the model.
-            framework (Framework): The framework of the model.
-            file_path (str): The file path where the model is located.
-            input_shape (List[str], optional): Input shape of the model. Defaults to [].
-
-        Note:
-            * If the model's `input_shape` is **dynamic**, it must be provided as a required input.
-            * If the model's `input_shape` is **static**, it should be set to the same shape as the model's input tensor.
-
-        Raises:
-            e: If an error occurs while uploading the model.
-
-        Returns:
-            Model: Uploaded model object.
-        """
-        try:
-            logger.info("Uploading Model...")
-            data = UploadModelRequest(
-                model_name=model_name,
-                task=task.value,
-                framework=framework.value,
-                file_path=file_path,
-                input_layers=input_shape,
-            )
-            model_info = self.client.upload_model(data=data, access_token=self.access_token)
-            model = Model(model_info)
-            logger.info(f"Upload model successful. Model ID: {model.model_id}")
-
-            return model
-
-        except Exception as e:
-            logger.error(f"Upload model failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def get_models(self) -> List[Dict[str, Any]]:
-        """Get the list of uploaded & compressed models.
-
-        Raises:
-            e: If an error occurs while getting the model list.
-
-        Returns:
-            List[Dict[str, Any]]: The list of uploaded & compressed models.
-        """
-        try:
-            logger.info("Getting model list...")
-            models = []
-            parent_models = self.client.get_parent_models(is_simple=True, access_token=self.access_token)
-            uploaded_models = [
-                vars(Model(parent_model)) for parent_model in parent_models if parent_model.origin_from == "custom"
-            ]
-            for uploaded_model in uploaded_models:
-                children_models = self.client.get_children_models(
-                    model_id=uploaded_model["model_id"], access_token=self.access_token
-                )
-                uploaded_model["compressed_models"] = [
-                    vars(CompressedModel(children_model)) for children_model in children_models
-                ]
-                models.append(uploaded_model)
-            logger.info("Get model list successful.")
-
-            return models
-
-        except Exception as e:
-            logger.error(f"Get model list failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def get_uploaded_models(self) -> List[Dict[str, Any]]:
-        """Get the list of uploaded models.
-
-        Raises:
-            e: If an error occurs while getting the uploaded model list.
-
-        Returns:
-            List[Dict[str, Any]]: The list of uploaded models.
-        """
-        try:
-            logger.info("Getting uploaded model list...")
-            parent_models = self.client.get_parent_models(is_simple=True, access_token=self.access_token)
-            uploaded_models = [
-                vars(Model(parent_model)) for parent_model in parent_models if parent_model.origin_from == "custom"
-            ]
-            logger.info("Get uploaded model list successful.")
-
-            return uploaded_models
-
-        except Exception as e:
-            logger.error(f"Get uploaded model list failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def get_compressed_models(self, model_id: str) -> List[Dict[str, Any]]:
-        """Get the list of compressed models for a given model ID.
-
-        Args:
-            model_id (str): The ID of the model.
-
-        Raises:
-            e: If an error occurs while getting the compressed model list.
-
-        Returns:
-            List[Dict[str, Any]]: The list of compressed models for a given model ID.
-        """
-        try:
-            logger.info("Getting compressed model list...")
-            children_models = self.client.get_children_models(model_id=model_id, access_token=self.access_token)
-            compressed_models = [vars(CompressedModel(children_model)) for children_model in children_models]
-            logger.info("Get compressed model list successful.")
-
-            return compressed_models
-
-        except Exception as e:
-            logger.error(f"Get compressed model list failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def get_model(self, model_id: str) -> Union[Model, CompressedModel]:
-        """Get the model for a given model ID.
-
-        Args:
-            model_id (str): The ID of the model.
-
-        Raises:
-            e: If an error occurs while getting the model.
-
-        Returns:
-            Union[Model, CompressedModel]: The retrieved model. If the model is compressed,
-            `CompressedModel` will be returned. Otherwise, `Model` will be returned.
-        """
-        try:
-            logger.info("Getting model...")
-            model_info = self.client.get_model_info(model_id=model_id, access_token=self.access_token)
-            if model_info.status.is_compressed:
-                model = CompressedModel(model_info)
-            else:
-                model = Model(model_info)
-            logger.info("Get model successful.")
-
-            return model
-
-        except Exception as e:
-            logger.error(f"Get model failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def download_model(self, model_id: str, local_path: str) -> None:
-        """Download the model for a given model ID to the local path.
-
-        Args:
-            model_id (str): The ID of the model.
-            local_path (str): The local path to save the downloaded model.
-
-        Raises:
-            e: If an error occurs while downloading the model.
-        """
-        try:
-            logger.info("Downloading model...")
-            download_link = self.client.get_download_model_link(model_id=model_id, access_token=self.access_token)
-            request.urlretrieve(download_link.url, local_path)
-            logger.info(f"Download model successful. Local Path: {local_path}")
-
-        except Exception as e:
-            logger.error(f"Download model failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def delete_model(self, model_id: str, recursive: bool = False) -> None:
-        """Delete the model for a given model ID.
-
-        Args:
-            model_id (str): The ID of the model.
-            recursive (bool, optional): Whether to also delete the compressed model for that model. Defaults to False.
-
-        Raises:
-            e: If an error occurs while deleting the model.
-        """
-        try:
-            logger.info("Deleting model...")
-            children_models = self.client.get_children_models(model_id=model_id, access_token=self.access_token)
-            if len(children_models) != 0:
-                if not recursive:
-                    logger.warning(
-                        "Deleting the model will also delete its compressed models. To proceed with the deletion, set the `recursive` parameter to True."
-                    )
-                else:
-                    logger.info("The compressed model for that model will also be deleted.")
-                    self.client.delete_model(model_id=model_id, access_token=self.access_token)
-                    logger.info("Delete model successful.")
-            else:
-                logger.info("The model will be deleted.")
-                self.client.delete_model(model_id=model_id, access_token=self.access_token)
-                logger.info("Delete model successful.")
-
-        except Exception as e:
-            logger.error(f"Delete model failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def select_compression_method(self, model_id: str, compression_method: CompressionMethod) -> CompressionBase:
-        """Select a compression method for a model.
-
-        Args:
-            model_id (str): The ID of the model.
-            compression_method (CompressionMethod): The selected compression method.
-
-        Raises:
-            e: If an error occurs while selecting the compression method.
-
-        Returns:
-            CompressionBase: The compression information for the selected compression method.
-        """
-        try:
-            logger.info("Selecting compression method...")
-            data = GetAvailableLayersRequest(model_id=model_id, compression_method=compression_method.value)
-            response = self.client.get_available_layers(data=data, access_token=self.access_token)
-            compression_info = CompressionBase(compression_method.value, response.available_layers, model_id)
-            logger.info("Select compression method successful.")
-
-            return compression_info
-
-        except Exception as e:
-            logger.error(f"Select compression method failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def get_compression(self, compression_id: str) -> CompressionInfo:
-        """Get information about a compression.
-
-        Args:
-            compression_id (str): The ID of the compression.
-
-        Raises:
-            e: If an error occurs while getting the compression information.
-
-        Returns:
-            CompressionInfo: The information about the compression.
-        """
-        try:
-            logger.info("Getting compression...")
-            compression_info = CompressionInfo(
-                self.client.get_compression_info(compression_id=compression_id, access_token=self.access_token)
-            )
-            logger.info("Get compression successful.")
-
-            return compression_info
-
-        except Exception as e:
-            logger.error(f"Get compression failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def compress_model(self, compression: CompressionInfo, model_name: str, output_path: str) -> CompressedModel:
-        """Compress a model using the provided compression information.
-
-        Args:
-            compression (CompressionInfo): The information about the compression.
-            model_name (str): The name of the compressed model.
-            output_path (str): The local path to save the compressed model.
-
-        Raises:
-            e: If an error occurs while compressing the model.
-
-        Returns:
-            CompressedModel: The compressed model.
-        """
-        try:
-            logger.info("Compressing model...")
-            data = CreateCompressionRequest(
-                model_id=compression.model_id,
-                model_name=model_name,
-                compression_method=compression.compression_method,
-            )
-            compression_info = self.client.create_compression(data=data, access_token=self.access_token)
-
-            for available_layers in compression.available_layers:
-                if available_layers.values != [""]:
-                    available_layers.use = True
-
-            data = CompressionRequest(
-                compression_id=compression_info.compression_id,
-                compression_method=compression.compression_method,
-                layers=compression.available_layers,
-                compressed_model_id=compression_info.new_model_id,
-            )
-            self.client.compress_model(data=data, access_token=self.access_token)
-            self.download_model(model_id=compression_info.new_model_id, local_path=output_path)
-            compressed_model = self.get_model(model_id=compression_info.new_model_id)
-            logger.info(f"Compress model successful. Compressed Model ID: {compressed_model.model_id}")
-            logger.info("50 credits have been consumed.")
-
-            return compressed_model
-
-        except Exception as e:
-            logger.error(f"Compress model failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def recommendation_compression(
-        self,
-        model_id: str,
-        model_name: str,
-        compression_method: CompressionMethod,
-        recommendation_method: RecommendationMethod,
-        recommendation_ratio: float,
-        output_path: str,
-    ) -> CompressedModel:
-        """Compress a recommendation-based model using the given compression and recommendation methods.
-
-        Args:
-            model_id (str): The ID of the model.
-            model_name (str): The name of the compressed model.
-            compression_method (CompressionMethod): The selected compression method.
-            recommendation_method (RecommendationMethod): The selected recommendation method.
-            recommendation_ratio (float): The compression ratio recommended by the recommendation method.
-            output_path (str): The local path to save the compressed model.
-        
-        Note:
-            - recommendation_method
-                - If you selected PR_L2, PR_GM, PR_NN for compression_method
-                    - The recommended_method available is **SLAMP**.
-                - If you selected FD_TK, FD_SVD for compression_method
-                    - The recommended_method available is **VBMF**.
-            - recommendation_ratio:
-                - SLAMP: 0 < ratio <= 1
-                - VBMF: -1 <= ratio <= 1
-
-        Raises:
-            e: If an error occurs while performing recommendation compression.
-
-        Returns:
-            CompressedModel: The compressed model.
-        """
-        try:
-            logger.info("Compressing recommendation-based model...")
-            data = CreateCompressionRequest(
-                model_id=model_id,
-                model_name=model_name,
-                compression_method=compression_method.value,
-            )
-            compression_info = self.client.create_compression(data=data, access_token=self.access_token)
-
-            data = RecommendationRequest(
-                model_id=model_id,
-                compression_id=compression_info.compression_id,
-                recommendation_method=recommendation_method.value,
-                recommendation_ratio=recommendation_ratio,
-            )
-            recommendation_result = self.client.get_recommendation(data=data, access_token=self.access_token)
-
-            for available_layer, recommended_info in zip(
-                compression_info.available_layers, recommendation_result.recommended_layers
-            ):
-                available_layer.use = True
-                available_layer.values = recommended_info.values
-
-            data = CompressionRequest(
-                compression_id=compression_info.compression_id,
-                compression_method=compression_method.value,
-                layers=compression_info.available_layers,
-                compressed_model_id=compression_info.new_model_id,
-            )
-            self.client.compress_model(data=data, access_token=self.access_token)
-            self.download_model(model_id=compression_info.new_model_id, local_path=output_path)
-            compressed_model = self.get_model(model_id=compression_info.new_model_id)
-            logger.info(f"Recommendation compression successful. Compressed Model ID: {compressed_model.model_id}")
-            logger.info("50 credits have been consumed.")
-
-            return compressed_model
-
-        except Exception as e:
-            logger.error(f"Recommendation compression failed. Error: {e}")
-            raise e
-
-    @validate_token
-    def automatic_compression(
-        self, model_id: str, model_name: str, output_path: str, compression_ratio: float = 0.5
-    ) -> CompressedModel:
-        """Compress a model automatically based on the given compression ratio.
-
-        Args:
-            model_id (str): The ID of the model.
-            model_name (str): The name of the compressed model.
-            output_path (str): The local path to save the compressed model.
-            compression_ratio (float): The compression ratio for automatic compression. Defaults to 0.5.
-        
-        Note:
-            - compression_ratio: 0 < ratio <= 1
-
-        Raises:
-            e: If an error occurs while performing automatic compression.
-
-        Returns:
-            CompressedModel: The compressed model.
-        """
-        try:
-            logger.info("Compressing automatic-based model...")
-            data = AutoCompressionRequest(
-                model_id=model_id,
-                model_name=model_name,
-                recommendation_ratio=compression_ratio,
-                save_path=output_path,
-            )
-            model_info = self.client.auto_compression(data=data, access_token=self.access_token)
-            self.download_model(model_id=model_info.model_id, local_path=output_path)
-            compressed_model = CompressedModel(model_info)
-            logger.info(f"Automatic compression successful. Compressed Model ID: {compressed_model.model_id}")
-            logger.info("25 credits have been consumed.")
-
-            return compressed_model
-
-        except Exception as e:
-            logger.error(f"Automatic compression failed. Error: {e}")
-            raise e
+from functools import wraps
+from typing import Any, Dict, List, Union
+
+from urllib import request
+from loguru import logger
+
+from netspresso.compressor.client import (
+    ModelCompressorAPIClient,
+    Task,
+    Framework,
+    CompressionMethod,
+    RecommendationMethod,
+)
+from netspresso.compressor.client.schemas.auth import LoginRequest, RefreshTokenRequest
+from netspresso.compressor.client.schemas.model import UploadModelRequest
+from netspresso.compressor.client.schemas.compression import (
+    AutoCompressionRequest,
+    CompressionRequest,
+    GetAvailableLayersRequest,
+    CreateCompressionRequest,
+    RecommendationRequest,
+    UploadDatasetRequest,
+)
+from netspresso.compressor.core.model import CompressedModel, Model
+from netspresso.compressor.core.compression import CompressionBase, CompressionInfo
+from netspresso.compressor.utils.token import check_jwt_exp
+
+
+class ModelCompressor:
+    def __init__(self, email: str, password: str):
+        """Initialize the Model Compressor.
+
+        Args:
+            email (str): The email address for a user account.
+            password (str): The password for a user account.
+        """
+        self.email = email
+        self.password = password
+        self.client = ModelCompressorAPIClient()
+        self.__login()
+
+    def __login(self) -> None:
+        try:
+            data = LoginRequest(username=self.email, password=self.password)
+            response = self.client.login(data)
+            self.access_token = response.access_token
+            self.refresh_token = response.refresh_token
+            logger.info("Login successful")
+
+        except Exception as e:
+            logger.error(f"Login failed. Error: {e}")
+            raise e
+
+    def validate_token(func) -> None:
+        @wraps(func)
+        def wrapper(self, *args, **kwargs):
+            if not check_jwt_exp(self.access_token):
+                self.__reissue_token()
+            return func(self, *args, **kwargs)
+
+        return wrapper
+
+    def __reissue_token(self) -> None:
+        try:
+            data = RefreshTokenRequest(access_token=self.access_token, refresh_token=self.refresh_token)
+            response = self.client.refresh_token(data)
+            self.access_token = response.access_token
+            self.refresh_token = response.refresh_token
+
+        except Exception as e:
+            raise e
+
+    @validate_token
+    def get_credit(self) -> int:
+        """Get the available NetsPresso credits.
+
+        Raises:
+            e: If an error occurs while getting credit information.
+
+        Returns:
+            int: The total amount of available NetsPresso credits.
+        """
+        try:
+            credit = self.client.get_credit(access_token=self.access_token)
+            logger.info(f"Get Credit successful. Credit: {credit.total}")
+
+            return credit.total
+
+        except Exception as e:
+            logger.error(f"Get Credit failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def upload_model(
+        self, model_name: str, task: Task, framework: Framework, file_path: str, input_shape: List = []
+    ) -> Model:
+        """Upload a model for compression.
+
+        Args:
+            model_name (str): The name of the model.
+            task (Task): The task of the model.
+            framework (Framework): The framework of the model.
+            file_path (str): The file path where the model is located.
+            input_shape (List[str], optional): Input shape of the model. Defaults to [].
+
+        Note:
+            * If the model's `input_shape` is **dynamic**, it must be provided as a required input.
+            * If the model's `input_shape` is **static**, it should be set to the same shape as the model's input tensor.
+
+        Raises:
+            e: If an error occurs while uploading the model.
+
+        Returns:
+            Model: Uploaded model object.
+        """
+        try:
+            logger.info("Uploading Model...")
+            data = UploadModelRequest(
+                model_name=model_name,
+                task=task.value,
+                framework=framework.value,
+                file_path=file_path,
+                input_layers=input_shape,
+            )
+            model_info = self.client.upload_model(data=data, access_token=self.access_token)
+            model = Model(model_info)
+            logger.info(f"Upload model successful. Model ID: {model.model_id}")
+
+            return model
+
+        except Exception as e:
+            logger.error(f"Upload model failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def get_models(self) -> List[Dict[str, Any]]:
+        """Get the list of uploaded & compressed models.
+
+        Raises:
+            e: If an error occurs while getting the model list.
+
+        Returns:
+            List[Dict[str, Any]]: The list of uploaded & compressed models.
+        """
+        try:
+            logger.info("Getting model list...")
+            models = []
+            parent_models = self.client.get_parent_models(is_simple=True, access_token=self.access_token)
+            uploaded_models = [
+                vars(Model(parent_model)) for parent_model in parent_models if parent_model.origin_from == "custom"
+            ]
+            for uploaded_model in uploaded_models:
+                children_models = self.client.get_children_models(
+                    model_id=uploaded_model["model_id"], access_token=self.access_token
+                )
+                uploaded_model["compressed_models"] = [
+                    vars(CompressedModel(children_model)) for children_model in children_models
+                ]
+                models.append(uploaded_model)
+            logger.info("Get model list successful.")
+
+            return models
+
+        except Exception as e:
+            logger.error(f"Get model list failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def get_uploaded_models(self) -> List[Dict[str, Any]]:
+        """Get the list of uploaded models.
+
+        Raises:
+            e: If an error occurs while getting the uploaded model list.
+
+        Returns:
+            List[Dict[str, Any]]: The list of uploaded models.
+        """
+        try:
+            logger.info("Getting uploaded model list...")
+            parent_models = self.client.get_parent_models(is_simple=True, access_token=self.access_token)
+            uploaded_models = [
+                vars(Model(parent_model)) for parent_model in parent_models if parent_model.origin_from == "custom"
+            ]
+            logger.info("Get uploaded model list successful.")
+
+            return uploaded_models
+
+        except Exception as e:
+            logger.error(f"Get uploaded model list failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def get_compressed_models(self, model_id: str) -> List[Dict[str, Any]]:
+        """Get the list of compressed models for a given model ID.
+
+        Args:
+            model_id (str): The ID of the model.
+
+        Raises:
+            e: If an error occurs while getting the compressed model list.
+
+        Returns:
+            List[Dict[str, Any]]: The list of compressed models for a given model ID.
+        """
+        try:
+            logger.info("Getting compressed model list...")
+            children_models = self.client.get_children_models(model_id=model_id, access_token=self.access_token)
+            compressed_models = [vars(CompressedModel(children_model)) for children_model in children_models]
+            logger.info("Get compressed model list successful.")
+
+            return compressed_models
+
+        except Exception as e:
+            logger.error(f"Get compressed model list failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def get_model(self, model_id: str) -> Union[Model, CompressedModel]:
+        """Get the model for a given model ID.
+
+        Args:
+            model_id (str): The ID of the model.
+
+        Raises:
+            e: If an error occurs while getting the model.
+
+        Returns:
+            Union[Model, CompressedModel]: The retrieved model. If the model is compressed,
+            `CompressedModel` will be returned. Otherwise, `Model` will be returned.
+        """
+        try:
+            logger.info("Getting model...")
+            model_info = self.client.get_model_info(model_id=model_id, access_token=self.access_token)
+            if model_info.status.is_compressed:
+                model = CompressedModel(model_info)
+            else:
+                model = Model(model_info)
+            logger.info("Get model successful.")
+
+            return model
+
+        except Exception as e:
+            logger.error(f"Get model failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def download_model(self, model_id: str, local_path: str) -> None:
+        """Download the model for a given model ID to the local path.
+
+        Args:
+            model_id (str): The ID of the model.
+            local_path (str): The local path to save the downloaded model.
+
+        Raises:
+            e: If an error occurs while downloading the model.
+        """
+        try:
+            logger.info("Downloading model...")
+            download_link = self.client.get_download_model_link(model_id=model_id, access_token=self.access_token)
+            request.urlretrieve(download_link.url, local_path)
+            logger.info(f"Download model successful. Local Path: {local_path}")
+
+        except Exception as e:
+            logger.error(f"Download model failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def delete_model(self, model_id: str, recursive: bool = False) -> None:
+        """Delete the model for a given model ID.
+
+        Args:
+            model_id (str): The ID of the model.
+            recursive (bool, optional): Whether to also delete the compressed model for that model. Defaults to False.
+
+        Raises:
+            e: If an error occurs while deleting the model.
+        """
+        try:
+            logger.info("Deleting model...")
+            children_models = self.client.get_children_models(model_id=model_id, access_token=self.access_token)
+            if len(children_models) != 0:
+                if not recursive:
+                    logger.warning(
+                        "Deleting the model will also delete its compressed models. To proceed with the deletion, set the `recursive` parameter to True."
+                    )
+                else:
+                    logger.info("The compressed model for that model will also be deleted.")
+                    self.client.delete_model(model_id=model_id, access_token=self.access_token)
+                    logger.info("Delete model successful.")
+            else:
+                logger.info("The model will be deleted.")
+                self.client.delete_model(model_id=model_id, access_token=self.access_token)
+                logger.info("Delete model successful.")
+
+        except Exception as e:
+            logger.error(f"Delete model failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def select_compression_method(self, model_id: str, compression_method: CompressionMethod) -> CompressionBase:
+        """Select a compression method for a model.
+
+        Args:
+            model_id (str): The ID of the model.
+            compression_method (CompressionMethod): The selected compression method.
+
+        Raises:
+            e: If an error occurs while selecting the compression method.
+
+        Returns:
+            CompressionBase: The compression information for the selected compression method.
+        """
+        try:
+            logger.info("Selecting compression method...")
+            data = GetAvailableLayersRequest(model_id=model_id, compression_method=compression_method.value)
+            response = self.client.get_available_layers(data=data, access_token=self.access_token)
+            compression_info = CompressionBase(compression_method.value, response.available_layers, model_id)
+            logger.info("Select compression method successful.")
+
+            return compression_info
+
+        except Exception as e:
+            logger.error(f"Select compression method failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def get_compression(self, compression_id: str) -> CompressionInfo:
+        """Get information about a compression.
+
+        Args:
+            compression_id (str): The ID of the compression.
+
+        Raises:
+            e: If an error occurs while getting the compression information.
+
+        Returns:
+            CompressionInfo: The information about the compression.
+        """
+        try:
+            logger.info("Getting compression...")
+            compression_info = CompressionInfo(
+                self.client.get_compression_info(compression_id=compression_id, access_token=self.access_token)
+            )
+            logger.info("Get compression successful.")
+
+            return compression_info
+
+        except Exception as e:
+            logger.error(f"Get compression failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def __upload_dataset(self, model_id: str, dataset_path: str) -> None:
+        """Upload a dataset for nuclear norm compression method.
+
+        Args:
+            model_id (str): The ID of the model.
+            dataset_path (str): The file path where the dataset is located.
+
+        Raises:
+            e: If an error occurs while uploading the dataset.
+        """
+        try:
+            logger.info(f"Uploading dataset...")
+            data = UploadDatasetRequest(model_id=model_id, file_path=dataset_path)
+            self.client.upload_dataset(data=data, access_token=self.access_token)
+            logger.info(f"Upload dataset successful.")
+
+        except Exception as e:
+            logger.error(f"Upload dataset failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def compress_model(
+        self, compression: CompressionInfo, model_name: str, output_path: str, dataset_path: str = None
+    ) -> CompressedModel:
+        """Compress a model using the provided compression information.
+
+        Args:
+            compression (CompressionInfo): The information about the compression.
+            model_name (str): The name of the compressed model.
+            output_path (str): The local path to save the compressed model.
+            dataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.
+
+        Raises:
+            e: If an error occurs while compressing the model.
+
+        Returns:
+            CompressedModel: The compressed model.
+        """
+        try:
+            logger.info("Compressing model...")
+            data = CreateCompressionRequest(
+                model_id=compression.model_id,
+                model_name=model_name,
+                compression_method=compression.compression_method,
+            )
+            compression_info = self.client.create_compression(data=data, access_token=self.access_token)
+
+            if dataset_path and compression.compression_method == CompressionMethod.PR_NN.value:
+                self.__upload_dataset(model_id=compression.model_id, dataset_path=dataset_path)
+
+            for available_layers in compression.available_layers:
+                if available_layers.values != [""]:
+                    available_layers.use = True
+
+            data = CompressionRequest(
+                compression_id=compression_info.compression_id,
+                compression_method=compression.compression_method,
+                layers=compression.available_layers,
+                compressed_model_id=compression_info.new_model_id,
+            )
+            self.client.compress_model(data=data, access_token=self.access_token)
+            self.download_model(model_id=compression_info.new_model_id, local_path=output_path)
+            compressed_model = self.get_model(model_id=compression_info.new_model_id)
+            logger.info(f"Compress model successful. Compressed Model ID: {compressed_model.model_id}")
+            logger.info("50 credits have been consumed.")
+
+            return compressed_model
+
+        except Exception as e:
+            logger.error(f"Compress model failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def recommendation_compression(
+        self,
+        model_id: str,
+        model_name: str,
+        compression_method: CompressionMethod,
+        recommendation_method: RecommendationMethod,
+        recommendation_ratio: float,
+        output_path: str,
+        dataset_path: str = None,
+    ) -> CompressedModel:
+        """Compress a recommendation-based model using the given compression and recommendation methods.
+
+        Args:
+            model_id (str): The ID of the model.
+            model_name (str): The name of the compressed model.
+            compression_method (CompressionMethod): The selected compression method.
+            recommendation_method (RecommendationMethod): The selected recommendation method.
+            recommendation_ratio (float): The compression ratio recommended by the recommendation method.
+            output_path (str): The local path to save the compressed model.
+            dataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.
+
+        Note:
+            - recommendation_method
+                - If you selected PR_L2, PR_GM, PR_NN for compression_method
+                    - The recommended_method available is **SLAMP**.
+                - If you selected FD_TK, FD_SVD for compression_method
+                    - The recommended_method available is **VBMF**.
+            - recommendation_ratio:
+                - SLAMP: 0 < ratio <= 1
+                - VBMF: -1 <= ratio <= 1
+
+        Raises:
+            e: If an error occurs while performing recommendation compression.
+
+        Returns:
+            CompressedModel: The compressed model.
+        """
+        try:
+            logger.info("Compressing recommendation-based model...")
+
+            if (
+                compression_method in [CompressionMethod.PR_L2, CompressionMethod.PR_GM, CompressionMethod.PR_NN]
+                and recommendation_method != RecommendationMethod.SLAMP
+            ):
+                raise Exception(
+                    f"The {compression_method.value} compression method is only available the SLAMP recommendation method."
+                )
+
+            if (
+                compression_method in [CompressionMethod.FD_TK, CompressionMethod.FD_SVD]
+                and recommendation_method != RecommendationMethod.VBMF
+            ):
+                raise Exception(
+                    f"The {compression_method.value} compression method is only available the VBMF recommendation method."
+                )
+
+            data = CreateCompressionRequest(
+                model_id=model_id,
+                model_name=model_name,
+                compression_method=compression_method.value,
+            )
+            compression_info = self.client.create_compression(data=data, access_token=self.access_token)
+
+            if dataset_path and compression_method == CompressionMethod.PR_NN:
+                self.__upload_dataset(model_id=model_id, dataset_path=dataset_path)
+
+            data = RecommendationRequest(
+                model_id=model_id,
+                compression_id=compression_info.compression_id,
+                recommendation_method=recommendation_method.value,
+                recommendation_ratio=recommendation_ratio,
+            )
+            recommendation_result = self.client.get_recommendation(data=data, access_token=self.access_token)
+
+            for available_layer, recommended_info in zip(
+                compression_info.available_layers, recommendation_result.recommended_layers
+            ):
+                available_layer.use = True
+                available_layer.values = recommended_info.values
+
+            data = CompressionRequest(
+                compression_id=compression_info.compression_id,
+                compression_method=compression_method.value,
+                layers=compression_info.available_layers,
+                compressed_model_id=compression_info.new_model_id,
+            )
+            self.client.compress_model(data=data, access_token=self.access_token)
+            self.download_model(model_id=compression_info.new_model_id, local_path=output_path)
+            compressed_model = self.get_model(model_id=compression_info.new_model_id)
+            logger.info(f"Recommendation compression successful. Compressed Model ID: {compressed_model.model_id}")
+            logger.info("50 credits have been consumed.")
+
+            return compressed_model
+
+        except Exception as e:
+            logger.error(f"Recommendation compression failed. Error: {e}")
+            raise e
+
+    @validate_token
+    def automatic_compression(
+        self, model_id: str, model_name: str, output_path: str, compression_ratio: float = 0.5
+    ) -> CompressedModel:
+        """Compress a model automatically based on the given compression ratio.
+
+        Args:
+            model_id (str): The ID of the model.
+            model_name (str): The name of the compressed model.
+            output_path (str): The local path to save the compressed model.
+            compression_ratio (float): The compression ratio for automatic compression. Defaults to 0.5.
+
+        Note:
+            - compression_ratio: 0 < ratio <= 1
+
+        Raises:
+            e: If an error occurs while performing automatic compression.
+
+        Returns:
+            CompressedModel: The compressed model.
+        """
+        try:
+            logger.info("Compressing automatic-based model...")
+            data = AutoCompressionRequest(
+                model_id=model_id,
+                model_name=model_name,
+                recommendation_ratio=compression_ratio,
+                save_path=output_path,
+            )
+            model_info = self.client.auto_compression(data=data, access_token=self.access_token)
+            self.download_model(model_id=model_info.model_id, local_path=output_path)
+            compressed_model = CompressedModel(model_info)
+            logger.info(f"Automatic compression successful. Compressed Model ID: {compressed_model.model_id}")
+            logger.info("25 credits have been consumed.")
+
+            return compressed_model
+
+        except Exception as e:
+            logger.error(f"Automatic compression failed. Error: {e}")
+            raise e
```

## netspresso/compressor/client/__init__.py

```diff
@@ -1,198 +1,202 @@
-import json
-import requests
-
-from netspresso.compressor.client.schemas.auth import (
-    CreditResponse,
-    LoginResponse,
-    UserRespone,
-    RefreshTokenResponse,
-)
-from netspresso.compressor.client.schemas.compression import CompressionResponse, GetAvailableLayersReponse, RecommendationResponse
-from netspresso.compressor.client.schemas.model import UploadModelRequest, ModelResponse, GetDownloadLinkResponse
-from netspresso.compressor.client.utils.common import get_files, get_headers
-from netspresso.compressor.client.utils.enum import Task, Framework, CompressionMethod, RecommendationMethod  # noqa
-from netspresso.compressor.client.config import Config
-
-
-class ModelCompressorAPIClient:
-    def __init__(self):
-        self.config = Config()
-        self.ip = self.config.IP
-        self.port = self.config.PORT
-        self.prefix = self.config.API_PREFIX
-        self.url = f"{self.ip}:{self.port}{self.prefix}"
-
-    def login(self, data) -> LoginResponse:
-        url = f"{self.url}/login"
-        response = requests.post(url, data=data.dict())
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200 or response.status_code == 201:
-            return LoginResponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def refresh_token(self, data) -> RefreshTokenResponse:
-        url = f"{self.url}/token"
-        response = requests.post(url, data=data.json(), headers=get_headers(json_type=True))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200 or response.status_code == 201:
-            return RefreshTokenResponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def get_credit(self, access_token) -> CreditResponse:
-        url = f"{self.url}/credit"
-        response = requests.get(url, headers=get_headers(access_token))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200 or response.status_code == 201:
-            return CreditResponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def get_user(self, access_token) -> UserRespone:
-        url = f"{self.url}/user"
-        response = requests.get(url, headers=get_headers(access_token))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200 or response.status_code == 201:
-            return UserRespone(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def upload_model(self, data: UploadModelRequest, access_token) -> ModelResponse:
-        url = f"{self.url}/models"
-        files = get_files(data.file_path)
-        response = requests.post(url, data=data.dict(), files=files, headers=get_headers(access_token))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return ModelResponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def get_parent_models(self, is_simple, access_token):
-        url = f"{self.url}/models/parents?is_simple={is_simple}"
-        response = requests.get(url, headers=get_headers(access_token))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return [ModelResponse(**r) for r in response_body]
-        else:
-            raise Exception(response_body["detail"])
-
-    def get_children_models(self, model_id, access_token):
-        url = f"{self.url}/models/{model_id}/children"
-        response = requests.get(url, headers=get_headers(access_token))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return [ModelResponse(**r) for r in response_body]
-        else:
-            raise Exception(response_body["detail"])
-
-    def get_model_info(self, model_id, access_token) -> ModelResponse:
-        url = f"{self.url}/models/{model_id}"
-        response = requests.get(url, headers=get_headers(access_token))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return ModelResponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def get_download_model_link(self, model_id, access_token) -> GetDownloadLinkResponse:
-        url = f"{self.url}/models/{model_id}/download"
-        response = requests.post(url, headers=get_headers(access_token))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return GetDownloadLinkResponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def delete_model(self, model_id, access_token):
-        url = f"{self.url}/models/{model_id}"
-        response = requests.delete(url, headers=get_headers(access_token))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return response_body
-        else:
-            raise Exception(response_body["detail"])
-
-    def get_available_layers(self, data, access_token) -> GetAvailableLayersReponse:
-        url = f"{self.url}/models/{data.model_id}/get_available_layers"
-        response = requests.post(url, data=data.json(), headers=get_headers(access_token, json_type=True))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return GetAvailableLayersReponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def create_compression(self, data, access_token) -> CompressionResponse:
-        url = f"{self.url}/compressions"
-        response = requests.post(url, data=data.json(), headers=get_headers(access_token, json_type=True))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return CompressionResponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def get_recommendation(self, data, access_token) -> RecommendationResponse:
-        url = f"{self.url}/models/{data.model_id}/recommendation"
-        response = requests.post(url, data=data.json(), headers=get_headers(access_token, json_type=True))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            response_body = {"recommended_layers": response_body}
-            return RecommendationResponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def compress_model(self, data, access_token):
-        url = f"{self.url}/compressions/{data.compression_id}"
-        response = requests.put(url, data=data.json(), headers=get_headers(access_token, json_type=True))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return CompressionResponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def auto_compression(self, data, access_token):
-        url = f"{self.url}/models/{data.model_id}/auto_compress"
-        response = requests.post(url, data=data.json(), headers=get_headers(access_token, json_type=True))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            response = ModelResponse(**response_body)
-            return response
-        else:
-            raise Exception(response_body["detail"])
-
-    def get_compression_info(self, compression_id, access_token):
-        url = f"{self.url}/compressions/{compression_id}"
-
-        response = requests.get(url, headers=get_headers(access_token))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return CompressionResponse(**response_body)
-        else:
-            raise Exception(response_body["detail"])
-
-    def upload_dataset(self, data, access_token):
-        url = f"{self.url}/models/{data.model_id}/datasets"
-        files = get_files(data.file_path)
-        response = requests.post(url, files=files, headers=get_headers(access_token))
-        response_body = json.loads(response.text)
-
-        if response.status_code == 200:
-            return response_body
-        else:
-            raise Exception(response_body["detail"])
+import json
+import requests
+
+from netspresso.compressor.client.schemas.auth import (
+    CreditResponse,
+    LoginResponse,
+    UserRespone,
+    RefreshTokenResponse,
+)
+from netspresso.compressor.client.schemas.compression import (
+    CompressionResponse,
+    GetAvailableLayersReponse,
+    RecommendationResponse,
+)
+from netspresso.compressor.client.schemas.model import UploadModelRequest, ModelResponse, GetDownloadLinkResponse
+from netspresso.compressor.client.utils.common import get_files, get_headers
+from netspresso.compressor.client.utils.enum import Task, Framework, CompressionMethod, RecommendationMethod  # noqa
+from netspresso.compressor.client.config import Config
+
+
+class ModelCompressorAPIClient:
+    def __init__(self):
+        self.config = Config()
+        self.ip = self.config.IP
+        self.port = self.config.PORT
+        self.prefix = self.config.API_PREFIX
+        self.url = f"{self.ip}:{self.port}{self.prefix}"
+
+    def login(self, data) -> LoginResponse:
+        url = f"{self.url}/login"
+        response = requests.post(url, data=data.dict())
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200 or response.status_code == 201:
+            return LoginResponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def refresh_token(self, data) -> RefreshTokenResponse:
+        url = f"{self.url}/token"
+        response = requests.post(url, data=data.json(), headers=get_headers(json_type=True))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200 or response.status_code == 201:
+            return RefreshTokenResponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def get_credit(self, access_token) -> CreditResponse:
+        url = f"{self.url}/credit"
+        response = requests.get(url, headers=get_headers(access_token))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200 or response.status_code == 201:
+            return CreditResponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def get_user(self, access_token) -> UserRespone:
+        url = f"{self.url}/user"
+        response = requests.get(url, headers=get_headers(access_token))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200 or response.status_code == 201:
+            return UserRespone(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def upload_model(self, data: UploadModelRequest, access_token) -> ModelResponse:
+        url = f"{self.url}/models"
+        files = get_files(data.file_path)
+        response = requests.post(url, data=data.dict(), files=files, headers=get_headers(access_token))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return ModelResponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def get_parent_models(self, is_simple, access_token):
+        url = f"{self.url}/models/parents?is_simple={is_simple}"
+        response = requests.get(url, headers=get_headers(access_token))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return [ModelResponse(**r) for r in response_body]
+        else:
+            raise Exception(response_body["detail"])
+
+    def get_children_models(self, model_id, access_token):
+        url = f"{self.url}/models/{model_id}/children"
+        response = requests.get(url, headers=get_headers(access_token))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return [ModelResponse(**r) for r in response_body]
+        else:
+            raise Exception(response_body["detail"])
+
+    def get_model_info(self, model_id, access_token) -> ModelResponse:
+        url = f"{self.url}/models/{model_id}"
+        response = requests.get(url, headers=get_headers(access_token))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return ModelResponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def get_download_model_link(self, model_id, access_token) -> GetDownloadLinkResponse:
+        url = f"{self.url}/models/{model_id}/download"
+        response = requests.post(url, headers=get_headers(access_token))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return GetDownloadLinkResponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def delete_model(self, model_id, access_token):
+        url = f"{self.url}/models/{model_id}"
+        response = requests.delete(url, headers=get_headers(access_token))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return response_body
+        else:
+            raise Exception(response_body["detail"])
+
+    def get_available_layers(self, data, access_token) -> GetAvailableLayersReponse:
+        url = f"{self.url}/models/{data.model_id}/get_available_layers"
+        response = requests.post(url, data=data.json(), headers=get_headers(access_token, json_type=True))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return GetAvailableLayersReponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def create_compression(self, data, access_token) -> CompressionResponse:
+        url = f"{self.url}/compressions"
+        response = requests.post(url, data=data.json(), headers=get_headers(access_token, json_type=True))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return CompressionResponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def get_recommendation(self, data, access_token) -> RecommendationResponse:
+        url = f"{self.url}/models/{data.model_id}/recommendation"
+        response = requests.post(url, data=data.json(), headers=get_headers(access_token, json_type=True))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            response_body = {"recommended_layers": response_body}
+            return RecommendationResponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def compress_model(self, data, access_token):
+        url = f"{self.url}/compressions/{data.compression_id}"
+        response = requests.put(url, data=data.json(), headers=get_headers(access_token, json_type=True))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return CompressionResponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def auto_compression(self, data, access_token):
+        url = f"{self.url}/models/{data.model_id}/auto_compress"
+        response = requests.post(url, data=data.json(), headers=get_headers(access_token, json_type=True))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            response = ModelResponse(**response_body)
+            return response
+        else:
+            raise Exception(response_body["detail"])
+
+    def get_compression_info(self, compression_id, access_token):
+        url = f"{self.url}/compressions/{compression_id}"
+
+        response = requests.get(url, headers=get_headers(access_token))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return CompressionResponse(**response_body)
+        else:
+            raise Exception(response_body["detail"])
+
+    def upload_dataset(self, data, access_token):
+        url = f"{self.url}/models/{data.model_id}/datasets"
+        files = get_files(data.file_path)
+        response = requests.post(url, files=files, headers=get_headers(access_token))
+        response_body = json.loads(response.text)
+
+        if response.status_code == 200:
+            return response_body
+        else:
+            raise Exception(response_body["detail"])
```

## netspresso/compressor/client/config.py

```diff
@@ -1,18 +1,18 @@
-import configparser
-import os
-from pathlib import Path
-
-from loguru import logger
-from pydantic import BaseSettings
-
-BASE_DIR = Path(__file__).resolve().parent
-config = configparser.ConfigParser()
-DEPLOYMENT_MODE = os.getenv("DEPLOYMENT_MODE", "PROD")
-logger.info(f"Read {DEPLOYMENT_MODE} config")
-config.read(f"{BASE_DIR}/configs/config-{DEPLOYMENT_MODE.lower()}.ini")
-
-
-class Config(BaseSettings):
-    API_PREFIX: str = "/api/v2"
-    IP: str = config["GENERAL"]["IP"]
-    PORT: int = int(config["GENERAL"]["PORT"])
+import configparser
+import os
+from pathlib import Path
+
+from loguru import logger
+from pydantic import BaseSettings
+
+BASE_DIR = Path(__file__).resolve().parent
+config = configparser.ConfigParser()
+DEPLOYMENT_MODE = os.getenv("DEPLOYMENT_MODE", "LOCAL")
+logger.info(f"Read {DEPLOYMENT_MODE} config")
+config.read(f"{BASE_DIR}/configs/config-{DEPLOYMENT_MODE.lower()}.ini")
+
+
+class Config(BaseSettings):
+    API_PREFIX: str = "/api/v2"
+    IP: str = config["GENERAL"]["IP"]
+    PORT: int = int(config["GENERAL"]["PORT"])
```

## netspresso/compressor/client/schemas/auth.py

 * *Ordering differences only*

```diff
@@ -1,60 +1,60 @@
-from uuid import UUID
-
-from pydantic import BaseModel, Field, EmailStr
-
-
-class LoginRequest(BaseModel):
-    username: str = Field(..., description="User Name")
-    password: str = Field(..., description="Password")
-
-
-class LoginResponse(BaseModel):
-    email: EmailStr = Field(..., description="Email")
-    username: str = Field(..., description="User Name")
-    user_id: UUID = Field(..., description="User ID")
-    access_token: str = Field(..., description="Access Token")
-    refresh_token: str = Field(..., description="Refresh Token")
-    # session_id: UUID = Field(..., description="Session ID")
-    # current_time: str = Field(..., description="Current Time")
-
-
-class RefreshTokenRequest(BaseModel):
-    access_token: str = Field(..., description="Access Token")
-    refresh_token: str = Field(..., description="Refresh Token")
-
-
-class RefreshTokenResponse(BaseModel):
-    access_token: str = Field(..., description="Access Token")
-    refresh_token: str = Field(..., description="Refresh Token")
-
-
-class CreditResponse(BaseModel):
-    free: int = Field(..., description="Free Credit")
-    reward: int = Field(..., description="Reward Credit")
-    contract: int = Field(..., description="Contract Credit")
-    paid: int = Field(..., description="Paid Credit")
-    total: int = Field(..., description="Total Credit")
-
-
-class Authorities(BaseModel):
-    compressor: bool = Field(False, description="Compressor Authority")
-    searcher: bool = Field(False, description="Searcher Authority")
-    launcher: bool = Field(False, description="Launcher Authority")
-
-
-class UserRespone(BaseModel):
-    user_id: UUID = Field(..., description="User ID")
-    email: EmailStr = Field(..., description="Email")
-    username: str = Field(..., description="User Name")
-    first_name: str = Field(..., description="First Name")
-    last_name: str = Field(..., description="Last Name")
-    company: str = Field(..., description="Company")
-    # credit: int = Field(..., description="Credit")
-    # is_active: bool = Field(..., description="Active Status")
-    # is_admin: bool = Field(..., description="Admin Status")
-    # privacy_policy_agreement: bool = Field(..., description="Privacy Policy Agreement")
-    # marketing_agreement: bool = Field(..., description="Marketing Agreement")
-    # current_time: str = Field(..., description="Current Time")
-    # created_time: str = Field(..., description="Created Time")
-    # last_login_time: str = Field(..., description="Last Login Time")
-    # authorities: Authorities = Field(default_factory=Authorities, description="NP Module Authorities")
+from uuid import UUID
+
+from pydantic import BaseModel, Field, EmailStr
+
+
+class LoginRequest(BaseModel):
+    username: str = Field(..., description="User Name")
+    password: str = Field(..., description="Password")
+
+
+class LoginResponse(BaseModel):
+    email: EmailStr = Field(..., description="Email")
+    username: str = Field(..., description="User Name")
+    user_id: UUID = Field(..., description="User ID")
+    access_token: str = Field(..., description="Access Token")
+    refresh_token: str = Field(..., description="Refresh Token")
+    # session_id: UUID = Field(..., description="Session ID")
+    # current_time: str = Field(..., description="Current Time")
+
+
+class RefreshTokenRequest(BaseModel):
+    access_token: str = Field(..., description="Access Token")
+    refresh_token: str = Field(..., description="Refresh Token")
+
+
+class RefreshTokenResponse(BaseModel):
+    access_token: str = Field(..., description="Access Token")
+    refresh_token: str = Field(..., description="Refresh Token")
+
+
+class CreditResponse(BaseModel):
+    free: int = Field(..., description="Free Credit")
+    reward: int = Field(..., description="Reward Credit")
+    contract: int = Field(..., description="Contract Credit")
+    paid: int = Field(..., description="Paid Credit")
+    total: int = Field(..., description="Total Credit")
+
+
+class Authorities(BaseModel):
+    compressor: bool = Field(False, description="Compressor Authority")
+    searcher: bool = Field(False, description="Searcher Authority")
+    launcher: bool = Field(False, description="Launcher Authority")
+
+
+class UserRespone(BaseModel):
+    user_id: UUID = Field(..., description="User ID")
+    email: EmailStr = Field(..., description="Email")
+    username: str = Field(..., description="User Name")
+    first_name: str = Field(..., description="First Name")
+    last_name: str = Field(..., description="Last Name")
+    company: str = Field(..., description="Company")
+    # credit: int = Field(..., description="Credit")
+    # is_active: bool = Field(..., description="Active Status")
+    # is_admin: bool = Field(..., description="Admin Status")
+    # privacy_policy_agreement: bool = Field(..., description="Privacy Policy Agreement")
+    # marketing_agreement: bool = Field(..., description="Marketing Agreement")
+    # current_time: str = Field(..., description="Current Time")
+    # created_time: str = Field(..., description="Created Time")
+    # last_login_time: str = Field(..., description="Last Login Time")
+    # authorities: Authorities = Field(default_factory=Authorities, description="NP Module Authorities")
```

## netspresso/compressor/client/schemas/common.py

 * *Ordering differences only*

```diff
@@ -1,16 +1,16 @@
-from typing import Literal
-
-
-COMPRESSION_METHOD = Literal["PR_L2", "PR_GM", "PR_NN", "PR_ID", "FD_TK", "FD_CP", "FD_SVD"]
-RECOMMENDATION_METHOD = Literal["slamp", "vbmf"]
-TASK = Literal[
-    "image_classification",
-    "object_detection",
-    "image_segmentation",
-    "semantic_segmentation",
-    "instance_segmentation",
-    "panoptic_segmentation",
-    "other",
-]
-FRAMEWORK = Literal["tensorflow_keras", "onnx", "pytorch"]
-ORIGIN_FROM = Literal["custom", "npms"]
+from typing import Literal
+
+
+COMPRESSION_METHOD = Literal["PR_L2", "PR_GM", "PR_NN", "PR_ID", "FD_TK", "FD_CP", "FD_SVD"]
+RECOMMENDATION_METHOD = Literal["slamp", "vbmf"]
+TASK = Literal[
+    "image_classification",
+    "object_detection",
+    "image_segmentation",
+    "semantic_segmentation",
+    "instance_segmentation",
+    "panoptic_segmentation",
+    "other",
+]
+FRAMEWORK = Literal["tensorflow_keras", "onnx", "pytorch"]
+ORIGIN_FROM = Literal["custom", "npms"]
```

## netspresso/compressor/client/schemas/compression.py

 * *Ordering differences only*

```diff
@@ -1,99 +1,99 @@
-from typing import Dict, List, Any
-from uuid import UUID
-
-from pydantic import BaseModel, Field, root_validator
-
-from .common import COMPRESSION_METHOD, RECOMMENDATION_METHOD
-from ..utils.validator import CompressionParamsValidator
-
-
-class CreateCompressionRequest(BaseModel):
-    model_id: UUID = Field(..., description="Model ID")
-    model_name: str = Field(..., description="Model Name")
-    description: str = Field("", description="Description")
-    compression_method: COMPRESSION_METHOD = Field(..., description="Compression Method")
-
-
-class AvailableLayerBase(BaseModel):
-    name: str = Field(..., description="Layer Name")
-    values: List[Any] = Field([], description="Compression Parameters")
-
-
-class AvailableLayer(AvailableLayerBase):
-    use: bool = Field(False, description="Compression Selection Status")
-    channels: List[int] = Field([], description="Channel Info")
-
-
-class CompressionResponse(BaseModel):
-    new_model_id: UUID = Field(..., description="Model ID")
-    compression_id: UUID = Field(..., description="Compression ID")
-    compression_method: COMPRESSION_METHOD = Field(..., description="Compression Method")
-    available_layers: List[AvailableLayer] = Field([], description="Compressible Layers")
-
-
-class RecommendationRequest(BaseModel):
-    model_id: UUID = Field(..., description="Model ID")
-    compression_id: UUID = Field(..., description="Compression ID")
-    recommendation_method: RECOMMENDATION_METHOD = Field(..., description="Recommendation Method")
-    recommendation_ratio: float = Field(..., description="Recommendation Ratio")
-
-    @root_validator
-    def validate_ratio(cls, values):
-        method = values.get("recommendation_method")
-        ratio = values.get("recommendation_ratio")
-
-        if method in ["slamp"]:
-            assert 0 < ratio <= 1, "The ratio range for SLAMP is 0 < ratio < = 1."
-        elif method in ["vbmf"]:
-            assert -1 <= ratio <= 1, "The ratio range for VBMF is -1 <= ratio <= 1."
-        return values
-
-
-class RecommendationInfo(BaseModel):
-    name: str = Field(..., description="Layer Name")
-    values: List[Any] = Field(..., description="Recommended Values")
-
-
-class RecommendationResponse(BaseModel):
-    recommended_layers: List[RecommendationInfo] = Field([], description="Recommended Layers")
-
-
-class CompressionRequest(BaseModel):
-    compression_id: UUID = Field(..., description="Compression ID")
-    compression_method: COMPRESSION_METHOD = Field(..., description="Compression Method")
-    layers: List[AvailableLayer] = Field([], description="Compressible Layers")
-    options: Dict[str, str] = Field({"policy": "average"}, description="Compression Options")
-    compressed_model_id: UUID = Field(..., description="Compressed Model ID")
-
-    @root_validator
-    def validate_compression_params(cls, values):
-        compression_method = values.get("compression_method")
-        layers = values.get("layers")
-
-        compression_params_validator = CompressionParamsValidator(compression_method, layers)
-        compression_params_validator.validate()
-
-        return values
-
-
-class AutoCompressionRequest(BaseModel):
-    model_id: UUID = Field(..., description="Model ID")
-    model_name: str = Field(..., description="Model Name")
-    description: str = Field("", description="Description")
-    recommendation_ratio: float = Field(..., gt=0, le=1, description="Recommendation Ratio")
-    save_path: str = Field(..., description="Compressed Model Save Path")
-
-
-class UploadDatasetRequest(BaseModel):
-    model_id: UUID = Field(..., description="Model ID")
-    file_path: str = Field(..., description="Model Path")
-
-
-class GetAvailableLayersRequest(BaseModel):
-    model_id: UUID = Field(..., description="Model ID")
-    compression_method: COMPRESSION_METHOD = Field(..., description="Compression Method")
-
-
-class GetAvailableLayersReponse(BaseModel):
-    compression_method: COMPRESSION_METHOD = Field(..., description="Compression Method")
-    available_layers: List[AvailableLayer] = Field([], description="Compressible Layers")
+from typing import Dict, List, Any
+from uuid import UUID
+
+from pydantic import BaseModel, Field, root_validator
+
+from .common import COMPRESSION_METHOD, RECOMMENDATION_METHOD
+from ..utils.validator import CompressionParamsValidator
+
+
+class CreateCompressionRequest(BaseModel):
+    model_id: UUID = Field(..., description="Model ID")
+    model_name: str = Field(..., description="Model Name")
+    description: str = Field("", description="Description")
+    compression_method: COMPRESSION_METHOD = Field(..., description="Compression Method")
+
+
+class AvailableLayerBase(BaseModel):
+    name: str = Field(..., description="Layer Name")
+    values: List[Any] = Field([], description="Compression Parameters")
+
+
+class AvailableLayer(AvailableLayerBase):
+    use: bool = Field(False, description="Compression Selection Status")
+    channels: List[int] = Field([], description="Channel Info")
+
+
+class CompressionResponse(BaseModel):
+    new_model_id: UUID = Field(..., description="Model ID")
+    compression_id: UUID = Field(..., description="Compression ID")
+    compression_method: COMPRESSION_METHOD = Field(..., description="Compression Method")
+    available_layers: List[AvailableLayer] = Field([], description="Compressible Layers")
+
+
+class RecommendationRequest(BaseModel):
+    model_id: UUID = Field(..., description="Model ID")
+    compression_id: UUID = Field(..., description="Compression ID")
+    recommendation_method: RECOMMENDATION_METHOD = Field(..., description="Recommendation Method")
+    recommendation_ratio: float = Field(..., description="Recommendation Ratio")
+
+    @root_validator
+    def validate_ratio(cls, values):
+        method = values.get("recommendation_method")
+        ratio = values.get("recommendation_ratio")
+
+        if method in ["slamp"]:
+            assert 0 < ratio <= 1, "The ratio range for SLAMP is 0 < ratio < = 1."
+        elif method in ["vbmf"]:
+            assert -1 <= ratio <= 1, "The ratio range for VBMF is -1 <= ratio <= 1."
+        return values
+
+
+class RecommendationInfo(BaseModel):
+    name: str = Field(..., description="Layer Name")
+    values: List[Any] = Field(..., description="Recommended Values")
+
+
+class RecommendationResponse(BaseModel):
+    recommended_layers: List[RecommendationInfo] = Field([], description="Recommended Layers")
+
+
+class CompressionRequest(BaseModel):
+    compression_id: UUID = Field(..., description="Compression ID")
+    compression_method: COMPRESSION_METHOD = Field(..., description="Compression Method")
+    layers: List[AvailableLayer] = Field([], description="Compressible Layers")
+    options: Dict[str, str] = Field({"policy": "average"}, description="Compression Options")
+    compressed_model_id: UUID = Field(..., description="Compressed Model ID")
+
+    @root_validator
+    def validate_compression_params(cls, values):
+        compression_method = values.get("compression_method")
+        layers = values.get("layers")
+
+        compression_params_validator = CompressionParamsValidator(compression_method, layers)
+        compression_params_validator.validate()
+
+        return values
+
+
+class AutoCompressionRequest(BaseModel):
+    model_id: UUID = Field(..., description="Model ID")
+    model_name: str = Field(..., description="Model Name")
+    description: str = Field("", description="Description")
+    recommendation_ratio: float = Field(..., gt=0, le=1, description="Recommendation Ratio")
+    save_path: str = Field(..., description="Compressed Model Save Path")
+
+
+class UploadDatasetRequest(BaseModel):
+    model_id: UUID = Field(..., description="Model ID")
+    file_path: str = Field(..., description="Model Path")
+
+
+class GetAvailableLayersRequest(BaseModel):
+    model_id: UUID = Field(..., description="Model ID")
+    compression_method: COMPRESSION_METHOD = Field(..., description="Compression Method")
+
+
+class GetAvailableLayersReponse(BaseModel):
+    compression_method: COMPRESSION_METHOD = Field(..., description="Compression Method")
+    available_layers: List[AvailableLayer] = Field([], description="Compressible Layers")
```

## netspresso/compressor/client/schemas/model.py

```diff
@@ -1,102 +1,120 @@
-import json
-from typing import List, Any
-from uuid import UUID
-
-from pydantic import BaseModel, Field, validator, root_validator, HttpUrl
-from loguru import logger
-
-from .common import TASK, FRAMEWORK, ORIGIN_FROM
-
-
-class InputLayer(BaseModel):
-    batch: Any = Field(0, description="Input Batch")
-    channel: int = Field(0, description="Input Channel")
-    dimension: List[int] = Field([0], description="Input Diemension")
-
-
-class UploadModelRequest(BaseModel):
-    model_name: str = Field(..., description="Model Name")
-    description: str = Field("", description="Description")
-    task: TASK = Field(..., description="Task")
-    framework: FRAMEWORK = Field(..., description="Framework")
-    input_layers: List[InputLayer] = Field(None, description="Input Layers")
-    file_path: str = Field(..., description="Model Path")
-    # metric_unit: str = Field("", description="Metric Unit")
-    # metric_value: float = Field(0, description="Metric Value")
-
-    @validator("input_layers")
-    def validate_input_layers(cls, value):
-        if value:
-            input_layers = []
-            for v in value:
-                if any((v.batch == 0, v.channel == 0, v.dimension == [0])):
-                    return None
-                input_layers.append(v.dict())
-            return json.dumps(input_layers)
-        else:
-            return None
-
-    @root_validator(pre=True, skip_on_failure=True)
-    def validate_input_shape(cls, values):
-        framework = values.get("framework")
-        input_layers = values.get("input_layers")
-
-        if framework == "pytorch" and input_layers is None:
-            logger.info("Please fill in Input Layers fields.")
-
-        return values
-
-
-class Spec(BaseModel):
-    input_layers: List[InputLayer] = Field([], description="Input Layers")
-    model_size: float = Field(0, description="Model Size")
-    flops: float = Field(0, description="FLOPs")
-    trainable_parameters: float = Field(0, description="Trainable Parameters")
-    non_trainable_parameters: float = Field(0, description="Non Trainable Parameters")
-    number_of_layers: int = Field(0, description="Number of Layers")
-
-
-class Status(BaseModel):
-    is_convertible: bool = Field(False, description="Convertible Status")
-    is_packageable: bool = Field(False, description="Packageable Status")
-    is_compressible: bool = Field(False, description="Compressible Status")
-    is_visible: bool = Field(False, description="Visible Status")
-    is_compressed: bool = Field(False, description="Compressed Status")
-    is_trained: bool = Field(False, description="Trained Status")
-    is_downloadable: bool = Field(False, description="Downloadable Status")
-    is_retrainable: bool = Field(False, description="Retrainable Status")
-
-
-class Metric(BaseModel):
-    metric_unit: str = Field("", description="Metric Unit")
-    metric_value: float = Field(None, description="Metric Value")
-
-
-class Device(BaseModel):
-    name: str = Field("", description="Device Name")
-    total_latency: float = Field(0, description="Total Latency of Model")
-    performance: List = Field([], description="Metric Value")
-    spec: List = Field([], description="Metric Value")
-    layers: List = Field([], description="Metric Value")
-
-
-class ModelResponse(BaseModel):
-    model_id: UUID = Field(..., description="Model ID")
-    model_name: str = Field(..., description="Model Name")
-    description: str = Field("", description="Description")
-    original_model_id: str = Field(..., description="Original Model ID")
-    original_compression_id: str = Field("", description="Compression ID")
-    task: TASK = Field(..., description="Task")
-    framework: FRAMEWORK = Field(..., description="Framework")
-    origin_from: ORIGIN_FROM = Field(..., description="Origin From(Model Source)")
-    target_device: str = Field("", description="Target Device")
-    metric: Metric = Field(..., description="Metric")
-    spec: Spec = Field(..., description="Spec")
-    status: Status = Field(..., description="Status")
-    devices: List[Device] = Field([], description="Devices")
-    # edges: List = Field([], description="Edges")
-    # nodes: List = Field([], description="Nodes")
-
-
-class GetDownloadLinkResponse(BaseModel):
-    url: HttpUrl = Field(..., description="Model Path")
+import json
+from typing import List, Any
+from uuid import UUID
+from os.path import basename
+
+from pydantic import BaseModel, Field, validator, root_validator, HttpUrl
+
+from netspresso.compressor.client.schemas.common import TASK, FRAMEWORK, ORIGIN_FROM
+from netspresso.compressor.client.utils.enum import Framework, Extension
+
+
+class InputLayer(BaseModel):
+    batch: Any = Field(0, description="Input Batch")
+    channel: int = Field(0, description="Input Channel")
+    dimension: List[int] = Field([0], description="Input Diemension")
+
+
+class UploadModelRequest(BaseModel):
+    model_name: str = Field(..., description="Model Name")
+    description: str = Field("", description="Description")
+    task: TASK = Field(..., description="Task")
+    framework: FRAMEWORK = Field(..., description="Framework")
+    input_layers: List[InputLayer] = Field(None, description="Input Layers")
+    file_path: str = Field(..., description="Model Path")
+    # metric_unit: str = Field("", description="Metric Unit")
+    # metric_value: float = Field(0, description="Metric Value")
+
+    @validator("input_layers")
+    def validate_input_layers(cls, value):
+        if value:
+            input_layers = []
+            for v in value:
+                if any((v.batch == 0, v.channel == 0, v.dimension == [0])):
+                    return None
+                input_layers.append(v.dict())
+            return json.dumps(input_layers)
+        else:
+            return None
+
+    @root_validator(pre=True, skip_on_failure=True)
+    def validate_request_params(cls, values):
+        framework = values.get("framework")
+        input_layers = values.get("input_layers")
+        file_path = values.get("file_path")
+        file_extension = basename(file_path).split(".")[1]
+
+        if framework not in [Framework.TENSORFLOW_KERAS.value, Framework.PYTORCH.value, Framework.ONNX.value]:
+            raise Exception("Invalid framework. Supported frameworks are TensorFlow/Keras, PyTorch, and ONNX.")
+
+        if framework == Framework.TENSORFLOW_KERAS.value and not file_extension in [
+            Extension.H5.value,
+            Extension.ZIP.value,
+        ]:
+            raise Exception(
+                "Invalid file extension or framework. TensorFlow/Keras models should have .h5 or .zip extension."
+            )
+        elif framework == Framework.PYTORCH.value and not file_extension == Extension.PT.value:
+            raise Exception("Invalid file extension or framework. PyTorch models should have .pt extension.")
+        elif framework == Framework.ONNX.value and not file_extension == Extension.ONNX.value:
+            raise Exception("Invalid file extension or framework. ONNX models should have .onnx extension.")
+
+        if framework == Framework.PYTORCH.value and input_layers is None:
+            raise Exception("Invalid input shape. Input shape is required for PyTorch models.")
+
+        return values
+
+
+class Spec(BaseModel):
+    input_layers: List[InputLayer] = Field([], description="Input Layers")
+    model_size: float = Field(0, description="Model Size")
+    flops: float = Field(0, description="FLOPs")
+    trainable_parameters: float = Field(0, description="Trainable Parameters")
+    non_trainable_parameters: float = Field(0, description="Non Trainable Parameters")
+    number_of_layers: int = Field(0, description="Number of Layers")
+
+
+class Status(BaseModel):
+    is_convertible: bool = Field(False, description="Convertible Status")
+    is_packageable: bool = Field(False, description="Packageable Status")
+    is_compressible: bool = Field(False, description="Compressible Status")
+    is_visible: bool = Field(False, description="Visible Status")
+    is_compressed: bool = Field(False, description="Compressed Status")
+    is_trained: bool = Field(False, description="Trained Status")
+    is_downloadable: bool = Field(False, description="Downloadable Status")
+    is_retrainable: bool = Field(False, description="Retrainable Status")
+
+
+class Metric(BaseModel):
+    metric_unit: str = Field("", description="Metric Unit")
+    metric_value: float = Field(None, description="Metric Value")
+
+
+class Device(BaseModel):
+    name: str = Field("", description="Device Name")
+    total_latency: float = Field(0, description="Total Latency of Model")
+    performance: List = Field([], description="Metric Value")
+    spec: List = Field([], description="Metric Value")
+    layers: List = Field([], description="Metric Value")
+
+
+class ModelResponse(BaseModel):
+    model_id: UUID = Field(..., description="Model ID")
+    model_name: str = Field(..., description="Model Name")
+    description: str = Field("", description="Description")
+    original_model_id: str = Field(..., description="Original Model ID")
+    original_compression_id: str = Field("", description="Compression ID")
+    task: TASK = Field(..., description="Task")
+    framework: FRAMEWORK = Field(..., description="Framework")
+    origin_from: ORIGIN_FROM = Field(..., description="Origin From(Model Source)")
+    target_device: str = Field("", description="Target Device")
+    metric: Metric = Field(..., description="Metric")
+    spec: Spec = Field(..., description="Spec")
+    status: Status = Field(..., description="Status")
+    devices: List[Device] = Field([], description="Devices")
+    # edges: List = Field([], description="Edges")
+    # nodes: List = Field([], description="Nodes")
+
+
+class GetDownloadLinkResponse(BaseModel):
+    url: HttpUrl = Field(..., description="Model Path")
```

## netspresso/compressor/client/utils/common.py

 * *Ordering differences only*

```diff
@@ -1,16 +1,16 @@
-from os.path import basename
-
-
-def get_headers(access_token=None, json_type=False):
-    headers = {
-        "User-Agent": "NetsPresso Model Compressor API Client",
-    }
-    if access_token:
-        headers["Authorization"] = f"Bearer {access_token}"
-    if json_type:
-        headers["Content-Type"] = "application/json"
-    return headers
-
-
-def get_files(file_path):
-    return [("file", (basename(file_path), open(file_path, "rb"), "application/octet-stream"))]
+from os.path import basename
+
+
+def get_headers(access_token=None, json_type=False):
+    headers = {
+        "User-Agent": "NetsPresso Model Compressor API Client",
+    }
+    if access_token:
+        headers["Authorization"] = f"Bearer {access_token}"
+    if json_type:
+        headers["Content-Type"] = "application/json"
+    return headers
+
+
+def get_files(file_path):
+    return [("file", (basename(file_path), open(file_path, "rb"), "application/octet-stream"))]
```

## netspresso/compressor/client/utils/enum.py

```diff
@@ -1,31 +1,39 @@
-from enum import Enum
-
-
-class Task(Enum):
-    IMAGE_CLASSIFICATION = "image_classification"
-    OBJECT_DETECTION = "object_detection"
-    IMAGE_SEGMENTATION = "image_segmentation"
-    SEMANTIC_SEGMENTATION = "semantic_segmentation"
-    INSTANCE_SEGMENTATION = "instance_segmentation"
-    PANOPTIC_SEGMENTATION = "panoptic_segmentation"
-    OTHER = "other"
-
-
-class Framework(Enum):
-    TENSORFLOW_KERAS = "tensorflow_keras"
-    PYTORCH = "pytorch"
-    ONNX = "onnx"
-
-
-class CompressionMethod(Enum):
-    PR_L2 = "PR_L2"
-    PR_GM = "PR_GM"
-    PR_ID = "PR_ID"
-    FD_TK = "FD_TK"
-    FD_CP = "FD_CP"
-    FD_SVD = "FD_SVD"
-
-
-class RecommendationMethod(Enum):
-    SLAMP = "slamp"
-    VBMF = "vbmf"
+from enum import Enum
+
+
+class Task(Enum):
+    IMAGE_CLASSIFICATION = "image_classification"
+    OBJECT_DETECTION = "object_detection"
+    IMAGE_SEGMENTATION = "image_segmentation"
+    SEMANTIC_SEGMENTATION = "semantic_segmentation"
+    INSTANCE_SEGMENTATION = "instance_segmentation"
+    PANOPTIC_SEGMENTATION = "panoptic_segmentation"
+    OTHER = "other"
+
+
+class Framework(Enum):
+    TENSORFLOW_KERAS = "tensorflow_keras"
+    PYTORCH = "pytorch"
+    ONNX = "onnx"
+
+
+class Extension(Enum):
+    H5 = "h5"
+    ZIP = "zip"
+    PT = "pt"
+    ONNX = "onnx"
+
+
+class CompressionMethod(Enum):
+    PR_L2 = "PR_L2"
+    PR_GM = "PR_GM"
+    PR_NN = "PR_NN"
+    PR_ID = "PR_ID"
+    FD_TK = "FD_TK"
+    FD_CP = "FD_CP"
+    FD_SVD = "FD_SVD"
+
+
+class RecommendationMethod(Enum):
+    SLAMP = "slamp"
+    VBMF = "vbmf"
```

## netspresso/compressor/client/utils/validator.py

 * *Ordering differences only*

```diff
@@ -1,79 +1,79 @@
-from .enum import CompressionMethod
-
-
-class CompressionParamsValidator:
-    def __init__(self, compression_method, layers):
-        self.compression_method = compression_method
-        self.layers = layers
-        self.supported_method = list(CompressionMethod.__members__.keys())
-
-    def validate(self):
-        compression_methods = {
-            "PR_L2": self._validate_pr_ratio,
-            "PR_GM": self._validate_pr_ratio,
-            "PR_NN": self._validate_pr_ratio,
-            "PR_ID": self._validate_pr_index,
-            "FD_TK": self._validate_fd_rank2,
-            "FD_SVD": self._validate_fd_rank1,
-            "FD_CP": self._validate_fd_rank1,
-        }
-
-        validation_method = compression_methods.get(self.compression_method)
-        if validation_method:
-            validation_method()
-        else:
-            raise ValueError(
-                f"Invalid compression_method: {self.compression_method}. Please choose from {self.supported_method}."
-            )
-
-    def _validate_pr_ratio(self):
-        for layer in self.layers:
-            if not layer.use:
-                continue
-            if len(layer.values) != 1:
-                raise ValueError(f"The number of values should be 1, but got {len(layer.values)}.")
-            if not isinstance(layer.values[0], float):
-                raise ValueError(f"The type of the input value should be float, but got {layer.values}.")
-            if not 0.0 < layer.values[0] <= 1.0:
-                raise ValueError(f"The range of input value should be 0.0 < x <= 1.0, but got {layer.values}.")
-
-    def _validate_pr_index(self):
-        for layer in self.layers:
-            if not layer.use:
-                continue
-            if layer.channels[0] <= len(layer.values):
-                raise ValueError(
-                    f"The number of values should be less than {layer.channels[0]}, but got {len(layer.values)}."
-                )
-            if not all(isinstance(x, int) for x in layer.values):
-                raise ValueError(f"The type of the input values should be integer, but got {layer.values}")
-            if not all(0 <= x < layer.channels[0] for x in layer.values):
-                raise ValueError(
-                    f"The range of input values should be 0 <= x < out channels({layer.channels[0]}), but got {layer.values}"
-                )
-
-    def _validate_fd_rank2(self):
-        for layer in self.layers:
-            if not layer.use:
-                continue
-            if len(layer.values) != 2:
-                raise ValueError(f"The number of values should be 2, but got {len(layer.values)}.")
-            if not all(isinstance(x, int) for x in layer.values):
-                raise ValueError(f"The type of the input values should be integer, but got {layer.values}")
-            if not all(x > 0 and x <= channel for x, channel in zip(layer.values, layer.channels)):
-                raise ValueError(
-                    f"The range of input values should be 0 < x <= channels({layer.channels}), but got {layer.values}"
-                )
-
-    def _validate_fd_rank1(self):
-        for layer in self.layers:
-            if not layer.use:
-                continue
-            if len(layer.values) != 1:
-                raise ValueError(f"The number of values should be 1, but got {len(layer.values)}.")
-            if not isinstance(layer.values[0], int):
-                raise ValueError(f"The type of the input values should be integer, but got {layer.values}")
-            if not 0 < layer.values[0] <= min(layer.channels):
-                raise ValueError(
-                    f"The range of input values should be 0 < x < min(in channels, out channels)({min(layer.channels)}), but got {layer.values}"
-                )
+from .enum import CompressionMethod
+
+
+class CompressionParamsValidator:
+    def __init__(self, compression_method, layers):
+        self.compression_method = compression_method
+        self.layers = layers
+        self.supported_method = list(CompressionMethod.__members__.keys())
+
+    def validate(self):
+        compression_methods = {
+            "PR_L2": self._validate_pr_ratio,
+            "PR_GM": self._validate_pr_ratio,
+            "PR_NN": self._validate_pr_ratio,
+            "PR_ID": self._validate_pr_index,
+            "FD_TK": self._validate_fd_rank2,
+            "FD_SVD": self._validate_fd_rank1,
+            "FD_CP": self._validate_fd_rank1,
+        }
+
+        validation_method = compression_methods.get(self.compression_method)
+        if validation_method:
+            validation_method()
+        else:
+            raise ValueError(
+                f"Invalid compression_method: {self.compression_method}. Please choose from {self.supported_method}."
+            )
+
+    def _validate_pr_ratio(self):
+        for layer in self.layers:
+            if not layer.use:
+                continue
+            if len(layer.values) != 1:
+                raise ValueError(f"The number of values should be 1, but got {len(layer.values)}.")
+            if not isinstance(layer.values[0], float):
+                raise ValueError(f"The type of the input value should be float, but got {layer.values}.")
+            if not 0.0 < layer.values[0] <= 1.0:
+                raise ValueError(f"The range of input value should be 0.0 < x <= 1.0, but got {layer.values}.")
+
+    def _validate_pr_index(self):
+        for layer in self.layers:
+            if not layer.use:
+                continue
+            if layer.channels[0] <= len(layer.values):
+                raise ValueError(
+                    f"The number of values should be less than {layer.channels[0]}, but got {len(layer.values)}."
+                )
+            if not all(isinstance(x, int) for x in layer.values):
+                raise ValueError(f"The type of the input values should be integer, but got {layer.values}")
+            if not all(0 <= x < layer.channels[0] for x in layer.values):
+                raise ValueError(
+                    f"The range of input values should be 0 <= x < out channels({layer.channels[0]}), but got {layer.values}"
+                )
+
+    def _validate_fd_rank2(self):
+        for layer in self.layers:
+            if not layer.use:
+                continue
+            if len(layer.values) != 2:
+                raise ValueError(f"The number of values should be 2, but got {len(layer.values)}.")
+            if not all(isinstance(x, int) for x in layer.values):
+                raise ValueError(f"The type of the input values should be integer, but got {layer.values}")
+            if not all(x > 0 and x <= channel for x, channel in zip(layer.values, layer.channels)):
+                raise ValueError(
+                    f"The range of input values should be 0 < x <= channels({layer.channels}), but got {layer.values}"
+                )
+
+    def _validate_fd_rank1(self):
+        for layer in self.layers:
+            if not layer.use:
+                continue
+            if len(layer.values) != 1:
+                raise ValueError(f"The number of values should be 1, but got {len(layer.values)}.")
+            if not isinstance(layer.values[0], int):
+                raise ValueError(f"The type of the input values should be integer, but got {layer.values}")
+            if not 0 < layer.values[0] <= min(layer.channels):
+                raise ValueError(
+                    f"The range of input values should be 0 < x < min(in channels, out channels)({min(layer.channels)}), but got {layer.values}"
+                )
```

## netspresso/compressor/core/compression.py

 * *Ordering differences only*

```diff
@@ -1,12 +1,12 @@
-class CompressionBase:
-    def __init__(self, compression_method, available_layers, model_id):
-        self.compression_method = compression_method
-        self.available_layers = available_layers
-        self.model_id = model_id
-
-
-class CompressionInfo(CompressionBase):
-    def __init__(self, compression_info, model_id):
-        super().__init__(compression_info.compression_method, compression_info.available_layers, model_id)
-        self.new_model_id = compression_info.new_model_id
-        self.compression_id = compression_info.compression_id
+class CompressionBase:
+    def __init__(self, compression_method, available_layers, model_id):
+        self.compression_method = compression_method
+        self.available_layers = available_layers
+        self.model_id = model_id
+
+
+class CompressionInfo(CompressionBase):
+    def __init__(self, compression_info, model_id):
+        super().__init__(compression_info.compression_method, compression_info.available_layers, model_id)
+        self.new_model_id = compression_info.new_model_id
+        self.compression_id = compression_info.compression_id
```

## netspresso/compressor/core/model.py

 * *Ordering differences only*

```diff
@@ -1,14 +1,14 @@
-class Model:
-    def __init__(self, model_info) -> None:
-        self.model_id = model_info.model_id
-        self.model_name = model_info.model_name
-        self.framework = model_info.framework
-        self.task = model_info.task
-        self.spec = model_info.spec
-
-
-class CompressedModel(Model):
-    def __init__(self, model_info) -> None:
-        super().__init__(model_info)
-        self.compression_id = model_info.original_compression_id
-        self.original_model_id = model_info.original_model_id
+class Model:
+    def __init__(self, model_info) -> None:
+        self.model_id = model_info.model_id
+        self.model_name = model_info.model_name
+        self.framework = model_info.framework
+        self.task = model_info.task
+        self.spec = model_info.spec
+
+
+class CompressedModel(Model):
+    def __init__(self, model_info) -> None:
+        super().__init__(model_info)
+        self.compression_id = model_info.original_compression_id
+        self.original_model_id = model_info.original_model_id
```

## netspresso/compressor/utils/token.py

 * *Ordering differences only*

```diff
@@ -1,8 +1,8 @@
-from datetime import datetime
-import jwt
-import pytz
-
-
-def check_jwt_exp(access_token):
-    payload = jwt.decode(access_token, options={"verify_signature": False})
-    return datetime.now(pytz.utc).timestamp() <= payload["exp"]
+from datetime import datetime
+import jwt
+import pytz
+
+
+def check_jwt_exp(access_token):
+    payload = jwt.decode(access_token, options={"verify_signature": False})
+    return datetime.now(pytz.utc).timestamp() <= payload["exp"]
```

## Comparing `netspresso-0.1.4.dist-info/LICENSE` & `netspresso-0.1.5.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,201 +1,201 @@
-                                 Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
-
-   APPENDIX: How to apply the Apache License to your work.
-
-      To apply the Apache License to your work, attach the following
-      boilerplate notice, with the fields enclosed by brackets "[]"
-      replaced with your own identifying information. (Don't include
-      the brackets!)  The text should be enclosed in the appropriate
-      comment syntax for the file format. We also recommend that a
-      file or class name and description of purpose be included on the
-      same "printed page" as the copyright notice for easier
-      identification within third-party archives.
-
-   Copyright [yyyy] [name of copyright owner]
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
```

## Comparing `netspresso-0.1.4.dist-info/METADATA` & `netspresso-0.1.5.dist-info/METADATA`

 * *Files 19% similar despite different names*

```diff
@@ -1,26 +1,26 @@
-Metadata-Version: 2.1
-Name: netspresso
-Version: 0.1.4
-Summary: python client for the NetsPresso
-Home-page: https://github.com/nota-github/netspresso-python
-Author: NetsPresso
-Author-email: bmlee@nota.ai
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Requires-Python: >=3.8
-Description-Content-Type: text/markdown
-License-File: LICENSE
-Requires-Dist: loguru (==0.7.0)
-Requires-Dist: urllib3 (==2.0.2)
-Requires-Dist: PyJWT (==2.7.0)
-Requires-Dist: pydantic (==1.10.4)
-Requires-Dist: requests (==2.30.0)
-Requires-Dist: email-validator (==2.0.0)
-Requires-Dist: pytz (==2023.3)
-Requires-Dist: sphinx (==6.2.1)
-Requires-Dist: sphinx-rtd-theme (==1.2.1)
-Requires-Dist: recommonmark (==0.7.1)
-Requires-Dist: typing-extensions (==4.5.0)
-
-# NetsPresso
+Metadata-Version: 2.1
+Name: netspresso
+Version: 0.1.5
+Summary: python client for the NetsPresso
+Home-page: https://github.com/nota-github/netspresso-python
+Author: NetsPresso
+Author-email: bmlee@nota.ai
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Requires-Python: >=3.8
+Description-Content-Type: text/markdown
+License-File: LICENSE
+Requires-Dist: loguru (==0.7.0)
+Requires-Dist: urllib3 (==2.0.2)
+Requires-Dist: PyJWT (==2.7.0)
+Requires-Dist: pydantic (==1.10.4)
+Requires-Dist: requests (==2.30.0)
+Requires-Dist: email-validator (==2.0.0)
+Requires-Dist: pytz (==2023.3)
+Requires-Dist: sphinx (==6.2.1)
+Requires-Dist: sphinx-rtd-theme (==1.2.1)
+Requires-Dist: recommonmark (==0.7.1)
+Requires-Dist: typing-extensions (==4.5.0)
+
+# NetsPresso
```

## Comparing `netspresso-0.1.4.dist-info/RECORD` & `netspresso-0.1.5.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-netspresso/__init__.py,sha256=Wzf5T3NBDfhQoTnhnRNHSlAsE0XMqbclXG-M81Vas70,22
-netspresso/compressor/__init__.py,sha256=WIio--Rx346T7aX9DYV8V-kuPheWOOtugzQrlpqlDWY,20173
-netspresso/compressor/client/__init__.py,sha256=EQ6bIJ3MrdXImw3GLj6HE6FKe1AyeLwWfT8aG8jwY1E,8237
-netspresso/compressor/client/config.py,sha256=LRYWzn_wFLixxexrCbQ3XTk1lU9HaFbEfGmKehruQYE,517
+netspresso/__init__.py,sha256=bwvWpUk0EyEUuvD53CeliZB1Kg0oNPGd4LQm5A7KRo0,23
+netspresso/compressor/__init__.py,sha256=KVbB4_grNTqeubjKmG4WFYcNBuNYnzppLPR4hBtbp_Q,22980
+netspresso/compressor/client/__init__.py,sha256=pgYngRDyZBTc3vTDNeZPHpSc86KJ_122J-jdKFArpT0,8456
+netspresso/compressor/client/config.py,sha256=i3EZTWDZJEq527YY1hiyiSN-DIVQyjE7zgOI7_kLY9Y,536
 netspresso/compressor/client/schemas/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-netspresso/compressor/client/schemas/auth.py,sha256=6s3owU388I7u0XSMx1quwuHA3a534Z2EqiP1_Y_893k,2584
-netspresso/compressor/client/schemas/common.py,sha256=d6J6A40pqFncvRZtEY_3y49sMbcnNvCCBbWy9lV72gI,466
-netspresso/compressor/client/schemas/compression.py,sha256=Bzm8vHHsPQfT1Q4qugavYHeeCsmUsK7WhO1Vjq7BR20,4042
-netspresso/compressor/client/schemas/model.py,sha256=l_V3XVHJgIHLATShOPIwXx0moVbKHsMV5aE34fQfDH0,4243
+netspresso/compressor/client/schemas/auth.py,sha256=NGudVfx4Q7E8XppeDgcKmQlU_3UwKDu3YjYiIwsii1g,2644
+netspresso/compressor/client/schemas/common.py,sha256=w1rR-jqIvjQ6UqMRZ5KYWW8bQrlXMSrAdWXCzA3tQuk,482
+netspresso/compressor/client/schemas/compression.py,sha256=TT3ycahw4zRKgGot6Fk0y1GcgHkJuNPE1UhSJGpDhVw,4141
+netspresso/compressor/client/schemas/model.py,sha256=kedFDszHGRi8V2KuIYZe8BqWi4OMUyADZ4MRrY4mQoY,5581
 netspresso/compressor/client/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-netspresso/compressor/client/utils/common.py,sha256=JLxIRbkOwEjQQ1utVN8jNBBPp9rEch0l08-toHceYQk,465
-netspresso/compressor/client/utils/enum.py,sha256=ak9nJYKipWAMr0wCsR4xv6J8om7DTPc1ToUKU18YETE,694
-netspresso/compressor/client/utils/validator.py,sha256=H9eLujAKAJx-ZNs9JXpOWkOf6U_t-51zzsEqIWme29Y,3735
+netspresso/compressor/client/utils/common.py,sha256=gAHVbvzBGmoYNExaGOEgaqJHTszXuMOSwCFpyH_xEwc,481
+netspresso/compressor/client/utils/enum.py,sha256=RUtiknaDJhfML23sILSHnEvPJ2wBqsLDgId0d_IM0fI,840
+netspresso/compressor/client/utils/validator.py,sha256=0pONKSTlxTWcpSIiUw3P2ItPARoLXvu5YSGGxhUFPNU,3814
 netspresso/compressor/core/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-netspresso/compressor/core/compression.py,sha256=dlF0_tB1HjBEI7d2NQfNqnqdVMw5BIlxSjgdEQqmdjE,551
-netspresso/compressor/core/model.py,sha256=h69FnQeh-dgxxG-fmOFl045l-C5usRjZzK_3e7gAxPI,507
+netspresso/compressor/core/compression.py,sha256=XzLukrfHTYEJQPF0A01iYbVZEjKRfgweIMEmGsfpfXc,563
+netspresso/compressor/core/model.py,sha256=bDK_y5dtUxS3_uFEMhSbmv851hglfsA9w5YSLf9RhZE,521
 netspresso/compressor/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-netspresso/compressor/utils/token.py,sha256=Zqnmc9RK5s_AIrP3z0aAPE7dlO5OmD1xz6AAZ63woCc,228
-netspresso-0.1.4.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-netspresso-0.1.4.dist-info/METADATA,sha256=y3p7vlmf9ML22sjkXJdbC5QhKYcnUeC0QhHImkw4H4s,846
-netspresso-0.1.4.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-netspresso-0.1.4.dist-info/top_level.txt,sha256=aHBNCm2tepEeTCUHu2_PVIlFG6iGuQReNl0js5hzjdU,11
-netspresso-0.1.4.dist-info/RECORD,,
+netspresso/compressor/utils/token.py,sha256=zWKx6olb8N2c3nSQhUS22IRG7ILQZYIERScETEFeUXY,236
+netspresso-0.1.5.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
+netspresso-0.1.5.dist-info/METADATA,sha256=_zT7Mw0UJ9ard5dGivwJC3y0R7SB8q9ic5dbq8CXEMg,872
+netspresso-0.1.5.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+netspresso-0.1.5.dist-info/top_level.txt,sha256=aHBNCm2tepEeTCUHu2_PVIlFG6iGuQReNl0js5hzjdU,11
+netspresso-0.1.5.dist-info/RECORD,,
```

