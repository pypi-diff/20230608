# Comparing `tmp/evadb-0.2.6.tar.gz` & `tmp/evadb-0.2.7.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "evadb-0.2.6.tar", last modified: Sat Jun  3 03:19:58 2023, max compression
+gzip compressed data, was "evadb-0.2.7.tar", last modified: Thu Jun  8 00:40:00 2023, max compression
```

## Comparing `evadb-0.2.6.tar` & `evadb-0.2.7.tar`

### file list

```diff
@@ -1,480 +1,469 @@
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.725496 evadb-0.2.6/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    11357 2022-08-11 16:20:33.000000 evadb-0.2.6/LICENSE.txt
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    14211 2023-06-03 03:19:58.725496 evadb-0.2.6/PKG-INFO
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    13539 2023-06-02 21:04:24.000000 evadb-0.2.6/README.md
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.665494 evadb-0.2.6/eva/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      645 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.665494 evadb-0.2.6/eva/binder/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/binder/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7778 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/binder/binder_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    15552 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/binder/statement_binder.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7997 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/binder/statement_binder_context.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.665494 evadb-0.2.6/eva/catalog/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      616 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    18583 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/catalog_manager.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3320 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/catalog_type.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     8604 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/catalog_utils.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.669494 evadb-0.2.6/eva/catalog/models/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      886 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1499 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/association_models.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4671 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/base_model.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5266 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/column_catalog.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3393 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/index_catalog.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2997 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/table_catalog.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3532 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/udf_cache_catalog.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4429 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/udf_catalog.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2262 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/udf_cost_catalog.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4722 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/udf_io_catalog.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2668 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/models/udf_metadata_catalog.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2127 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/schema_utils.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.669494 evadb-0.2.6/eva/catalog/services/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/services/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1167 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/services/base_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2873 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/services/column_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2899 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/services/index_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4571 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/services/table_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3669 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/services/udf_cache_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3078 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/services/udf_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2826 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/services/udf_cost_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2476 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/services/udf_io_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1936 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/services/udf_metadata_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2654 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/catalog/sql_config.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.669494 evadb-0.2.6/eva/configuration/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      620 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/configuration/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5490 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/configuration/bootstrap_environment.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4798 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/configuration/configuration_manager.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1005 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/configuration/constants.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      882 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/constants.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      852 2023-06-02 21:04:24.000000 evadb-0.2.6/eva/eva.yml
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1997 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/eva_cmd_client.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3246 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/eva_server.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.677494 evadb-0.2.6/eva/executor/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      615 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2140 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/abstract_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1910 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/apply_and_merge_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2005 2023-06-02 21:04:24.000000 evadb-0.2.6/eva/executor/create_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5191 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/create_index_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1924 2023-06-02 21:04:24.000000 evadb-0.2.6/eva/executor/create_mat_view_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7292 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/create_udf_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4738 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/delete_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2515 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/drop_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1968 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/drop_udf_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3537 2023-06-02 21:04:24.000000 evadb-0.2.6/eva/executor/exchange_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3017 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/execution_context.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4366 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/executor_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1522 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/explain_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1591 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/function_scan_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1759 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/groupby_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1800 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/hash_join_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2255 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/insert_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1616 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/join_build_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1661 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/lateral_join_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1583 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/limit_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3086 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/load_csv_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1648 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/load_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6038 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/load_multimedia_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1488 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/nested_loop_join_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4183 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/orderby_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     8198 2023-06-02 21:04:24.000000 evadb-0.2.6/eva/executor/plan_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1644 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/pp_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1277 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/predicate_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1272 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/project_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2074 2023-06-02 21:04:24.000000 evadb-0.2.6/eva/executor/ray_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1186 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/rename_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1413 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/sample_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1812 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/seq_scan_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1870 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/show_info_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2533 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/storage_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1264 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/union_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3916 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/executor/vector_index_scan_executor.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.677494 evadb-0.2.6/eva/expression/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      617 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/expression/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5559 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/expression/abstract_expression.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3973 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/expression/aggregation_expression.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1618 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/expression/arithmetic_expression.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4351 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/expression/comparison_expression.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2542 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/expression/constant_value_expression.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10433 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/expression/expression_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10358 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/expression/function_expression.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3055 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/expression/logical_expression.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4685 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/expression/tuple_value_expression.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.677494 evadb-0.2.6/eva/interfaces/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/interfaces/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.677494 evadb-0.2.6/eva/interfaces/relational/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/interfaces/relational/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10769 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/interfaces/relational/db.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7278 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/interfaces/relational/relation.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4472 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/interfaces/relational/utils.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.677494 evadb-0.2.6/eva/models/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      633 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/models/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.677494 evadb-0.2.6/eva/models/catalog/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/models/catalog/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1332 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/models/catalog/frame_info.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      857 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/models/catalog/properties.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.677494 evadb-0.2.6/eva/models/server/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/models/server/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1961 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/models/server/response.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.677494 evadb-0.2.6/eva/models/storage/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/models/storage/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    14841 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/models/storage/batch.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.681494 evadb-0.2.6/eva/optimizer/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      620 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3259 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/binder.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2129 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/cost_model.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3450 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/group.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2669 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/group_expression.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4335 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/memo.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    37333 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/operators.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3837 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/optimizer_context.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      982 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/optimizer_task_stack.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    12582 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/optimizer_tasks.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10874 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/optimizer_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4102 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/plan_generator.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1169 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/property.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.681494 evadb-0.2.6/eva/optimizer/rules/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/rules/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1019 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/rules/pattern.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    49728 2023-06-02 21:04:24.000000 evadb-0.2.6/eva/optimizer/rules/rules.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7440 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/rules/rules_base.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7534 2023-06-02 21:04:24.000000 evadb-0.2.6/eva/optimizer/rules/rules_manager.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    13726 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/optimizer/statement_to_opr_converter.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.685494 evadb-0.2.6/eva/parser/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1360 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/alias.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2740 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/create_index_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2872 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/create_mat_view_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5341 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/create_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4882 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/create_udf_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2048 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/delete_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1767 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/drop_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1793 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/drop_udf_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    19702 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/eva.lark
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1384 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/explain_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2922 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/insert_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1716 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_parser.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.685494 evadb-0.2.6/eva/parser/lark_visitor/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2655 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2161 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_common_clauses_ids.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10824 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_create_statements.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1404 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_delete_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1202 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_drop_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1006 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_explain_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4672 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_expressions.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6231 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_functions.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2465 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_insert_statements.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2241 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_load_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      932 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_rename_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2143 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_select_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1112 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_show_statements.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     9469 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/lark_visitor/_table_sources.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3214 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/load_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1227 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/parser.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2007 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/rename_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6248 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/select_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1460 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/show_statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1426 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/statement.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     8637 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/table_ref.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1787 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/types.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2654 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/parser/utils.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.693495 evadb-0.2.6/eva/plan_nodes/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      614 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1689 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/abstract_join_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3453 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/abstract_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1455 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/abstract_scan_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1930 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/apply_and_merge_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2469 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/create_index_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2076 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/create_mat_view_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2200 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/create_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3603 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/create_udf_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1951 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/delete_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1660 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/drop_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1532 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/drop_udf_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2057 2023-06-02 21:04:24.000000 evadb-0.2.6/eva/plan_nodes/exchange_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1033 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/explain_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1755 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/function_scan_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1499 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/groupby_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1712 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/hash_join_build_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2179 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/hash_join_probe_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2023 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/insert_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1408 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/lateral_join_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1468 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/limit_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2710 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/load_data_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1510 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/nested_loop_join_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1564 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/orderby_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1177 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/pp_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1245 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/predicate_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1249 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/project_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1616 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/rename_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1469 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/sample_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1760 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/seq_scan_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1201 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/show_info_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4419 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/storage_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1421 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/types.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1245 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/union_plan.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2720 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/plan_nodes/vector_index_scan_plan.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.693495 evadb-0.2.6/eva/readers/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/readers/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2320 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/readers/abstract_reader.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2648 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/readers/csv_reader.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5987 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/readers/decord_reader.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.693495 evadb-0.2.6/eva/readers/document/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/readers/document/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1467 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/readers/document/document_reader.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1979 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/readers/document/registry.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.693495 evadb-0.2.6/eva/readers/image/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/readers/image/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1067 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/readers/image/opencv_image_reader.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2050 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/readers/pdf_reader.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.693495 evadb-0.2.6/eva/server/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      623 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/server/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3289 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/server/command_handler.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3263 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/server/interpreter.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2926 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/server/server.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.693495 evadb-0.2.6/eva/storage/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      616 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/storage/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6133 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/storage/abstract_media_storage_engine.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2383 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/storage/abstract_storage_engine.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1713 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/storage/document_storage_engine.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1717 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/storage/image_storage_engine.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1692 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/storage/pdf_storage_engine.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     8972 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/storage/sqlite_storage_engine.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1941 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/storage/storage_engine.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2496 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/storage/video_storage_engine.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.697495 evadb-0.2.6/eva/third_party/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      605 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/third_party/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.697495 evadb-0.2.6/eva/third_party/huggingface/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      612 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/third_party/huggingface/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1420 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/third_party/huggingface/binder.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6473 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/third_party/huggingface/create.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2615 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/third_party/huggingface/model.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.697495 evadb-0.2.6/eva/third_party/vector_stores/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      607 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/third_party/vector_stores/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3284 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/third_party/vector_stores/faiss.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2960 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/third_party/vector_stores/qdrant.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1376 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/third_party/vector_stores/types.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1594 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/third_party/vector_stores/utils.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.697495 evadb-0.2.6/eva/udfs/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      616 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.701495 evadb-0.2.6/eva/udfs/abstract/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      625 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/abstract/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2442 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/abstract/abstract_udf.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4040 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/abstract/hf_abstract_udf.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3843 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/abstract/pytorch_abstract_udf.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3914 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/abstract/tracker_abstract_udf.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3464 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/asl_action_recognition.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3413 2023-06-03 01:20:14.000000 evadb-0.2.6/eva/udfs/chatgpt.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.701495 evadb-0.2.6/eva/udfs/decorators/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/decorators/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2188 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/decorators/decorators.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.701495 evadb-0.2.6/eva/udfs/decorators/io_descriptors/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/decorators/io_descriptors/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2755 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/decorators/io_descriptors/abstract_types.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3376 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/decorators/io_descriptors/data_types.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2067 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/decorators/utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5478 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/emotion_detector.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2539 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/face_detector.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5999 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/fastrcnn_object_detector.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1822 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/feature_extractor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1028 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/gpu_compatible.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3528 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/mnist_image_classifier.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2200 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/mvit_action_recognition.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.701495 evadb-0.2.6/eva/udfs/ndarray/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      638 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2472 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/annotate.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2568 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/array_count.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1647 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/crop.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1179 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/fuzzy_join.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2200 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/gaussian_blur.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2202 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/horizontal_flip.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1557 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/open.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1782 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/similarity.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2139 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/to_grayscale.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2188 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ndarray/vertical_flip.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2750 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/ocr_extractor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2899 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/sift_feature_extractor.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.701495 evadb-0.2.6/eva/udfs/trackers/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      636 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/trackers/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2367 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/trackers/nor_fair.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.701495 evadb-0.2.6/eva/udfs/tutorials/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      636 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/tutorials/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7934 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/udf_bootstrap_queries.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3859 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/udfs/yolo_object_detector.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.705495 evadb-0.2.6/eva/utils/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      611 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/utils/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      909 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/utils/errors.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6966 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/utils/generic_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1956 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/utils/kv_cache.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      985 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/utils/logging_manager.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1388 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/utils/math_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1562 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/utils/s3_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1692 2023-06-01 22:37:10.000000 evadb-0.2.6/eva/utils/stats.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      123 2023-06-03 03:19:56.000000 evadb-0.2.6/eva/version.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.705495 evadb-0.2.6/evadb.egg-info/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    14211 2023-06-03 03:19:58.000000 evadb-0.2.6/evadb.egg-info/PKG-INFO
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    14107 2023-06-03 03:19:58.000000 evadb-0.2.6/evadb.egg-info/SOURCES.txt
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)        1 2023-06-03 03:19:58.000000 evadb-0.2.6/evadb.egg-info/dependency_links.txt
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)       88 2023-06-03 03:19:58.000000 evadb-0.2.6/evadb.egg-info/entry_points.txt
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1329 2023-06-03 03:19:58.000000 evadb-0.2.6/evadb.egg-info/requires.txt
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)       21 2023-06-03 03:19:58.000000 evadb-0.2.6/evadb.egg-info/top_level.txt
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)       90 2022-06-26 17:11:46.000000 evadb-0.2.6/pyproject.toml
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)       38 2023-06-03 03:19:58.725496 evadb-0.2.6/setup.cfg
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4575 2023-06-03 03:03:15.000000 evadb-0.2.6/setup.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.705495 evadb-0.2.6/test/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-09-30 14:20:49.000000 evadb-0.2.6/test/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.705495 evadb-0.2.6/test/benchmark_tests/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-01-02 23:54:53.000000 evadb-0.2.6/test/benchmark_tests/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1176 2023-05-09 19:58:04.000000 evadb-0.2.6/test/benchmark_tests/conftest.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6639 2023-05-12 03:48:38.000000 evadb-0.2.6/test/benchmark_tests/test_benchmark_pytorch.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.705495 evadb-0.2.6/test/binder/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/binder/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2032 2023-01-02 23:54:53.000000 evadb-0.2.6/test/binder/test_binder_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    13819 2023-06-01 22:37:10.000000 evadb-0.2.6/test/binder/test_statement_binder.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7962 2023-05-16 03:45:18.000000 evadb-0.2.6/test/binder/test_statement_binder_context.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.705495 evadb-0.2.6/test/catalog/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/catalog/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.705495 evadb-0.2.6/test/catalog/models/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/catalog/models/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7234 2023-03-28 02:19:14.000000 evadb-0.2.6/test/catalog/models/test_models.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.709495 evadb-0.2.6/test/catalog/services/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/catalog/services/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1918 2023-01-07 03:29:08.000000 evadb-0.2.6/test/catalog/services/test_column_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4794 2023-05-17 22:20:34.000000 evadb-0.2.6/test/catalog/services/test_index_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3639 2023-03-28 02:19:14.000000 evadb-0.2.6/test/catalog/services/test_table_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3639 2023-04-01 16:09:26.000000 evadb-0.2.6/test/catalog/services/test_udf_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3210 2023-03-28 02:19:14.000000 evadb-0.2.6/test/catalog/services/test_udf_cost_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3035 2023-04-02 20:13:44.000000 evadb-0.2.6/test/catalog/services/test_udf_io_catalog_service.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6808 2023-05-09 19:58:04.000000 evadb-0.2.6/test/catalog/test_catalog_manager.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1402 2022-12-13 23:02:13.000000 evadb-0.2.6/test/catalog/test_column_type.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1910 2023-04-01 16:09:26.000000 evadb-0.2.6/test/catalog/test_sqlalchemy.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.709495 evadb-0.2.6/test/configuration/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/configuration/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1486 2023-05-25 14:58:01.000000 evadb-0.2.6/test/configuration/test_bootstrap_environment.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1620 2023-05-25 14:58:01.000000 evadb-0.2.6/test/configuration/test_configuration_manager.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.709495 evadb-0.2.6/test/executor/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/executor/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1106 2023-03-28 02:19:14.000000 evadb-0.2.6/test/executor/test_abstract_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3989 2023-05-16 03:45:18.000000 evadb-0.2.6/test/executor/test_create_udf_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4227 2023-04-09 04:33:37.000000 evadb-0.2.6/test/executor/test_execution_context.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1275 2022-12-13 23:02:13.000000 evadb-0.2.6/test/executor/test_executor_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4650 2023-01-02 23:54:50.000000 evadb-0.2.6/test/executor/test_limit_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3890 2023-04-09 22:04:17.000000 evadb-0.2.6/test/executor/test_load_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2884 2023-01-02 23:54:50.000000 evadb-0.2.6/test/executor/test_orderby_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10983 2023-05-16 03:45:18.000000 evadb-0.2.6/test/executor/test_plan_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1397 2022-08-08 22:30:00.000000 evadb-0.2.6/test/executor/test_pp_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1817 2023-01-02 23:54:50.000000 evadb-0.2.6/test/executor/test_sample_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2752 2023-04-09 04:33:37.000000 evadb-0.2.6/test/executor/test_seq_scan_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      847 2022-08-08 22:30:00.000000 evadb-0.2.6/test/executor/utils.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.713495 evadb-0.2.6/test/expression/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/expression/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3722 2023-03-28 02:19:14.000000 evadb-0.2.6/test/expression/test_abstract_expression.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5149 2023-03-19 05:07:03.000000 evadb-0.2.6/test/expression/test_aggregation.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2975 2023-01-02 23:54:50.000000 evadb-0.2.6/test/expression/test_arithmetic.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5578 2023-01-02 23:54:53.000000 evadb-0.2.6/test/expression/test_comparison.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2867 2022-08-08 22:30:00.000000 evadb-0.2.6/test/expression/test_expression_tree.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7555 2023-04-01 16:09:26.000000 evadb-0.2.6/test/expression/test_expression_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2685 2022-11-12 17:07:12.000000 evadb-0.2.6/test/expression/test_function_expression.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10242 2023-04-28 05:16:29.000000 evadb-0.2.6/test/expression/test_logical.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.717496 evadb-0.2.6/test/integration_tests/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/integration_tests/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3585 2023-05-09 19:58:04.000000 evadb-0.2.6/test/integration_tests/test_array_count.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4522 2023-05-09 19:58:04.000000 evadb-0.2.6/test/integration_tests/test_chatgpt.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6167 2023-05-17 22:20:34.000000 evadb-0.2.6/test/integration_tests/test_create_index_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3886 2023-06-01 22:37:10.000000 evadb-0.2.6/test/integration_tests/test_create_table_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5158 2023-05-14 18:56:25.000000 evadb-0.2.6/test/integration_tests/test_delete_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4839 2023-05-16 03:45:18.000000 evadb-0.2.6/test/integration_tests/test_drop_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2358 2023-05-14 15:06:41.000000 evadb-0.2.6/test/integration_tests/test_error_handling_with_ray.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3361 2023-05-25 14:58:01.000000 evadb-0.2.6/test/integration_tests/test_explain_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3183 2023-04-09 04:33:37.000000 evadb-0.2.6/test/integration_tests/test_fuzzy_join.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    16033 2023-06-01 22:37:10.000000 evadb-0.2.6/test/integration_tests/test_huggingface_udfs.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3806 2023-05-12 03:48:38.000000 evadb-0.2.6/test/integration_tests/test_insert_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2983 2023-05-14 15:06:41.000000 evadb-0.2.6/test/integration_tests/test_like.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    20932 2023-05-25 14:58:01.000000 evadb-0.2.6/test/integration_tests/test_load_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1961 2023-05-25 14:58:01.000000 evadb-0.2.6/test/integration_tests/test_load_pdf_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7168 2023-06-01 22:37:10.000000 evadb-0.2.6/test/integration_tests/test_mat_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2658 2023-05-09 19:58:04.000000 evadb-0.2.6/test/integration_tests/test_open.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10646 2023-05-16 03:45:18.000000 evadb-0.2.6/test/integration_tests/test_optimizer_rules.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    14654 2023-06-02 21:04:24.000000 evadb-0.2.6/test/integration_tests/test_pytorch.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2953 2023-03-28 02:19:14.000000 evadb-0.2.6/test/integration_tests/test_rename_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10469 2023-05-25 14:58:01.000000 evadb-0.2.6/test/integration_tests/test_reuse.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5210 2023-04-09 04:33:37.000000 evadb-0.2.6/test/integration_tests/test_s3_load_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    30781 2023-05-09 19:58:04.000000 evadb-0.2.6/test/integration_tests/test_select_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3277 2023-05-07 22:24:29.000000 evadb-0.2.6/test/integration_tests/test_show_info_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    14709 2023-05-17 22:20:34.000000 evadb-0.2.6/test/integration_tests/test_similarity.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    12062 2023-04-09 04:33:37.000000 evadb-0.2.6/test/integration_tests/test_udf_executor.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1574 2023-05-17 22:20:34.000000 evadb-0.2.6/test/markers.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.717496 evadb-0.2.6/test/models/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/models/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.717496 evadb-0.2.6/test/models/catalog/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/models/catalog/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1010 2022-10-16 04:44:32.000000 evadb-0.2.6/test/models/catalog/test_frame_info.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.717496 evadb-0.2.6/test/models/storage/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/models/storage/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5919 2023-04-09 04:33:37.000000 evadb-0.2.6/test/models/storage/test_batch.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.717496 evadb-0.2.6/test/optimizer/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/optimizer/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.717496 evadb-0.2.6/test/optimizer/rules/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-03-28 02:19:14.000000 evadb-0.2.6/test/optimizer/rules/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    11653 2023-06-02 21:04:24.000000 evadb-0.2.6/test/optimizer/rules/test_rules.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4195 2023-03-16 05:59:55.000000 evadb-0.2.6/test/optimizer/test_binder.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2233 2023-05-25 14:58:01.000000 evadb-0.2.6/test/optimizer/test_cascade_optimizer.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4406 2022-08-08 22:30:00.000000 evadb-0.2.6/test/optimizer/test_cost_model.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2689 2022-08-08 22:30:00.000000 evadb-0.2.6/test/optimizer/test_group.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1996 2022-08-08 22:30:00.000000 evadb-0.2.6/test/optimizer/test_memo.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1034 2022-08-08 22:30:00.000000 evadb-0.2.6/test/optimizer/test_optimizer_context.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5522 2023-05-25 14:58:01.000000 evadb-0.2.6/test/optimizer/test_optimizer_task.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2000 2023-01-07 03:29:08.000000 evadb-0.2.6/test/optimizer/test_optimizer_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    13564 2023-05-17 22:20:34.000000 evadb-0.2.6/test/optimizer/test_statement_to_opr_converter.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.717496 evadb-0.2.6/test/parser/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/parser/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    36070 2023-05-17 22:20:34.000000 evadb-0.2.6/test/parser/test_parser.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7783 2023-05-17 22:20:34.000000 evadb-0.2.6/test/parser/test_parser_statements.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.717496 evadb-0.2.6/test/plan_nodes/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-01-02 23:54:50.000000 evadb-0.2.6/test/plan_nodes/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6292 2023-03-28 02:19:14.000000 evadb-0.2.6/test/plan_nodes/test_plan.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.717496 evadb-0.2.6/test/readers/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/readers/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1688 2023-04-01 16:09:26.000000 evadb-0.2.6/test/readers/test_csv_reader.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     8104 2023-05-07 22:24:29.000000 evadb-0.2.6/test/readers/test_decord_reader.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.721496 evadb-0.2.6/test/server/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-11-12 17:07:12.000000 evadb-0.2.6/test/server/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1268 2023-01-02 23:54:53.000000 evadb-0.2.6/test/server/test_command_handler.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5068 2023-06-01 22:37:10.000000 evadb-0.2.6/test/server/test_db_api.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2603 2023-06-01 22:37:10.000000 evadb-0.2.6/test/server/test_interpreter.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2066 2023-05-23 15:21:38.000000 evadb-0.2.6/test/server/test_server.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.721496 evadb-0.2.6/test/storage/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/storage/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4113 2023-05-07 22:24:29.000000 evadb-0.2.6/test/storage/test_sqlite_storage_engine.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4023 2023-03-28 02:19:14.000000 evadb-0.2.6/test/storage/test_video_storage.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3309 2023-05-16 03:45:18.000000 evadb-0.2.6/test/test_eva_cmd_client.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1294 2022-12-13 23:02:13.000000 evadb-0.2.6/test/test_eva_imports.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1841 2023-05-25 14:58:01.000000 evadb-0.2.6/test/test_eva_server.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.721496 evadb-0.2.6/test/udfs/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      638 2022-08-08 22:30:00.000000 evadb-0.2.6/test/udfs/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.721496 evadb-0.2.6/test/udfs/decorators/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-03-28 02:19:14.000000 evadb-0.2.6/test/udfs/decorators/__init__.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.721496 evadb-0.2.6/test/udfs/decorators/io_descriptors/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-03-28 02:19:14.000000 evadb-0.2.6/test/udfs/decorators/io_descriptors/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7429 2023-05-16 03:45:18.000000 evadb-0.2.6/test/udfs/decorators/io_descriptors/test_descriptors.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2137 2023-05-16 03:45:18.000000 evadb-0.2.6/test/udfs/decorators/test_decorators.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.721496 evadb-0.2.6/test/udfs/ndarray/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      648 2022-10-16 04:44:32.000000 evadb-0.2.6/test/udfs/ndarray/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1842 2023-06-01 22:37:10.000000 evadb-0.2.6/test/udfs/ndarray/test_annotate.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      849 2023-03-28 02:19:14.000000 evadb-0.2.6/test/udfs/ndarray/test_array_count.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2410 2022-10-16 04:44:32.000000 evadb-0.2.6/test/udfs/ndarray/test_crop.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2012 2023-05-25 14:58:01.000000 evadb-0.2.6/test/udfs/ndarray/test_flips.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1700 2023-05-25 14:58:01.000000 evadb-0.2.6/test/udfs/ndarray/test_gaussian_blur.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2374 2023-04-28 05:16:29.000000 evadb-0.2.6/test/udfs/ndarray/test_open.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1675 2023-05-25 14:58:01.000000 evadb-0.2.6/test/udfs/ndarray/test_to_grayscale.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4412 2023-05-10 04:58:49.000000 evadb-0.2.6/test/udfs/test_abstract_udf.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2154 2022-09-30 14:24:37.000000 evadb-0.2.6/test/udfs/test_emotion_detector.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3345 2023-03-28 02:19:14.000000 evadb-0.2.6/test/udfs/test_facenet_udf.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2548 2022-10-30 19:28:39.000000 evadb-0.2.6/test/udfs/test_fastrcnn_object_detector.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2768 2023-05-09 19:58:04.000000 evadb-0.2.6/test/udfs/test_yolo_object_detector.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    17438 2023-05-16 03:45:18.000000 evadb-0.2.6/test/util.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.725496 evadb-0.2.6/test/utils/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.6/test/utils/__init__.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4196 2023-04-28 05:16:29.000000 evadb-0.2.6/test/utils/test_generic_utils.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2256 2023-03-28 02:19:14.000000 evadb-0.2.6/test/utils/test_timer.py
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1296 2023-05-25 14:58:01.000000 evadb-0.2.6/test/utils/test_xdist.py
-drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-03 03:19:58.725496 evadb-0.2.6/third_party/
--rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)        0 2022-06-26 17:11:46.000000 evadb-0.2.6/third_party/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.974635 evadb-0.2.7/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    11357 2022-08-11 16:20:33.000000 evadb-0.2.7/LICENSE.txt
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    14211 2023-06-08 00:40:00.974635 evadb-0.2.7/PKG-INFO
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    13539 2023-06-07 03:30:14.000000 evadb-0.2.7/README.md
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.914633 evadb-0.2.7/evadb/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      903 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.914633 evadb-0.2.7/evadb/binder/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/binder/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     8760 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/binder/binder_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    15514 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/binder/statement_binder.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7980 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/binder/statement_binder_context.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.914633 evadb-0.2.7/evadb/catalog/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      616 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    19315 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/catalog_manager.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3322 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/catalog_type.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     9335 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/catalog_utils.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.918633 evadb-0.2.7/evadb/catalog/models/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1501 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/association_models.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4749 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/base_model.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4549 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/column_catalog.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2869 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/index_catalog.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2439 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/table_catalog.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3020 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/udf_cache_catalog.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3099 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/udf_catalog.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1802 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/udf_cost_catalog.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3921 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/udf_io_catalog.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2203 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/udf_metadata_catalog.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6787 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/models/utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2124 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/schema_utils.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.918633 evadb-0.2.7/evadb/catalog/services/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/services/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1289 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/services/base_service.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3375 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/services/column_catalog_service.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2968 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/services/index_catalog_service.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4959 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/services/table_catalog_service.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3997 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/services/udf_cache_catalog_service.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3247 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/services/udf_catalog_service.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3034 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/services/udf_cost_catalog_service.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2932 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/services/udf_io_catalog_service.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2224 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/services/udf_metadata_catalog_service.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2730 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/catalog/sql_config.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.918633 evadb-0.2.7/evadb/configuration/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      620 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/configuration/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5058 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/configuration/bootstrap_environment.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2501 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/configuration/configuration_manager.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1017 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/configuration/constants.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      882 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/constants.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1957 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/database.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2002 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/eva_cmd_client.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2657 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/eva_server.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      566 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/evadb.yml
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.926633 evadb-0.2.7/evadb/executor/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      615 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3795 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/abstract_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2318 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/apply_and_merge_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2029 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/create_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5093 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/create_index_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1946 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/create_mat_view_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7178 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/create_udf_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4734 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/delete_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4993 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/drop_object_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3613 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/exchange_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3023 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/execution_context.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5371 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/executor_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1590 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/explain_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1999 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/function_scan_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1891 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/groupby_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1938 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/hash_join_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2241 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/insert_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1682 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/join_build_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1837 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/lateral_join_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1649 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/limit_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3078 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/load_csv_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1736 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/load_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5944 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/load_multimedia_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1610 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/nested_loop_join_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4257 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/orderby_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     8302 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/plan_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1710 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/pp_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1361 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/predicate_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1356 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/project_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2076 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/ray_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1261 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/rename_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1479 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/sample_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1912 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/seq_scan_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1840 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/show_info_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2616 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/storage_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1330 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/union_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4389 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/executor/vector_index_scan_executor.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.926633 evadb-0.2.7/evadb/expression/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      617 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/expression/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5559 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/expression/abstract_expression.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3977 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/expression/aggregation_expression.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1622 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/expression/arithmetic_expression.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4355 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/expression/comparison_expression.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2548 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/expression/constant_value_expression.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10443 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/expression/expression_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10044 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/expression/function_expression.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3057 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/expression/logical_expression.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4691 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/expression/tuple_value_expression.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.926633 evadb-0.2.7/evadb/interfaces/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/interfaces/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.926633 evadb-0.2.7/evadb/interfaces/relational/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/interfaces/relational/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    11182 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/interfaces/relational/db.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7504 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/interfaces/relational/relation.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4618 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/interfaces/relational/utils.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.926633 evadb-0.2.7/evadb/models/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      633 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/models/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.926633 evadb-0.2.7/evadb/models/catalog/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/models/catalog/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1334 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/models/catalog/frame_info.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      857 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/models/catalog/properties.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.926633 evadb-0.2.7/evadb/models/server/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/models/server/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1967 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/models/server/response.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.926633 evadb-0.2.7/evadb/models/storage/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/models/storage/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    15328 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/models/storage/batch.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.930633 evadb-0.2.7/evadb/optimizer/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      620 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3267 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/binder.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2143 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/cost_model.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3458 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/group.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2675 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/group_expression.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4345 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/memo.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    36733 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/operators.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4009 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/optimizer_context.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      984 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/optimizer_task_stack.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    12596 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/optimizer_tasks.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    11288 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/optimizer_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4275 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/plan_generator.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1169 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/property.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.930633 evadb-0.2.7/evadb/optimizer/rules/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/rules/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1021 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/rules/pattern.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    49297 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/rules/rules.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7374 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/rules/rules_base.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7509 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/rules/rules_manager.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    13356 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/optimizer/statement_to_opr_converter.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.934633 evadb-0.2.7/evadb/parser/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1360 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/alias.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2752 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/create_index_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2882 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/create_mat_view_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5322 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/create_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4434 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/create_udf_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2056 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/delete_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2129 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/drop_object_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    19687 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/evadb.lark
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1388 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/explain_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2930 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/insert_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1720 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_parser.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.934633 evadb-0.2.7/evadb/parser/lark_visitor/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2683 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2169 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_common_clauses_ids.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10838 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_create_statements.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1408 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_delete_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2005 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_drop_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1008 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_explain_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4682 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_expressions.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5778 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_functions.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2471 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_insert_statements.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2245 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_load_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      936 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_rename_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2147 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_select_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1116 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_show_statements.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     9479 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/lark_visitor/_table_sources.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3222 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/load_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1231 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/parser.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2013 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/rename_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6256 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/select_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1464 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/show_statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1428 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/statement.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     8647 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/table_ref.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1868 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/types.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4269 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/parser/utils.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.942634 evadb-0.2.7/evadb/plan_nodes/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      614 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1697 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/abstract_join_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3455 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/abstract_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1461 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/abstract_scan_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1938 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/apply_and_merge_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2481 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/create_index_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2084 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/create_mat_view_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2208 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/create_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3611 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/create_udf_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1959 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/delete_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1497 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/drop_object_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2061 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/exchange_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1037 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/explain_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1761 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/function_scan_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1505 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/groupby_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1720 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/hash_join_build_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2189 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/hash_join_probe_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2031 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/insert_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1416 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/lateral_join_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1474 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/limit_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2718 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/load_data_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1518 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/nested_loop_join_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1568 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/orderby_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1183 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/pp_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1251 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/predicate_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1255 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/project_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1622 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/rename_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1475 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/sample_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1766 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/seq_scan_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1207 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/show_info_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4429 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/storage_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1406 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/types.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1249 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/union_plan.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2730 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/plan_nodes/vector_index_scan_plan.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.942634 evadb-0.2.7/evadb/readers/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/readers/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2326 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/readers/abstract_reader.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2654 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/readers/csv_reader.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5999 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/readers/decord_reader.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.942634 evadb-0.2.7/evadb/readers/document/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/readers/document/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1471 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/readers/document/document_reader.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1979 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/readers/document/registry.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.942634 evadb-0.2.7/evadb/readers/image/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/readers/image/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1069 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/readers/image/opencv_image_reader.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2052 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/readers/pdf_reader.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.942634 evadb-0.2.7/evadb/server/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      623 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/server/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3464 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/server/command_handler.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3599 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/server/interpreter.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3347 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/server/server.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.942634 evadb-0.2.7/evadb/storage/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      616 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/storage/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6181 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/storage/abstract_media_storage_engine.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2491 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/storage/abstract_storage_engine.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1779 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/storage/document_storage_engine.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1783 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/storage/image_storage_engine.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1758 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/storage/pdf_storage_engine.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     9491 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/storage/sqlite_storage_engine.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2058 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/storage/storage_engine.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2556 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/storage/video_storage_engine.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.942634 evadb-0.2.7/evadb/third_party/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      605 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/third_party/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.946634 evadb-0.2.7/evadb/third_party/huggingface/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      612 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/third_party/huggingface/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1426 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/third_party/huggingface/binder.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6481 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/third_party/huggingface/create.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2619 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/third_party/huggingface/model.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.946634 evadb-0.2.7/evadb/third_party/vector_stores/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      607 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/third_party/vector_stores/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3286 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/third_party/vector_stores/faiss.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2962 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/third_party/vector_stores/qdrant.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1376 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/third_party/vector_stores/types.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1606 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/third_party/vector_stores/utils.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.946634 evadb-0.2.7/evadb/udfs/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      616 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.950634 evadb-0.2.7/evadb/udfs/abstract/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      625 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/abstract/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2442 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/abstract/abstract_udf.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4046 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/abstract/hf_abstract_udf.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3849 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/abstract/pytorch_abstract_udf.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3922 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/abstract/tracker_abstract_udf.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3466 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/asl_action_recognition.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3440 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/chatgpt.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.950634 evadb-0.2.7/evadb/udfs/decorators/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/decorators/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2190 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/decorators/decorators.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.954634 evadb-0.2.7/evadb/udfs/decorators/io_descriptors/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/decorators/io_descriptors/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2759 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/decorators/io_descriptors/abstract_types.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3384 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/decorators/io_descriptors/data_types.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2071 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/decorators/utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5480 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/emotion_detector.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2545 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/face_detector.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6020 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/fastrcnn_object_detector.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1824 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/feature_extractor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1028 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/gpu_compatible.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3530 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/mnist_image_classifier.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2202 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/mvit_action_recognition.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.954634 evadb-0.2.7/evadb/udfs/ndarray/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      638 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2480 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/annotate.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2570 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/array_count.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1649 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/crop.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1181 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/fuzzy_join.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2208 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/gaussian_blur.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2210 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/horizontal_flip.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1559 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/open.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1784 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/similarity.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2147 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/to_grayscale.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2196 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ndarray/vertical_flip.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2754 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/ocr_extractor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2703 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/saliency_feature_extractor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2763 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/sentence_transformer_feature_extractor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2909 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/sift_feature_extractor.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.954634 evadb-0.2.7/evadb/udfs/trackers/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      636 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/trackers/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2371 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/trackers/nor_fair.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.954634 evadb-0.2.7/evadb/udfs/tutorials/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      636 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/tutorials/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7899 2023-06-08 00:38:31.000000 evadb-0.2.7/evadb/udfs/udf_bootstrap_queries.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3869 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/udfs/yolo_object_detector.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.954634 evadb-0.2.7/evadb/utils/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      611 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/utils/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      909 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/utils/errors.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6759 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/utils/generic_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1956 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/utils/kv_cache.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      985 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/utils/logging_manager.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1388 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/utils/math_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1562 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/utils/s3_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1694 2023-06-07 23:17:50.000000 evadb-0.2.7/evadb/utils/stats.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      123 2023-06-08 00:39:58.000000 evadb-0.2.7/evadb/version.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.914633 evadb-0.2.7/evadb.egg-info/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    14211 2023-06-08 00:40:00.000000 evadb-0.2.7/evadb.egg-info/PKG-INFO
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    14182 2023-06-08 00:40:00.000000 evadb-0.2.7/evadb.egg-info/SOURCES.txt
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)        1 2023-06-08 00:40:00.000000 evadb-0.2.7/evadb.egg-info/dependency_links.txt
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)       92 2023-06-08 00:40:00.000000 evadb-0.2.7/evadb.egg-info/entry_points.txt
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1373 2023-06-08 00:40:00.000000 evadb-0.2.7/evadb.egg-info/requires.txt
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)       23 2023-06-08 00:40:00.000000 evadb-0.2.7/evadb.egg-info/top_level.txt
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)       90 2022-06-26 17:11:46.000000 evadb-0.2.7/pyproject.toml
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)       38 2023-06-08 00:40:00.974635 evadb-0.2.7/setup.cfg
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4617 2023-06-07 23:17:50.000000 evadb-0.2.7/setup.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.958634 evadb-0.2.7/test/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-09-30 14:20:49.000000 evadb-0.2.7/test/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.958634 evadb-0.2.7/test/benchmark_tests/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-01-02 23:54:53.000000 evadb-0.2.7/test/benchmark_tests/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1263 2023-06-07 23:17:50.000000 evadb-0.2.7/test/benchmark_tests/conftest.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6891 2023-06-07 23:17:50.000000 evadb-0.2.7/test/benchmark_tests/test_benchmark_pytorch.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.958634 evadb-0.2.7/test/binder/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/binder/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    14197 2023-06-07 23:17:50.000000 evadb-0.2.7/test/binder/test_statement_binder.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     8054 2023-06-07 23:17:50.000000 evadb-0.2.7/test/binder/test_statement_binder_context.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.958634 evadb-0.2.7/test/catalog/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/catalog/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.958634 evadb-0.2.7/test/catalog/models/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/catalog/models/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7246 2023-06-07 23:17:50.000000 evadb-0.2.7/test/catalog/models/test_models.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7353 2023-06-07 23:17:50.000000 evadb-0.2.7/test/catalog/test_catalog_manager.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1404 2023-06-07 23:17:50.000000 evadb-0.2.7/test/catalog/test_column_type.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.958634 evadb-0.2.7/test/executor/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/executor/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1108 2023-06-07 23:17:50.000000 evadb-0.2.7/test/executor/test_abstract_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4079 2023-06-07 23:17:50.000000 evadb-0.2.7/test/executor/test_create_udf_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4271 2023-06-07 23:17:50.000000 evadb-0.2.7/test/executor/test_execution_context.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4745 2023-06-07 23:17:50.000000 evadb-0.2.7/test/executor/test_limit_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2934 2023-06-07 23:17:50.000000 evadb-0.2.7/test/executor/test_orderby_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     9931 2023-06-07 23:17:50.000000 evadb-0.2.7/test/executor/test_plan_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1865 2023-06-07 23:17:50.000000 evadb-0.2.7/test/executor/test_sample_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3035 2023-06-07 23:17:50.000000 evadb-0.2.7/test/executor/test_seq_scan_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      849 2023-06-07 23:17:50.000000 evadb-0.2.7/test/executor/utils.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.962634 evadb-0.2.7/test/expression/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/expression/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3732 2023-06-07 23:17:50.000000 evadb-0.2.7/test/expression/test_abstract_expression.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5157 2023-06-07 23:17:50.000000 evadb-0.2.7/test/expression/test_aggregation.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2983 2023-06-07 23:17:50.000000 evadb-0.2.7/test/expression/test_arithmetic.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5588 2023-06-07 23:17:50.000000 evadb-0.2.7/test/expression/test_comparison.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2881 2023-06-07 23:17:50.000000 evadb-0.2.7/test/expression/test_expression_tree.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7569 2023-06-07 23:17:50.000000 evadb-0.2.7/test/expression/test_expression_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2699 2023-06-07 23:17:50.000000 evadb-0.2.7/test/expression/test_function_expression.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10254 2023-06-07 23:17:50.000000 evadb-0.2.7/test/expression/test_logical.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.966635 evadb-0.2.7/test/integration_tests/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/integration_tests/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3701 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_array_count.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     6122 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_create_index_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3894 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_create_table_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5195 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_delete_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7099 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_drop_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2371 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_error_handling_with_ray.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3681 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_explain_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3264 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_fuzzy_join.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    17569 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_huggingface_udfs.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3956 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_insert_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3092 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_like.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    21878 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_load_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2018 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_load_pdf_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7734 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_mat_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2665 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_open.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    11067 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_optimizer_rules.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    15564 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_pytorch.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3081 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_rename_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    10842 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_reuse.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5315 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_s3_load_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2349 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_saliency.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    31937 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_select_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3434 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_show_info_executor.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    15007 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_similarity.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    12509 2023-06-07 23:17:50.000000 evadb-0.2.7/test/integration_tests/test_udf_executor.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.966635 evadb-0.2.7/test/interfaces/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 23:17:50.000000 evadb-0.2.7/test/interfaces/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.966635 evadb-0.2.7/test/interfaces/relational/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-06-07 03:30:15.000000 evadb-0.2.7/test/interfaces/relational/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    12369 2023-06-07 23:17:50.000000 evadb-0.2.7/test/interfaces/relational/test_relational_api.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1604 2023-06-07 23:17:50.000000 evadb-0.2.7/test/markers.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.966635 evadb-0.2.7/test/models/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/models/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.966635 evadb-0.2.7/test/models/catalog/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/models/catalog/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1014 2023-06-07 23:17:50.000000 evadb-0.2.7/test/models/catalog/test_frame_info.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.966635 evadb-0.2.7/test/models/storage/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/models/storage/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5923 2023-06-07 23:17:50.000000 evadb-0.2.7/test/models/storage/test_batch.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.966635 evadb-0.2.7/test/optimizer/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/optimizer/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.966635 evadb-0.2.7/test/optimizer/rules/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-03-28 02:19:14.000000 evadb-0.2.7/test/optimizer/rules/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    11752 2023-06-07 23:17:50.000000 evadb-0.2.7/test/optimizer/rules/test_rules.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4244 2023-06-07 23:17:50.000000 evadb-0.2.7/test/optimizer/test_binder.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2327 2023-06-07 23:17:50.000000 evadb-0.2.7/test/optimizer/test_cascade_optimizer.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4510 2023-06-07 23:17:50.000000 evadb-0.2.7/test/optimizer/test_cost_model.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2695 2023-06-07 23:17:50.000000 evadb-0.2.7/test/optimizer/test_group.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2000 2023-06-07 23:17:50.000000 evadb-0.2.7/test/optimizer/test_memo.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1051 2023-06-07 23:17:50.000000 evadb-0.2.7/test/optimizer/test_optimizer_context.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5666 2023-06-07 23:17:50.000000 evadb-0.2.7/test/optimizer/test_optimizer_task.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2006 2023-06-07 23:17:50.000000 evadb-0.2.7/test/optimizer/test_optimizer_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    13111 2023-06-07 23:17:50.000000 evadb-0.2.7/test/optimizer/test_statement_to_opr_converter.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.970635 evadb-0.2.7/test/parser/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/parser/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    35632 2023-06-07 23:17:50.000000 evadb-0.2.7/test/parser/test_parser.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7795 2023-06-07 23:17:50.000000 evadb-0.2.7/test/parser/test_parser_statements.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.970635 evadb-0.2.7/test/plan_nodes/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-01-02 23:54:50.000000 evadb-0.2.7/test/plan_nodes/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5985 2023-06-07 23:17:50.000000 evadb-0.2.7/test/plan_nodes/test_plan.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.970635 evadb-0.2.7/test/readers/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/readers/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1692 2023-06-07 23:17:50.000000 evadb-0.2.7/test/readers/test_csv_reader.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     8120 2023-06-07 23:17:50.000000 evadb-0.2.7/test/readers/test_decord_reader.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.970635 evadb-0.2.7/test/server/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-11-12 17:07:12.000000 evadb-0.2.7/test/server/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1276 2023-06-07 23:17:50.000000 evadb-0.2.7/test/server/test_command_handler.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5169 2023-06-07 23:17:50.000000 evadb-0.2.7/test/server/test_db_api.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2615 2023-06-07 23:17:50.000000 evadb-0.2.7/test/server/test_interpreter.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2078 2023-06-07 23:17:50.000000 evadb-0.2.7/test/server/test_server.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.970635 evadb-0.2.7/test/storage/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/storage/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4510 2023-06-07 23:17:50.000000 evadb-0.2.7/test/storage/test_sqlite_storage_engine.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4163 2023-06-07 23:17:50.000000 evadb-0.2.7/test/storage/test_video_storage.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3321 2023-06-07 23:17:50.000000 evadb-0.2.7/test/test_eva_cmd_client.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1298 2023-06-07 23:17:50.000000 evadb-0.2.7/test/test_eva_imports.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1330 2023-06-07 23:17:50.000000 evadb-0.2.7/test/test_eva_server.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.970635 evadb-0.2.7/test/udfs/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      638 2022-08-08 22:30:00.000000 evadb-0.2.7/test/udfs/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.970635 evadb-0.2.7/test/udfs/decorators/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-03-28 02:19:14.000000 evadb-0.2.7/test/udfs/decorators/__init__.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.970635 evadb-0.2.7/test/udfs/decorators/io_descriptors/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2023-03-28 02:19:14.000000 evadb-0.2.7/test/udfs/decorators/io_descriptors/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     7435 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/decorators/io_descriptors/test_descriptors.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2143 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/decorators/test_decorators.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.974635 evadb-0.2.7/test/udfs/ndarray/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      648 2022-10-16 04:44:32.000000 evadb-0.2.7/test/udfs/ndarray/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1846 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/ndarray/test_annotate.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      851 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/ndarray/test_array_count.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2412 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/ndarray/test_crop.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2018 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/ndarray/test_flips.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1661 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/ndarray/test_gaussian_blur.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2262 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/ndarray/test_open.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     1654 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/ndarray/test_to_grayscale.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     4422 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/test_abstract_udf.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     5405 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/test_chatgpt.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2158 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/test_emotion_detector.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3357 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/test_facenet_udf.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2556 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/test_fastrcnn_object_detector.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2772 2023-06-07 23:17:50.000000 evadb-0.2.7/test/udfs/test_yolo_object_detector.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)    17773 2023-06-07 23:17:50.000000 evadb-0.2.7/test/util.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.974635 evadb-0.2.7/test/utils/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)      587 2022-08-08 22:30:00.000000 evadb-0.2.7/test/utils/__init__.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     3871 2023-06-07 23:17:50.000000 evadb-0.2.7/test/utils/test_generic_utils.py
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)     2281 2023-06-07 23:17:50.000000 evadb-0.2.7/test/utils/test_timer.py
+drwxr-xr-x   0 jarulraj3 (347863) gtperson  (2626)        0 2023-06-08 00:40:00.974635 evadb-0.2.7/third_party/
+-rw-r--r--   0 jarulraj3 (347863) gtperson  (2626)        0 2022-06-26 17:11:46.000000 evadb-0.2.7/third_party/__init__.py
```

### Comparing `evadb-0.2.6/LICENSE.txt` & `evadb-0.2.7/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/PKG-INFO` & `evadb-0.2.7/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: evadb
-Version: 0.2.6
+Version: 0.2.7
 Summary: EVA AI-Relational Database System
 Home-page: https://github.com/georgia-tech-db/eva
 Download-URL: https://github.com/georgia-tech-db/eva
 Author: Georgia Tech Database Group
 Author-email: arulraj@gatech.edu
 License: Apache License 2.0
 Classifier: Development Status :: 5 - Production/Stable
```

#### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: evadb Version: 0.2.6 Summary: EVA AI-Relational
+Metadata-Version: 2.1 Name: evadb Version: 0.2.7 Summary: EVA AI-Relational
 Database System Home-page: https://github.com/georgia-tech-db/eva Download-URL:
 https://github.com/georgia-tech-db/eva Author: Georgia Tech Database Group
 Author-email: arulraj@gatech.edu License: Apache License 2.0 Classifier:
 Development Status :: 5 - Production/Stable Classifier: License :: OSI Approved
 :: Apache Software License Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9 Classifier: Programming
 Language :: Python :: 3.10 Requires-Python: >=3.8 Description-Content-Type:
```

### Comparing `evadb-0.2.6/README.md` & `evadb-0.2.7/README.md`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/__init__.py` & `evadb-0.2.7/evadb/server/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -8,8 +8,8 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from .version import VERSION as __version__  # noqa: F401
+"""sets up a local-hosted server"""
```

### Comparing `evadb-0.2.6/eva/binder/__init__.py` & `evadb-0.2.7/evadb/binder/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/binder/binder_utils.py` & `evadb-0.2.7/evadb/binder/binder_utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -13,48 +13,50 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from __future__ import annotations
 
 import re
 from typing import TYPE_CHECKING, List
 
-from eva.catalog.catalog_type import TableType
-from eva.catalog.catalog_utils import (
+from evadb.catalog.catalog_type import TableType
+from evadb.catalog.catalog_utils import (
     get_video_table_column_definitions,
+    is_document_table,
     is_string_col,
     is_video_table,
 )
-from eva.expression.function_expression import FunctionExpression
-from eva.parser.alias import Alias
+from evadb.expression.function_expression import FunctionExpression
+from evadb.parser.alias import Alias
 
 if TYPE_CHECKING:
-    from eva.binder.statement_binder_context import StatementBinderContext
-
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.table_ref import TableInfo, TableRef
-from eva.utils.logging_manager import logger
+    from evadb.binder.statement_binder_context import StatementBinderContext
+    from evadb.catalog.catalog_manager import CatalogManager
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.table_ref import TableInfo, TableRef
+from evadb.utils.logging_manager import logger
 
 
 class BinderError(Exception):
     pass
 
 
-def bind_table_info(table_info: TableInfo) -> TableCatalogEntry:
+def bind_table_info(
+    catalog: CatalogManager, table_info: TableInfo
+) -> TableCatalogEntry:
     """
     Uses catalog to bind the table information .
 
     Arguments:
+         catalog (CatalogManager): catalog manager to use
          table_info (TableInfo): table information obtained from SQL query
 
     Returns:
         TableCatalogEntry  -  corresponding table catalog entry for the input table info
     """
-    catalog = CatalogManager()
     obj = catalog.get_table_catalog_entry(
         table_info.table_name,
         table_info.database_name,
     )
 
     # Users should not be allowed to directly access or modify the SYSTEM tables, as
     # doing so can lead to the corruption of other tables. These tables include
@@ -89,31 +91,50 @@
             TupleValueExpression(col_name=col_name, table_alias=alias)
             for alias, col_name in col_objs
         ]
     )
     return target_list
 
 
-def check_groupby_pattern(groupby_string: str) -> None:
-    # match the pattern of group by clause (e.g., 16f or 8s)
-    pattern = re.search(r"^\d+[fs]$", groupby_string)
+def check_groupby_pattern(table_ref: TableRef, groupby_string: str) -> None:
+    # match the pattern of group by clause (e.g., 16 frames or 8 samples)
+    pattern = re.search(r"^\d+\s*(?:frames|samples|paragraphs)$", groupby_string)
     # if valid pattern
     if not pattern:
         err_msg = "Incorrect GROUP BY pattern: {}".format(groupby_string)
         raise BinderError(err_msg)
     match_string = pattern.group(0)
-    if not match_string[-1] == "f":
-        err_msg = "Only grouping by frames (f) is supported"
+    suffix_string = re.sub(r"^\d+\s*", "", match_string)
+
+    if suffix_string not in ["frames", "samples", "paragraphs"]:
+        err_msg = "Grouping only supported by frames for videos, by samples for audio, and by paragraphs for documents"
         raise BinderError(err_msg)
+
+    if suffix_string == "frames" and not is_video_table(table_ref.table.table_obj):
+        err_msg = "Grouping by frames only supported for videos"
+        raise BinderError(err_msg)
+
+    if suffix_string == "samples" and not is_video_table(table_ref.table.table_obj):
+        err_msg = "Grouping by samples only supported for videos"
+        raise BinderError(err_msg)
+
+    if suffix_string == "paragraphs" and not is_document_table(
+        table_ref.table.table_obj
+    ):
+        err_msg = "Grouping by paragraphs only supported for documents"
+        raise BinderError(err_msg)
+
     # TODO ACTION condition on segment length?
 
 
-def check_table_object_is_video(table_ref: TableRef) -> None:
-    if not is_video_table(table_ref.table.table_obj):
-        err_msg = "GROUP BY only supported for video tables"
+def check_table_object_is_groupable(table_ref: TableRef) -> None:
+    if not is_video_table(table_ref.table.table_obj) and not is_document_table(
+        table_ref.table.table_obj
+    ):
+        err_msg = "GROUP BY only supported for video and document tables"
         raise BinderError(err_msg)
 
 
 def check_column_name_is_string(col_ref) -> None:
     if not is_string_col(col_ref.col_object):
         err_msg = "LIKE only supported for string columns"
         raise BinderError(err_msg)
```

### Comparing `evadb-0.2.6/eva/binder/statement_binder.py` & `evadb-0.2.7/evadb/binder/statement_binder.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,52 +10,52 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from functools import singledispatchmethod
 from pathlib import Path
+from typing import Callable
 
-from eva.binder.binder_utils import (
+from evadb.binder.binder_utils import (
     BinderError,
     bind_table_info,
     check_column_name_is_string,
     check_groupby_pattern,
-    check_table_object_is_video,
+    check_table_object_is_groupable,
     extend_star,
     handle_bind_extract_object_function,
     resolve_alias_table_value_expression,
 )
-from eva.binder.statement_binder_context import StatementBinderContext
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import NdArrayType, TableType, VideoColumnName
-from eva.catalog.catalog_utils import get_metadata_properties
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.expression.abstract_expression import AbstractExpression, ExpressionType
-from eva.expression.function_expression import FunctionExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.create_index_statement import CreateIndexStatement
-from eva.parser.create_mat_view_statement import CreateMaterializedViewStatement
-from eva.parser.create_statement import ColumnDefinition, CreateTableStatement
-from eva.parser.delete_statement import DeleteTableStatement
-from eva.parser.explain_statement import ExplainStatement
-from eva.parser.rename_statement import RenameTableStatement
-from eva.parser.select_statement import SelectStatement
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableRef
-from eva.parser.types import UDFType
-from eva.third_party.huggingface.binder import assign_hf_udf
-from eva.utils.generic_utils import get_file_checksum, load_udf_class_from_file
-from eva.utils.logging_manager import logger
+from evadb.binder.statement_binder_context import StatementBinderContext
+from evadb.catalog.catalog_type import NdArrayType, TableType, VideoColumnName
+from evadb.catalog.catalog_utils import get_metadata_properties
+from evadb.configuration.constants import EVA_INSTALLATION_DIR
+from evadb.expression.abstract_expression import AbstractExpression, ExpressionType
+from evadb.expression.function_expression import FunctionExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.create_index_statement import CreateIndexStatement
+from evadb.parser.create_mat_view_statement import CreateMaterializedViewStatement
+from evadb.parser.create_statement import ColumnDefinition, CreateTableStatement
+from evadb.parser.delete_statement import DeleteTableStatement
+from evadb.parser.explain_statement import ExplainStatement
+from evadb.parser.rename_statement import RenameTableStatement
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import TableRef
+from evadb.parser.types import UDFType
+from evadb.third_party.huggingface.binder import assign_hf_udf
+from evadb.utils.generic_utils import get_file_checksum, load_udf_class_from_file
+from evadb.utils.logging_manager import logger
 
 
 class StatementBinder:
     def __init__(self, binder_context: StatementBinderContext):
         self._binder_context = binder_context
-        self._catalog = CatalogManager()
+        self._catalog: Callable = binder_context._catalog
 
     @singledispatchmethod
     def bind(self, node):
         raise NotImplementedError(f"Cannot bind {type(node)}")
 
     @bind.register(AbstractStatement)
     def _bind_abstract_statement(self, node: AbstractStatement):
@@ -89,16 +89,15 @@
             col = [col for col in table_ref_obj.columns if col.name == col_def.name][0]
             assert (
                 col.array_type == NdArrayType.FLOAT32
             ), "Index input needs to be float32."
             assert len(col.array_dimensions) == 2
         else:
             # Output of the UDF should be 2 dimension and float32 type.
-            catalog_manager = CatalogManager()
-            udf_obj = catalog_manager.get_udf_catalog_entry_by_name(node.udf_func.name)
+            udf_obj = self._catalog().get_udf_catalog_entry_by_name(node.udf_func.name)
             for output in udf_obj.outputs:
                 assert (
                     output.array_type == NdArrayType.FLOAT32
                 ), "Index input needs to be float32."
                 assert (
                     len(output.array_dimensions) == 2
                 ), "Index input needs to be 2 dimensional."
@@ -119,22 +118,22 @@
                 and node.target_list[0].col_name == "*"
             ):
                 node.target_list = extend_star(self._binder_context)
             for expr in node.target_list:
                 self.bind(expr)
         if node.groupby_clause:
             self.bind(node.groupby_clause)
-            check_groupby_pattern(node.groupby_clause.value)
-            check_table_object_is_video(node.from_table)
+            check_table_object_is_groupable(node.from_table)
+            check_groupby_pattern(node.from_table, node.groupby_clause.value)
         if node.orderby_list:
             for expr in node.orderby_list:
                 self.bind(expr[0])
         if node.union_link:
             current_context = self._binder_context
-            self._binder_context = StatementBinderContext()
+            self._binder_context = StatementBinderContext(self._catalog)
             self.bind(node.union_link)
             self._binder_context = current_context
 
         assert not (
             self._binder_context.is_retrieve_audio()
             and self._binder_context.is_retrieve_video()
         ), "Cannot query over both audio and video streams"
@@ -156,22 +155,26 @@
             num_projected_columns = 0
             for expr in node.query.target_list:
                 if expr.etype == ExpressionType.TUPLE_VALUE:
                     num_projected_columns += 1
                 elif expr.etype == ExpressionType.FUNCTION_EXPRESSION:
                     num_projected_columns += len(expr.output_objs)
                 else:
-                    raise BinderError("Unsupported expression type {}.".format(expr.etype))
+                    raise BinderError(
+                        "Unsupported expression type {}.".format(expr.etype)
+                    )
 
             binded_col_list = []
             idx = 0
             for expr in node.query.target_list:
-                output_objs = [(expr.col_name, expr.col_object)] \
-                    if expr.etype == ExpressionType.TUPLE_VALUE \
+                output_objs = (
+                    [(expr.col_name, expr.col_object)]
+                    if expr.etype == ExpressionType.TUPLE_VALUE
                     else zip(expr.projection_columns, expr.output_objs)
+                )
                 for col_name, output_obj in output_objs:
                     binded_col_list.append(
                         ColumnDefinition(
                             col_name,
                             output_obj.type,
                             output_obj.array_type,
                             output_obj.array_dimensions,
@@ -230,18 +233,18 @@
     @bind.register(TableRef)
     def _bind_tableref(self, node: TableRef):
         if node.is_table_atom():
             # Table
             self._binder_context.add_table_alias(
                 node.alias.alias_name, node.table.table_name
             )
-            bind_table_info(node.table)
+            bind_table_info(self._catalog(), node.table)
         elif node.is_select():
             current_context = self._binder_context
-            self._binder_context = StatementBinderContext()
+            self._binder_context = StatementBinderContext(self._catalog)
             self.bind(node.select_statement)
             self._binder_context = current_context
             self._binder_context.add_derived_table_alias(
                 node.alias.alias_name, node.select_statement.target_list
             )
         elif node.is_join():
             self.bind(node.join_node.left)
@@ -287,15 +290,15 @@
         if node.name.upper() == str(UDFType.EXTRACT_OBJECT):
             handle_bind_extract_object_function(node, self)
             return
         # bind all the children
         for child in node.children:
             self.bind(child)
 
-        udf_obj = self._catalog.get_udf_catalog_entry_by_name(node.name)
+        udf_obj = self._catalog().get_udf_catalog_entry_by_name(node.name)
         if udf_obj is None:
             err_msg = (
                 f"UDF with name {node.name} does not exist in the catalog. "
                 "Please create the UDF using CREATE UDF command."
             )
             logger.error(err_msg)
             raise BinderError(err_msg)
@@ -303,31 +306,26 @@
         if udf_obj.type == "HuggingFace":
             node.function = assign_hf_udf(udf_obj)
 
         else:
             if udf_obj.type == "ultralytics":
                 # manually set the impl_path for yolo udfs we only handle object
                 # detection for now, hopefully this can be generalized
-                udf_dir = (
-                    Path(
-                        ConfigurationManager().get_value("core", "eva_installation_dir")
-                    )
-                    / "udfs"
-                )
+                udf_dir = Path(EVA_INSTALLATION_DIR) / "udfs"
                 udf_obj.impl_file_path = (
                     Path(f"{udf_dir}/yolo_object_detector.py").absolute().as_posix()
                 )
 
             # Verify the consistency of the UDF. If the checksum of the UDF does not
             # match the one stored in the catalog, an error will be thrown and the user
             # will be asked to register the UDF again.
             assert (
                 get_file_checksum(udf_obj.impl_file_path) == udf_obj.checksum
             ), f"""UDF file {udf_obj.impl_file_path} has been modified from the
-                registration. Please create a new UDF using the CREATE UDF command or UPDATE the existing one."""
+                registration. Please use DROP UDF to drop it and re-create it using CREATE UDF."""
 
             try:
                 udf_class = load_udf_class_from_file(
                     udf_obj.impl_file_path,
                     udf_obj.name,
                 )
                 # certain udfs take additional inputs like yolo needs the model_name
@@ -338,15 +336,15 @@
                     f"{str(e)}. Please verify that the UDF class name in the"
                     "implementation file matches the UDF name."
                 )
                 logger.error(err_msg)
                 raise BinderError(err_msg)
 
         node.udf_obj = udf_obj
-        output_objs = self._catalog.get_udf_io_catalog_output_entries(udf_obj)
+        output_objs = self._catalog().get_udf_io_catalog_output_entries(udf_obj)
         if node.output:
             for obj in output_objs:
                 if obj.name.lower() == node.output:
                     node.output_objs = [obj]
             if not node.output_objs:
                 err_msg = f"Output {node.output} does not exist for {udf_obj.name}."
                 logger.error(err_msg)
```

### Comparing `evadb-0.2.6/eva/binder/statement_binder_context.py` & `evadb-0.2.7/evadb/binder/statement_binder_context.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,24 +8,23 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from typing import Dict, List, Tuple, Union
+from typing import Callable, Dict, List, Tuple, Union
 
-from eva.binder.binder_utils import BinderError
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.expression.function_expression import FunctionExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.utils.logging_manager import logger
+from evadb.binder.binder_utils import BinderError
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.expression.function_expression import FunctionExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.utils.logging_manager import logger
 
 CatalogColumnType = Union[ColumnCatalogEntry, UdfIOCatalogEntry]
 
 
 class StatementBinderContext:
     """
     This context is used to store information that is useful during the process of binding a statement (such as a SELECT statement) to the catalog. It stores the following information:
@@ -40,18 +39,18 @@
 
         `Select * FROM (SELECT id1, id2 FROM table) AS A` :
             `{A: {id1: table.col1, id2: table.col2}}`
         `Select * FROM video LATERAL JOIN func AS T(a, b)` :
             `{T: {a: func.obj1, b:func.obj2}}`
     """
 
-    def __init__(self):
+    def __init__(self, catalog: Callable):
+        self._catalog = catalog
         self._table_alias_map: Dict[str, TableCatalogEntry] = dict()
         self._derived_table_alias_map: Dict[str, Dict[str, CatalogColumnType]] = dict()
-        self._catalog = CatalogManager()
         self._retrieve_audio = False
         self._retrieve_video = False
 
     def _check_duplicate_alias(self, alias: str):
         """
         Sanity check: no duplicate alias in table and derived_table
         Arguments:
@@ -69,15 +68,15 @@
         """
         Add a alias -> table_name mapping
         Arguments:
             alias (str): name of alias
             table_name (str): name of the table
         """
         self._check_duplicate_alias(alias)
-        table_obj = self._catalog.get_table_catalog_entry(table_name)
+        table_obj = self._catalog().get_table_catalog_entry(table_name)
         self._table_alias_map[alias] = table_obj
 
     def add_derived_table_alias(
         self,
         alias: str,
         target_list: List[
             Union[TupleValueExpression, FunctionExpression, UdfIOCatalogEntry]
@@ -141,15 +140,15 @@
             alias (str): alias name
 
         Returns:
             column object
         """
         table_obj = self._table_alias_map.get(alias, None)
         if table_obj:
-            return self._catalog.get_column_catalog_entry(table_obj, col_name)
+            return self._catalog().get_column_catalog_entry(table_obj, col_name)
 
     def _check_derived_table_alias_map(self, alias, col_name) -> CatalogColumnType:
         """
         Find the column object in derived table alias map
         Arguments:
             col_name (str): column name
             alias (str): alias name
```

### Comparing `evadb-0.2.6/eva/catalog/__init__.py` & `evadb-0.2.7/evadb/catalog/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/catalog/catalog_manager.py` & `evadb-0.2.7/evadb/catalog/catalog_manager.py`

 * *Files 9% similar despite different names*

```diff
@@ -12,79 +12,80 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import shutil
 from pathlib import Path
 from typing import List
 
-from eva.catalog.catalog_type import (
+from evadb.catalog.catalog_type import (
     ColumnType,
     TableType,
     VectorStoreType,
     VideoColumnName,
 )
-from eva.catalog.catalog_utils import (
+from evadb.catalog.catalog_utils import (
     cleanup_storage,
     construct_udf_cache_catalog_entry,
     get_document_table_column_definitions,
     get_image_table_column_definitions,
     get_pdf_table_column_definitions,
     get_video_table_column_definitions,
     xform_column_definitions_to_catalog_entries,
 )
-from eva.catalog.models.base_model import (
+from evadb.catalog.models.utils import (
+    ColumnCatalogEntry,
+    IndexCatalogEntry,
+    TableCatalogEntry,
+    UdfCacheCatalogEntry,
+    UdfCatalogEntry,
+    UdfCostCatalogEntry,
+    UdfIOCatalogEntry,
+    UdfMetadataCatalogEntry,
     drop_all_tables_except_catalog,
     init_db,
     truncate_catalog_tables,
 )
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.index_catalog import IndexCatalogEntry
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.catalog.models.udf_cache_catalog import UdfCacheCatalogEntry
-from eva.catalog.models.udf_catalog import UdfCatalogEntry
-from eva.catalog.models.udf_cost_catalog import UdfCostCatalogEntry
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.catalog.models.udf_metadata_catalog import UdfMetadataCatalogEntry
-from eva.catalog.services.column_catalog_service import ColumnCatalogService
-from eva.catalog.services.index_catalog_service import IndexCatalogService
-from eva.catalog.services.table_catalog_service import TableCatalogService
-from eva.catalog.services.udf_cache_catalog_service import UdfCacheCatalogService
-from eva.catalog.services.udf_catalog_service import UdfCatalogService
-from eva.catalog.services.udf_cost_catalog_service import UdfCostCatalogService
-from eva.catalog.services.udf_io_catalog_service import UdfIOCatalogService
-from eva.catalog.services.udf_metadata_catalog_service import UdfMetadataCatalogService
-from eva.catalog.sql_config import IDENTIFIER_COLUMN
-from eva.expression.function_expression import FunctionExpression
-from eva.parser.create_statement import ColumnDefinition
-from eva.parser.table_ref import TableInfo
-from eva.parser.types import FileFormatType
-from eva.utils.generic_utils import generate_file_path, get_file_checksum
-from eva.utils.logging_manager import logger
+from evadb.catalog.services.column_catalog_service import ColumnCatalogService
+from evadb.catalog.services.index_catalog_service import IndexCatalogService
+from evadb.catalog.services.table_catalog_service import TableCatalogService
+from evadb.catalog.services.udf_cache_catalog_service import UdfCacheCatalogService
+from evadb.catalog.services.udf_catalog_service import UdfCatalogService
+from evadb.catalog.services.udf_cost_catalog_service import UdfCostCatalogService
+from evadb.catalog.services.udf_io_catalog_service import UdfIOCatalogService
+from evadb.catalog.services.udf_metadata_catalog_service import (
+    UdfMetadataCatalogService,
+)
+from evadb.catalog.sql_config import IDENTIFIER_COLUMN, SQLConfig
+from evadb.configuration.configuration_manager import ConfigurationManager
+from evadb.expression.function_expression import FunctionExpression
+from evadb.parser.create_statement import ColumnDefinition
+from evadb.parser.table_ref import TableInfo
+from evadb.parser.types import FileFormatType
+from evadb.utils.generic_utils import generate_file_path, get_file_checksum
+from evadb.utils.logging_manager import logger
 
 
 class CatalogManager(object):
-    def __new__(cls):
-        if not hasattr(cls, "_instance"):
-            cls._instance = super(CatalogManager, cls).__new__(cls)
-
-            cls._instance._bootstrap_catalog()
-
-        return cls._instance
-
-    def __init__(self):
-        self._table_catalog_service: TableCatalogService = TableCatalogService()
-        self._column_service: ColumnCatalogService = ColumnCatalogService()
-        self._udf_service: UdfCatalogService = UdfCatalogService()
-        self._udf_cost_catalog_service: UdfCostCatalogService = UdfCostCatalogService()
-        self._udf_io_service: UdfIOCatalogService = UdfIOCatalogService()
-        self._udf_metadata_service: UdfMetadataCatalogService = (
-            UdfMetadataCatalogService()
-        )
-        self._index_service: IndexCatalogService = IndexCatalogService()
-        self._udf_cache_service: UdfCacheCatalogService = UdfCacheCatalogService()
+    def __init__(self, db_uri: str, config: ConfigurationManager):
+        self._db_uri = db_uri
+        self._sql_config = SQLConfig(db_uri)
+        self._config = config
+        self._bootstrap_catalog()
+        self._table_catalog_service = TableCatalogService(self._sql_config.session)
+        self._column_service = ColumnCatalogService(self._sql_config.session)
+        self._udf_service = UdfCatalogService(self._sql_config.session)
+        self._udf_cost_catalog_service = UdfCostCatalogService(self._sql_config.session)
+        self._udf_io_service = UdfIOCatalogService(self._sql_config.session)
+        self._udf_metadata_service = UdfMetadataCatalogService(self._sql_config.session)
+        self._index_service = IndexCatalogService(self._sql_config.session)
+        self._udf_cache_service = UdfCacheCatalogService(self._sql_config.session)
+
+    @property
+    def sql_config(self):
+        return self._sql_config
 
     def reset(self):
         """
         This method resets the state of the singleton instance.
         It should clear the contents of the catalog tables and any storage data
         Used by testcases to reset the db state before
         """
@@ -93,28 +94,28 @@
     def _bootstrap_catalog(self):
         """Bootstraps catalog.
         This method runs all tasks required for using catalog. Currently,
         it includes only one task ie. initializing database. It creates the
         catalog database and tables if they do not exist.
         """
         logger.info("Bootstrapping catalog")
-        init_db()
+        init_db(self._sql_config.engine)
 
     def _clear_catalog_contents(self):
         """
         This method is responsible for clearing the contents of the
         catalog. It clears the tuples in the catalog tables, indexes, and cached data.
         """
         logger.info("Clearing catalog")
         # drop tables which are not part of catalog
-        drop_all_tables_except_catalog()
+        drop_all_tables_except_catalog(self._sql_config.engine)
         # truncate the catalog tables
-        truncate_catalog_tables()
+        truncate_catalog_tables(self._sql_config.engine)
         # clean up the dataset, index, and cache directories
-        cleanup_storage()
+        cleanup_storage(self._config)
 
     "Table catalog services"
 
     def insert_table_catalog_entry(
         self,
         name: str,
         file_url: str,
@@ -338,15 +339,16 @@
 
     def get_all_index_catalog_entries(self):
         return self._index_service.get_all_entries()
 
     """ Udf Cache related"""
 
     def insert_udf_cache_catalog_entry(self, func_expr: FunctionExpression):
-        entry = construct_udf_cache_catalog_entry(func_expr)
+        cache_dir = self._config.get_value("storage", "cache_dir")
+        entry = construct_udf_cache_catalog_entry(func_expr, cache_dir=cache_dir)
         return self._udf_cache_service.insert_entry(entry)
 
     def get_udf_cache_catalog_entry_by_name(self, name: str) -> UdfCacheCatalogEntry:
         return self._udf_cache_service.get_entry_by_name(name)
 
     def drop_udf_cache_catalog_entry(self, entry: UdfCacheCatalogEntry) -> bool:
         # remove the data structure associated with the entry
@@ -393,15 +395,17 @@
             table_type (TableType, optional): table type. Defaults to TableType.STRUCTURED_DATA.
 
         Returns:
             TableCatalogEntry: entry that has been inserted into the table catalog
         """
         table_name = table_info.table_name
         column_catalog_entries = xform_column_definitions_to_catalog_entries(columns)
-        file_url = str(generate_file_path(table_name))
+
+        dataset_location = self._config.get_value("core", "datasets_dir")
+        file_url = str(generate_file_path(dataset_location, table_name))
         table_catalog_entry = self.insert_table_catalog_entry(
             table_name,
             file_url,
             column_catalog_entries,
             identifier_column=identifier_column,
             table_type=table_type,
         )
@@ -491,7 +495,19 @@
         obj = self.create_and_insert_table_catalog_entry(
             TableInfo(media_metadata_name),
             columns,
             identifier_column=columns[0].name,
             table_type=TableType.SYSTEM_STRUCTURED_DATA,
         )
         return obj
+
+
+#### get catalog instance
+# This function plays a crucial role in ensuring that different threads do
+# not share the same catalog object, as it can result in serialization issues and
+# incorrect behavior with SQLAlchemy. Therefore, whenever a catalog instance is
+# required, we create a new one. One possible optimization is to share the catalog
+# instance across all objects within the same thread. It is worth investigating whether
+# SQLAlchemy already handles this optimization for us, which will be explored at a
+# later time.
+def get_catalog_instance(db_uri: str, config: ConfigurationManager):
+    return CatalogManager(db_uri, config)
```

### Comparing `evadb-0.2.6/eva/catalog/catalog_type.py` & `evadb-0.2.7/evadb/catalog/catalog_type.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from eva.utils.generic_utils import EVAEnum
+from evadb.utils.generic_utils import EVAEnum
 
 
 class Dimension(EVAEnum):
     ANYDIM  # noqa: F821
 
 
 class TableType(EVAEnum):
```

### Comparing `evadb-0.2.6/eva/catalog/catalog_utils.py` & `evadb-0.2.7/evadb/catalog/catalog_utils.py`

 * *Files 16% similar despite different names*

```diff
@@ -12,32 +12,34 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import uuid
 from pathlib import Path
 from typing import Any, Dict, List
 
-from eva.catalog.catalog_type import (
+from evadb.catalog.catalog_type import (
     ColumnType,
     DocumentColumnName,
     ImageColumnName,
     NdArrayType,
     PDFColumnName,
     TableType,
     VideoColumnName,
 )
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.catalog.models.udf_cache_catalog import UdfCacheCatalogEntry
-from eva.catalog.models.udf_catalog import UdfCatalogEntry
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.expression.function_expression import FunctionExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.create_statement import ColConstraintInfo, ColumnDefinition
-from eva.utils.generic_utils import get_str_hash, remove_directory_contents
+from evadb.catalog.models.utils import (
+    ColumnCatalogEntry,
+    TableCatalogEntry,
+    UdfCacheCatalogEntry,
+    UdfCatalogEntry,
+)
+from evadb.configuration.configuration_manager import ConfigurationManager
+from evadb.expression.function_expression import FunctionExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.create_statement import ColConstraintInfo, ColumnDefinition
+from evadb.utils.generic_utils import get_str_hash, remove_directory_contents
 
 CATALOG_TABLES = [
     "column_catalog",
     "table_catalog",
     "depend_column_and_udf_cache",
     "udf_cache",
     "udf_catalog",
@@ -49,14 +51,21 @@
 ]
 
 
 def is_video_table(table: TableCatalogEntry):
     return table.table_type == TableType.VIDEO_DATA
 
 
+def is_document_table(table: TableCatalogEntry):
+    return (
+        table.table_type == TableType.DOCUMENT_DATA
+        or table.table_type == TableType.PDF_DATA
+    )
+
+
 def is_string_col(col: ColumnCatalogEntry):
     return col.type == ColumnType.TEXT or col.array_type == NdArrayType.STR
 
 
 def get_video_table_column_definitions() -> List[ColumnDefinition]:
     """
     name: video path
@@ -185,53 +194,52 @@
         # todo: change me
         result_list.append(column_entry)
 
     return result_list
 
 
 def construct_udf_cache_catalog_entry(
-    func_expr: FunctionExpression,
+    func_expr: FunctionExpression, cache_dir: str
 ) -> UdfCacheCatalogEntry:
     """Constructs a udf cache catalog entry from a given function expression.
     It is assumed that the function expression has already been bound using the binder.
     The catalog entry is populated with dependent udfs and columns by traversing the
     expression tree. The cache name is represented by the signature of the function
     expression.
     Args:
         func_expr (FunctionExpression): the function expression with which the cache is associated
+        cache_dir (str): path to store the cache
     Returns:
         UdfCacheCatalogEntry: the udf cache catalog entry
     """
     udf_depends = []
     col_depends = []
     for expr in func_expr.find_all(FunctionExpression):
         udf_depends.append(expr.udf_obj.row_id)
     for expr in func_expr.find_all(TupleValueExpression):
         col_depends.append(expr.col_object.row_id)
     cache_name = func_expr.signature()
 
     # add salt to the cache_name so that we generate unique name
     path = str(get_str_hash(cache_name + uuid.uuid4().hex))
-    cache_dir = ConfigurationManager().get_value("storage", "cache_dir")
     cache_path = str(Path(cache_dir) / Path(f"{path}_{func_expr.name}"))
     args = tuple([arg.signature() for arg in func_expr.children])
     entry = UdfCacheCatalogEntry(
         name=func_expr.signature(),
         udf_id=func_expr.udf_obj.row_id,
         cache_path=cache_path,
         args=args,
         udf_depends=udf_depends,
         col_depends=col_depends,
     )
 
     return entry
 
 
-def cleanup_storage():
-    config = ConfigurationManager()
+def cleanup_storage(config):
     remove_directory_contents(config.get_value("storage", "index_dir"))
     remove_directory_contents(config.get_value("storage", "cache_dir"))
     remove_directory_contents(config.get_value("core", "datasets_dir"))
 
 
 def get_metadata_entry_or_val(
     udf_obj: UdfCatalogEntry, key: str, default_val: Any = None
@@ -265,7 +273,21 @@
     Returns:
         Dict: key-value for each metadata entry
     """
     properties = {}
     for metadata in udf_obj.metadata:
         properties[metadata.key] = metadata.value
     return properties
+
+
+#### get catalog instance
+# This function plays a crucial role in ensuring that different threads do
+# not share the same catalog object, as it can result in serialization issues and
+# incorrect behavior with SQLAlchemy. Therefore, whenever a catalog instance is
+# required, we create a new one. One possible optimization is to share the catalog
+# instance across all objects within the same thread. It is worth investigating whether
+# SQLAlchemy already handles this optimization for us, which will be explored at a
+# later time.
+def get_catalog_instance(db_uri: str, config: ConfigurationManager):
+    from evadb.catalog.catalog_manager import CatalogManager
+
+    return CatalogManager(db_uri, config)
```

### Comparing `evadb-0.2.6/eva/catalog/models/association_models.py` & `evadb-0.2.7/evadb/catalog/models/association_models.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from sqlalchemy import Column, ForeignKey, Table, UniqueConstraint
 
-from eva.catalog.models.base_model import BaseModel
+from evadb.catalog.models.base_model import BaseModel
 
 # dependency table to maintain a many-to-many relationship between udf_catalog and udf_cache_catalog. This is important to ensure that any changes to udf are propagated to udf_cache. For example, deletion of a udf should also clear the associated caches.
 
 depend_udf_and_udf_cache = Table(
     "depend_udf_and_udf_cache",
     BaseModel.metadata,
     Column("_udf_id", ForeignKey("udf_catalog._row_id")),
```

### Comparing `evadb-0.2.6/eva/catalog/models/base_model.py` & `evadb-0.2.7/evadb/catalog/models/base_model.py`

 * *Files 11% similar despite different names*

```diff
@@ -10,134 +10,132 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import contextlib
 
+import sqlalchemy
 from sqlalchemy import Column, Integer
+from sqlalchemy.engine import Engine
 from sqlalchemy.exc import SQLAlchemyError
 from sqlalchemy.ext.declarative import declarative_base
 from sqlalchemy_utils import create_database, database_exists
 
-from eva.catalog.sql_config import CATALOG_TABLES, SQLConfig
-from eva.utils.logging_manager import logger
-
-db_session = SQLConfig().session
+from evadb.catalog.sql_config import CATALOG_TABLES
+from evadb.utils.logging_manager import logger
 
 
 class CustomModel:
     """This overrides the default `_declarative_constructor` constructor.
 
     It skips the attributes that are not present for the model, thus if a
     dict is passed with some unknown attributes for the model on creation,
     it won't complain for `unknown field`s.
     Declares and int `_row_id` field for all tables
     """
 
-    query = db_session.query_property()
     _row_id = Column("_row_id", Integer, primary_key=True)
 
     def __init__(self, **kwargs):
         cls_ = type(self)
         for k in kwargs:
             if hasattr(cls_, k):
                 setattr(self, k, kwargs[k])
             else:
                 continue
 
-    def save(self):
+    def save(self, db_session):
         """Add and commit
 
         Returns: saved object
 
         """
         try:
             db_session.add(self)
-            self._commit()
+            self._commit(db_session)
         except Exception as e:
             db_session.rollback()
             logger.error(f"Database save failed : {str(e)}")
             raise e
         return self
 
-    def update(self, **kwargs):
+    def update(self, db_session, **kwargs):
         """Update and commit
 
         Args:
             **kwargs: attributes to update
 
         Returns: updated object
 
         """
         try:
             for attr, value in kwargs.items():
                 if hasattr(self, attr):
                     setattr(self, attr, value)
-            return self.save()
+            return self.save(db_session)
         except Exception as e:
             db_session.rollback()
             logger.error(f"Database update failed : {str(e)}")
             raise e
 
-    def delete(self):
+    def delete(self, db_session):
         """Delete and commit"""
         try:
             db_session.delete(self)
-            self._commit()
+            self._commit(db_session)
         except Exception as e:
             db_session.rollback()
             logger.error(f"Database delete failed : {str(e)}")
             raise e
 
-    def _commit(self):
+    def _commit(self, db_session):
         """Try to commit. If an error is raised, the session is rollbacked."""
         try:
             db_session.commit()
         except SQLAlchemyError as e:
             db_session.rollback()
             logger.error(f"Database commit failed : {str(e)}")
             raise e
 
 
 # Custom Base Model to be inherited by all models
-BaseModel = declarative_base(cls=CustomModel, constructor=None, bind=SQLConfig().engine)
+BaseModel = declarative_base(cls=CustomModel, constructor=None)
 
 
-def init_db():
+def init_db(engine: Engine):
     """Create database if doesn't exist and create all tables."""
-    engine = SQLConfig().engine
     if not database_exists(engine.url):
         logger.info("Database does not exist, creating database.")
         create_database(engine.url)
         logger.info("Creating tables")
-        BaseModel.metadata.create_all()
+        BaseModel.metadata.create_all(bind=engine)
 
 
-def truncate_catalog_tables():
+def truncate_catalog_tables(engine: Engine):
     """Truncate all the catalog tables"""
     # https://stackoverflow.com/questions/4763472/sqlalchemy-clear-database-content-but-dont-drop-the-schema/5003705#5003705 #noqa
-    engine = SQLConfig().engine
     # reflect to refresh the metadata
     BaseModel.metadata.reflect(bind=engine)
+    insp = sqlalchemy.inspect(engine)
     if database_exists(engine.url):
         with contextlib.closing(engine.connect()) as con:
             trans = con.begin()
             for table in reversed(BaseModel.metadata.sorted_tables):
-                if table.exists(con):
+                if insp.has_table(table.name):
                     con.execute(table.delete())
             trans.commit()
 
 
-def drop_all_tables_except_catalog():
+def drop_all_tables_except_catalog(engine: Engine):
     """drop all the tables except the catalog"""
-    engine = SQLConfig().engine
     # reflect to refresh the metadata
     BaseModel.metadata.reflect(bind=engine)
+    insp = sqlalchemy.inspect(engine)
     if database_exists(engine.url):
         with contextlib.closing(engine.connect()) as con:
             trans = con.begin()
             for table in reversed(BaseModel.metadata.sorted_tables):
                 if table.name not in CATALOG_TABLES:
-                    if table.exists(con):
+                    if insp.has_table(table.name):
                         table.drop(con)
             trans.commit()
```

### Comparing `evadb-0.2.6/eva/catalog/models/column_catalog.py` & `evadb-0.2.7/evadb/catalog/models/column_catalog.py`

 * *Files 12% similar despite different names*

```diff
@@ -10,29 +10,25 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from __future__ import annotations
 
-import typing
 from ast import literal_eval
-from dataclasses import dataclass, field
-from typing import List, Tuple
-
-if typing.TYPE_CHECKING:
-    from eva.catalog.models.udf_cache_catalog import UdfCacheCatalogEntry
+from typing import Tuple
 
 from sqlalchemy import Boolean, Column, ForeignKey, Integer, String, UniqueConstraint
 from sqlalchemy.orm import relationship
 from sqlalchemy.types import Enum
 
-from eva.catalog.catalog_type import ColumnType, Dimension, NdArrayType
-from eva.catalog.models.association_models import depend_column_and_udf_cache
-from eva.catalog.models.base_model import BaseModel
+from evadb.catalog.catalog_type import ColumnType, Dimension, NdArrayType
+from evadb.catalog.models.association_models import depend_column_and_udf_cache
+from evadb.catalog.models.base_model import BaseModel
+from evadb.catalog.models.utils import ColumnCatalogEntry
 
 
 class ColumnCatalog(BaseModel):
     """The `ColumnCatalog` catalog stores information about the columns of the table.
     It maintains the following information for each column
     `_row_id:` an autogenerated identifier
     `_name: ` name of the column
@@ -114,24 +110,7 @@
             is_nullable=self._is_nullable,
             array_type=self._array_type,
             array_dimensions=self.array_dimensions,
             table_id=self._table_id,
             table_name=self._table_catalog._name,
             dep_caches=[cache.as_dataclass() for cache in self._dep_caches],
         )
-
-
-@dataclass(unsafe_hash=True)
-class ColumnCatalogEntry:
-    """Class decouples the ColumnCatalog from the sqlalchemy.
-    This is done to ensure we don't expose the sqlalchemy dependencies beyond catalog service. Further, sqlalchemy does not allow sharing of objects across threads.
-    """
-
-    name: str
-    type: ColumnType
-    is_nullable: bool = False
-    array_type: NdArrayType = None
-    array_dimensions: Tuple[int] = field(default_factory=tuple)
-    table_id: int = None
-    table_name: str = None
-    row_id: int = None
-    dep_caches: List[UdfCacheCatalogEntry] = field(compare=False, default_factory=list)
```

### Comparing `evadb-0.2.6/eva/catalog/models/index_catalog.py` & `evadb-0.2.7/evadb/catalog/models/index_catalog.py`

 * *Files 12% similar despite different names*

```diff
@@ -8,23 +8,22 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from dataclasses import dataclass
 
 from sqlalchemy import Column, ForeignKey, Integer, String
 from sqlalchemy.orm import relationship
 from sqlalchemy.types import Enum
 
-from eva.catalog.catalog_type import VectorStoreType
-from eva.catalog.models.base_model import BaseModel
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.catalog_type import VectorStoreType
+from evadb.catalog.models.base_model import BaseModel
+from evadb.catalog.models.utils import IndexCatalogEntry
 
 
 class IndexCatalog(BaseModel):
     """The `IndexCatalogEntry` catalog stores information about all the indexes in the system.
     `_row_id:` an autogenerated unique identifier.
     `_name:` the name of the index.
     `_save_file_path:` the path to the index file on disk
@@ -70,22 +69,7 @@
             name=self._name,
             save_file_path=self._save_file_path,
             type=self._type,
             feat_column_id=self._feat_column_id,
             udf_signature=self._udf_signature,
             feat_column=feat_column,
         )
-
-
-@dataclass(unsafe_hash=True)
-class IndexCatalogEntry:
-    """Dataclass representing an entry in the IndexCatalogEntry.
-    This is done to ensure we don't expose the sqlalchemy dependencies beyond catalog service. Further, sqlalchemy does not allow sharing of objects across threads.
-    """
-
-    name: str
-    save_file_path: str
-    type: VectorStoreType
-    row_id: int = None
-    feat_column_id: int = None
-    udf_signature: str = None
-    feat_column: ColumnCatalogEntry = None
```

### Comparing `evadb-0.2.6/eva/catalog/models/table_catalog.py` & `evadb-0.2.7/evadb/catalog/models/table_catalog.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,23 +8,21 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from dataclasses import dataclass, field
-from typing import List
 
 from sqlalchemy import Column, Enum, String
 from sqlalchemy.orm import relationship
 
-from eva.catalog.catalog_type import TableType
-from eva.catalog.models.base_model import BaseModel
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.catalog_type import TableType
+from evadb.catalog.models.base_model import BaseModel
+from evadb.catalog.models.utils import TableCatalogEntry
 
 
 class TableCatalog(BaseModel):
     """The `TableCatalog` catalog stores information about all tables (structured, media, etc.) and materialized views. It has the following columns, not all of which are relevant for all table types.
     `_row_id:` an autogenerated unique identifier.
     `_name:` the name of the table, view, etc.
     `_file_url:` the path to the data file on disk
@@ -59,21 +57,7 @@
             row_id=self._row_id,
             name=self._name,
             file_url=self._file_url,
             identifier_column=self._identifier_column,
             table_type=self._table_type,
             columns=column_entries,
         )
-
-
-@dataclass(unsafe_hash=True)
-class TableCatalogEntry:
-    """Dataclass representing an entry in the ColumnCatalog.
-    This is done to ensure we don't expose the sqlalchemy dependencies beyond catalog service. Further, sqlalchemy does not allow sharing of objects across threads.
-    """
-
-    name: str
-    file_url: str
-    table_type: TableType
-    identifier_column: str = "id"
-    columns: List[ColumnCatalogEntry] = field(compare=False, default_factory=list)
-    row_id: int = None
```

### Comparing `evadb-0.2.6/eva/catalog/models/udf_cache_catalog.py` & `evadb-0.2.7/evadb/catalog/models/udf_cache_catalog.py`

 * *Files 14% similar despite different names*

```diff
@@ -9,25 +9,25 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from ast import literal_eval
-from dataclasses import dataclass, field
 from typing import Tuple
 
 from sqlalchemy import Column, ForeignKey, Integer, String, UniqueConstraint
 from sqlalchemy.orm import relationship
 
-from eva.catalog.models.association_models import (
+from evadb.catalog.models.association_models import (
     depend_column_and_udf_cache,
     depend_udf_and_udf_cache,
 )
-from eva.catalog.models.base_model import BaseModel
+from evadb.catalog.models.base_model import BaseModel
+from evadb.catalog.models.utils import UdfCacheCatalogEntry
 
 
 class UdfCacheCatalog(BaseModel):
     """The `UdfCacheCatalog` catalog stores information about the udf cache.
 
     It maintains the following information for each cache entry:
     `_row_id:` An autogenerated identifier for the cache entry.
@@ -77,22 +77,7 @@
             name=self._name,
             udf_id=self._udf_id,
             cache_path=self._cache_path,
             args=literal_eval(self._args),
             udf_depends=udf_depends,
             col_depends=col_depends,
         )
-
-
-@dataclass(unsafe_hash=True)
-class UdfCacheCatalogEntry:
-    """Dataclass representing an entry in the `UdfCatalog`.
-    This is done to ensure we don't expose the sqlalchemy dependencies beyond catalog service. Further, sqlalchemy does not allow sharing of objects across threads.
-    """
-
-    name: str
-    udf_id: int
-    cache_path: str
-    args: Tuple[str]
-    row_id: int = None
-    udf_depends: Tuple[int] = field(compare=False, default_factory=tuple)
-    col_depends: Tuple[int] = field(compare=False, default_factory=tuple)
```

### Comparing `evadb-0.2.6/eva/catalog/models/udf_cost_catalog.py` & `evadb-0.2.7/evadb/catalog/models/udf_cost_catalog.py`

 * *Files 18% similar despite different names*

```diff
@@ -8,19 +8,19 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from dataclasses import dataclass
 
 from sqlalchemy import Column, Float, ForeignKey, Integer, String
 
-from eva.catalog.models.base_model import BaseModel
+from evadb.catalog.models.base_model import BaseModel
+from evadb.catalog.models.utils import UdfCostCatalogEntry
 
 
 class UdfCostCatalog(BaseModel):
     """The `UdfCostCatalog` catalog stores information about the runtime of user-defined functions (UDFs) in the system. It maintains the following information for each UDF.
     `_row_id:` an autogenerated unique identifier.
     `_name:` name of the UDF
     `_udf_id`: the row_id of the UDF
@@ -45,22 +45,7 @@
     def as_dataclass(self) -> "UdfCostCatalogEntry":
         return UdfCostCatalogEntry(
             udf_id=self._udf_id,
             name=self._udf_name,
             cost=self._cost,
             row_id=self._row_id,
         )
-
-
-@dataclass(unsafe_hash=True)
-class UdfCostCatalogEntry:
-    """Dataclass representing an entry in the `UdfCostCatalog`.
-    This is done to ensure we don't expose the sqlalchemy dependencies beyond catalog service. Further, sqlalchemy does not allow sharing of objects across threads.
-    """
-
-    name: str
-    cost: float = None
-    udf_id: int = None
-    row_id: int = None
-
-    def display_format(self):
-        return {"udf_id": self.udf_id, "name": self.name, "cost": self.cost}
```

### Comparing `evadb-0.2.6/eva/catalog/models/udf_io_catalog.py` & `evadb-0.2.7/evadb/catalog/models/udf_io_catalog.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,23 +9,23 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from ast import literal_eval
-from dataclasses import dataclass
 from typing import Tuple
 
 from sqlalchemy import Boolean, Column, ForeignKey, Integer, String, UniqueConstraint
 from sqlalchemy.orm import relationship
 from sqlalchemy.types import Enum
 
-from eva.catalog.catalog_type import ColumnType, Dimension, NdArrayType
-from eva.catalog.models.base_model import BaseModel
+from evadb.catalog.catalog_type import ColumnType, Dimension, NdArrayType
+from evadb.catalog.models.base_model import BaseModel
+from evadb.catalog.models.utils import UdfIOCatalogEntry
 
 
 class UdfIOCatalog(BaseModel):
     """The `UdfIOCatalog` catalog stores information about the input and output
     attributes of user-defined functions (UDFs). It maintains the following information
     for each attribute:
     `_row_id:` an autogenerated identifier
@@ -96,33 +96,7 @@
             is_nullable=self._is_nullable,
             array_type=self._array_type,
             array_dimensions=self.array_dimensions,
             is_input=self._is_input,
             udf_id=self._udf_id,
             udf_name=self._udf._name,
         )
-
-
-@dataclass(unsafe_hash=True)
-class UdfIOCatalogEntry:
-    """Class decouples the `UdfIOCatalog` from the sqlalchemy.
-    This is done to ensure we don't expose the sqlalchemy dependencies beyond catalog service. Further, sqlalchemy does not allow sharing of objects across threads.
-    """
-
-    name: str
-    type: ColumnType
-    is_nullable: bool = False
-    array_type: NdArrayType = None
-    array_dimensions: Tuple[int] = None
-    is_input: bool = True
-    udf_id: int = None
-    udf_name: str = None
-    row_id: int = None
-
-    def display_format(self):
-        data_type = self.type.name
-        if self.type == ColumnType.NDARRAY:
-            data_type = "{} {} {}".format(
-                data_type, self.array_type.name, self.array_dimensions
-            )
-
-        return {"name": self.name, "data_type": data_type}
```

### Comparing `evadb-0.2.6/eva/catalog/models/udf_metadata_catalog.py` & `evadb-0.2.7/evadb/catalog/models/udf_metadata_catalog.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,20 +8,20 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from dataclasses import dataclass
 
 from sqlalchemy import Column, ForeignKey, Integer, String, UniqueConstraint
 from sqlalchemy.orm import relationship
 
-from eva.catalog.models.base_model import BaseModel
+from evadb.catalog.models.base_model import BaseModel
+from evadb.catalog.models.utils import UdfMetadataCatalogEntry
 
 
 class UdfMetadataCatalog(BaseModel):
     """
     The `UdfMetadataCatalog` catalog stores information about the metadata of user-defined functions (UDFs).
     Metadata is implemented a key-value pair that can be used to store additional information about the UDF.
     It maintains the following information for each attribute:
@@ -51,23 +51,7 @@
         return UdfMetadataCatalogEntry(
             row_id=self._row_id,
             key=self._key,
             value=self._value,
             udf_id=self._udf_id,
             udf_name=self._udf._name,
         )
-
-
-@dataclass(unsafe_hash=True)
-class UdfMetadataCatalogEntry:
-    """Class decouples the `UdfMetadataCatalog` from the sqlalchemy.
-    This is done to ensure we don't expose the sqlalchemy dependencies beyond catalog service. Further, sqlalchemy does not allow sharing of objects across threads.
-    """
-
-    key: str
-    value: str
-    udf_id: int = None
-    udf_name: str = None
-    row_id: int = None
-
-    def display_format(self):
-        return f"{self.udf_name} - {self.key}: {self.value}"
```

### Comparing `evadb-0.2.6/eva/catalog/schema_utils.py` & `evadb-0.2.7/evadb/catalog/schema_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,17 +12,17 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Dict, List
 
 from sqlalchemy import TEXT, Column, Float, Integer, LargeBinary
 
-from eva.catalog.catalog_type import ColumnType
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.utils.logging_manager import logger
+from evadb.catalog.catalog_type import ColumnType
+from evadb.catalog.models.utils import ColumnCatalogEntry
+from evadb.utils.logging_manager import logger
 
 
 class SchemaUtils(object):
     @staticmethod
     def xform_to_sqlalchemy_column(df_column: ColumnCatalogEntry) -> Column:
         column_type = df_column.type
```

### Comparing `evadb-0.2.6/eva/catalog/services/__init__.py` & `evadb-0.2.7/evadb/catalog/models/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/catalog/services/base_service.py` & `evadb-0.2.7/evadb/catalog/services/base_service.py`

 * *Files 18% similar despite different names*

```diff
@@ -10,27 +10,30 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
+from sqlalchemy.orm import Session
 from sqlalchemy.orm.exc import NoResultFound
 
-from eva.catalog.models.base_model import BaseModel
+from evadb.catalog.models.base_model import BaseModel
 
 
 class BaseService:
     """
     Base service for all the models. Implemented by all other services.
     The services perform business logic using the model provided
     """
 
-    def __init__(self, model: BaseModel):
+    def __init__(self, model: BaseModel, session: Session):
         self.model = model
+        self.session = session
+        self.query = session.query(model)
 
     def get_all_entries(self) -> List:
         try:
-            entries = self.model.query.all()
+            entries = self.query.all()
             return [entry.as_dataclass() for entry in entries]
         except NoResultFound:
             return []
```

### Comparing `evadb-0.2.6/eva/catalog/services/column_catalog_service.py` & `evadb-0.2.7/evadb/catalog/services/column_catalog_service.py`

 * *Files 23% similar despite different names*

```diff
@@ -10,45 +10,59 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
+from sqlalchemy.orm import Session
 from sqlalchemy.orm.exc import NoResultFound
+from sqlalchemy.sql.expression import select
 
-from eva.catalog.models.column_catalog import ColumnCatalog, ColumnCatalogEntry
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.catalog.services.base_service import BaseService
+from evadb.catalog.models.column_catalog import ColumnCatalog
+from evadb.catalog.models.utils import ColumnCatalogEntry, TableCatalogEntry
+from evadb.catalog.services.base_service import BaseService
 
 
 class ColumnCatalogService(BaseService):
-    def __init__(self):
-        super().__init__(ColumnCatalog)
+    def __init__(self, db_session: Session):
+        super().__init__(ColumnCatalog, db_session)
 
     def filter_entry_by_table_id_and_name(
         self, table_id, column_name
     ) -> ColumnCatalogEntry:
-        entry = self.model.query.filter(
-            self.model._table_id == table_id,
-            self.model._name == column_name,
-        ).one_or_none()
+        entry = self.session.execute(
+            select(self.model).filter(
+                self.model._table_id == table_id,
+                self.model._name == column_name,
+            )
+        ).scalar_one_or_none()
         if entry:
             return entry.as_dataclass()
         return entry
 
     def filter_entries_by_table_id(self, table_id: int) -> List[ColumnCatalogEntry]:
         """return all the columns for table table_id"""
-        entries = self.model.query.filter(self.model._table_id == table_id).all()
+        entries = (
+            self.session.execute(
+                select(self.model).filter(
+                    self.model._table_id == table_id,
+                )
+            )
+            .scalars()
+            .all()
+        )
         return [entry.as_dataclass() for entry in entries]
 
     def get_entry_by_id(
         self, col_id: int, return_alchemy=False
     ) -> List[ColumnCatalogEntry]:
-        entry = self.model.query.filter(self.model._row_id == col_id).one_or_none()
+        entry = self.session.execute(
+            select(self.model).filter(self.model._row_id == col_id)
+        ).scalar_one_or_none()
         if entry:
             return entry if return_alchemy else entry.as_dataclass()
         return entry
 
     def insert_entries(self, column_list: List[ColumnCatalogEntry]):
         catalog_column_objs = [
             self.model(
@@ -59,21 +73,25 @@
                 array_dimensions=col.array_dimensions,
                 table_id=col.table_id,
             )
             for col in column_list
         ]
         saved_column_objs = []
         for column in catalog_column_objs:
-            saved_column_objs.append(column.save())
+            saved_column_objs.append(column.save(self.session))
         return [obj.as_dataclass() for obj in saved_column_objs]
 
     def filter_entries_by_table(
         self, table: TableCatalogEntry
     ) -> List[ColumnCatalogEntry]:
         try:
-            entries = self.model.query.filter(
-                self.model._table_id == table.row_id
-            ).all()
+            entries = (
+                self.session.execute(
+                    select(self.model).filter(self.model._table_id == table.row_id)
+                )
+                .scalars()
+                .all()
+            )
             return [entry.as_dataclass() for entry in entries]
 
         except NoResultFound:
             return None
```

### Comparing `evadb-0.2.6/eva/catalog/services/index_catalog_service.py` & `evadb-0.2.7/evadb/catalog/services/index_catalog_service.py`

 * *Files 9% similar despite different names*

```diff
@@ -10,72 +10,73 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 
+from sqlalchemy.orm import Session
 from sqlalchemy.orm.exc import NoResultFound
 
-from eva.catalog.catalog_type import VectorStoreType
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.index_catalog import IndexCatalog, IndexCatalogEntry
-from eva.catalog.services.base_service import BaseService
-from eva.utils.logging_manager import logger
+from evadb.catalog.catalog_type import VectorStoreType
+from evadb.catalog.models.index_catalog import IndexCatalog, IndexCatalogEntry
+from evadb.catalog.models.utils import ColumnCatalogEntry
+from evadb.catalog.services.base_service import BaseService
+from evadb.utils.logging_manager import logger
 
 
 class IndexCatalogService(BaseService):
-    def __init__(self):
-        super().__init__(IndexCatalog)
+    def __init__(self, db_session: Session):
+        super().__init__(IndexCatalog, db_session)
 
     def insert_entry(
         self,
         name: str,
         save_file_path: str,
         type: VectorStoreType,
         feat_column: ColumnCatalogEntry,
         udf_signature: str,
     ) -> IndexCatalogEntry:
         index_entry = IndexCatalog(
             name, save_file_path, type, feat_column.row_id, udf_signature
         )
-        index_entry = index_entry.save()
+        index_entry = index_entry.save(self.session)
         return index_entry.as_dataclass()
 
     def get_entry_by_name(self, name: str) -> IndexCatalogEntry:
         try:
-            entry = self.model.query.filter(self.model._name == name).one()
+            entry = self.query.filter(self.model._name == name).one()
             return entry.as_dataclass()
         except NoResultFound:
             return None
 
     def get_entry_by_id(self, id: int) -> IndexCatalogEntry:
         try:
-            entry = self.model.query.filter(self.model._row_id == id).one()
+            entry = self.query.filter(self.model._row_id == id).one()
             return entry.as_dataclass()
         except NoResultFound:
             return None
 
     def get_entry_by_column_and_udf_signature(
         self, column: ColumnCatalogEntry, udf_signature: str
     ):
         try:
-            entry = self.model.query.filter(
+            entry = self.query.filter(
                 self.model._feat_column_id == column.row_id,
                 self.model._udf_signature == udf_signature,
             ).one()
             return entry.as_dataclass()
         except NoResultFound:
             return None
 
     def delete_entry_by_name(self, name: str):
         try:
-            index_obj = self.model.query.filter(self.model._name == name).one()
+            index_obj = self.query.filter(self.model._name == name).one()
             index_metadata = index_obj.as_dataclass()
             # clean up the on disk data
             if os.path.exists(index_metadata.save_file_path):
                 os.remove(index_metadata.save_file_path)
-            index_obj.delete()
+            index_obj.delete(self.session)
         except Exception:
             logger.exception("Delete index failed for name {}".format(name))
             return False
         return True
```

### Comparing `evadb-0.2.6/eva/catalog/services/table_catalog_service.py` & `evadb-0.2.7/evadb/catalog/services/table_catalog_service.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,26 +9,29 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from eva.catalog.catalog_type import TableType
-from eva.catalog.models.table_catalog import TableCatalog, TableCatalogEntry
-from eva.catalog.services.base_service import BaseService
-from eva.catalog.services.column_catalog_service import ColumnCatalogService
-from eva.utils.errors import CatalogError
-from eva.utils.logging_manager import logger
+from sqlalchemy.orm import Session
+from sqlalchemy.sql.expression import select
+
+from evadb.catalog.catalog_type import TableType
+from evadb.catalog.models.table_catalog import TableCatalog, TableCatalogEntry
+from evadb.catalog.services.base_service import BaseService
+from evadb.catalog.services.column_catalog_service import ColumnCatalogService
+from evadb.utils.errors import CatalogError
+from evadb.utils.logging_manager import logger
 
 
 class TableCatalogService(BaseService):
-    def __init__(self):
-        super().__init__(TableCatalog)
-        self._column_service: ColumnCatalogService = ColumnCatalogService()
+    def __init__(self, db_session: Session):
+        super().__init__(TableCatalog, db_session)
+        self._column_service: ColumnCatalogService = ColumnCatalogService(db_session)
 
     def insert_entry(
         self,
         name: str,
         file_url: str,
         identifier_column: str,
         table_type: TableType,
@@ -45,15 +48,15 @@
         try:
             table_catalog_obj = self.model(
                 name=name,
                 file_url=file_url,
                 identifier_column=identifier_column,
                 table_type=table_type,
             )
-            table_catalog_obj = table_catalog_obj.save()
+            table_catalog_obj = table_catalog_obj.save(self.session)
 
             # populate the table_id for all the columns
             for column in column_list:
                 column.table_id = table_catalog_obj._row_id
             column_list = self._column_service.insert_entries(column_list)
 
         except Exception as e:
@@ -69,57 +72,62 @@
         Returns the table by ID
         Arguments:
             table_id (int)
             return_alchemy (bool): if True, return a sqlalchemy object
         Returns:
            TableCatalogEntry
         """
-        entry = self.model.query.filter(self.model._row_id == table_id).one()
+        entry = self.session.execute(
+            select(self.model).filter(self.model._row_id == table_id)
+        ).scalar_one()
         return entry if return_alchemy else entry.as_dataclass()
 
     def get_entry_by_name(
         self, database_name, table_name, return_alchemy=False
     ) -> TableCatalogEntry:
         """
         Get the table catalog entry with given table name.
         Arguments:
             database_name  (str): Database to which table belongs # TODO:
             use this field
             table_name (str): name of the table
         Returns:
             TableCatalogEntry - catalog entry for given table_name
         """
-        entry = self.model.query.filter(self.model._name == table_name).one_or_none()
+        entry = self.session.execute(
+            select(self.model).filter(self.model._name == table_name)
+        ).scalar_one_or_none()
         if entry:
             return entry if return_alchemy else entry.as_dataclass()
         return entry
 
     def delete_entry(self, table: TableCatalogEntry):
         """Delete table from the db
         Arguments:
             table  (TableCatalogEntry): table to delete
         Returns:
             True if successfully removed else false
         """
         try:
-            table_obj = self.model.query.filter(
-                self.model._row_id == table.row_id
-            ).one()
-            table_obj.delete()
+            table_obj = self.session.execute(
+                select(self.model).filter(self.model._row_id == table.row_id)
+            ).scalar_one_or_none()
+            table_obj.delete(self.session)
             return True
         except Exception as e:
             err_msg = f"Delete table failed for {table} with error {str(e)}."
             logger.exception(err_msg)
             raise CatalogError(err_msg)
 
     def rename_entry(self, table: TableCatalogEntry, new_name: str):
         try:
-            table_obj = self.model.query.filter(
-                self.model._row_id == table.row_id
-            ).one()
-            table_obj.update(_name=new_name)
+            table_obj = self.session.execute(
+                select(self.model).filter(self.model._row_id == table.row_id)
+            ).scalar_one_or_none()
+            if table_obj:
+                table_obj.update(self.session, _name=new_name)
         except Exception as e:
             err_msg = "Update table name failed for {} with error {}".format(
                 table.name, str(e)
             )
             logger.error(err_msg)
             raise RuntimeError(err_msg)
```

### Comparing `evadb-0.2.6/eva/catalog/services/udf_cache_catalog_service.py` & `evadb-0.2.7/evadb/catalog/services/udf_cache_catalog_service.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,30 +8,32 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
+from sqlalchemy.orm import Session
 from sqlalchemy.orm.exc import NoResultFound
+from sqlalchemy.sql.expression import select
 
-from eva.catalog.models.udf_cache_catalog import UdfCacheCatalog, UdfCacheCatalogEntry
-from eva.catalog.services.base_service import BaseService
-from eva.catalog.services.column_catalog_service import ColumnCatalogService
-from eva.catalog.services.udf_catalog_service import UdfCatalogService
-from eva.utils.errors import CatalogError
-from eva.utils.logging_manager import logger
+from evadb.catalog.models.udf_cache_catalog import UdfCacheCatalog
+from evadb.catalog.models.utils import UdfCacheCatalogEntry
+from evadb.catalog.services.base_service import BaseService
+from evadb.catalog.services.column_catalog_service import ColumnCatalogService
+from evadb.catalog.services.udf_catalog_service import UdfCatalogService
+from evadb.utils.errors import CatalogError
+from evadb.utils.logging_manager import logger
 
 
 class UdfCacheCatalogService(BaseService):
-    def __init__(self):
-        super().__init__(UdfCacheCatalog)
-        self._column_service: ColumnCatalogService = ColumnCatalogService()
-        self._udf_service: UdfCatalogService = UdfCatalogService()
+    def __init__(self, db_session: Session):
+        super().__init__(UdfCacheCatalog, db_session)
+        self._column_service: ColumnCatalogService = ColumnCatalogService(db_session)
+        self._udf_service: UdfCatalogService = UdfCatalogService(db_session)
 
     def insert_entry(self, entry: UdfCacheCatalogEntry) -> UdfCacheCatalogEntry:
         """Insert a new udf cache entry into udf cache catalog.
         Arguments:
             `name` (str): name of the cache table
             `udf_id` (int): `row_id` of the UDF on which the cache is built
             `cache_path` (str): path of the cache table
@@ -53,40 +55,44 @@
                 self._udf_service.get_entry_by_id(udf_id, return_alchemy=True)
                 for udf_id in entry.udf_depends
             ]
             cache_obj._col_depends = [
                 self._column_service.get_entry_by_id(col_id, return_alchemy=True)
                 for col_id in entry.col_depends
             ]
-            cache_obj = cache_obj.save()
+            cache_obj = cache_obj.save(self.session)
 
         except Exception as e:
             err_msg = (
                 f"Failed to insert entry into udf cache catalog with exception {str(e)}"
             )
             logger.exception(err_msg)
             raise CatalogError(err_msg)
         else:
             return cache_obj.as_dataclass()
 
     def get_entry_by_name(self, name: str) -> UdfCacheCatalogEntry:
         try:
-            entry = self.model.query.filter(self.model._name == name).one()
+            entry = self.session.execute(
+                select(self.model).filter(self.model._name == name)
+            ).scalar_one()
             return entry.as_dataclass()
         except NoResultFound:
             return None
 
     def delete_entry(self, cache: UdfCacheCatalogEntry):
         """Delete cache table from the db
         Arguments:
             cache  (UdfCacheCatalogEntry): cache to delete
         Returns:
             True if successfully removed else false
         """
         try:
-            obj = self.model.query.filter(self.model._row_id == cache.row_id).one()
-            obj.delete()
+            obj = self.session.execute(
+                select(self.model).filter(self.model._row_id == cache.row_id)
+            ).scalar_one()
+            obj.delete(self.session)
             return True
         except Exception as e:
             err_msg = f"Delete cache failed for {cache} with error {str(e)}."
             logger.exception(err_msg)
             raise CatalogError(err_msg)
```

### Comparing `evadb-0.2.6/eva/catalog/services/udf_catalog_service.py` & `evadb-0.2.7/evadb/catalog/services/udf_catalog_service.py`

 * *Files 14% similar despite different names*

```diff
@@ -8,82 +8,85 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from sqlalchemy.orm.exc import NoResultFound
+from sqlalchemy.orm import Session
+from sqlalchemy.sql.expression import select
 
-from eva.catalog.models.udf_catalog import UdfCatalog, UdfCatalogEntry
-from eva.catalog.services.base_service import BaseService
-from eva.utils.logging_manager import logger
+from evadb.catalog.models.udf_catalog import UdfCatalog, UdfCatalogEntry
+from evadb.catalog.services.base_service import BaseService
+from evadb.utils.logging_manager import logger
 
 
 class UdfCatalogService(BaseService):
-    def __init__(self):
-        super().__init__(UdfCatalog)
+    def __init__(self, db_session: Session):
+        super().__init__(UdfCatalog, db_session)
 
     def insert_entry(
         self, name: str, impl_path: str, type: str, checksum: str
     ) -> UdfCatalogEntry:
         """Insert a new udf entry
 
         Arguments:
             name (str): name of the udf
-            impl_path (str): path to the udf implementation relative to eva/udf
+            impl_path (str): path to the udf implementation relative to evadb/udf
             type (str): udf operator kind, classification or detection or etc
             checksum(str): checksum of the udf file content, used for consistency
 
         Returns:
             UdfCatalogEntry: Returns the new entry created
         """
         udf_obj = self.model(name, impl_path, type, checksum)
-        udf_obj = udf_obj.save()
+        udf_obj = udf_obj.save(self.session)
         return udf_obj.as_dataclass()
 
     def get_entry_by_name(self, name: str) -> UdfCatalogEntry:
         """return the udf entry that matches the name provided.
            None if no such entry found.
 
         Arguments:
             name (str): name to be searched
         """
 
-        try:
-            udf_obj = self.model.query.filter(self.model._name == name).one()
+        udf_obj = self.session.execute(
+            select(self.model).filter(self.model._name == name)
+        ).scalar_one_or_none()
+        if udf_obj:
             return udf_obj.as_dataclass()
-        except NoResultFound:
-            return None
+        return None
 
     def get_entry_by_id(self, id: int, return_alchemy=False) -> UdfCatalogEntry:
         """return the udf entry that matches the id provided.
            None if no such entry found.
 
         Arguments:
             id (int): id to be searched
         """
 
-        try:
-            udf_obj = self.model.query.filter(self.model._row_id == id).one()
-            if udf_obj:
-                return udf_obj if return_alchemy else udf_obj.as_dataclass()
-            return udf_obj
-        except NoResultFound:
-            return None
+        udf_obj = self.session.execute(
+            select(self.model).filter(self.model._row_id == id)
+        ).scalar_one_or_none()
+        if udf_obj:
+            return udf_obj if return_alchemy else udf_obj.as_dataclass()
+        return udf_obj
 
     def delete_entry_by_name(self, name: str):
         """Delete a udf entry from the catalog UdfCatalog
 
         Arguments:
             name (str): udf name to be deleted
 
         Returns:
             True if successfully deleted else True
         """
         try:
-            udf_obj = self.model.query.filter(self.model._name == name).one()
-            udf_obj.delete()
+            udf_obj = self.session.execute(
+                select(self.model).filter(self.model._name == name)
+            ).scalar_one()
+            udf_obj.delete(self.session)
         except Exception as e:
             logger.exception(f"Delete udf failed for name {name} with error {str(e)}")
             return False
         return True
```

### Comparing `evadb-0.2.6/eva/catalog/services/udf_cost_catalog_service.py` & `evadb-0.2.7/evadb/catalog/services/udf_cost_catalog_service.py`

 * *Files 14% similar despite different names*

```diff
@@ -9,56 +9,59 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from eva.catalog.models.udf_cost_catalog import UdfCostCatalog, UdfCostCatalogEntry
-from eva.catalog.services.base_service import BaseService
-from eva.utils.errors import CatalogError
+from sqlalchemy.orm import Session
+from sqlalchemy.sql.expression import select
+
+from evadb.catalog.models.udf_cost_catalog import UdfCostCatalog, UdfCostCatalogEntry
+from evadb.catalog.services.base_service import BaseService
+from evadb.utils.errors import CatalogError
 
 
 class UdfCostCatalogService(BaseService):
-    def __init__(self):
-        super().__init__(UdfCostCatalog)
+    def __init__(self, db_session: Session):
+        super().__init__(UdfCostCatalog, db_session)
 
     def insert_entry(self, udf_id: int, name: str, cost: int) -> UdfCostCatalogEntry:
         """Insert a new udf cost entry
 
         Arguments:
             udf_id(int): id of the udf
             name (str) : name of the udf
             cost(int)  : cost of the udf
 
         Returns:
             UdfCostCatalogEntry: Returns the new entry created
         """
         try:
             udf_obj = self.model(udf_id, name, cost)
-            udf_obj.save()
+            udf_obj.save(self.session)
         except Exception as e:
             raise CatalogError(
                 f"Error while inserting entry to UdfCostCatalog: {str(e)}"
             )
 
     def upsert_entry(self, udf_id: int, name: str, new_cost: int):
         """Upserts a new udf cost entry
 
         Arguments:
             udf_id(int): id of the udf
             name (str) : name of the udf
             cost(int)  : cost of the udf
         """
         try:
-            udf_obj = self.model.query.filter(
-                self.model._udf_id == udf_id
-            ).one_or_none()
+            udf_obj = self.session.execute(
+                select(self.model).filter(self.model._udf_id == udf_id)
+            ).scalar_one_or_none()
             if udf_obj:
-                udf_obj.update(cost=new_cost)
+                udf_obj.update(self.session, cost=new_cost)
             else:
                 self.insert_entry(udf_id, name, new_cost)
         except Exception as e:
             raise CatalogError(
                 f"Error while upserting entry to UdfCostCatalog: {str(e)}"
             )
 
@@ -67,17 +70,17 @@
            None if no such entry found.
 
         Arguments:
             name (str): name to be searched
         """
 
         try:
-            udf_obj = self.model.query.filter(
-                self.model._udf_name == name
-            ).one_or_none()
+            udf_obj = self.session.execute(
+                select(self.model).filter(self.model._udf_name == name)
+            ).scalar_one_or_none()
             if udf_obj:
                 return udf_obj.as_dataclass()
             return None
         except Exception as e:
             raise CatalogError(
                 f"Error while getting entry for udf {name} from UdfCostCatalog: {str(e)}"
             )
```

### Comparing `evadb-0.2.6/eva/catalog/services/udf_io_catalog_service.py` & `evadb-0.2.7/evadb/catalog/services/udf_io_catalog_service.py`

 * *Files 16% similar despite different names*

```diff
@@ -10,41 +10,56 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.catalog.models.udf_io_catalog import UdfIOCatalog, UdfIOCatalogEntry
-from eva.catalog.services.base_service import BaseService
-from eva.utils.logging_manager import logger
+from sqlalchemy.orm import Session
+from sqlalchemy.sql.expression import select
+
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalog, UdfIOCatalogEntry
+from evadb.catalog.services.base_service import BaseService
+from evadb.utils.logging_manager import logger
 
 
 class UdfIOCatalogService(BaseService):
-    def __init__(self):
-        super().__init__(UdfIOCatalog)
+    def __init__(self, db_session: Session):
+        super().__init__(UdfIOCatalog, db_session)
 
     def get_input_entries_by_udf_id(self, udf_id: int) -> List[UdfIOCatalogEntry]:
         try:
-            result = self.model.query.filter(
-                self.model._udf_id == udf_id,
-                self.model._is_input == True,  # noqa
-            ).all()
+            result = (
+                self.session.execute(
+                    select(self.model).filter(
+                        self.model._udf_id == udf_id,
+                        self.model._is_input == True,  # noqa
+                    )
+                )
+                .scalars()
+                .all()
+            )
             return [obj.as_dataclass() for obj in result]
         except Exception as e:
             error = f"Getting inputs for UDF id {udf_id} raised {e}"
             logger.error(error)
             raise RuntimeError(error)
 
     def get_output_entries_by_udf_id(self, udf_id: int) -> List[UdfIOCatalogEntry]:
         try:
-            result = self.model.query.filter(
-                self.model._udf_id == udf_id,
-                self.model._is_input == False,  # noqa
-            ).all()
+            result = (
+                self.session.execute(
+                    select(self.model).filter(
+                        self.model._udf_id == udf_id,
+                        self.model._is_input == False,  # noqa
+                    )
+                )
+                .scalars()
+                .all()
+            )
             return [obj.as_dataclass() for obj in result]
         except Exception as e:
             error = f"Getting outputs for UDF id {udf_id} raised {e}"
             logger.error(error)
             raise RuntimeError(error)
 
     def insert_entries(self, io_list: List[UdfIOCatalogEntry]):
@@ -60,8 +75,8 @@
                 type=io.type,
                 is_nullable=io.is_nullable,
                 array_type=io.array_type,
                 array_dimensions=io.array_dimensions,
                 is_input=io.is_input,
                 udf_id=io.udf_id,
             )
-            io_obj.save()
+            io_obj.save(self.session)
```

### Comparing `evadb-0.2.6/eva/catalog/sql_config.py` & `evadb-0.2.7/evadb/catalog/sql_config.py`

 * *Files 13% similar despite different names*

```diff
@@ -8,19 +8,20 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+import weakref
+from threading import Lock
+
 from sqlalchemy import create_engine, event
 from sqlalchemy.orm import scoped_session, sessionmaker
 
-from eva.configuration.configuration_manager import ConfigurationManager
-
 IDENTIFIER_COLUMN = "_row_id"
 
 CATALOG_TABLES = [
     "column_catalog",
     "table_catalog",
     "depend_column_and_udf_cache",
     "udf_cache",
@@ -29,51 +30,53 @@
     "index_catalog",
     "udfio_catalog",
     "udf_cost_catalog",
     "udf_metadata_catalog",
 ]
 
 
-class SQLConfig:
-    """Singleton class for configuring connection to the database.
-
-    Attributes:
-        _instance: stores the singleton instance of the class.
+class SingletonMeta(type):
+    """
+    This is a thread-safe implementation of Singleton.
     """
 
-    def __new__(cls):
-        """Overrides the default __new__ method.
+    _instances = weakref.WeakValueDictionary()
 
-        Returns the existing instance or creates a new one if an instance
-        does not exist.
+    _lock: Lock = Lock()
+
+    def __call__(cls, uri):
+        key = (cls, uri)
+        with cls._lock:
+            if key not in cls._instances:
+                instance = super().__call__(uri)
+                cls._instances[key] = instance
+        return cls._instances[key]
 
-        Returns:
-            An instance of the class.
-        """
-        if not hasattr(cls, "_instance"):
-            cls._instance = super(SQLConfig, cls).__new__(cls)
-        return cls._instance
 
-    def __init__(self):
+class SQLConfig(metaclass=SingletonMeta):
+    def __init__(self, uri):
         """Initializes the engine and session for database operations
 
         Retrieves the database uri for connection from ConfigurationManager.
         """
-        uri = ConfigurationManager().get_value("core", "catalog_database_uri")
 
         self.worker_uri = str(uri)
         # set echo=True to log SQL
-        self.engine = create_engine(self.worker_uri, isolation_level="SERIALIZABLE")
+        self.engine = create_engine(self.worker_uri)
 
         if self.engine.url.get_backend_name() == "sqlite":
             # enforce foreign key constraint and wal logging for sqlite
             # https://docs.sqlalchemy.org/en/20/dialects/sqlite.html#foreign-key-support
 
             def _enable_sqlite_pragma(dbapi_con, con_record):
                 dbapi_con.execute("pragma foreign_keys=ON")
                 dbapi_con.execute("pragma synchronous=NORMAL")
-                dbapi_con.execute("pragma journal_mode=WAL")
 
-            event.listen(self.engine, "connect", _enable_sqlite_pragma)
+                # disabling WAL for now, we need to fix the catalog operations.
+                # Currently, there are too many connections being made, which is not an
+                # optimal design. Ideally, we should implement a connection pool for
+                # better management.
+                # dbapi_con.execute("pragma journal_mode=WAL")
 
+            event.listen(self.engine, "connect", _enable_sqlite_pragma)
         # statements
         self.session = scoped_session(sessionmaker(bind=self.engine))
```

### Comparing `evadb-0.2.6/eva/configuration/__init__.py` & `evadb-0.2.7/evadb/configuration/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/configuration/bootstrap_environment.py` & `evadb-0.2.7/evadb/configuration/bootstrap_environment.py`

 * *Files 5% similar despite different names*

```diff
@@ -10,41 +10,40 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import importlib.resources as importlib_resources
 import logging
-import shutil
 from pathlib import Path
 from typing import Union
 
 import yaml
 
-from eva.configuration.constants import (
+from evadb.configuration.constants import (
     CACHE_DIR,
     DB_DEFAULT_NAME,
     EVA_CONFIG_FILE,
     EVA_DATASET_DIR,
     INDEX_DIR,
     S3_DOWNLOAD_DIR,
     TMP_DIR,
     UDF_DIR,
 )
-from eva.utils.logging_manager import logger as eva_logger
+from evadb.utils.logging_manager import logger as eva_logger
 
 
 def get_base_config(eva_installation_dir: Path) -> Path:
     """
-    Get path to .eva.yml source path.
+    Get path to .evadb.yml source path.
     This file will be copied to user's .eva directory.
     """
     # if eva package is installed into environment
-    if importlib_resources.is_resource("eva", EVA_CONFIG_FILE):
-        with importlib_resources.path("eva", EVA_CONFIG_FILE) as yml_path:
+    if importlib_resources.is_resource("evadb", EVA_CONFIG_FILE):
+        with importlib_resources.path("evadb", EVA_CONFIG_FILE) as yml_path:
             return yml_path
     else:
         # For local dev environments without package installed
         return eva_installation_dir / EVA_CONFIG_FILE
 
 
 def get_default_db_uri(eva_db_dir: Path):
@@ -56,47 +55,36 @@
     Populates necessary configuration for EVA to be able to run.
 
     Arguments:
         eva_db_dir: path to eva database directory
         eva_installation_dir: path to eva module
     """
 
-    config_file_path = eva_db_dir / EVA_CONFIG_FILE
+    default_config_path = get_base_config(eva_installation_dir).resolve()
 
     # creates necessary directories
     config_default_dict = create_directories_and_get_default_config_values(
         Path(eva_db_dir), Path(eva_installation_dir)
     )
 
     assert eva_db_dir.exists(), f"{eva_db_dir} does not exist"
     assert eva_installation_dir.exists(), f"{eva_installation_dir} does not exist"
-
-    # copy eva.yml into config path
-    if not config_file_path.exists():
-        default_config_path = get_base_config(eva_installation_dir).resolve()
-        shutil.copy(str(default_config_path.resolve()), str(eva_db_dir.resolve()))
-
-    # Update eva.yml with user specific paths
-    with config_file_path.open("r+") as yml_file:
+    config_obj = {}
+    with default_config_path.open("r") as yml_file:
         config_obj = yaml.load(yml_file, Loader=yaml.FullLoader)
-
-        if config_obj is None:
-            raise ValueError(f"Invalid yml file at {config_file_path}")
-
-        config_obj = merge_dict_of_dicts(config_obj, config_default_dict)
-        mode = config_obj["core"]["mode"]
-        yml_file.seek(0)
-        yml_file.write(yaml.dump(config_obj))
-        yml_file.truncate()
+    config_obj = merge_dict_of_dicts(config_obj, config_default_dict)
+    mode = config_obj["core"]["mode"]
 
     # set logger to appropriate level (debug or release)
     level = logging.WARN if mode == "release" else logging.DEBUG
     eva_logger.setLevel(level)
     eva_logger.debug(f"Setting logging level to: {str(level)}")
 
+    return config_obj
+
 
 def create_directories_and_get_default_config_values(
     eva_db_dir: Path, eva_installation_dir: Path, category: str = None, key: str = None
 ) -> Union[dict, str]:
     default_install_dir = eva_installation_dir
     dataset_location = eva_db_dir / EVA_DATASET_DIR
     index_dir = eva_db_dir / INDEX_DIR
```

### Comparing `evadb-0.2.6/eva/configuration/constants.py` & `evadb-0.2.7/evadb/configuration/constants.py`

 * *Files 14% similar despite different names*

```diff
@@ -10,21 +10,21 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 
-import eva
+import evadb
 
-EVA_INSTALLATION_DIR = Path(eva.__file__).parent
-EVA_ROOT_DIR = Path(eva.__file__).parent.parent
-EVA_DATABASE_DIR = "eva_data"
-EVA_DATASET_DIR = "eva_datasets"
-EVA_CONFIG_FILE = "eva.yml"
+EVA_INSTALLATION_DIR = Path(evadb.__file__).parent
+EVA_ROOT_DIR = Path(evadb.__file__).parent.parent
+EVA_DATABASE_DIR = "evadb_data"
+EVA_DATASET_DIR = "evadb_datasets"
+EVA_CONFIG_FILE = "evadb.yml"
 UDF_DIR = "udfs"
 CATALOG_DIR = "catalog"
 INDEX_DIR = "index"
 CACHE_DIR = "cache"
 DATASET_DATAFRAME_NAME = "dataset"
 DB_DEFAULT_NAME = "eva.db"
 S3_DOWNLOAD_DIR = "s3_downloads"
```

### Comparing `evadb-0.2.6/eva/constants.py` & `evadb-0.2.7/evadb/constants.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/eva_cmd_client.py` & `evadb-0.2.7/evadb/eva_cmd_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,25 +13,25 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import argparse
 import asyncio
 import sys
 from os.path import abspath, dirname, join
 
-from eva.utils.logging_manager import logger
+from evadb.utils.logging_manager import logger
 
 """
 To allow running eva_server from any location
 """
 THIS_DIR = dirname(__file__)
 EVA_CODE_DIR = abspath(join(THIS_DIR, ".."))
 sys.path.append(EVA_CODE_DIR)
 
-from eva.configuration.configuration_manager import ConfigurationManager  # noqa: E402
-from eva.server.interpreter import start_cmd_client  # noqa: E402
+from evadb.configuration.configuration_manager import ConfigurationManager  # noqa: E402
+from evadb.server.interpreter import start_cmd_client  # noqa: E402
 
 
 async def eva_client(host: str, port: int):
     """
     Start the eva client
     """
 
@@ -54,15 +54,15 @@
     )
 
     parser.add_argument(
         "--port",
         help="Specify the port number of the server you want to connect to.",
     )
 
-    ## PARSE ARGS
+    # PARSE ARGS
     args, unknown = parser.parse_known_args()
 
     host = (
         args.host if args.host else ConfigurationManager().get_value("server", "host")
     )
 
     port = (
```

### Comparing `evadb-0.2.6/eva/eva_server.py` & `evadb-0.2.7/evadb/eva_server.py`

 * *Files 16% similar despite different names*

```diff
@@ -23,25 +23,23 @@
 """
 To allow running eva_server from any location
 """
 THIS_DIR = dirname(__file__)
 EVA_CODE_DIR = abspath(join(THIS_DIR, ".."))
 sys.path.append(EVA_CODE_DIR)
 
-from eva.configuration.configuration_manager import ConfigurationManager  # noqa: E402
-from eva.configuration.constants import EVA_DATABASE_DIR  # noqa: E402
-from eva.server.server import EvaServer  # noqa: E402
-from eva.utils.logging_manager import logger  # noqa: E402
+from evadb.server.server import EvaServer  # noqa: E402
 
 
-async def start_eva_server(host: str, port: int):
+async def start_eva_server(
+    db_dir: str, host: str, port: str, custom_db_uri: str = None
+):
     """Start the eva server"""
     eva_server = EvaServer()
-
-    await eva_server.start_eva_server(host, port)
+    await eva_server.start_eva_server(db_dir, host, port, custom_db_uri)
 
 
 def stop_server():
     """
     Stop the eva server
     """
     for proc in process_iter():
@@ -61,15 +59,20 @@
 
     parser.add_argument(
         "--port",
         help="Specify the port number on which the server will start.",
     )
 
     parser.add_argument(
-        "--database", help="Specify the database folder which the server should access."
+        "--db_dir", help="Specify the eva directory which the server should access."
+    )
+
+    parser.add_argument(
+        "--sql_backend",
+        help="Specify the custom sql database to use for structured data.",
     )
 
     parser.add_argument(
         "--start",
         help="start server",
         action="store_true",
         default=True,
@@ -81,36 +84,23 @@
         action="store_true",
         default=False,
     )
 
     ## PARSE ARGS
     args, unknown = parser.parse_known_args()
 
+    args.host = args.host or "0.0.0.0"
+    args.port = args.port or "8803"
     # Stop server
     if args.stop:
         return stop_server()
 
-    eva_db_dir = args.database if args.database else EVA_DATABASE_DIR
-
-    logger.debug(f"Database dir: {eva_db_dir}")
-
-    # Instantiate a Configuration Manager object with the appropriate database directory
-    # Subsequent calls will utilize the specified database directory
-    config_manager = ConfigurationManager(EVA_DATABASE_DIR=eva_db_dir)
-
-    host = args.host if args.host else config_manager.get_value("server", "host")
-
-    port = args.port if args.port else config_manager.get_value("server", "port")
-
     # Start server
     if args.start:
-        mode = config_manager.get_value("core", "mode")
-        from eva.udfs.udf_bootstrap_queries import init_builtin_udfs  # noqa: E402
-
-        init_builtin_udfs(mode=mode)
-
-        asyncio.run(start_eva_server(host=host, port=int(port)))
+        asyncio.run(
+            start_eva_server(args.db_dir, args.host, args.port, args.sql_backend)
+        )
 
 
 if __name__ == "__main__":
     # execute only if run as the entry point into the program
     main()
```

### Comparing `evadb-0.2.6/eva/executor/__init__.py` & `evadb-0.2.7/evadb/executor/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/executor/abstract_executor.py` & `evadb-0.2.7/evadb/udfs/abstract/abstract_udf.py`

 * *Files 23% similar despite different names*

```diff
@@ -8,64 +8,84 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from abc import ABC, abstractmethod
-from typing import Generator, Iterable, List, TypeVar
+from abc import ABCMeta, abstractmethod
+from typing import List, Union
 
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.abstract_plan import AbstractPlan
+import pandas as pd
+from numpy.typing import ArrayLike
 
-AbstractExecutor = TypeVar("AbstractExecutor")
+InputType = Union[pd.DataFrame, ArrayLike]
 
 
-class AbstractExecutor(ABC):
+class AbstractUDF(metaclass=ABCMeta):
     """
-    An abstract class for the executor engine
-    Arguments:
-        node (AbstractPlan): Plan node corresponding to this executor
+    Abstract class for UDFs. All the UDFs in EVA will inherit from this.
+
+    Load and initialize the machine learning model in the __init__.
+
     """
 
-    def __init__(self, node: AbstractPlan):
-        self._node = node
-        self._children = []
+    def __init__(self, *args, **kwargs):
+        self.setup(*args, **kwargs)
+
+    def __call__(self, *args, **kwargs):
+        return self.forward(args[0])
 
-    def append_child(self, child: AbstractExecutor):
+    def __str__(self):
+        return self.name
+
+    """Abstract Methods all UDFs must implement. """
+
+    @abstractmethod
+    def setup(self, *args, **kwargs) -> None:
         """
-        appends a child executor node
+        Do necessary setup in here. Gets called automatically on initialization.
+        """
+        pass
 
-        Arguments:
-            child {AbstractExecutor} -- child node
+    @abstractmethod
+    def forward(self, frames: InputType) -> InputType:
         """
-        self._children.append(child)
+        Implement UDF function call by overriding this function.
+        Gets called automatically by __call__.
+        """
+        pass
 
     @property
-    def children(self) -> List[AbstractExecutor]:
+    @abstractmethod
+    def name(self) -> str:
+        pass
+
+
+class AbstractClassifierUDF(AbstractUDF):
+    @property
+    @abstractmethod
+    def labels(self) -> List[str]:
         """
-        Returns the list of child executor
         Returns:
-            [] -- list of children
+            List[str]: list of labels the classifier predicts
         """
-        return self._children
-
-    @children.setter
-    def children(self, children):
-        self._children = children
+        pass
 
-    @property
-    def node(self) -> AbstractPlan:
-        return self._node
 
+class AbstractTransformationUDF(AbstractUDF):
     @abstractmethod
-    def exec(self, *args, **kwargs) -> Iterable[Batch]:
+    def transform(self, frames: ArrayLike) -> ArrayLike:
         """
-        This method is implemented by every executor.
-        Contains logic for that executor;
-        For retrieval based executor : It fetches frame batches from
-        child nodes and emits it to parent node.
+        Takes as input a batch of frames and transforms them
+        by applying the frame transformation model.
+
+        Arguments:
+            frames: Input batch of frames on which prediction
+            needs to be made
+
+        Returns:
+            Transformed frames
         """
 
-    def __call__(self, *args, **kwargs) -> Generator[Batch, None, None]:
-        yield from self.exec(*args, **kwargs)
+    def __call__(self, *args, **kwargs):
+        return self.transform(*args, **kwargs)
```

### Comparing `evadb-0.2.6/eva/executor/apply_and_merge_executor.py` & `evadb-0.2.7/evadb/executor/apply_and_merge_executor.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,40 +10,49 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.apply_and_merge_plan import ApplyAndMergePlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.apply_and_merge_plan import ApplyAndMergePlan
 
 
 class ApplyAndMergeExecutor(AbstractExecutor):
     """
     Apply the function expression to the input data, merge the output of the function
     with the input data, and yield the result to the parent. The current implementation
     assumes an inner join while merging. Therefore, if the function does not return any
     output, the input rows are dropped.
     Arguments:
         node (AbstractPlan): ApplyAndMergePlan
 
     """
 
-    def __init__(self, node: ApplyAndMergePlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: ApplyAndMergePlan):
+        super().__init__(db, node)
         self.func_expr = node.func_expr
         self.do_unnest = node.do_unnest
         self.alias = node.alias
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         child_executor = self.children[0]
         for batch in child_executor.exec(**kwargs):
             func_result = self.func_expr.evaluate(batch)
+
+            # persist stats of function expression
+            if self.func_expr.udf_obj and self.func_expr._stats:
+                udf_id = self.func_expr.udf_obj.row_id
+                self.catalog().upsert_udf_cost_catalog_entry(
+                    udf_id, self.func_expr.udf_obj.name, self.func_expr._stats.prev_cost
+                )
+
             output = Batch.merge_column_wise([batch, func_result])
             if self.do_unnest:
                 output.unnest(func_result.columns)
                 # we reset the index as after unnest there can be duplicate index
                 output.reset_index()
 
             yield output
```

### Comparing `evadb-0.2.6/eva/executor/create_executor.py` & `evadb-0.2.7/evadb/executor/create_executor.py`

 * *Files 14% similar despite different names*

```diff
@@ -8,35 +8,36 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.catalog.catalog_manager import CatalogManager
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import handle_if_not_exists
-from eva.plan_nodes.create_plan import CreatePlan
-from eva.storage.storage_engine import StorageEngine
-from eva.utils.logging_manager import logger
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import handle_if_not_exists
+from evadb.plan_nodes.create_plan import CreatePlan
+from evadb.storage.storage_engine import StorageEngine
+from evadb.utils.logging_manager import logger
 
 
 class CreateExecutor(AbstractExecutor):
-    def __init__(self, node: CreatePlan):
-        super().__init__(node)
-        self.catalog = CatalogManager()
+    def __init__(self, db: EVADatabase, node: CreatePlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs):
-        if not handle_if_not_exists(self.node.table_info, self.node.if_not_exists):
+        if not handle_if_not_exists(
+            self.catalog(), self.node.table_info, self.node.if_not_exists
+        ):
             logger.debug(f"Creating table {self.node.table_info}")
 
-            catalog_entry = self.catalog.create_and_insert_table_catalog_entry(
+            catalog_entry = self.catalog().create_and_insert_table_catalog_entry(
                 self.node.table_info, self.node.column_list
             )
-            storage_engine = StorageEngine.factory(catalog_entry)
+            storage_engine = StorageEngine.factory(self.db, catalog_entry)
             storage_engine.create(table=catalog_entry)
 
             if self.children != []:
                 assert (
                     len(self.children) == 1
                 ), "Create materialized view expects 1 child, finds {}".format(
                     len(self.children)
```

### Comparing `evadb-0.2.6/eva/executor/create_index_executor.py` & `evadb-0.2.7/evadb/executor/create_index_executor.py`

 * *Files 9% similar despite different names*

```diff
@@ -12,34 +12,32 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 
 import pandas as pd
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.sql_config import IDENTIFIER_COLUMN
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import ExecutorError, handle_vector_store_params
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.create_index_plan import CreateIndexPlan
-from eva.storage.storage_engine import StorageEngine
-from eva.third_party.vector_stores.types import FeaturePayload
-from eva.third_party.vector_stores.utils import VectorStoreFactory
-from eva.utils.logging_manager import logger
+from evadb.catalog.sql_config import IDENTIFIER_COLUMN
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import ExecutorError, handle_vector_store_params
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.create_index_plan import CreateIndexPlan
+from evadb.storage.storage_engine import StorageEngine
+from evadb.third_party.vector_stores.types import FeaturePayload
+from evadb.third_party.vector_stores.utils import VectorStoreFactory
+from evadb.utils.logging_manager import logger
 
 
 class CreateIndexExecutor(AbstractExecutor):
-    def __init__(self, node: CreateIndexPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: CreateIndexPlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs):
-        catalog_manager = CatalogManager()
-        if catalog_manager.get_index_catalog_entry_by_name(self.node.name):
+        if self.catalog().get_index_catalog_entry_by_name(self.node.name):
             msg = f"Index {self.node.name} already exists."
             logger.error(msg)
             raise ExecutorError(msg)
 
         self.index_path = self._get_index_save_path()
         self.index = None
         self._create_index()
@@ -47,15 +45,15 @@
         yield Batch(
             pd.DataFrame(
                 [f"Index {self.node.name} successfully added to the database."]
             )
         )
 
     def _get_index_save_path(self) -> Path:
-        index_dir = Path(ConfigurationManager().get_value("storage", "index_dir"))
+        index_dir = Path(self.config.get_value("storage", "index_dir"))
         if not index_dir.exists():
             index_dir.mkdir(parents=True, exist_ok=True)
         return str(
             index_dir
             / Path("{}_{}.index".format(self.node.vector_store_type, self.node.name))
         )
 
@@ -69,15 +67,15 @@
             feat_column = [
                 col for col in feat_catalog_entry.columns if col.name == feat_col_name
             ][0]
 
             # Add features to index.
             # TODO: batch size is hardcoded for now.
             input_dim = -1
-            storage_engine = StorageEngine.factory(feat_catalog_entry)
+            storage_engine = StorageEngine.factory(self.db, feat_catalog_entry)
             for input_batch in storage_engine.read(feat_catalog_entry):
                 if self.node.udf_func:
                     # Create index through UDF expression.
                     # UDF(input column) -> 2 dimension feature vector.
                     input_batch.modify_column_alias(feat_catalog_entry.name.lower())
                     feat_batch = self.node.udf_func.evaluate(input_batch)
                     feat_batch.drop_column_alias()
@@ -107,15 +105,15 @@
                     # Row ID for mapping back to the row.
                     self.index.add([FeaturePayload(row_id[i], row_feat)])
 
             # Persist index.
             self.index.persist()
 
             # Save to catalog.
-            CatalogManager().insert_index_catalog_entry(
+            self.catalog().insert_index_catalog_entry(
                 self.node.name,
                 self.index_path,
                 self.node.vector_store_type,
                 feat_column,
                 self.node.udf_func.signature() if self.node.udf_func else None,
             )
         except Exception as e:
```

### Comparing `evadb-0.2.6/eva/executor/create_mat_view_executor.py` & `evadb-0.2.7/evadb/executor/create_mat_view_executor.py`

 * *Files 16% similar despite different names*

```diff
@@ -8,39 +8,40 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.catalog.catalog_manager import CatalogManager
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import handle_if_not_exists
-from eva.plan_nodes.create_mat_view_plan import CreateMaterializedViewPlan
-from eva.storage.storage_engine import StorageEngine
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import handle_if_not_exists
+from evadb.plan_nodes.create_mat_view_plan import CreateMaterializedViewPlan
+from evadb.storage.storage_engine import StorageEngine
 
 
 class CreateMaterializedViewExecutor(AbstractExecutor):
-    def __init__(self, node: CreateMaterializedViewPlan):
-        super().__init__(node)
-        self.catalog = CatalogManager()
+    def __init__(self, db: EVADatabase, node: CreateMaterializedViewPlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs):
         """Create materialized view executor"""
-        if not handle_if_not_exists(self.node.view, self.node.if_not_exists):
+        if not handle_if_not_exists(
+            self.catalog(), self.node.view, self.node.if_not_exists
+        ):
             assert (
                 len(self.children) == 1
             ), "Create materialized view expects 1 child, finds {}".format(
                 len(self.children)
             )
             child = self.children[0]
 
-            view_catalog_entry = self.catalog.create_and_insert_table_catalog_entry(
+            view_catalog_entry = self.catalog().create_and_insert_table_catalog_entry(
                 self.node.view, self.node.columns
             )
-            storage_engine = StorageEngine.factory(view_catalog_entry)
+            storage_engine = StorageEngine.factory(self.db, view_catalog_entry)
             storage_engine.create(table=view_catalog_entry)
 
             # Populate the view
             for batch in child.exec():
                 batch.drop_column_alias()
                 storage_engine.write(view_catalog_entry, batch)
```

### Comparing `evadb-0.2.6/eva/executor/create_udf_executor.py` & `evadb-0.2.7/evadb/executor/create_udf_executor.py`

 * *Files 7% similar despite different names*

```diff
@@ -13,35 +13,33 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 from typing import Dict, List
 
 import pandas as pd
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_utils import get_metadata_properties
-from eva.catalog.models.udf_catalog import UdfCatalogEntry
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.create_udf_plan import CreateUDFPlan
-from eva.third_party.huggingface.create import gen_hf_io_catalog_entries
-from eva.udfs.decorators.utils import load_io_from_udf_decorators
-from eva.utils.errors import UDFIODefinitionError
-from eva.utils.generic_utils import load_udf_class_from_file
-from eva.utils.logging_manager import logger
+from evadb.catalog.catalog_utils import get_metadata_properties
+from evadb.catalog.models.udf_catalog import UdfCatalogEntry
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.create_udf_plan import CreateUDFPlan
+from evadb.third_party.huggingface.create import gen_hf_io_catalog_entries
+from evadb.udfs.decorators.utils import load_io_from_udf_decorators
+from evadb.utils.errors import UDFIODefinitionError
+from evadb.utils.generic_utils import load_udf_class_from_file
+from evadb.utils.logging_manager import logger
 
 
 class CreateUDFExecutor(AbstractExecutor):
-    def __init__(self, node: CreateUDFPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: CreateUDFPlan):
+        super().__init__(db, node)
         self.udf_dir = (
-            Path(ConfigurationManager().get_value("core", "eva_installation_dir"))
-            / "udfs"
+            Path(self.config.get_value("core", "eva_installation_dir")) / "udfs"
         )
 
     def handle_huggingface_udf(self):
         """Handle HuggingFace UDFs
 
         HuggingFace UDFs are special UDFs that are not loaded from a file.
         So we do not need to call the setup method on them like we do for other UDFs.
@@ -92,17 +90,16 @@
         )
 
     def exec(self, *args, **kwargs):
         """Create udf executor
 
         Calls the catalog to insert a udf catalog entry.
         """
-        catalog_manager = CatalogManager()
         # check catalog if it already has this udf entry
-        if catalog_manager.get_udf_catalog_entry_by_name(self.node.name):
+        if self.catalog().get_udf_catalog_entry_by_name(self.node.name):
             if self.node.if_not_exists:
                 msg = f"UDF {self.node.name} already exists, nothing added."
                 yield Batch(pd.DataFrame([msg]))
                 return
             else:
                 msg = f"UDF {self.node.name} already exists."
                 logger.error(msg)
@@ -112,15 +109,15 @@
         if self.node.udf_type == "HuggingFace":
             name, impl_path, udf_type, io_list, metadata = self.handle_huggingface_udf()
         elif self.node.udf_type == "ultralytics":
             name, impl_path, udf_type, io_list, metadata = self.handle_ultralytics_udf()
         else:
             name, impl_path, udf_type, io_list, metadata = self.handle_generic_udf()
 
-        catalog_manager.insert_udf_catalog_entry(
+        self.catalog().insert_udf_catalog_entry(
             name, impl_path, udf_type, io_list, metadata
         )
         yield Batch(
             pd.DataFrame([f"UDF {self.node.name} successfully added to the database."])
         )
 
     def _try_initializing_udf(
```

### Comparing `evadb-0.2.6/eva/executor/delete_executor.py` & `evadb-0.2.7/evadb/executor/delete_executor.py`

 * *Files 7% similar despite different names*

```diff
@@ -13,35 +13,34 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
 import pandas as pd
 from sqlalchemy import and_, or_
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import TableType
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.logical_expression import LogicalExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.project_plan import ProjectPlan
-from eva.storage.storage_engine import StorageEngine
+from evadb.catalog.catalog_type import TableType
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.logical_expression import LogicalExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.project_plan import ProjectPlan
+from evadb.storage.storage_engine import StorageEngine
 
 
 class DeleteExecutor(AbstractExecutor):
     """ """
 
-    def __init__(self, node: ProjectPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: ProjectPlan):
+        super().__init__(db, node)
         self.predicate = node.where_clause
-        self.catalog = CatalogManager()
 
     def predicate_node_to_filter_clause(
         self, table: TableCatalogEntry, predicate_node: ComparisonExpression
     ):
         filter_clause = None
         left = predicate_node.get_child(0)
         right = predicate_node.get_child(1)
@@ -89,15 +88,15 @@
             elif predicate_node.etype == ExpressionType.COMPARE_NEQ:
                 filter_clause = x != y
 
         return filter_clause
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         table_catalog = self.node.table_ref.table.table_obj
-        storage_engine = StorageEngine.factory(table_catalog)
+        storage_engine = StorageEngine.factory(self.db, table_catalog)
 
         assert (
             table_catalog.table_type == TableType.STRUCTURED_DATA
         ), "DELETE only implemented for structured data"
 
         table_to_delete_from = storage_engine._try_loading_table_via_reflection(
             table_catalog.name
```

### Comparing `evadb-0.2.6/eva/executor/drop_executor.py` & `evadb-0.2.7/evadb/executor/load_csv_executor.py`

 * *Files 24% similar despite different names*

```diff
@@ -8,65 +8,82 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
-
 import pandas as pd
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import ExecutorError
-from eva.models.storage.batch import Batch
-from eva.parser.table_ref import TableInfo
-from eva.plan_nodes.drop_plan import DropPlan
-from eva.storage.storage_engine import StorageEngine
-from eva.utils.logging_manager import logger
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import ExecutorError
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.load_data_plan import LoadDataPlan
+from evadb.readers.csv_reader import CSVReader
+from evadb.storage.storage_engine import StorageEngine
+from evadb.utils.logging_manager import logger
 
 
-class DropExecutor(AbstractExecutor):
-    def __init__(self, node: DropPlan):
-        super().__init__(node)
+class LoadCSVExecutor(AbstractExecutor):
+    def __init__(self, db: EVADatabase, node: LoadDataPlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs):
-        """Drop table executor"""
-        catalog_manager = CatalogManager()
-
-        assert len(self.node.table_infos) == 1, "Drop supports only single table"
-
-        table_info: TableInfo = self.node.table_infos[0]
-
-        if not catalog_manager.check_table_exists(
-            table_info.table_name, table_info.database_name
-        ):
-            err_msg = "Table: {} does not exist".format(table_info)
-            if self.node.if_exists:
-                logger.warn(err_msg)
-                return Batch(pd.DataFrame([err_msg]))
-            else:
-                raise ExecutorError(err_msg)
-
-        table_obj = catalog_manager.get_table_catalog_entry(
-            table_info.table_name, table_info.database_name
+        """
+        Read the input csv file using pandas and persist data
+        using storage engine
+        """
+
+        # Check table existence
+        table_info = self.node.table_info
+        database_name = table_info.database_name
+        table_name = table_info.table_name
+        table_obj = self.catalog().get_table_catalog_entry(
+            table_name,
+            database_name,
         )
-        storage_engine = StorageEngine.factory(table_obj)
-
-        logger.debug(f"Dropping table {table_info}")
-        storage_engine.drop(table=table_obj)
+        if table_obj is None:
+            error = f"{table_name} does not exist."
+            logger.error(error)
+            raise ExecutorError(error)
+
+        # Get the column information
+        column_list = []
+        for column in table_obj.columns:
+            column_list.append(
+                TupleValueExpression(
+                    col_name=column.name,
+                    table_alias=table_obj.name.lower(),
+                    col_object=column,
+                )
+            )
 
-        for col_obj in table_obj.columns:
-            for cache in col_obj.dep_caches:
-                catalog_manager.drop_udf_cache_catalog_entry(cache)
+        # Read the CSV file
+        # converters is a dictionary of functions that convert the values
+        # in the column to the desired type
+        csv_reader = CSVReader(
+            self.node.file_path,
+            column_list=column_list,
+            batch_mem_size=self.node.batch_mem_size,
+        )
 
-        assert catalog_manager.delete_table_catalog_entry(
-            table_obj
-        ), "Failed to drop {}".format(table_info)
+        storage_engine = StorageEngine.factory(self.db, table_obj)
+        # write with storage engine in batches
+        num_loaded_frames = 0
+        for batch in csv_reader.read():
+            storage_engine.write(table_obj, batch)
+            num_loaded_frames += len(batch)
 
-        yield Batch(
+        # yield result
+        df_yield_result = Batch(
             pd.DataFrame(
-                {"Table Successfully dropped: {}".format(table_info.table_name)},
+                {
+                    "CSV": str(self.node.file_path),
+                    "Number of loaded frames": num_loaded_frames,
+                },
                 index=[0],
             )
         )
+
+        yield df_yield_result
```

### Comparing `evadb-0.2.6/eva/executor/exchange_executor.py` & `evadb-0.2.7/evadb/executor/exchange_executor.py`

 * *Files 4% similar despite different names*

```diff
@@ -12,29 +12,30 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
 from ray.util.queue import Queue
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import ExecutorError
-from eva.executor.ray_utils import (
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import ExecutorError
+from evadb.executor.ray_utils import (
     StageCompleteSignal,
     ray_parallel,
     ray_pull,
     ray_wait_and_alert,
 )
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.exchange_plan import ExchangePlan
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.exchange_plan import ExchangePlan
 
 
 class QueueReaderExecutor(AbstractExecutor):
     def __init__(self):
-        super().__init__(None)
+        super().__init__(None, None)
 
     def exec(self, **kwargs) -> Iterator[Batch]:
         assert "input_queue" in kwargs, "Invalid ray execution. No input_queue found"
         input_queue = kwargs["input_queue"]
 
         while True:
             next_item = input_queue.get(block=True)
@@ -48,20 +49,20 @@
                 input_queue.put(next_item)
                 raise next_item
             else:
                 yield next_item
 
 
 class ExchangeExecutor(AbstractExecutor):
-    def __init__(self, node: ExchangePlan):
+    def __init__(self, db: EVADatabase, node: ExchangePlan):
         self.inner_plan = node.inner_plan
         self.parallelism = node.parallelism
         self.ray_pull_env_conf_dict = node.ray_pull_env_conf_dict
         self.ray_parallel_env_conf_dict = node.ray_parallel_env_conf_dict
-        super().__init__(node)
+        super().__init__(db, node)
 
     def build_inner_executor(self, inner_executor):
         self.inner_executor = inner_executor
         self.inner_executor.children = [QueueReaderExecutor()]
 
     def exec(self) -> Iterator[Batch]:
         input_queue = Queue(maxsize=100)
```

### Comparing `evadb-0.2.6/eva/executor/execution_context.py` & `evadb-0.2.7/evadb/executor/execution_context.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,17 +12,17 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 import random
 from typing import List
 
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.constants import NO_GPU
-from eva.utils.generic_utils import get_gpu_count, is_gpu_available
+from evadb.configuration.configuration_manager import ConfigurationManager
+from evadb.constants import NO_GPU
+from evadb.utils.generic_utils import get_gpu_count, is_gpu_available
 
 
 class Context:
     """
     Stores the context information of the executor, i.e.,
     if using spark, name of the application, current spark executors,
     if using horovod: current rank etc.
```

### Comparing `evadb-0.2.6/eva/executor/executor_utils.py` & `evadb-0.2.7/evadb/executor/executor_utils.py`

 * *Files 23% similar despite different names*

```diff
@@ -11,49 +11,75 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import glob
 import os
 from pathlib import Path
-from typing import Generator, List
+from typing import TYPE_CHECKING, Generator, List
 
 import cv2
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import VectorStoreType
-from eva.expression.abstract_expression import AbstractExpression
-from eva.models.storage.batch import Batch
-from eva.parser.table_ref import TableInfo
-from eva.parser.types import FileFormatType
-from eva.readers.document.registry import SUPPORTED_TYPES
-from eva.utils.logging_manager import logger
+if TYPE_CHECKING:
+    from evadb.catalog.catalog_manager import CatalogManager
+
+from evadb.catalog.catalog_type import VectorStoreType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.expression.function_expression import FunctionExpression
+from evadb.models.storage.batch import Batch
+from evadb.parser.table_ref import TableInfo
+from evadb.parser.types import FileFormatType
+from evadb.readers.document.registry import SUPPORTED_TYPES
+from evadb.utils.logging_manager import logger
 
 
 class ExecutorError(Exception):
     pass
 
 
-def apply_project(batch: Batch, project_list: List[AbstractExpression]):
+def apply_project(
+    batch: Batch, project_list: List[AbstractExpression], catalog: "CatalogManager"
+):
     if not batch.empty() and project_list:
         batches = [expr.evaluate(batch) for expr in project_list]
         batch = Batch.merge_column_wise(batches)
+
+        # persist stats of function expression
+        for expr in project_list:
+            for func_expr in expr.find_all(FunctionExpression):
+                if func_expr.udf_obj and func_expr._stats:
+                    udf_id = func_expr.udf_obj.row_id
+                    catalog.upsert_udf_cost_catalog_entry(
+                        udf_id, func_expr.udf_obj.name, func_expr._stats.prev_cost
+                    )
     return batch
 
 
-def apply_predicate(batch: Batch, predicate: AbstractExpression) -> Batch:
+def apply_predicate(
+    batch: Batch, predicate: AbstractExpression, catalog: "CatalogManager"
+) -> Batch:
     if not batch.empty() and predicate is not None:
         outcomes = predicate.evaluate(batch)
         batch.drop_zero(outcomes)
+
+        # persist stats of function expression
+        for func_expr in predicate.find_all(FunctionExpression):
+            if func_expr.udf_obj and func_expr._stats:
+                udf_id = func_expr.udf_obj.row_id
+                catalog.upsert_udf_cost_catalog_entry(
+                    udf_id, func_expr.udf_obj.name, func_expr._stats.prev_cost
+                )
     return batch
 
 
-def handle_if_not_exists(table_info: TableInfo, if_not_exist=False):
+def handle_if_not_exists(
+    catalog: "CatalogManager", table_info: TableInfo, if_not_exist=False
+):
     # Table exists
-    if CatalogManager().check_table_exists(
+    if catalog.check_table_exists(
         table_info.table_name,
         table_info.database_name,
     ):
         err_msg = "Table: {} already exists".format(table_info)
         if if_not_exist:
             logger.warn(err_msg)
             return True
```

### Comparing `evadb-0.2.6/eva/executor/explain_executor.py` & `evadb-0.2.7/evadb/executor/explain_executor.py`

 * *Files 13% similar despite different names*

```diff
@@ -10,23 +10,24 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import pandas as pd
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.explain_plan import ExplainPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.explain_plan import ExplainPlan
 
 
 class ExplainExecutor(AbstractExecutor):
-    def __init__(self, node: ExplainPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: ExplainPlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs):
         # Traverse optimized physical plan, which is commonly supported.
         # Logical plan can be also printed by passing explainable_opr
         # attribute of the node, but is not done for now.
         plan_str = self._exec(self._node.children[0], 0)
         yield Batch(pd.DataFrame([plan_str]))
```

### Comparing `evadb-0.2.6/eva/executor/function_scan_executor.py` & `evadb-0.2.7/evadb/executor/function_scan_executor.py`

 * *Files 13% similar despite different names*

```diff
@@ -10,37 +10,46 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.function_scan_plan import FunctionScanPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.function_scan_plan import FunctionScanPlan
 
 
 class FunctionScanExecutor(AbstractExecutor):
     """
     Executes functional expression which yields a table of rows
     Arguments:
         node (AbstractPlan): FunctionScanPlan
 
     """
 
-    def __init__(self, node: FunctionScanPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: FunctionScanPlan):
+        super().__init__(db, node)
         self.func_expr = node.func_expr
         self.do_unnest = node.do_unnest
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         assert (
             "lateral_input" in kwargs
         ), "Key lateral_input not passed to the FunctionScan"
         lateral_input = kwargs.get("lateral_input")
         if not lateral_input.empty():
             res = self.func_expr.evaluate(lateral_input)
+
+            # persist stats of function expression
+            if self.func_expr.udf_obj and self.func_expr._stats:
+                udf_id = self.func_expr.udf_obj.row_id
+                self.catalog().upsert_udf_cost_catalog_entry(
+                    udf_id, self.func_expr.udf_obj.name, self.func_expr._stats.prev_cost
+                )
+
             if not res.empty():
                 if self.do_unnest:
                     res.unnest(res.columns)
 
                 yield res
```

### Comparing `evadb-0.2.6/eva/executor/groupby_executor.py` & `evadb-0.2.7/evadb/executor/groupby_executor.py`

 * *Files 18% similar despite different names*

```diff
@@ -8,36 +8,39 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+import re
 from typing import Iterator
 
 import pandas as pd
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.groupby_plan import GroupByPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.groupby_plan import GroupByPlan
 
 
 class GroupByExecutor(AbstractExecutor):
     """
     Group inputs into 4d segments of length provided in the query
-    E.g., "GROUP BY '8f'" groups every 8 frames into one segment
+    E.g., "GROUP BY '8 frames'" groups every 8 frames into one segment
 
     Arguments:
         node (AbstractPlan): The GroupBy Plan
 
     """
 
-    def __init__(self, node: GroupByPlan):
-        super().__init__(node)
-        self._segment_length = int(node.groupby_clause.value[:-1])
+    def __init__(self, db: EVADatabase, node: GroupByPlan):
+        super().__init__(db, node)
+        numbers_only = re.sub(r"\D", "", node.groupby_clause.value)
+        self._segment_length = int(numbers_only)
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         child_executor = self.children[0]
 
         buffer = Batch(pd.DataFrame())
         for batch in child_executor.exec(**kwargs):
             new_batch = buffer + batch
```

### Comparing `evadb-0.2.6/eva/executor/hash_join_executor.py` & `evadb-0.2.7/evadb/executor/hash_join_executor.py`

 * *Files 22% similar despite different names*

```diff
@@ -10,33 +10,36 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import apply_predicate, apply_project
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.hash_join_probe_plan import HashJoinProbePlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import apply_predicate, apply_project
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.hash_join_probe_plan import HashJoinProbePlan
 
 
 class HashJoinExecutor(AbstractExecutor):
-    def __init__(self, node: HashJoinProbePlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: HashJoinProbePlan):
+        super().__init__(db, node)
         self.predicate = node.join_predicate
         self.join_type = node.join_type
         self.probe_keys = node.probe_keys
         self.join_project = node.join_project
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         build_table = self.children[0]
         probe_table = self.children[1]
         hash_keys = [key.col_alias for key in self.probe_keys]
         for build_batch in build_table.exec():
             for probe_batch in probe_table.exec():
                 probe_batch.reassign_indices_to_hash(hash_keys)
                 join_batch = Batch.join(probe_batch, build_batch)
                 join_batch.reset_index()
-                join_batch = apply_predicate(join_batch, self.predicate)
-                join_batch = apply_project(join_batch, self.join_project)
+                join_batch = apply_predicate(join_batch, self.predicate, self.catalog())
+                join_batch = apply_project(
+                    join_batch, self.join_project, self.catalog()
+                )
                 yield join_batch
```

### Comparing `evadb-0.2.6/eva/executor/insert_executor.py` & `evadb-0.2.7/evadb/executor/insert_executor.py`

 * *Files 16% similar despite different names*

```diff
@@ -10,35 +10,34 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import pandas as pd
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import TableType
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.insert_plan import InsertPlan
-from eva.storage.storage_engine import StorageEngine
+from evadb.catalog.catalog_type import TableType
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.insert_plan import InsertPlan
+from evadb.storage.storage_engine import StorageEngine
 
 
 class InsertExecutor(AbstractExecutor):
-    def __init__(self, node: InsertPlan):
-        super().__init__(node)
-        self.catalog = CatalogManager()
+    def __init__(self, db: EVADatabase, node: InsertPlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs):
         storage_engine = None
         table_catalog_entry = None
 
         # Get catalog entry
         table_name = self.node.table_ref.table.table_name
         database_name = self.node.table_ref.table.database_name
-        table_catalog_entry = self.catalog.get_table_catalog_entry(
+        table_catalog_entry = self.catalog().get_table_catalog_entry(
             table_name, database_name
         )
 
         # Implemented only for STRUCTURED_DATA
         assert (
             table_catalog_entry.table_type == TableType.STRUCTURED_DATA
         ), "INSERT only implemented for structured data"
@@ -47,13 +46,13 @@
         tuple_to_insert = tuple(values_to_insert)
         columns_to_insert = [col_node.col_name for col_node in self.node.column_list]
 
         # Adding all values to Batch for insert
         dataframe = pd.DataFrame([tuple_to_insert], columns=columns_to_insert)
         batch = Batch(dataframe)
 
-        storage_engine = StorageEngine.factory(table_catalog_entry)
+        storage_engine = StorageEngine.factory(self.db, table_catalog_entry)
         storage_engine.write(table_catalog_entry, batch)
 
         yield Batch(
             pd.DataFrame([f"Number of rows loaded: {str(len(values_to_insert))}"])
         )
```

### Comparing `evadb-0.2.6/eva/executor/join_build_executor.py` & `evadb-0.2.7/evadb/executor/join_build_executor.py`

 * *Files 17% similar despite different names*

```diff
@@ -10,22 +10,23 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.hash_join_build_plan import HashJoinBuildPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.hash_join_build_plan import HashJoinBuildPlan
 
 
 class BuildJoinExecutor(AbstractExecutor):
-    def __init__(self, node: HashJoinBuildPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: HashJoinBuildPlan):
+        super().__init__(db, node)
         self.predicate = None  # node.join_predicate
         self.join_type = node.join_type
         self.build_keys = node.build_keys
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         child_executor = self.children[0]
         # build in memory hash table and pass to the probe phase
```

### Comparing `evadb-0.2.6/eva/executor/lateral_join_executor.py` & `evadb-0.2.7/evadb/executor/lateral_join_executor.py`

 * *Files 16% similar despite different names*

```diff
@@ -10,30 +10,35 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import apply_predicate, apply_project
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.lateral_join_plan import LateralJoinPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import apply_predicate, apply_project
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.lateral_join_plan import LateralJoinPlan
 
 
 class LateralJoinExecutor(AbstractExecutor):
-    def __init__(self, node: LateralJoinPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: LateralJoinPlan):
+        super().__init__(db, node)
         self.predicate = node.join_predicate
         self.join_project = node.join_project
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         outer = self.children[0]
         inner = self.children[1]
         for outer_batch in outer.exec(**kwargs):
             for result_batch in inner.exec(lateral_input=outer_batch):
                 result_batch = Batch.join(outer_batch, result_batch)
                 result_batch.reset_index()
-                result_batch = apply_predicate(result_batch, self.predicate)
-                result_batch = apply_project(result_batch, self.join_project)
+                result_batch = apply_predicate(
+                    result_batch, self.predicate, self.catalog()
+                )
+                result_batch = apply_project(
+                    result_batch, self.join_project, self.catalog()
+                )
                 if not result_batch.empty():
                     yield result_batch
```

### Comparing `evadb-0.2.6/eva/executor/limit_executor.py` & `evadb-0.2.7/evadb/executor/limit_executor.py`

 * *Files 7% similar despite different names*

```diff
@@ -10,30 +10,31 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.limit_plan import LimitPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.limit_plan import LimitPlan
 
 
 class LimitExecutor(AbstractExecutor):
     """
     Limits the number of rows returned
 
     Arguments:
         node (AbstractPlan): The Limit Plan
 
     """
 
-    def __init__(self, node: LimitPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: LimitPlan):
+        super().__init__(db, node)
         self._limit_count = node.limit_value
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         child_executor = self.children[0]
         remaining_tuples = self._limit_count
         # aggregates the batches into one large batch
         for batch in child_executor.exec(**kwargs):
```

### Comparing `evadb-0.2.6/eva/executor/load_csv_executor.py` & `evadb-0.2.7/evadb/storage/abstract_storage_engine.py`

 * *Files 22% similar despite different names*

```diff
@@ -8,83 +8,66 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-import pandas as pd
+from abc import ABCMeta, abstractmethod
+from typing import Iterator
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import ExecutorError
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.load_data_plan import LoadDataPlan
-from eva.readers.csv_reader import CSVReader
-from eva.storage.storage_engine import StorageEngine
-from eva.utils.logging_manager import logger
-
-
-class LoadCSVExecutor(AbstractExecutor):
-    def __init__(self, node: LoadDataPlan):
-        super().__init__(node)
-        self.catalog = CatalogManager()
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.database import EVADatabase
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.models.storage.batch import Batch
 
-    def exec(self, *args, **kwargs):
+
+class AbstractStorageEngine(metaclass=ABCMeta):
+    """
+    Abstract class for defining storage engine. Storage engine is responsible
+    for handling data storage and retrieval tasks.
+    This contains a minimal set of APIs that each engine should implement
+
+    """
+
+    def __init__(self, db: EVADatabase):
+        self.db = db
+
+    @abstractmethod
+    def create(self, table: TableCatalogEntry):
+        """Interface that implements all the necessary task required for
+            creating the basic unit of storage(table or dataframe)
+
+        Attributes:
+            table: storage unit to be created
         """
-        Read the input csv file using pandas and persist data
-        using storage engine
+
+    @abstractmethod
+    def write(self, table: TableCatalogEntry, rows: Batch):
+        """Interface responsible for inserting the rows into the required
+        table. Internally calls the _open function and does the required
+        task.
+
+        Attributes:
+            table: storage unit to be created
+            rows : rows data to be written
         """
 
-        # Check table existence
-        table_info = self.node.table_info
-        database_name = table_info.database_name
-        table_name = table_info.table_name
-        table_obj = self.catalog.get_table_catalog_entry(
-            table_name,
-            database_name,
-        )
-        if table_obj is None:
-            error = f"{table_name} does not exist."
-            logger.error(error)
-            raise ExecutorError(error)
-
-        # Get the column information
-        column_list = []
-        for column in table_obj.columns:
-            column_list.append(
-                TupleValueExpression(
-                    col_name=column.name,
-                    table_alias=table_obj.name.lower(),
-                    col_object=column,
-                )
-            )
-
-        # Read the CSV file
-        # converters is a dictionary of functions that convert the values
-        # in the column to the desired type
-        csv_reader = CSVReader(
-            self.node.file_path,
-            column_list=column_list,
-            batch_mem_size=self.node.batch_mem_size,
-        )
-
-        storage_engine = StorageEngine.factory(table_obj)
-        # write with storage engine in batches
-        num_loaded_frames = 0
-        for batch in csv_reader.read():
-            storage_engine.write(table_obj, batch)
-            num_loaded_frames += len(batch)
-
-        # yield result
-        df_yield_result = Batch(
-            pd.DataFrame(
-                {
-                    "CSV": str(self.node.file_path),
-                    "Number of loaded frames": num_loaded_frames,
-                },
-                index=[0],
-            )
-        )
+    @abstractmethod
+    def read(
+        self,
+        table: TableCatalogEntry,
+        batch_mem_size: int = 30000000,
+        predicate: AbstractExpression = None,
+    ) -> Iterator[Batch]:
+        """Interface responsible for yielding row/rows to the client.
+        This should be implemented as an iterator over of table. Helpful
+        while doing full table scan. `pos` parameter is used if user wants
+        to fetch specific rows.
+
+        Attributes:
+            table: storage unit to be read
+            pos: row position to be returned
 
-        yield df_yield_result
+        Returns:
+            Batch: an iterator of the batch read
+        """
```

### Comparing `evadb-0.2.6/eva/executor/load_executor.py` & `evadb-0.2.7/evadb/executor/load_executor.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,37 +8,38 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.load_csv_executor import LoadCSVExecutor
-from eva.executor.load_multimedia_executor import LoadMultimediaExecutor
-from eva.parser.types import FileFormatType
-from eva.plan_nodes.load_data_plan import LoadDataPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.load_csv_executor import LoadCSVExecutor
+from evadb.executor.load_multimedia_executor import LoadMultimediaExecutor
+from evadb.parser.types import FileFormatType
+from evadb.plan_nodes.load_data_plan import LoadDataPlan
 
 
 class LoadDataExecutor(AbstractExecutor):
-    def __init__(self, node: LoadDataPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: LoadDataPlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs):
         """
         Use TYPE to determine the type of data to load.
         """
 
         # invoke the appropriate executor
         if self.node.file_options["file_format"] in [
             FileFormatType.VIDEO,
             FileFormatType.IMAGE,
             FileFormatType.DOCUMENT,
             FileFormatType.PDF,
         ]:
-            executor = LoadMultimediaExecutor(self.node)
+            executor = LoadMultimediaExecutor(self.db, self.node)
         elif self.node.file_options["file_format"] == FileFormatType.CSV:
-            executor = LoadCSVExecutor(self.node)
+            executor = LoadCSVExecutor(self.db, self.node)
 
         # for each batch, exec the executor
         for batch in executor.exec():
             yield batch
```

### Comparing `evadb-0.2.6/eva/executor/load_multimedia_executor.py` & `evadb-0.2.7/evadb/executor/load_multimedia_executor.py`

 * *Files 11% similar despite different names*

```diff
@@ -14,46 +14,42 @@
 # limitations under the License.
 import multiprocessing as mp
 from multiprocessing import Pool
 from pathlib import Path
 
 import pandas as pd
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import ExecutorError, iter_path_regex, validate_media
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.load_data_plan import LoadDataPlan
-from eva.storage.abstract_storage_engine import AbstractStorageEngine
-from eva.storage.storage_engine import StorageEngine
-from eva.utils.errors import DatasetFileNotFoundError
-from eva.utils.logging_manager import logger
-from eva.utils.s3_utils import download_from_s3
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import ExecutorError, iter_path_regex, validate_media
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.load_data_plan import LoadDataPlan
+from evadb.storage.abstract_storage_engine import AbstractStorageEngine
+from evadb.storage.storage_engine import StorageEngine
+from evadb.utils.errors import DatasetFileNotFoundError
+from evadb.utils.logging_manager import logger
+from evadb.utils.s3_utils import download_from_s3
 
 
 class LoadMultimediaExecutor(AbstractExecutor):
-    def __init__(self, node: LoadDataPlan):
-        super().__init__(node)
-        self.catalog = CatalogManager()
+    def __init__(self, db: EVADatabase, node: LoadDataPlan):
+        super().__init__(db, node)
         self.media_type = self.node.file_options["file_format"]
 
     def exec(self, *args, **kwargs):
         storage_engine = None
         table_obj = None
         try:
             video_files = []
             valid_files = []
 
             # If it is a s3 path, download the file to local
             if self.node.file_path.as_posix().startswith("s3:/"):
-                s3_dir = Path(
-                    ConfigurationManager().get_value("storage", "s3_download_dir")
-                )
+                s3_dir = Path(self.config.get_value("storage", "s3_download_dir"))
                 dst_path = s3_dir / self.node.table_info.table_name
                 dst_path.mkdir(parents=True, exist_ok=True)
                 video_files = download_from_s3(self.node.file_path, dst_path)
             else:
                 # Local Storage
                 video_files = list(iter_path_regex(self.node.file_path))
 
@@ -94,28 +90,30 @@
 
             # Create catalog entry
             table_info = self.node.table_info
             database_name = table_info.database_name
             table_name = table_info.table_name
             # Sanity check to make sure there is no existing table with same name
             do_create = False
-            table_obj = self.catalog.get_table_catalog_entry(table_name, database_name)
+            table_obj = self.catalog().get_table_catalog_entry(
+                table_name, database_name
+            )
             if table_obj:
                 msg = f"Adding to an existing table {table_name}."
                 logger.info(msg)
             # Create the catalog entry
             else:
                 table_obj = (
-                    self.catalog.create_and_insert_multimedia_table_catalog_entry(
+                    self.catalog().create_and_insert_multimedia_table_catalog_entry(
                         table_name, self.media_type
                     )
                 )
                 do_create = True
 
-            storage_engine = StorageEngine.factory(table_obj)
+            storage_engine = StorageEngine.factory(self.db, table_obj)
             if do_create:
                 storage_engine.create(table_obj)
 
             storage_engine.write(
                 table_obj,
                 Batch(pd.DataFrame({"file_path": valid_files})),
             )
```

### Comparing `evadb-0.2.6/eva/executor/nested_loop_join_executor.py` & `evadb-0.2.7/evadb/executor/nested_loop_join_executor.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,28 +10,31 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import apply_predicate
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.nested_loop_join_plan import NestedLoopJoinPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import apply_predicate
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.nested_loop_join_plan import NestedLoopJoinPlan
 
 
 class NestedLoopJoinExecutor(AbstractExecutor):
-    def __init__(self, node: NestedLoopJoinPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: NestedLoopJoinPlan):
+        super().__init__(db, node)
         self.predicate = node.join_predicate
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         outer = self.children[0]
         inner = self.children[1]
         for row1 in outer.exec(**kwargs):
             for row2 in inner.exec(**kwargs):
                 result_batch = Batch.join(row1, row2)
                 result_batch.reset_index()
-                result_batch = apply_predicate(result_batch, self.predicate)
+                result_batch = apply_predicate(
+                    result_batch, self.predicate, self.catalog()
+                )
                 if not result_batch.empty():
                     yield result_batch
```

### Comparing `evadb-0.2.6/eva/executor/orderby_executor.py` & `evadb-0.2.7/evadb/executor/orderby_executor.py`

 * *Files 10% similar despite different names*

```diff
@@ -10,34 +10,35 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import ExecutorError
-from eva.expression.function_expression import FunctionExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.models.storage.batch import Batch
-from eva.parser.types import ParserOrderBySortType
-from eva.plan_nodes.orderby_plan import OrderByPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import ExecutorError
+from evadb.expression.function_expression import FunctionExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.models.storage.batch import Batch
+from evadb.parser.types import ParserOrderBySortType
+from evadb.plan_nodes.orderby_plan import OrderByPlan
 
 
 class OrderByExecutor(AbstractExecutor):
     """
     Sort the frames which satisfy the condition
 
     Arguments:
         node (AbstractPlan): The OrderBy Plan
 
     """
 
-    def __init__(self, node: OrderByPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: OrderByPlan):
+        super().__init__(db, node)
         self._orderby_list = node.orderby_list
         self._columns = node.columns
         self._sort_types = node.sort_types
         self.batch_sizes = []
 
     def _extract_column_name(self, col):
         col_name = []
```

### Comparing `evadb-0.2.6/eva/executor/pp_executor.py` & `evadb-0.2.7/evadb/executor/pp_executor.py`

 * *Files 14% similar despite different names*

```diff
@@ -10,32 +10,33 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.pp_plan import PPScanPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.pp_plan import PPScanPlan
 
 
 class PPExecutor(AbstractExecutor):
     """
     Applies PP to filter out the frames that doesn't satisfy the condition
     Arguments:
         node (AbstractPlan): ...
 
     Note: This look kind of redundant. This logic for now is similar to that
     of sequential scan executor. Will decide to delete it depending on how
     sequential scan evolves.
     """
 
-    def __init__(self, node: PPScanPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: PPScanPlan):
+        super().__init__(db, node)
         self.predicate = node.predicate
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         child_executor = self.children[0]
         for batch in child_executor.exec():
             outcomes = self.predicate.evaluate(batch)
             required_frame_ids = []
```

### Comparing `evadb-0.2.6/eva/executor/predicate_executor.py` & `evadb-0.2.7/evadb/executor/predicate_executor.py`

 * *Files 10% similar despite different names*

```diff
@@ -10,26 +10,27 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import apply_predicate
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.predicate_plan import PredicatePlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import apply_predicate
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.predicate_plan import PredicatePlan
 
 
 class PredicateExecutor(AbstractExecutor):
     """ """
 
-    def __init__(self, node: PredicatePlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: PredicatePlan):
+        super().__init__(db, node)
         self.predicate = node.predicate
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         child_executor = self.children[0]
         for batch in child_executor.exec(**kwargs):
-            batch = apply_predicate(batch, self.predicate)
+            batch = apply_predicate(batch, self.predicate, self.catalog())
             if not batch.empty():
                 yield batch
```

### Comparing `evadb-0.2.6/eva/executor/project_executor.py` & `evadb-0.2.7/evadb/executor/project_executor.py`

 * *Files 11% similar despite different names*

```diff
@@ -10,27 +10,28 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import apply_project
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.project_plan import ProjectPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import apply_project
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.project_plan import ProjectPlan
 
 
 class ProjectExecutor(AbstractExecutor):
     """ """
 
-    def __init__(self, node: ProjectPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: ProjectPlan):
+        super().__init__(db, node)
         self.target_list = node.target_list
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         child_executor = self.children[0]
         for batch in child_executor.exec(**kwargs):
-            batch = apply_project(batch, self.target_list)
+            batch = apply_project(batch, self.target_list, self.catalog())
 
             if not batch.empty():
                 yield batch
```

### Comparing `evadb-0.2.6/eva/executor/ray_utils.py` & `evadb-0.2.7/evadb/executor/ray_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 import os
 from typing import Callable, Dict, List
 
 import ray
 from ray.exceptions import RayTaskError
 from ray.util.queue import Queue
 
-from eva.executor.executor_utils import ExecutorError
+from evadb.executor.executor_utils import ExecutorError
 
 
 class StageCompleteSignal:
     pass
 
 
 @ray.remote(num_cpus=0)
```

### Comparing `evadb-0.2.6/eva/executor/rename_executor.py` & `evadb-0.2.7/evadb/executor/rename_executor.py`

 * *Files 12% similar despite different names*

```diff
@@ -8,24 +8,25 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.plan_nodes.rename_plan import RenamePlan
-from eva.storage.storage_engine import StorageEngine
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.plan_nodes.rename_plan import RenamePlan
+from evadb.storage.storage_engine import StorageEngine
 
 
 class RenameExecutor(AbstractExecutor):
-    def __init__(self, node: RenamePlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: RenamePlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs):
         """rename table executor
 
         Calls the catalog to modified catalog entry corresponding to the table.
         """
         obj = self.node.old_table.table.table_obj
-        storage_engine = StorageEngine.factory(obj)
+        storage_engine = StorageEngine.factory(self.db, obj)
         storage_engine.rename(obj, self.node.new_name)
```

### Comparing `evadb-0.2.6/eva/executor/sample_executor.py` & `evadb-0.2.7/evadb/executor/sample_executor.py`

 * *Files 18% similar despite different names*

```diff
@@ -10,30 +10,31 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.sample_plan import SamplePlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.sample_plan import SamplePlan
 
 
 class SampleExecutor(AbstractExecutor):
     """
     Samples uniformly from the rows.
 
     Arguments:
         node (AbstractPlan): The Sample Plan
 
     """
 
-    def __init__(self, node: SamplePlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: SamplePlan):
+        super().__init__(db, node)
         self._sample_freq = node.sample_freq.value
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         child_executor = self.children[0]
 
         current = 0
         for batch in child_executor.exec():
```

### Comparing `evadb-0.2.6/eva/executor/seq_scan_executor.py` & `evadb-0.2.7/evadb/executor/seq_scan_executor.py`

 * *Files 6% similar despite different names*

```diff
@@ -10,42 +10,43 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import apply_predicate, apply_project
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.seq_scan_plan import SeqScanPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import apply_predicate, apply_project
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.seq_scan_plan import SeqScanPlan
 
 
 class SequentialScanExecutor(AbstractExecutor):
     """
     Applies predicates to filter the frames which satisfy the condition
     Arguments:
         node (AbstractPlan): The SequentialScanPlan
 
     """
 
-    def __init__(self, node: SeqScanPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: SeqScanPlan):
+        super().__init__(db, node)
         self.predicate = node.predicate
         self.project_expr = node.columns
         self.alias = node.alias
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         child_executor = self.children[0]
         for batch in child_executor.exec(**kwargs):
             # apply alias to the batch
             # id, data -> myvideo.id, myvideo.data
             if self.alias:
                 batch.modify_column_alias(self.alias)
 
             # We do the predicate first
-            batch = apply_predicate(batch, self.predicate)
+            batch = apply_predicate(batch, self.predicate, self.catalog())
             # Then do project
-            batch = apply_project(batch, self.project_expr)
+            batch = apply_project(batch, self.project_expr, self.catalog())
 
             if not batch.empty():
                 yield batch
```

### Comparing `evadb-0.2.6/eva/executor/show_info_executor.py` & `evadb-0.2.7/evadb/executor/show_info_executor.py`

 * *Files 25% similar despite different names*

```diff
@@ -10,39 +10,38 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import pandas as pd
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import TableType
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.parser.types import ShowType
-from eva.plan_nodes.show_info_plan import ShowInfoPlan
+from evadb.catalog.catalog_type import TableType
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.parser.types import ShowType
+from evadb.plan_nodes.show_info_plan import ShowInfoPlan
 
 
 class ShowInfoExecutor(AbstractExecutor):
-    def __init__(self, node: ShowInfoPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: ShowInfoPlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs):
-        catalog_manager = CatalogManager()
         show_entries = []
 
         assert (
             self.node.show_type is ShowType.UDFS or ShowType.TABLES
         ), f"Show command does not support type {self.node.show_type}"
 
         if self.node.show_type is ShowType.UDFS:
-            udfs = catalog_manager.get_all_udf_catalog_entries()
+            udfs = self.catalog().get_all_udf_catalog_entries()
             for udf in udfs:
                 show_entries.append(udf.display_format())
         elif self.node.show_type is ShowType.TABLES:
-            tables = catalog_manager.get_all_table_catalog_entries()
+            tables = self.catalog().get_all_table_catalog_entries()
             for table in tables:
                 if table.table_type != TableType.SYSTEM_STRUCTURED_DATA:
                     show_entries.append(table.name)
             show_entries = {"name": show_entries}
 
         yield Batch(pd.DataFrame(show_entries))
```

### Comparing `evadb-0.2.6/eva/executor/storage_executor.py` & `evadb-0.2.7/evadb/executor/storage_executor.py`

 * *Files 5% similar despite different names*

```diff
@@ -10,30 +10,31 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.catalog.catalog_type import TableType
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import ExecutorError
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.storage_plan import StoragePlan
-from eva.storage.storage_engine import StorageEngine
-from eva.utils.logging_manager import logger
+from evadb.catalog.catalog_type import TableType
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import ExecutorError
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.storage_plan import StoragePlan
+from evadb.storage.storage_engine import StorageEngine
+from evadb.utils.logging_manager import logger
 
 
 class StorageExecutor(AbstractExecutor):
-    def __init__(self, node: StoragePlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: StoragePlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         try:
-            storage_engine = StorageEngine.factory(self.node.table)
+            storage_engine = StorageEngine.factory(self.db, self.node.table)
 
             if self.node.table.table_type == TableType.VIDEO_DATA:
                 return storage_engine.read(
                     self.node.table,
                     self.node.batch_mem_size,
                     predicate=self.node.predicate,
                     sampling_rate=self.node.sampling_rate,
```

### Comparing `evadb-0.2.6/eva/executor/union_executor.py` & `evadb-0.2.7/evadb/executor/union_executor.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,29 +10,30 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.union_plan import UnionPlan
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.union_plan import UnionPlan
 
 
 class UnionExecutor(AbstractExecutor):
     """
     Merge the seq scan queries
     Arguments:
         node (AbstractPlan): The UnionPlan
 
     """
 
-    def __init__(self, node: UnionPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: UnionPlan):
+        super().__init__(db, node)
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
         assert self.node.all is True, "Only UNION ALL is supported now."
 
         # We should have only two children
         for child in self.children:
             for batch in child.exec():
```

### Comparing `evadb-0.2.6/eva/executor/vector_index_scan_executor.py` & `evadb-0.2.7/evadb/executor/vector_index_scan_executor.py`

 * *Files 9% similar despite different names*

```diff
@@ -12,52 +12,51 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Iterator
 
 import pandas as pd
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.sql_config import IDENTIFIER_COLUMN
-from eva.executor.abstract_executor import AbstractExecutor
-from eva.executor.executor_utils import handle_vector_store_params
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.vector_index_scan_plan import VectorIndexScanPlan
-from eva.third_party.vector_stores.types import VectorIndexQuery
-from eva.third_party.vector_stores.utils import VectorStoreFactory
+from evadb.catalog.sql_config import IDENTIFIER_COLUMN
+from evadb.database import EVADatabase
+from evadb.executor.abstract_executor import AbstractExecutor
+from evadb.executor.executor_utils import handle_vector_store_params
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.vector_index_scan_plan import VectorIndexScanPlan
+from evadb.third_party.vector_stores.types import VectorIndexQuery
+from evadb.third_party.vector_stores.utils import VectorStoreFactory
+from evadb.utils.logging_manager import logger
 
 
 # Helper function for getting row_id column alias.
 def get_row_id_column_alias(column_list):
     for column in column_list:
         alias, col_name = column.split(".")
         if col_name == IDENTIFIER_COLUMN:
             return alias
 
 
 class VectorIndexScanExecutor(AbstractExecutor):
-    def __init__(self, node: VectorIndexScanPlan):
-        super().__init__(node)
+    def __init__(self, db: EVADatabase, node: VectorIndexScanPlan):
+        super().__init__(db, node)
 
         self.index_name = node.index_name
         self.limit_count = node.limit_count
         self.search_query_expr = node.search_query_expr
 
     def exec(self, *args, **kwargs) -> Iterator[Batch]:
-        catalog_manager = CatalogManager()
-
         # Fetch the index from disk.
-        index_catalog_entry = catalog_manager.get_index_catalog_entry_by_name(
+        index_catalog_entry = self.catalog().get_index_catalog_entry_by_name(
             self.index_name
         )
         self.index_path = index_catalog_entry.save_file_path
         self.index = VectorStoreFactory.init_vector_store(
             self.node.vector_store_type,
             self.index_name,
-            **handle_vector_store_params(self.node.vector_store_type, self.index_path)
+            **handle_vector_store_params(self.node.vector_store_type, self.index_path),
         )
 
         # Get the query feature vector. Create a dummy
         # batch to retreat a single file path.
         dummy_batch = Batch(
             frames=pd.DataFrame(
                 {"0": [0]},
@@ -75,15 +74,24 @@
         )
         # todo support queries over distance as well
         # distance_list = index_result.similarities
         row_id_np = index_result.ids
 
         # Load projected columns from disk and join with search results.
         row_id_col_name = None
-        res_row_list = [None for _ in range(self.limit_count.value)]
+
+        # handle the case where the index_results are less than self.limit_count.value
+        num_required_results = self.limit_count.value
+        if len(index_result.ids) < self.limit_count.value:
+            num_required_results = len(index_result.ids)
+            logger.warning(
+                f"The index {self.index_name} returned only {num_required_results} results, which is fewer than the required {self.limit_count.value}."
+            )
+
+        res_row_list = [None for _ in range(num_required_results)]
         for batch in self.children[0].exec(**kwargs):
             column_list = batch.columns
             if not row_id_col_name:
                 row_id_alias = get_row_id_column_alias(column_list)
                 row_id_col_name = "{}.{}".format(row_id_alias, IDENTIFIER_COLUMN)
 
             # Nested join.
```

### Comparing `evadb-0.2.6/eva/expression/__init__.py` & `evadb-0.2.7/evadb/expression/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/expression/abstract_expression.py` & `evadb-0.2.7/evadb/expression/abstract_expression.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/expression/aggregation_expression.py` & `evadb-0.2.7/evadb/expression/aggregation_expression.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,20 +8,20 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.abstract_expression import (
+from evadb.expression.abstract_expression import (
     AbstractExpression,
     ExpressionReturnType,
     ExpressionType,
 )
-from eva.models.storage.batch import Batch
+from evadb.models.storage.batch import Batch
 
 
 class AggregationExpression(AbstractExpression):
     def __init__(
         self,
         exp_type: ExpressionType,
         left: AbstractExpression,
```

### Comparing `evadb-0.2.6/eva/expression/arithmetic_expression.py` & `evadb-0.2.7/evadb/expression/arithmetic_expression.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,20 +9,20 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from eva.expression.abstract_expression import (
+from evadb.expression.abstract_expression import (
     AbstractExpression,
     ExpressionReturnType,
     ExpressionType,
 )
-from eva.models.storage.batch import Batch
+from evadb.models.storage.batch import Batch
 
 
 class ArithmeticExpression(AbstractExpression):
     def __init__(
         self,
         exp_type: ExpressionType,
         left: AbstractExpression,
```

### Comparing `evadb-0.2.6/eva/expression/comparison_expression.py` & `evadb-0.2.7/evadb/expression/comparison_expression.py`

 * *Files 0% similar despite different names*

```diff
@@ -9,20 +9,20 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from eva.expression.abstract_expression import (
+from evadb.expression.abstract_expression import (
     AbstractExpression,
     ExpressionReturnType,
     ExpressionType,
 )
-from eva.models.storage.batch import Batch
+from evadb.models.storage.batch import Batch
 
 
 class ComparisonExpression(AbstractExpression):
     def __init__(
         self,
         exp_type: ExpressionType,
         left: AbstractExpression,
```

### Comparing `evadb-0.2.6/eva/expression/constant_value_expression.py` & `evadb-0.2.7/evadb/expression/constant_value_expression.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,17 +13,17 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Any
 
 import numpy as np
 import pandas as pd
 
-from eva.catalog.catalog_type import ColumnType
-from eva.expression.abstract_expression import AbstractExpression, ExpressionType
-from eva.models.storage.batch import Batch
+from evadb.catalog.catalog_type import ColumnType
+from evadb.expression.abstract_expression import AbstractExpression, ExpressionType
+from evadb.models.storage.batch import Batch
 
 
 class ConstantValueExpression(AbstractExpression):
     # Todo Implement generic value class
     # for now we don't assign any class to value
     # it can have types like string, int etc
     # return type not set, handle that based on value
```

### Comparing `evadb-0.2.6/eva/expression/expression_utils.py` & `evadb-0.2.7/evadb/expression/expression_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,19 +11,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import List, Set
 
-from eva.expression.abstract_expression import AbstractExpression, ExpressionType
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.logical_expression import LogicalExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
+from evadb.expression.abstract_expression import AbstractExpression, ExpressionType
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.logical_expression import LogicalExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
 
 
 def to_conjunction_list(
     expression_tree: AbstractExpression,
 ) -> List[AbstractExpression]:
     """Convert expression tree to list of conjunctives
```

### Comparing `evadb-0.2.6/eva/expression/function_expression.py` & `evadb-0.2.7/evadb/expression/function_expression.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,25 +14,25 @@
 # limitations under the License.
 from dataclasses import dataclass
 from typing import Callable, List, Tuple
 
 import numpy as np
 import pandas as pd
 
-from eva.catalog.models.udf_catalog import UdfCatalogEntry
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.constants import NO_GPU
-from eva.executor.execution_context import Context
-from eva.expression.abstract_expression import AbstractExpression, ExpressionType
-from eva.models.storage.batch import Batch
-from eva.parser.alias import Alias
-from eva.udfs.gpu_compatible import GPUCompatible
-from eva.utils.kv_cache import DiskKVCache
-from eva.utils.logging_manager import logger
-from eva.utils.stats import UDFStats
+from evadb.catalog.models.udf_catalog import UdfCatalogEntry
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.constants import NO_GPU
+from evadb.executor.execution_context import Context
+from evadb.expression.abstract_expression import AbstractExpression, ExpressionType
+from evadb.models.storage.batch import Batch
+from evadb.parser.alias import Alias
+from evadb.udfs.gpu_compatible import GPUCompatible
+from evadb.utils.kv_cache import DiskKVCache
+from evadb.utils.logging_manager import logger
+from evadb.utils.stats import UDFStats
 
 
 class FunctionExpression(AbstractExpression):
     """
     Consider FunctionExpression: ObjDetector -> (labels, boxes)
 
     `output`: If the user wants only subset of outputs. Eg,
@@ -97,37 +97,29 @@
     def enable_cache(self, cache: "FunctionExpressionCache"):
         self._cache = cache
         return self
 
     def has_cache(self):
         return self._cache is not None
 
-    def persist_stats(self):
-        from eva.catalog.catalog_manager import CatalogManager
-
+    def consolidate_stats(self):
         if self.udf_obj is None:
             return
-        udf_id = self.udf_obj.row_id
 
         # if the function expression support cache only approximate using cache_miss entries.
         if self.has_cache() and self._stats.cache_misses > 0:
             cost_per_func_call = (
                 self._stats.timer.total_elapsed_time / self._stats.cache_misses
             )
         else:
             cost_per_func_call = self._stats.timer.total_elapsed_time / (
                 self._stats.num_calls
             )
 
-        # persist stats to catalog only if it differ by greater than 10% from
-        # the previous value
         if abs(self._stats.prev_cost - cost_per_func_call) > cost_per_func_call / 10:
-            CatalogManager().upsert_udf_cost_catalog_entry(
-                udf_id, self.udf_obj.name, cost_per_func_call
-            )
             self._stats.prev_cost = cost_per_func_call
 
     def evaluate(self, batch: Batch, **kwargs) -> Batch:
         func = self._gpu_enabled_function()
         # record the time taken for the udf execution
         # note the udf might be using cache
         with self._stats.timer:
@@ -140,15 +132,15 @@
                 outcomes.modify_column_alias(self.alias)
 
         # record the number of function calls
         self._stats.num_calls += len(batch)
 
         # try persisting the stats to catalog and do not crash if we fail in doing so
         try:
-            self.persist_stats()
+            self.consolidate_stats()
         except Exception as e:
             logger.warn(
                 f"Persisting Function Expression {str(self)} stats failed with {str(e)}"
             )
 
         return outcomes
```

### Comparing `evadb-0.2.6/eva/expression/logical_expression.py` & `evadb-0.2.7/evadb/expression/logical_expression.py`

 * *Files 0% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.abstract_expression import (
+from evadb.expression.abstract_expression import (
     AbstractExpression,
     ExpressionReturnType,
     ExpressionType,
 )
 
 
 class LogicalExpression(AbstractExpression):
```

### Comparing `evadb-0.2.6/eva/expression/tuple_value_expression.py` & `evadb-0.2.7/evadb/expression/tuple_value_expression.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,17 +10,17 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Union
 
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.models.storage.batch import Batch
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.models.storage.batch import Batch
 
 from .abstract_expression import (
     AbstractExpression,
     ExpressionReturnType,
     ExpressionType,
 )
```

### Comparing `evadb-0.2.6/eva/interfaces/__init__.py` & `evadb-0.2.7/evadb/catalog/services/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/interfaces/relational/__init__.py` & `evadb-0.2.7/evadb/interfaces/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/interfaces/relational/db.py` & `evadb-0.2.7/evadb/interfaces/relational/db.py`

 * *Files 15% similar despite different names*

```diff
@@ -12,141 +12,67 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import asyncio
 
 import pandas
 
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.interfaces.relational.relation import EVARelation
-from eva.interfaces.relational.utils import execute_statement, try_binding
-from eva.models.server.response import Response
-from eva.models.storage.batch import Batch
-from eva.parser.alias import Alias
-from eva.parser.select_statement import SelectStatement
-from eva.parser.utils import (
+from evadb.configuration.constants import EVA_DATABASE_DIR
+from evadb.database import EVADatabase, init_eva_db_instance
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.interfaces.relational.relation import EVADBQuery
+from evadb.interfaces.relational.utils import execute_statement, try_binding
+from evadb.models.server.response import Response
+from evadb.models.storage.batch import Batch
+from evadb.parser.alias import Alias
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.utils import (
+    parse_create_udf,
     parse_create_vector_index,
+    parse_drop_index,
+    parse_drop_table,
+    parse_drop_udf,
     parse_load,
     parse_query,
     parse_table_clause,
 )
-from eva.utils.logging_manager import logger
+from evadb.udfs.udf_bootstrap_queries import init_builtin_udfs
+from evadb.utils.logging_manager import logger
 
 
-class EVAConnection:
-    def __init__(self, reader, writer):
+class EVADBConnection:
+    def __init__(self, evadb: EVADatabase, reader, writer):
         self._reader = reader
         self._writer = writer
         self._cursor = None
         self._result: Batch = None
+        self._evadb = evadb
 
-    def create_vector_index(
-        self, index_name: str, table_name: str, expr: str, using: str
-    ) -> "EVAConnection":
-        """
-        Create a vector index on a table in the database.
-
-        Args:
-            index_name (str): Name of the index to be created.
-            table_name (str): Name of the table on which to build the index.
-            expr (str): Expression defining the indexed vector column.
-            using (str): Name of the vector indexing method to use.
+    def cursor(self):
+        """Retrieves a cursor associated with the connection.
 
         Returns:
-            EVAConnection: The connection object for executing further operations.
-        """
-        stmt = parse_create_vector_index(index_name, table_name, expr, using)
-        self._result = execute_statement(stmt)
-        return self
+            EVADBCursor: The cursor object used to execute queries.
 
-    def cursor(self) -> "EVACursor":
-        """
-        Get a cursor for executing database operations.
 
-        Returns:
-            EVACursor: The cursor object for executing operations on the database.
+        Examples:
+            >>> from eva import connect
+            >>> conn = connect()
+            >>> cursor = conn.cursor()
         """
-
         # One unique cursor for one connection
         if self._cursor is None:
-            self._cursor = EVACursor(self)
+            self._cursor = EVADBCursor(self)
         return self._cursor
 
-    def df(self) -> pandas.DataFrame:
-        """
-        Get the result of the last executed query on the connection as a pandas
-        DataFrame.
-
-        Returns:
-            pandas.DataFrame: The result of the query as a DataFrame.
-
-        Raises:
-            Exception: If there is no valid result with the current connection.
-        """
-        if not self._result:
-            raise Exception("No valid result with the current connection")
-        return self._result.frames
-
-    def load(
-        self, file_regex: str, table_name: str, format: str, **kwargs
-    ) -> EVARelation:
-        """
-        Load data from files into a table in the database.
-
-        Args:
-            file_regex (str): Regular expression pattern for matching input files.
-            table_name (str): Name of the table to be created.
-            format (str): File format of the input files.
-            **kwargs: Additional keyword arguments for configuring the load operation.
-
-        Returns:
-            EVARelation: The EVARelation object representing the loaded table.
-        """
-        return self.cursor().load(file_regex, table_name, format, **kwargs)
-
-    def sql(self, sql_query: str) -> EVARelation:
-        """
-        Execute a SQL query.
-
-        Args:
-            sql_query (str): The SQL query to execute.
-
-        Returns:
-            EVARelation: The EVARelation object representing the result of the query.
-        """
-        return self.cursor().sql(sql_query)
-
-    def table(self, table_name: str) -> EVARelation:
-        """
-        Get a EVARelation object representing a table in the database.
 
-        Args:
-            table_name (str): Name of the table.
-
-        Returns:
-            EVARelation: The EVARelation object representing the table.
-        """
-        return self.cursor().table(table_name)
-
-    def query(self, sql_query: str) -> EVARelation:
-        """
-        Execute a SQL query.
-
-        Args:
-            sql_query (str): The SQL query to execute.
-
-        Returns:
-            EVARelation: The EVARelation object representing the result of the query.
-        """
-        return self.cursor().query(sql_query)
-
-
-class EVACursor(object):
+class EVADBCursor(object):
     def __init__(self, connection):
         self._connection = connection
+        self._evadb = connection._evadb
         self._pending_query = False
         self._result = None
 
     async def execute_async(self, query: str):
         """
         Send query to the EVA server.
         """
@@ -204,123 +130,194 @@
         def func_sync(*args, **kwargs):
             loop = asyncio.get_event_loop()
             res = loop.run_until_complete(func(*args, **kwargs))
             return res
 
         return func_sync
 
-    def table(self, table_name: str) -> EVARelation:
+    def table(self, table_name: str) -> EVADBQuery:
         """
-        Get a EVARelation object representing a table in the database.
+        Retrieves data from a table in the database.
 
         Args:
             table_name (str): Name of the table.
 
         Returns:
-            EVARelation: The EVARelation object representing the table.
+            EVADBQuery: The EVADBQuery object representing the table query.
         """
         table = parse_table_clause(table_name)
         # SELECT * FROM table
         select_stmt = SelectStatement(
             target_list=[TupleValueExpression(col_name="*")], from_table=table
         )
-        try_binding(select_stmt)
-        return EVARelation(select_stmt, alias=Alias(table_name.lower()))
+        try_binding(self._evadb.catalog, select_stmt)
+        return EVADBQuery(self._evadb, select_stmt, alias=Alias(table_name.lower()))
 
     def df(self) -> pandas.DataFrame:
         """
-        Get the result of the last executed query on the cursor as a pandas
-        DataFrame.
+        Returns the result as a pandas DataFrame.
 
         Returns:
-            pandas.DataFrame: The result of the query as a DataFrame.
+            pandas.DataFrame: The result as a DataFrame.
 
         Raises:
-            Exception: If there is no valid result with the current cursor.
+            Exception: If no valid result is available with the current connection.
         """
         if not self._result:
-            raise Exception("No valid result with the current connection")
+            raise Exception("No valid result with the current cursor")
         return self._result.frames
 
     def create_vector_index(
         self, index_name: str, table_name: str, expr: str, using: str
-    ) -> "EVACursor":
+    ) -> "EVADBCursor":
         """
-        Create a vector index on a table in the database.
+        Creates a vector index using the provided expr on the table.
 
         Args:
-            index_name (str): Name of the index to be created.
-            table_name (str): Name of the table on which to build the index.
-            expr (str): Expression defining the indexed vector column.
-            using (str): Name of the vector indexing method to use.
+            index_name (str): Name of the index.
+            table_name (str): Name of the table.
+            expr (str): Expression used to build the vector index.
+            using (str): Method used for indexing, can be `FAISS` or `QDRANT`.
 
         Returns:
-            EVACursor: The cursor object for executing further operations.
+            EVADBCursor: The EVADBCursor object.
+
         """
         stmt = parse_create_vector_index(index_name, table_name, expr, using)
-        self._result = execute_statement(stmt)
+        self._result = execute_statement(self._evadb, stmt)
         return self
 
     def load(
         self, file_regex: str, table_name: str, format: str, **kwargs
-    ) -> EVARelation:
+    ) -> EVADBQuery:
         """
-        Load data from files into a table in the database.
+        Loads data from files into a table.
 
         Args:
-            file_regex (str): Regular expression pattern for matching input files.
-            table_name (str): Name of the table to be created.
-            format (str): File format of the input files.
+            file_regex (str): Regular expression specifying the files to load.
+            table_name (str): Name of the table.
+            format (str): File format of the data.
             **kwargs: Additional keyword arguments for configuring the load operation.
 
         Returns:
-            EVARelation: The EVARelation object representing the loaded table.
+            EVADBQuery: The EVADBQuery object representing the load query.
         """
         # LOAD {FORMAT} file_regex INTO table_name
         stmt = parse_load(table_name, file_regex, format, **kwargs)
-        return EVARelation(stmt)
+        return EVADBQuery(self._evadb, stmt)
 
-    def query(self, sql_query: str) -> EVARelation:
+    def drop_table(self, table_name: str, if_exists: bool = True) -> "EVADBQuery":
         """
-        Execute a SQL query.
+        Drop a table in the database.
 
         Args:
-            sql_query (str): The SQL query to execute.
+            table_name (str): Name of the table to be dropped.
+            if_exists (bool): If True, do not raise an error if the Tabel does not already exist. If False, raise an error.
 
-        Returns:
-            EVARelation: The EVARelation object representing the result of the query.
+        Returns
+            EVADBQuery: The EVADBQuery object representing the DROP TABLE.
         """
-        stmt = parse_query(sql_query)
-        return EVARelation(stmt)
+        stmt = parse_drop_table(table_name, if_exists)
+        return EVADBQuery(self._evadb, stmt)
 
-    def sql(self, sql_query: str) -> EVARelation:
+    def drop_udf(self, udf_name: str, if_exists: bool = True) -> "EVADBQuery":
         """
-        Execute a SQL query.
+        Drop a udf in the database.
 
         Args:
-            sql_query (str): The SQL query to execute.
+            udf_name (str): Name of the udf to be dropped.
+            if_exists (bool): If True, do not raise an error if the UDF does not already exist. If False, raise an error.
 
-        Returns:
-            EVARelation: The EVARelation object representing the result of the query.
+        Returns
+            EVADBQuery: The EVADBQuery object representing the DROP UDF.
         """
-        return self.query(sql_query)
+        stmt = parse_drop_udf(udf_name, if_exists)
+        return EVADBQuery(self._evadb, stmt)
 
+    def drop_index(self, index_name: str, if_exists: bool = True) -> "EVADBQuery":
+        """
+        Drop an index in the database.
 
-async def get_connection(host: str, port: int) -> EVAConnection:
-    reader, writer = await asyncio.open_connection(host, port)
-    connection = EVAConnection(reader, writer)
-    return connection
+        Args:
+            index_name (str): Name of the index to be dropped.
+            if_exists (bool): If True, do not raise an error if the index does not already exist. If False, raise an error.
 
+        Returns
+            EVADBQuery: The EVADBQuery object representing the DROP INDEX.
+        """
+        stmt = parse_drop_index(index_name, if_exists)
+        return EVADBQuery(self._evadb, stmt)
+
+    def create_udf(
+        self,
+        udf_name: str,
+        if_not_exists: bool = True,
+        impl_path: str = None,
+        type: str = None,
+        **kwargs
+    ) -> "EVADBQuery":
+        """
+        Create a udf in the database.
 
-def connect(host: str = "0.0.0.0", port: int = 8803) -> EVAConnection:
+        Args:
+            udf_name (str): Name of the udf to be created.
+            if_not_exists (bool): If True, do not raise an error if the UDF already exist. If False, raise an error.
+            impl_path (str): Path string to udf's implementation.
+            type (str): Type of the udf (e.g. HuggingFace).
+            **kwargs: Additional keyword arguments for configuring the create udf operation.
+
+        Returns
+            EVADBQuery: The EVADBQuery object representing the UDF created.
+        """
+        stmt = parse_create_udf(udf_name, if_not_exists, impl_path, type, **kwargs)
+        return EVADBQuery(self._evadb, stmt)
+
+    def query(self, sql_query: str) -> EVADBQuery:
+        """
+        Executes a SQL query.
+
+        Args:
+            sql_query (str): The SQL query to be executed
+        Returns:
+            EVADBQuery: The EVADBQuery object.
+        """
+        stmt = parse_query(sql_query)
+        return EVADBQuery(self._evadb, stmt)
+
+
+def connect(
+    eva_dir: str = EVA_DATABASE_DIR, sql_backend: str = None
+) -> EVADBConnection:
     """
-    Connect to the EVA server and return a connection object.
+    Connects to the EVA server and returns a connection object.
 
     Args:
-        host (str): The hostname or IP address of the EVA server. Default is "0.0.0.0".
-        port (int): The port number of the EVA server. Default is 8803.
+        eva_dir (str): The directory used by EVA to store database-related content. Default is "eva_db".
+        sql_backend (str): Custom database URI to be used. We follow the SQLAlchemy database URL format.
+            Default is SQLite in the EVA directory. See https://docs.sqlalchemy.org/en/20/core/engines.html#database-urls.
 
     Returns:
-        EVAConnection: A connection object representing the connection to the EVA server.
+        EVADBConnection: A connection object representing the connection to the EVA database.
     """
+
+    # As we are not employing a client-server approach for the Pythonic interface, the
+    # host and port parameters are irrelevant. Additionally, for the EVADBConnection, the
+    # reader and writer parameters are not relevant in the serverless approach.
+    evadb = init_eva_db_instance(eva_dir, custom_db_uri=sql_backend)
+    init_builtin_udfs(evadb, mode="release")
+    return EVADBConnection(evadb, None, None)
+
+
+# WIP
+# support remote connections from pythonic APIs
+
+
+async def get_connection(host: str, port: int) -> EVADBConnection:
+    reader, writer = await asyncio.open_connection(host, port)
+    # no db required for remote connection
+    connection = EVADBConnection(None, reader, writer)
+    return connection
+
+
+def connect_remote(host: str, port: int) -> EVADBConnection:
     connection = asyncio.run(get_connection(host, port))
     return connection
```

### Comparing `evadb-0.2.6/eva/interfaces/relational/relation.py` & `evadb-0.2.7/evadb/interfaces/relational/relation.py`

 * *Files 15% similar despite different names*

```diff
@@ -12,64 +12,69 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Union
 
 import pandas
 
-from eva.interfaces.relational.utils import (
+from evadb.database import EVADatabase
+from evadb.interfaces.relational.utils import (
     create_limit_expression,
     create_star_expression,
     execute_statement,
     handle_select_clause,
     sql_predicate_to_expresssion_tree,
     sql_string_to_expresssion_list,
     string_to_lateral_join,
     try_binding,
 )
-from eva.models.storage.batch import Batch
-from eva.parser.alias import Alias
-from eva.parser.select_statement import SelectStatement
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import JoinNode, TableRef
-from eva.parser.types import JoinType
-from eva.parser.utils import parse_sql_orderby_expr
+from evadb.models.storage.batch import Batch
+from evadb.parser.alias import Alias
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import JoinNode, TableRef
+from evadb.parser.types import JoinType
+from evadb.parser.utils import parse_sql_orderby_expr
 
 
-class EVARelation:
+class EVADBQuery:
     def __init__(
-        self, query_node: Union[AbstractStatement, TableRef], alias: Alias = None
+        self,
+        evadb: EVADatabase,
+        query_node: Union[AbstractStatement, TableRef],
+        alias: Alias = None,
     ):
+        self._evadb = evadb
         self._query_node = query_node
         self._alias = alias
 
-    def alias(self, alias: str) -> "EVARelation":
+    def alias(self, alias: str) -> "EVADBQuery":
         """Returns a new Relation with an alias set.
 
         Args:
             alias (str): an alias name to be set for the Relation.
 
         Returns:
-            EVARelation: Aliased Relation.
+            EVADBQuery: Aliased Relation.
 
         Examples:
             >>> relation = conn.table("sample_table")
             >>> relation.alias('table')
         """
         self._alias = Alias(alias)
 
-    def cross_apply(self, expr: str, alias: str) -> "EVARelation":
+    def cross_apply(self, expr: str, alias: str) -> "EVADBQuery":
         """Execute a expr on all the rows of the relation
 
         Args:
             expr (str): sql expression
             alias (str): alias of the output of the expr
 
         Returns:
-            `EVARelation`: relation
+            `EVADBQuery`: relation
 
         Examples:
 
             Runs Yolo on all the frames of the input table
 
             >>> relation = conn.table("videos")
             >>> relation.cross_apply("Yolo(data)", "objs(labels, bboxes, scores)")
@@ -89,15 +94,15 @@
             )
         )
         self._query_node = SelectStatement(
             target_list=create_star_expression(), from_table=join_table
         )
         # reset the alias as after join there isn't a single alias
         self._alias = Alias("Relation")
-        try_binding(self._query_node)
+        try_binding(self._evadb.catalog, self._query_node)
         return self
 
     def df(self) -> pandas.DataFrame:
         """Execute and fetch all rows as a pandas DataFrame
 
         Returns:
             pandas.DataFrame:
@@ -108,27 +113,27 @@
 
     def execute(self) -> Batch:
         """Transform the relation into a result set
 
         Returns:
             Batch: result as eva Batch
         """
-        result = execute_statement(self._query_node.copy())
+        result = execute_statement(self._evadb, self._query_node.copy())
         assert result.frames is not None
         return result
 
-    def filter(self, expr: str) -> "EVARelation":
+    def filter(self, expr: str) -> "EVADBQuery":
         """
         Filters rows using the given condition. Multiple chained filters results in `AND`
 
         Parameters:
             expr (str): The filter expression.
 
         Returns:
-            EVARelation : Filtered EVARelation.
+            EVADBQuery : Filtered EVADBQuery.
         Examples:
             >>> relation = conn.table("sample_table")
             >>> relation.filter("col1 > 10")
 
             Filter by sql string
 
             >>> relation.filter("col1 > 10 AND col1 < 20")
@@ -136,91 +141,91 @@
         """
         parsed_expr = sql_predicate_to_expresssion_tree(expr)
 
         self._query_node = handle_select_clause(
             self._query_node, self._alias, "where_clause", parsed_expr
         )
 
-        try_binding(self._query_node)
+        try_binding(self._evadb.catalog, self._query_node)
 
         return self
 
-    def limit(self, num: int) -> "EVARelation":
+    def limit(self, num: int) -> "EVADBQuery":
         """Limits the result count to the number specified.
 
         Args:
             num (int): Number of records to return. Will return num records or all records if the Relation contains fewer records.
 
         Returns:
-            EVARelation: Relation with subset of records
+            EVADBQuery: Relation with subset of records
 
         Examples:
             >>> relation = conn.table("sample_table")
             >>> relation.limit(10)
 
         """
 
         limit_expr = create_limit_expression(num)
         self._query_node = handle_select_clause(
             self._query_node, self._alias, "limit_count", limit_expr
         )
 
-        try_binding(self._query_node)
+        try_binding(self._evadb.catalog, self._query_node)
 
         return self
 
-    def order(self, order_expr: str) -> "EVARelation":
+    def order(self, order_expr: str) -> "EVADBQuery":
         """Reorder the relation based on the order_expr
 
         Args:
             order_expr (str): sql expression to order the relation
 
         Returns:
-            EVARelation: A EVARelation ordered based on the order_expr.
+            EVADBQuery: A EVADBQuery ordered based on the order_expr.
         """
 
         parsed_expr = parse_sql_orderby_expr(order_expr)
         self._query_node = handle_select_clause(
             self._query_node, self._alias, "orderby_list", parsed_expr
         )
 
-        try_binding(self._query_node)
+        try_binding(self._evadb.catalog, self._query_node)
 
         return self
 
-    def select(self, expr: str) -> "EVARelation":
+    def select(self, expr: str) -> "EVADBQuery":
         """
-        Projects a set of expressions and returns a new EVARelation.
+        Projects a set of expressions and returns a new EVADBQuery.
 
         Parameters:
-            exprs (Union[str, List[str]]): The expression(s) to be selected. If '*' is provided, it expands to all columns in the current EVARelation.
+            exprs (Union[str, List[str]]): The expression(s) to be selected. If '*' is provided, it expands to all columns in the current EVADBQuery.
 
         Returns:
-            EVARelation: A EVARelation with subset (or all) of columns.
+            EVADBQuery: A EVADBQuery with subset (or all) of columns.
 
         Examples:
             >>> relation = conn.table("sample_table")
 
-            Select all columns in the EVARelation.
+            Select all columns in the EVADBQuery.
 
             >>> relation.select("*")
 
-            Select all subset of columns in the EVARelation.
+            Select all subset of columns in the EVADBQuery.
 
             >>> relation.select("col1")
             >>> relation.select("col1, col2")
         """
 
         parsed_exprs = sql_string_to_expresssion_list(expr)
 
         self._query_node = handle_select_clause(
             self._query_node, self._alias, "target_list", parsed_exprs
         )
 
-        try_binding(self._query_node)
+        try_binding(self._evadb.catalog, self._query_node)
 
         return self
 
     def show(self) -> pandas.DataFrame:
         """Execute and fetch all rows as a pandas DataFrame
 
         Returns:
```

### Comparing `evadb-0.2.6/eva/interfaces/relational/utils.py` & `evadb-0.2.7/evadb/interfaces/relational/utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,29 +9,30 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import asyncio
-from typing import List, Union
+from typing import Callable, List, Union
 
-from eva.binder.statement_binder import StatementBinder
-from eva.binder.statement_binder_context import StatementBinderContext
-from eva.executor.plan_executor import PlanExecutor
-from eva.expression.abstract_expression import AbstractExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.models.storage.batch import Batch
-from eva.optimizer.plan_generator import PlanGenerator
-from eva.optimizer.statement_to_opr_converter import StatementToPlanConverter
-from eva.parser.select_statement import SelectStatement
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableRef
-from eva.parser.utils import (
+from evadb.binder.statement_binder import StatementBinder
+from evadb.binder.statement_binder_context import StatementBinderContext
+from evadb.database import EVADatabase
+from evadb.executor.plan_executor import PlanExecutor
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.models.storage.batch import Batch
+from evadb.optimizer.plan_generator import PlanGenerator
+from evadb.optimizer.statement_to_opr_converter import StatementToPlanConverter
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import TableRef
+from evadb.parser.utils import (
     parse_expression,
     parse_lateral_join,
     parse_predicate_expression,
 )
 
 
 def sql_string_to_expresssion_list(expr: str) -> List[AbstractExpression]:
@@ -47,19 +48,19 @@
     return parse_expression(expr)
 
 
 def sql_predicate_to_expresssion_tree(expr: str) -> AbstractExpression:
     return parse_predicate_expression(expr)
 
 
-def execute_statement(statement: AbstractStatement) -> Batch:
-    StatementBinder(StatementBinderContext()).bind(statement)
+def execute_statement(evadb: EVADatabase, statement: AbstractStatement) -> Batch:
+    StatementBinder(StatementBinderContext(evadb.catalog)).bind(statement)
     l_plan = StatementToPlanConverter().visit(statement)
-    p_plan = asyncio.run(PlanGenerator().build(l_plan))
-    output = PlanExecutor(p_plan).execute_plan()
+    p_plan = asyncio.run(PlanGenerator(evadb).build(l_plan))
+    output = PlanExecutor(evadb, p_plan).execute_plan()
     if output:
         batch_list = list(output)
         return Batch.concat(batch_list, copy=False)
 
 
 def string_to_lateral_join(expr: str, alias: str):
     return parse_lateral_join(expr, alias)
@@ -69,19 +70,19 @@
     return [TupleValueExpression(col_name="*")]
 
 
 def create_limit_expression(num: int):
     return ConstantValueExpression(num)
 
 
-def try_binding(stmt: AbstractStatement):
+def try_binding(catalog: Callable, stmt: AbstractStatement):
     # To avoid complications in subsequent binder calls, we attempt to bind a copy of
     # the statement since the binder modifies the statement in place and can cause
     # issues if statement is partially bound.
-    StatementBinder(StatementBinderContext()).bind(stmt.copy())
+    StatementBinder(StatementBinderContext(catalog)).bind(stmt.copy())
 
 
 def handle_select_clause(
     query: SelectStatement, alias: str, clause: str, value: Union[str, int, list]
 ) -> SelectStatement:
     """
     Modifies a SELECT statement object by adding or modifying a specific clause.
```

### Comparing `evadb-0.2.6/eva/models/__init__.py` & `evadb-0.2.7/evadb/models/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/models/catalog/__init__.py` & `evadb-0.2.7/evadb/interfaces/relational/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/models/catalog/frame_info.py` & `evadb-0.2.7/evadb/models/catalog/frame_info.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from dataclasses import dataclass
 
-from eva.models.catalog.properties import ColorSpace
+from evadb.models.catalog.properties import ColorSpace
 
 
 @dataclass(frozen=True)
 class FrameInfo:
     """
     Data model contains information about the frame
```

### Comparing `evadb-0.2.6/eva/models/catalog/properties.py` & `evadb-0.2.7/evadb/models/catalog/properties.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/models/server/__init__.py` & `evadb-0.2.7/evadb/models/catalog/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/models/server/response.py` & `evadb-0.2.7/evadb/models/server/response.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,17 +12,17 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from dataclasses import dataclass
 from enum import Enum
 from typing import Optional
 
-from eva.executor.executor_utils import ExecutorError
-from eva.models.storage.batch import Batch
-from eva.utils.generic_utils import PickleSerializer
+from evadb.executor.executor_utils import ExecutorError
+from evadb.models.storage.batch import Batch
+from evadb.utils.generic_utils import PickleSerializer
 
 
 class ResponseStatus(str, Enum):
     FAIL = -1
     SUCCESS = 0
```

### Comparing `evadb-0.2.6/eva/models/storage/__init__.py` & `evadb-0.2.7/evadb/models/server/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/models/storage/batch.py` & `evadb-0.2.7/evadb/models/storage/batch.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,18 +13,18 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Callable, Iterable, List, TypeVar, Union
 
 import numpy as np
 import pandas as pd
 
-from eva.expression.abstract_expression import ExpressionType
-from eva.parser.alias import Alias
-from eva.utils.generic_utils import PickleSerializer
-from eva.utils.logging_manager import logger
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.parser.alias import Alias
+from evadb.utils.generic_utils import PickleSerializer
+from evadb.utils.logging_manager import logger
 
 Batch = TypeVar("Batch")
 
 
 class Batch:
     """
     Data model used for storing a batch of frames.
@@ -308,18 +308,26 @@
 
         Returns:
             Batch (always of length 1)
         """
         if len(batch.columns) > 1:
             raise ValueError("Stack can only be called on single-column batches")
         frame_data_col = batch.columns[0]
+        data_to_stack = batch.frames[frame_data_col].values.tolist()
 
-        stacked_array = np.array(batch.frames[frame_data_col].values.tolist())
-        stacked_frame = pd.DataFrame([{frame_data_col: stacked_array}])
+        if isinstance(data_to_stack[0], np.ndarray) and len(data_to_stack[0].shape) > 1:
+            # if data_to_stack has more than 1 axis, we add a new axis
+            # [(3, 224, 224) * 10] -> (10, 3, 224, 224)
+            stacked_array = np.array(batch.frames[frame_data_col].values.tolist())
+        else:
+            # we concatenate along the zeroth axis
+            # this makes sense for audio and text
+            stacked_array = np.hstack(batch.frames[frame_data_col].values)
 
+        stacked_frame = pd.DataFrame([{frame_data_col: stacked_array}])
         return Batch(stacked_frame)
 
     @classmethod
     def join(cls, first: Batch, second: Batch, how="inner") -> Batch:
         return cls(
             first._frames.merge(
                 second._frames, left_index=True, right_index=True, how=how
```

### Comparing `evadb-0.2.6/eva/optimizer/__init__.py` & `evadb-0.2.7/evadb/optimizer/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/optimizer/binder.py` & `evadb-0.2.7/evadb/optimizer/binder.py`

 * *Files 3% similar despite different names*

```diff
@@ -11,18 +11,18 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import copy
 import itertools
 
-from eva.optimizer.group_expression import GroupExpression
-from eva.optimizer.memo import Memo
-from eva.optimizer.operators import Dummy, Operator, OperatorType
-from eva.optimizer.rules.pattern import Pattern
+from evadb.optimizer.group_expression import GroupExpression
+from evadb.optimizer.memo import Memo
+from evadb.optimizer.operators import Dummy, Operator, OperatorType
+from evadb.optimizer.rules.pattern import Pattern
 
 
 class Binder:
     def __init__(self, grp_expr: GroupExpression, pattern: Pattern, memo: Memo):
         self._grp_expr = grp_expr
         self._pattern = pattern
         self._memo = memo
```

### Comparing `evadb-0.2.6/eva/optimizer/cost_model.py` & `evadb-0.2.7/evadb/optimizer/cost_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -10,21 +10,21 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from functools import singledispatch
 
-from eva.optimizer.group_expression import GroupExpression
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.apply_and_merge_plan import ApplyAndMergePlan
-from eva.plan_nodes.hash_join_build_plan import HashJoinBuildPlan
-from eva.plan_nodes.hash_join_probe_plan import HashJoinProbePlan
-from eva.plan_nodes.nested_loop_join_plan import NestedLoopJoinPlan
-from eva.plan_nodes.seq_scan_plan import SeqScanPlan
+from evadb.optimizer.group_expression import GroupExpression
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.apply_and_merge_plan import ApplyAndMergePlan
+from evadb.plan_nodes.hash_join_build_plan import HashJoinBuildPlan
+from evadb.plan_nodes.hash_join_probe_plan import HashJoinProbePlan
+from evadb.plan_nodes.nested_loop_join_plan import NestedLoopJoinPlan
+from evadb.plan_nodes.seq_scan_plan import SeqScanPlan
 
 
 class CostModel:
     """
     Basic cost model. Change it as we add more cost based rules
     """
```

### Comparing `evadb-0.2.6/eva/optimizer/group.py` & `evadb-0.2.7/evadb/optimizer/group.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,18 +12,18 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from __future__ import annotations
 
 from typing import Dict, List
 
-from eva.constants import UNDEFINED_GROUP_ID
-from eva.optimizer.group_expression import GroupExpression
-from eva.optimizer.property import Property
-from eva.utils.logging_manager import logger
+from evadb.constants import UNDEFINED_GROUP_ID
+from evadb.optimizer.group_expression import GroupExpression
+from evadb.optimizer.property import Property
+from evadb.utils.logging_manager import logger
 
 
 class Winner:
     def __init__(self, grp_expr: GroupExpression, cost: float):
         self._cost = cost
         self._grp_expr = grp_expr
```

### Comparing `evadb-0.2.6/eva/optimizer/group_expression.py` & `evadb-0.2.7/evadb/optimizer/group_expression.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,17 +10,17 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.constants import UNDEFINED_GROUP_ID
-from eva.optimizer.operators import Operator
-from eva.optimizer.rules.rules_base import RuleType
+from evadb.constants import UNDEFINED_GROUP_ID
+from evadb.optimizer.operators import Operator
+from evadb.optimizer.rules.rules_base import RuleType
 
 
 class GroupExpression:
     def __init__(
         self,
         opr: Operator,
         group_id: int = UNDEFINED_GROUP_ID,
```

### Comparing `evadb-0.2.6/eva/optimizer/memo.py` & `evadb-0.2.7/evadb/optimizer/memo.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,19 +10,19 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Dict, List
 
-from eva.constants import UNDEFINED_GROUP_ID
-from eva.optimizer.group import Group
-from eva.optimizer.group_expression import GroupExpression
-from eva.optimizer.operators import OperatorType
-from eva.utils.logging_manager import logger
+from evadb.constants import UNDEFINED_GROUP_ID
+from evadb.optimizer.group import Group
+from evadb.optimizer.group_expression import GroupExpression
+from evadb.optimizer.operators import OperatorType
+from evadb.utils.logging_manager import logger
 
 
 class Memo:
     """
     For now, we assume every group has only one logic expression.
     """
```

### Comparing `evadb-0.2.6/eva/optimizer/operators.py` & `evadb-0.2.7/evadb/optimizer/operators.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,26 +13,26 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from collections import deque
 from enum import IntEnum, auto
 from pathlib import Path
 from typing import Any, List
 
-from eva.catalog.catalog_type import VectorStoreType
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.catalog.models.udf_metadata_catalog import UdfMetadataCatalogEntry
-from eva.expression.abstract_expression import AbstractExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.function_expression import FunctionExpression
-from eva.parser.alias import Alias
-from eva.parser.create_statement import ColumnDefinition
-from eva.parser.table_ref import TableInfo, TableRef
-from eva.parser.types import JoinType, ShowType
+from evadb.catalog.catalog_type import VectorStoreType
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.catalog.models.udf_metadata_catalog import UdfMetadataCatalogEntry
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.function_expression import FunctionExpression
+from evadb.parser.alias import Alias
+from evadb.parser.create_statement import ColumnDefinition
+from evadb.parser.table_ref import TableInfo, TableRef
+from evadb.parser.types import JoinType, ObjectType, ShowType
 
 
 class OperatorType(IntEnum):
     """
     Manages enums for all the operators supported
     """
 
@@ -41,28 +41,27 @@
     LOGICALGET = auto()
     LOGICALFILTER = auto()
     LOGICALPROJECT = auto()
     LOGICALINSERT = auto()
     LOGICALDELETE = auto()
     LOGICALCREATE = auto()
     LOGICALRENAME = auto()
-    LOGICALDROP = auto()
+    LOGICAL_DROP_OBJECT = auto()
     LOGICALCREATEUDF = auto()
     LOGICALLOADDATA = auto()
     LOGICALQUERYDERIVEDGET = auto()
     LOGICALUNION = auto()
     LOGICALGROUPBY = auto()
     LOGICALORDERBY = auto()
     LOGICALLIMIT = auto()
     LOGICALSAMPLE = auto()
     LOGICALJOIN = auto()
     LOGICALFUNCTIONSCAN = auto()
     LOGICAL_CREATE_MATERIALIZED_VIEW = auto()
     LOGICAL_SHOW = auto()
-    LOGICALDROPUDF = auto()
     LOGICALEXPLAIN = auto()
     LOGICALCREATEINDEX = auto()
     LOGICAL_APPLY_AND_MERGE = auto()
     LOGICAL_EXTRACT_OBJECT = auto()
     LOGICAL_VECTOR_INDEX_SCAN = auto()
     LOGICALDELIMITER = auto()
 
@@ -627,46 +626,14 @@
             and self._old_table_ref == other._old_table_ref
         )
 
     def __hash__(self) -> int:
         return hash((super().__hash__(), self._new_name, self._old_table_ref))
 
 
-class LogicalDrop(Operator):
-    """
-    Logical node for drop table operations
-    """
-
-    def __init__(self, table_infos: List[TableInfo], if_exists: bool, children=None):
-        super().__init__(OperatorType.LOGICALDROP, children)
-        self._table_infos = table_infos
-        self._if_exists = if_exists
-
-    @property
-    def table_infos(self):
-        return self._table_infos
-
-    @property
-    def if_exists(self):
-        return self._if_exists
-
-    def __eq__(self, other):
-        is_subtree_equal = super().__eq__(other)
-        if not isinstance(other, LogicalDrop):
-            return False
-        return (
-            is_subtree_equal
-            and self.table_infos == other.table_infos
-            and self.if_exists == other.if_exists
-        )
-
-    def __hash__(self) -> int:
-        return hash((super().__hash__(), tuple(self._table_infos), self._if_exists))
-
-
 class LogicalCreateUDF(Operator):
     """
     Logical node for create udf operations
 
     Attributes:
         name: str
             udf_name provided by the user required
@@ -759,51 +726,60 @@
                 self.udf_type,
                 self.impl_path,
                 tuple(self.metadata),
             )
         )
 
 
-class LogicalDropUDF(Operator):
+class LogicalDropObject(Operator):
     """
-    Logical node for DROP UDF operations
+    Logical node for DROP Object operations
 
     Attributes:
+        object_type: ObjectType
         name: str
             UDF name provided by the user
         if_exists: bool
             if false, throws an error when no UDF with name exists
             else logs a warning
     """
 
-    def __init__(self, name: str, if_exists: bool, children: List = None):
-        super().__init__(OperatorType.LOGICALDROPUDF, children)
+    def __init__(
+        self, object_type: ObjectType, name: str, if_exists: bool, children: List = None
+    ):
+        super().__init__(OperatorType.LOGICAL_DROP_OBJECT, children)
+        self._object_type = object_type
         self._name = name
         self._if_exists = if_exists
 
     @property
+    def object_type(self):
+        return self._object_type
+
+    @property
     def name(self):
         return self._name
 
     @property
     def if_exists(self):
         return self._if_exists
 
     def __eq__(self, other):
         is_subtree_equal = super().__eq__(other)
-        if not isinstance(other, LogicalDropUDF):
+        if not isinstance(other, LogicalDropObject):
             return False
         return (
             is_subtree_equal
+            and self.object_type == other.object_type
             and self.name == other.name
             and self.if_exists == other.if_exists
         )
 
     def __hash__(self) -> int:
-        return hash((super().__hash__(), self.name, self.if_exists))
+        return hash((super().__hash__(), self.object_type, self.name, self.if_exists))
 
 
 class LogicalLoadData(Operator):
     """Logical node for load data operation
 
     Arguments:
         table(TableCatalogEntry): table to load data into
```

### Comparing `evadb-0.2.6/eva/optimizer/optimizer_context.py` & `evadb-0.2.7/evadb/optimizer/optimizer_context.py`

 * *Files 6% similar despite different names*

```diff
@@ -10,37 +10,45 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import copy
 
-from eva.constants import UNDEFINED_GROUP_ID
-from eva.optimizer.cost_model import CostModel
-from eva.optimizer.group_expression import GroupExpression
-from eva.optimizer.memo import Memo
-from eva.optimizer.operators import Dummy, Operator
-from eva.optimizer.optimizer_task_stack import OptimizerTaskStack
-from eva.optimizer.rules.rules_manager import RulesManager
+from evadb.constants import UNDEFINED_GROUP_ID
+from evadb.database import EVADatabase
+from evadb.optimizer.cost_model import CostModel
+from evadb.optimizer.group_expression import GroupExpression
+from evadb.optimizer.memo import Memo
+from evadb.optimizer.operators import Dummy, Operator
+from evadb.optimizer.optimizer_task_stack import OptimizerTaskStack
+from evadb.optimizer.rules.rules_manager import RulesManager
 
 
 class OptimizerContext:
     """
     Maintain context information for the optimizer
 
     Arguments:
         _task_queue(OptimizerTaskStack):
             stack to keep track outstanding tasks
     """
 
-    def __init__(self, cost_model: CostModel, rules_manager: RulesManager = None):
+    def __init__(
+        self, db: EVADatabase, cost_model: CostModel, rules_manager: RulesManager = None
+    ):
+        self._db = db
         self._task_stack = OptimizerTaskStack()
         self._memo = Memo()
         self._cost_model = cost_model
-        self._rules_manager = rules_manager or RulesManager()
+        self._rules_manager = rules_manager or RulesManager(db.config)
+
+    @property
+    def db(self):
+        return self._db
 
     @property
     def rules_manager(self):
         return self._rules_manager
 
     @property
     def cost_model(self):
```

### Comparing `evadb-0.2.6/eva/optimizer/optimizer_task_stack.py` & `evadb-0.2.7/evadb/optimizer/optimizer_task_stack.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from collections import deque
 
-from eva.optimizer.optimizer_tasks import OptimizerTask
+from evadb.optimizer.optimizer_tasks import OptimizerTask
 
 
 class OptimizerTaskStack:
     def __init__(self):
         self._task_stack = deque()
 
     def push(self, task: OptimizerTask):
```

### Comparing `evadb-0.2.6/eva/optimizer/optimizer_tasks.py` & `evadb-0.2.7/evadb/optimizer/optimizer_tasks.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,23 +14,23 @@
 # limitations under the License.
 from __future__ import annotations
 
 from abc import abstractmethod
 from enum import IntEnum, auto
 from typing import TYPE_CHECKING, List
 
-from eva.optimizer.binder import Binder
-from eva.optimizer.group import Group
-from eva.optimizer.group_expression import GroupExpression
-from eva.optimizer.property import PropertyType
-from eva.optimizer.rules.rules_base import Rule
-from eva.utils.logging_manager import logger
+from evadb.optimizer.binder import Binder
+from evadb.optimizer.group import Group
+from evadb.optimizer.group_expression import GroupExpression
+from evadb.optimizer.property import PropertyType
+from evadb.optimizer.rules.rules_base import Rule
+from evadb.utils.logging_manager import logger
 
 if TYPE_CHECKING:
-    from eva.optimizer.optimizer_context import OptimizerContext
+    from evadb.optimizer.optimizer_context import OptimizerContext
 
 
 class OptimizerTaskType(IntEnum):
     """Manages Enum for all the supported optimizer tasks"""
 
     TOP_DOWN_REWRITE = auto()
     BOTTOM_UP_REWRITE = auto()
```

### Comparing `evadb-0.2.6/eva/optimizer/optimizer_utils.py` & `evadb-0.2.7/evadb/optimizer/optimizer_utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -8,38 +8,41 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+import typing
 from typing import List, Tuple
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_utils import get_table_primary_columns
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.catalog.models.udf_metadata_catalog import UdfMetadataCatalogEntry
-from eva.constants import CACHEABLE_UDFS, DEFAULT_FUNCTION_EXPRESSION_COST
-from eva.expression.abstract_expression import AbstractExpression, ExpressionType
-from eva.expression.expression_utils import (
+if typing.TYPE_CHECKING:
+    from evadb.optimizer.optimizer_context import OptimizerContext
+
+from evadb.catalog.catalog_utils import get_table_primary_columns
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.catalog.models.udf_metadata_catalog import UdfMetadataCatalogEntry
+from evadb.constants import CACHEABLE_UDFS, DEFAULT_FUNCTION_EXPRESSION_COST
+from evadb.expression.abstract_expression import AbstractExpression, ExpressionType
+from evadb.expression.expression_utils import (
     conjunction_list_to_expression_tree,
     contains_single_column,
     get_columns_in_predicate,
     is_simple_predicate,
     to_conjunction_list,
 )
-from eva.expression.function_expression import (
+from evadb.expression.function_expression import (
     FunctionExpression,
     FunctionExpressionCache,
 )
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.alias import Alias
-from eva.parser.create_statement import ColumnDefinition
-from eva.utils.kv_cache import DiskKVCache
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.alias import Alias
+from evadb.parser.create_statement import ColumnDefinition
+from evadb.utils.kv_cache import DiskKVCache
 
 
 def column_definition_to_udf_io(col_list: List[ColumnDefinition], is_input: bool):
     """Create the UdfIOCatalogEntry object for each column definition provided
 
     Arguments:
         col_list(List[ColumnDefinition]): parsed input/output definitions
@@ -183,15 +186,15 @@
             rem_pred.append(pred)
     return (
         conjunction_list_to_expression_tree(pushdown_preds),
         conjunction_list_to_expression_tree(rem_pred),
     )
 
 
-def optimize_cache_key(expr: FunctionExpression):
+def optimize_cache_key(context: "OptimizerContext", expr: FunctionExpression):
     """Optimize the cache key
 
     It tries to reduce the caching overhead by replacing the caching key with logically equivalent key. For instance, frame data can be replaced with frame id.
 
     Args:
         expr (FunctionExpression): expression to optimize the caching key for.
 
@@ -199,106 +202,116 @@
         Yolo(data) -> return id
 
     Todo: Optimize complex expression
         FaceDet(Crop(data, bbox)) -> return
 
     """
     keys = expr.children
+    catalog = context.db.catalog()
     # handle simple one column inputs
     if len(keys) == 1 and isinstance(keys[0], TupleValueExpression):
         child = keys[0]
         col_catalog_obj = child.col_object
         if isinstance(col_catalog_obj, ColumnCatalogEntry):
             new_keys = []
-            table_obj = CatalogManager().get_table_catalog_entry(
-                col_catalog_obj.table_name
-            )
+            table_obj = catalog.get_table_catalog_entry(col_catalog_obj.table_name)
             for col in get_table_primary_columns(table_obj):
-                new_obj = CatalogManager().get_column_catalog_entry(table_obj, col.name)
+                new_obj = catalog.get_column_catalog_entry(table_obj, col.name)
                 new_keys.append(
                     TupleValueExpression(
                         col_name=col.name,
                         table_alias=child.table_alias,
                         col_object=new_obj,
                         col_alias=f"{child.table_alias}.{col.name}",
                     )
                 )
 
             return new_keys
     return keys
 
 
-def enable_cache_init(func_expr: FunctionExpression) -> FunctionExpressionCache:
-    optimized_key = optimize_cache_key(func_expr)
+def enable_cache_init(
+    context: "OptimizerContext", func_expr: FunctionExpression
+) -> FunctionExpressionCache:
+    optimized_key = optimize_cache_key(context, func_expr)
     if optimized_key == func_expr.children:
         optimized_key = [None]
 
+    catalog = context.db.catalog()
     name = func_expr.signature()
-    cache_entry = CatalogManager().get_udf_cache_catalog_entry_by_name(name)
+    cache_entry = catalog.get_udf_cache_catalog_entry_by_name(name)
     if not cache_entry:
-        cache_entry = CatalogManager().insert_udf_cache_catalog_entry(func_expr)
+        cache_entry = catalog.insert_udf_cache_catalog_entry(func_expr)
 
     cache = FunctionExpressionCache(
         key=tuple(optimized_key), store=DiskKVCache(cache_entry.cache_path)
     )
     return cache
 
 
-def enable_cache(func_expr: FunctionExpression) -> FunctionExpression:
+def enable_cache(
+    context: "OptimizerContext", func_expr: FunctionExpression
+) -> FunctionExpression:
     """Enables cache for a function expression.
 
     The cache key is optimized by replacing it with logical equivalent expressions.
     A cache entry is inserted in the catalog corresponding to the expression.
 
     Args:
+        context (OptimizerContext): associated optimizer context
         func_expr (FunctionExpression): The function expression to enable cache for.
 
     Returns:
         FunctionExpression: The function expression with cache enabled.
     """
-    cache = enable_cache_init(func_expr)
+    cache = enable_cache_init(context, func_expr)
     return func_expr.copy().enable_cache(cache)
 
 
-def enable_cache_on_expression_tree(expr_tree: AbstractExpression):
+def enable_cache_on_expression_tree(
+    context: "OptimizerContext", expr_tree: AbstractExpression
+):
     func_exprs = list(expr_tree.find_all(FunctionExpression))
     func_exprs = list(
         filter(lambda expr: check_expr_validity_for_cache(expr), func_exprs)
     )
     for expr in func_exprs:
-        cache = enable_cache_init(expr)
+        cache = enable_cache_init(context, expr)
         expr.enable_cache(cache)
 
 
 def check_expr_validity_for_cache(expr: FunctionExpression):
     return (
         expr.name in CACHEABLE_UDFS
         and not expr.has_cache()
         and len(expr.children) <= 1
         and isinstance(expr.children[0], TupleValueExpression)
     )
 
 
-def get_expression_execution_cost(expr: AbstractExpression) -> float:
+def get_expression_execution_cost(
+    context: "OptimizerContext", expr: AbstractExpression
+) -> float:
     """
     This function computes the estimated cost of executing the given abstract expression
     based on the statistics in the catalog. The function assumes that all the
     expression, except for the FunctionExpression, have a cost of zero.
     For FunctionExpression, it checks the catalog for relevant statistics; if none are
     available, it uses a default cost of DEFAULT_FUNCTION_EXPRESSION_COST.
 
     Args:
+        context (OptimizerContext): the associated optimizer context
         expr (AbstractExpression): The AbstractExpression object whose cost
         needs to be computed.
 
     Returns:
         float: The estimated cost of executing the function expression.
     """
     total_cost = 0
     # iterate over all the function expression and accumulate the cost
     for child_expr in expr.find_all(FunctionExpression):
-        cost_entry = CatalogManager().get_udf_cost_catalog_entry(child_expr.name)
+        cost_entry = context.db.catalog().get_udf_cost_catalog_entry(child_expr.name)
         if cost_entry:
             total_cost += cost_entry.cost
         else:
             total_cost += DEFAULT_FUNCTION_EXPRESSION_COST
     return total_cost
```

### Comparing `evadb-0.2.6/eva/optimizer/plan_generator.py` & `evadb-0.2.7/evadb/optimizer/plan_generator.py`

 * *Files 10% similar despite different names*

```diff
@@ -12,34 +12,43 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import asyncio
 
 import nest_asyncio
 
-from eva.optimizer.cost_model import CostModel
-from eva.optimizer.operators import Operator
-from eva.optimizer.optimizer_context import OptimizerContext
-from eva.optimizer.optimizer_task_stack import OptimizerTaskStack
-from eva.optimizer.optimizer_tasks import BottomUpRewrite, OptimizeGroup, TopDownRewrite
-from eva.optimizer.property import PropertyType
-from eva.optimizer.rules.rules_manager import RulesManager
+from evadb.database import EVADatabase
+from evadb.optimizer.cost_model import CostModel
+from evadb.optimizer.operators import Operator
+from evadb.optimizer.optimizer_context import OptimizerContext
+from evadb.optimizer.optimizer_task_stack import OptimizerTaskStack
+from evadb.optimizer.optimizer_tasks import (
+    BottomUpRewrite,
+    OptimizeGroup,
+    TopDownRewrite,
+)
+from evadb.optimizer.property import PropertyType
+from evadb.optimizer.rules.rules_manager import RulesManager
 
 nest_asyncio.apply()
 
 
 class PlanGenerator:
     """
     Used for building Physical Plan from Logical Plan.
     """
 
     def __init__(
-        self, rules_manager: RulesManager = None, cost_model: CostModel = None
+        self,
+        db: EVADatabase,
+        rules_manager: RulesManager = None,
+        cost_model: CostModel = None,
     ) -> None:
-        self.rules_manager = rules_manager or RulesManager()
+        self.db = db
+        self.rules_manager = rules_manager or RulesManager(db.config)
         self.cost_model = cost_model or CostModel()
 
     def execute_task_stack(self, task_stack: OptimizerTaskStack):
         while not task_stack.empty():
             task = task_stack.pop()
             task.execute()
 
@@ -57,15 +66,17 @@
                 child_grp_id, optimizer_context
             )
             physical_plan.append_child(child_plan)
 
         return physical_plan
 
     async def optimize(self, logical_plan: Operator):
-        optimizer_context = OptimizerContext(self.cost_model, self.rules_manager)
+        optimizer_context = OptimizerContext(
+            self.db, self.cost_model, self.rules_manager
+        )
         memo = optimizer_context.memo
         grp_expr = optimizer_context.add_opr_to_group(opr=logical_plan)
         root_grp_id = grp_expr.group_id
         root_expr = memo.groups[root_grp_id].logical_exprs[0]
 
         # TopDown Rewrite
         # We specify rules that should be applied initially to prevent any interference
```

### Comparing `evadb-0.2.6/eva/optimizer/property.py` & `evadb-0.2.7/evadb/optimizer/property.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/optimizer/rules/__init__.py` & `evadb-0.2.7/evadb/models/storage/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/optimizer/rules/pattern.py` & `evadb-0.2.7/evadb/optimizer/rules/pattern.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from __future__ import annotations
 
-from eva.optimizer.operators import OperatorType
+from evadb.optimizer.operators import OperatorType
 
 
 class Pattern:
     def __init__(self, opr_type: OperatorType):
         self._opr_type = opr_type
         self._children = []
```

### Comparing `evadb-0.2.6/eva/optimizer/rules/rules.py` & `evadb-0.2.7/evadb/optimizer/rules/rules.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,60 +12,58 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import TableType
-from eva.catalog.catalog_utils import is_video_table
-from eva.constants import CACHEABLE_UDFS
-from eva.executor.execution_context import Context
-from eva.expression.expression_utils import (
+from evadb.catalog.catalog_type import TableType
+from evadb.catalog.catalog_utils import is_video_table
+from evadb.constants import CACHEABLE_UDFS
+from evadb.executor.execution_context import Context
+from evadb.expression.expression_utils import (
     conjunction_list_to_expression_tree,
     to_conjunction_list,
 )
-from eva.expression.function_expression import FunctionExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.optimizer.optimizer_utils import (
+from evadb.expression.function_expression import FunctionExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.optimizer.optimizer_utils import (
     check_expr_validity_for_cache,
     enable_cache,
     enable_cache_on_expression_tree,
     extract_equi_join_keys,
     extract_pushdown_predicate,
     extract_pushdown_predicate_for_alias,
     get_expression_execution_cost,
 )
-from eva.optimizer.rules.pattern import Pattern
-from eva.optimizer.rules.rules_base import Promise, Rule, RuleType
-from eva.parser.types import JoinType, ParserOrderBySortType
-from eva.plan_nodes.apply_and_merge_plan import ApplyAndMergePlan
-from eva.plan_nodes.create_mat_view_plan import CreateMaterializedViewPlan
-from eva.plan_nodes.exchange_plan import ExchangePlan
-from eva.plan_nodes.explain_plan import ExplainPlan
-from eva.plan_nodes.hash_join_build_plan import HashJoinBuildPlan
-from eva.plan_nodes.nested_loop_join_plan import NestedLoopJoinPlan
-from eva.plan_nodes.predicate_plan import PredicatePlan
-from eva.plan_nodes.project_plan import ProjectPlan
-from eva.plan_nodes.show_info_plan import ShowInfoPlan
+from evadb.optimizer.rules.pattern import Pattern
+from evadb.optimizer.rules.rules_base import Promise, Rule, RuleType
+from evadb.parser.types import JoinType, ParserOrderBySortType
+from evadb.plan_nodes.apply_and_merge_plan import ApplyAndMergePlan
+from evadb.plan_nodes.create_mat_view_plan import CreateMaterializedViewPlan
+from evadb.plan_nodes.exchange_plan import ExchangePlan
+from evadb.plan_nodes.explain_plan import ExplainPlan
+from evadb.plan_nodes.hash_join_build_plan import HashJoinBuildPlan
+from evadb.plan_nodes.nested_loop_join_plan import NestedLoopJoinPlan
+from evadb.plan_nodes.predicate_plan import PredicatePlan
+from evadb.plan_nodes.project_plan import ProjectPlan
+from evadb.plan_nodes.show_info_plan import ShowInfoPlan
 
 if TYPE_CHECKING:
-    from eva.optimizer.optimizer_context import OptimizerContext
+    from evadb.optimizer.optimizer_context import OptimizerContext
 
-from eva.optimizer.operators import (
+from evadb.optimizer.operators import (
     Dummy,
     LogicalApplyAndMerge,
     LogicalCreate,
     LogicalCreateIndex,
     LogicalCreateMaterializedView,
     LogicalCreateUDF,
     LogicalDelete,
-    LogicalDrop,
-    LogicalDropUDF,
+    LogicalDropObject,
     LogicalExchange,
     LogicalExplain,
     LogicalExtractObject,
     LogicalFilter,
     LogicalFunctionScan,
     LogicalGet,
     LogicalGroupBy,
@@ -80,33 +78,32 @@
     LogicalSample,
     LogicalShow,
     LogicalUnion,
     LogicalVectorIndexScan,
     Operator,
     OperatorType,
 )
-from eva.plan_nodes.create_index_plan import CreateIndexPlan
-from eva.plan_nodes.create_plan import CreatePlan
-from eva.plan_nodes.create_udf_plan import CreateUDFPlan
-from eva.plan_nodes.delete_plan import DeletePlan
-from eva.plan_nodes.drop_plan import DropPlan
-from eva.plan_nodes.drop_udf_plan import DropUDFPlan
-from eva.plan_nodes.function_scan_plan import FunctionScanPlan
-from eva.plan_nodes.groupby_plan import GroupByPlan
-from eva.plan_nodes.hash_join_probe_plan import HashJoinProbePlan
-from eva.plan_nodes.insert_plan import InsertPlan
-from eva.plan_nodes.lateral_join_plan import LateralJoinPlan
-from eva.plan_nodes.limit_plan import LimitPlan
-from eva.plan_nodes.load_data_plan import LoadDataPlan
-from eva.plan_nodes.orderby_plan import OrderByPlan
-from eva.plan_nodes.rename_plan import RenamePlan
-from eva.plan_nodes.seq_scan_plan import SeqScanPlan
-from eva.plan_nodes.storage_plan import StoragePlan
-from eva.plan_nodes.union_plan import UnionPlan
-from eva.plan_nodes.vector_index_scan_plan import VectorIndexScanPlan
+from evadb.plan_nodes.create_index_plan import CreateIndexPlan
+from evadb.plan_nodes.create_plan import CreatePlan
+from evadb.plan_nodes.create_udf_plan import CreateUDFPlan
+from evadb.plan_nodes.delete_plan import DeletePlan
+from evadb.plan_nodes.drop_object_plan import DropObjectPlan
+from evadb.plan_nodes.function_scan_plan import FunctionScanPlan
+from evadb.plan_nodes.groupby_plan import GroupByPlan
+from evadb.plan_nodes.hash_join_probe_plan import HashJoinProbePlan
+from evadb.plan_nodes.insert_plan import InsertPlan
+from evadb.plan_nodes.lateral_join_plan import LateralJoinPlan
+from evadb.plan_nodes.limit_plan import LimitPlan
+from evadb.plan_nodes.load_data_plan import LoadDataPlan
+from evadb.plan_nodes.orderby_plan import OrderByPlan
+from evadb.plan_nodes.rename_plan import RenamePlan
+from evadb.plan_nodes.seq_scan_plan import SeqScanPlan
+from evadb.plan_nodes.storage_plan import StoragePlan
+from evadb.plan_nodes.union_plan import UnionPlan
+from evadb.plan_nodes.vector_index_scan_plan import VectorIndexScanPlan
 
 ##############################################
 # REWRITE RULES START
 
 
 class EmbedFilterIntoGet(Rule):
     def __init__(self):
@@ -213,15 +210,15 @@
         if len(valid_exprs) > 0:
             return True
         return False
 
     def apply(self, before: LogicalProject, context: OptimizerContext):
         new_target_list = [expr.copy() for expr in before.target_list]
         for expr in new_target_list:
-            enable_cache_on_expression_tree(expr)
+            enable_cache_on_expression_tree(context, expr)
         after = LogicalProject(target_list=new_target_list, children=before.children)
         yield after
 
 
 class CacheFunctionExpressionInFilter(Rule):
     def __init__(self):
         pattern = Pattern(OperatorType.LOGICALFILTER)
@@ -243,15 +240,15 @@
         return False
 
     def apply(self, before: LogicalFilter, context: OptimizerContext):
         # there could be 2^n different combinations with enable and disable option
         # cache for n function Expressions. Currently considering only the case where
         # cache is enabled for all eligible function expressions
         after_predicate = before.predicate.copy()
-        enable_cache_on_expression_tree(after_predicate)
+        enable_cache_on_expression_tree(context, after_predicate)
         after_operator = LogicalFilter(
             predicate=after_predicate, children=before.children
         )
         yield after_operator
 
 
 class CacheFunctionExpressionInApply(Rule):
@@ -275,15 +272,15 @@
         ):
             return False
         return True
 
     def apply(self, before: LogicalApplyAndMerge, context: OptimizerContext):
         # todo: this will create a catalog entry even in the case of explain command
         # We should run this code conditionally
-        new_func_expr = enable_cache(before.func_expr)
+        new_func_expr = enable_cache(context, before.func_expr)
         after = LogicalApplyAndMerge(
             func_expr=new_func_expr, alias=before.alias, do_unnest=before.do_unnest
         )
         after.append_child(before.children[0])
         yield after
 
 
@@ -522,15 +519,15 @@
     def promise(self):
         return Promise.COMBINE_SIMILARITY_ORDERBY_AND_LIMIT_TO_VECTOR_INDEX_SCAN
 
     def check(self, before: LogicalLimit, context: OptimizerContext):
         return True
 
     def apply(self, before: LogicalLimit, context: OptimizerContext):
-        catalog_manager = CatalogManager()
+        catalog_manager = context.db.catalog
 
         # Get corresponding nodes.
         limit_node = before
         orderby_node = before.children[0]
         sub_tree_root = orderby_node.children[0]
 
         # Check if predicate exists on table.
@@ -570,15 +567,15 @@
             if isinstance(base_func_expr, TupleValueExpression)
             else base_func_expr.signature()
         )
 
         # Get index catalog. Check if an index exists for matching
         # udf signature and table columns.
         index_catalog_entry = (
-            catalog_manager.get_index_catalog_entry_by_column_and_udf_signature(
+            catalog_manager().get_index_catalog_entry_by_column_and_udf_signature(
                 column_catalog_entry, udf_signature
             )
         )
         if not index_catalog_entry:
             return
 
         # Construct the Vector index scan plan.
@@ -658,15 +655,16 @@
                 contains_func_exprs.append(conjunct)
             else:
                 simple_exprs.append(conjunct)
 
         # Compute the cost of every function expression and sort them in
         # ascending order of cost
         function_expr_cost_tuples = [
-            (expr, get_expression_execution_cost(expr)) for expr in contains_func_exprs
+            (expr, get_expression_execution_cost(context, expr))
+            for expr in contains_func_exprs
         ]
         function_expr_cost_tuples = sorted(
             function_expr_cost_tuples, key=lambda x: x[1]
         )
 
         # Build the final ordered list of conjuncts
         ordered_conjuncts = simple_exprs + [
@@ -738,30 +736,14 @@
         return True
 
     def apply(self, before: LogicalRename, context: OptimizerContext):
         after = RenamePlan(before.old_table_ref, before.new_name)
         yield after
 
 
-class LogicalDropToPhysical(Rule):
-    def __init__(self):
-        pattern = Pattern(OperatorType.LOGICALDROP)
-        super().__init__(RuleType.LOGICAL_DROP_TO_PHYSICAL, pattern)
-
-    def promise(self):
-        return Promise.LOGICAL_DROP_TO_PHYSICAL
-
-    def check(self, before: Operator, context: OptimizerContext):
-        return True
-
-    def apply(self, before: LogicalDrop, context: OptimizerContext):
-        after = DropPlan(before.table_infos, before.if_exists)
-        yield after
-
-
 class LogicalCreateUDFToPhysical(Rule):
     def __init__(self):
         pattern = Pattern(OperatorType.LOGICALCREATEUDF)
         super().__init__(RuleType.LOGICAL_CREATE_UDF_TO_PHYSICAL, pattern)
 
     def promise(self):
         return Promise.LOGICAL_CREATE_UDF_TO_PHYSICAL
@@ -800,27 +782,27 @@
             before.col_list,
             before.vector_store_type,
             before.udf_func,
         )
         yield after
 
 
-class LogicalDropUDFToPhysical(Rule):
+class LogicalDropObjectToPhysical(Rule):
     def __init__(self):
-        pattern = Pattern(OperatorType.LOGICALDROPUDF)
-        super().__init__(RuleType.LOGICAL_DROP_UDF_TO_PHYSICAL, pattern)
+        pattern = Pattern(OperatorType.LOGICAL_DROP_OBJECT)
+        super().__init__(RuleType.LOGICAL_DROP_OBJECT_TO_PHYSICAL, pattern)
 
     def promise(self):
-        return Promise.LOGICAL_DROP_UDF_TO_PHYSICAL
+        return Promise.LOGICAL_DROP_OBJECT_TO_PHYSICAL
 
     def check(self, before: Operator, context: OptimizerContext):
         return True
 
-    def apply(self, before: LogicalDropUDF, context: OptimizerContext):
-        after = DropUDFPlan(before.name, before.if_exists)
+    def apply(self, before: LogicalDropObject, context: OptimizerContext):
+        after = DropObjectPlan(before.object_type, before.name, before.if_exists)
         yield after
 
 
 class LogicalInsertToPhysical(Rule):
     def __init__(self):
         pattern = Pattern(OperatorType.LOGICALINSERT)
         super().__init__(RuleType.LOGICAL_INSERT_TO_PHYSICAL, pattern)
```

### Comparing `evadb-0.2.6/eva/optimizer/rules/rules_base.py` & `evadb-0.2.7/evadb/optimizer/rules/rules_base.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,17 +15,17 @@
 from __future__ import annotations
 
 from abc import ABC, abstractmethod
 from enum import Flag, IntEnum, auto
 from typing import TYPE_CHECKING
 
 if TYPE_CHECKING:
-    from eva.optimizer.optimizer_context import OptimizerContext
+    from evadb.optimizer.optimizer_context import OptimizerContext
 
-from eva.optimizer.operators import Operator
+from evadb.optimizer.operators import Operator
 
 
 class RuleType(Flag):
     """
     Manages enums for all the supported rules
     """
 
@@ -62,28 +62,27 @@
     LOGICAL_LIMIT_TO_PHYSICAL = auto()
     LOGICAL_INSERT_TO_PHYSICAL = auto()
     LOGICAL_DELETE_TO_PHYSICAL = auto()
     LOGICAL_LOAD_TO_PHYSICAL = auto()
     LOGICAL_CREATE_TO_PHYSICAL = auto()
     LOGICAL_CREATE_FROM_SELECT_TO_PHYSICAL = auto()
     LOGICAL_RENAME_TO_PHYSICAL = auto()
-    LOGICAL_DROP_TO_PHYSICAL = auto()
+    LOGICAL_DROP_OBJECT_TO_PHYSICAL = auto()
     LOGICAL_CREATE_UDF_TO_PHYSICAL = auto()
     LOGICAL_MATERIALIZED_VIEW_TO_PHYSICAL = auto()
     LOGICAL_GET_TO_SEQSCAN = auto()
     LOGICAL_SAMPLE_TO_UNIFORMSAMPLE = auto()
     LOGICAL_DERIVED_GET_TO_PHYSICAL = auto()
     LOGICAL_LATERAL_JOIN_TO_PHYSICAL = auto()
     LOGICAL_JOIN_TO_PHYSICAL_HASH_JOIN = auto()
     LOGICAL_JOIN_TO_PHYSICAL_NESTED_LOOP_JOIN = auto()
     LOGICAL_FUNCTION_SCAN_TO_PHYSICAL = auto()
     LOGICAL_FILTER_TO_PHYSICAL = auto()
     LOGICAL_PROJECT_TO_PHYSICAL = auto()
     LOGICAL_SHOW_TO_PHYSICAL = auto()
-    LOGICAL_DROP_UDF_TO_PHYSICAL = auto()
     LOGICAL_EXPLAIN_TO_PHYSICAL = auto()
     LOGICAL_CREATE_INDEX_TO_VECTOR_INDEX = auto()
     LOGICAL_APPLY_AND_MERGE_TO_PHYSICAL = auto()
     LOGICAL_VECTOR_INDEX_SCAN_TO_PHYSICAL = auto()
     IMPLEMENTATION_DELIMITER = auto()
 
     NUM_RULES = auto()
@@ -102,15 +101,15 @@
     LOGICAL_MATERIALIZED_VIEW_TO_PHYSICAL = auto()
     LOGICAL_GROUPBY_TO_PHYSICAL = auto()
     LOGICAL_ORDERBY_TO_PHYSICAL = auto()
     LOGICAL_LIMIT_TO_PHYSICAL = auto()
     LOGICAL_INSERT_TO_PHYSICAL = auto()
     LOGICAL_DELETE_TO_PHYSICAL = auto()
     LOGICAL_RENAME_TO_PHYSICAL = auto()
-    LOGICAL_DROP_TO_PHYSICAL = auto()
+    LOGICAL_DROP_OBJECT_TO_PHYSICAL = auto()
     LOGICAL_LOAD_TO_PHYSICAL = auto()
     LOGICAL_CREATE_TO_PHYSICAL = auto()
     LOGICAL_CREATE_FROM_SELECT_TO_PHYSICAL = auto()
     LOGICAL_CREATE_UDF_TO_PHYSICAL = auto()
     LOGICAL_SAMPLE_TO_UNIFORMSAMPLE = auto()
     LOGICAL_GET_TO_SEQSCAN = auto()
     LOGICAL_DERIVED_GET_TO_PHYSICAL = auto()
@@ -119,15 +118,14 @@
     LOGICAL_JOIN_TO_PHYSICAL_HASH_JOIN = auto()
     LOGICAL_JOIN_TO_PHYSICAL_NESTED_LOOP_JOIN = auto()
 
     LOGICAL_FUNCTION_SCAN_TO_PHYSICAL = auto()
     LOGICAL_FILTER_TO_PHYSICAL = auto()
     LOGICAL_PROJECT_TO_PHYSICAL = auto()
     LOGICAL_SHOW_TO_PHYSICAL = auto()
-    LOGICAL_DROP_UDF_TO_PHYSICAL = auto()
     LOGICAL_EXPLAIN_TO_PHYSICAL = auto()
     LOGICAL_CREATE_INDEX_TO_VECTOR_INDEX = auto()
     LOGICAL_APPLY_AND_MERGE_TO_PHYSICAL = auto()
     LOGICAL_VECTOR_INDEX_SCAN_TO_PHYSICAL = auto()
 
     # IMPLEMENTATION DELIMITER
     IMPLEMENTATION_DELIMITER = auto()
```

### Comparing `evadb-0.2.6/eva/optimizer/rules/rules_manager.py` & `evadb-0.2.7/evadb/optimizer/rules/rules_manager.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,16 +13,16 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from __future__ import annotations
 
 from contextlib import contextmanager
 from typing import List
 
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.optimizer.rules.rules import (
+from evadb.configuration.configuration_manager import ConfigurationManager
+from evadb.optimizer.rules.rules import (
     CacheFunctionExpressionInApply,
     CacheFunctionExpressionInFilter,
     CacheFunctionExpressionInProject,
     CombineSimilarityOrderByAndLimitToVectorIndexScan,
     EmbedFilterIntoGet,
     EmbedSampleIntoGet,
     LogicalApplyAndMergeToPhysical,
@@ -30,16 +30,15 @@
     LogicalCreateFromSelectToPhysical,
     LogicalCreateIndexToVectorIndex,
     LogicalCreateMaterializedViewToPhysical,
     LogicalCreateToPhysical,
     LogicalCreateUDFToPhysical,
     LogicalDeleteToPhysical,
     LogicalDerivedGetToPhysical,
-    LogicalDropToPhysical,
-    LogicalDropUDFToPhysical,
+    LogicalDropObjectToPhysical,
     LogicalExchangeToPhysical,
     LogicalExplainToPhysical,
     LogicalFilterToPhysical,
     LogicalFunctionScanToPhysical,
     LogicalGetToSeqScan,
     LogicalGroupByToPhysical,
     LogicalInnerJoinCommutativity,
@@ -58,19 +57,19 @@
     LogicalVectorIndexScanToPhysical,
     PushDownFilterThroughApplyAndMerge,
     PushDownFilterThroughJoin,
     ReorderPredicates,
     XformExtractObjectToLinearFlow,
     XformLateralJoinToLinearFlow,
 )
-from eva.optimizer.rules.rules_base import Rule
+from evadb.optimizer.rules.rules_base import Rule
 
 
 class RulesManager:
-    def __init__(self):
+    def __init__(self, config: ConfigurationManager):
         self._logical_rules = [
             LogicalInnerJoinCommutativity(),
             CacheFunctionExpressionInApply(),
             CacheFunctionExpressionInFilter(),
             CacheFunctionExpressionInProject(),
         ]
 
@@ -89,17 +88,16 @@
             ReorderPredicates(),
         ]
 
         self._implementation_rules = [
             LogicalCreateToPhysical(),
             LogicalCreateFromSelectToPhysical(),
             LogicalRenameToPhysical(),
-            LogicalDropToPhysical(),
             LogicalCreateUDFToPhysical(),
-            LogicalDropUDFToPhysical(),
+            LogicalDropObjectToPhysical(),
             LogicalInsertToPhysical(),
             LogicalDeleteToPhysical(),
             LogicalLoadToPhysical(),
             LogicalGetToSeqScan(),
             LogicalDerivedGetToPhysical(),
             LogicalUnionToPhysical(),
             LogicalGroupByToPhysical(),
@@ -113,15 +111,15 @@
             LogicalFilterToPhysical(),
             LogicalShowToPhysical(),
             LogicalExplainToPhysical(),
             LogicalCreateIndexToVectorIndex(),
             LogicalVectorIndexScanToPhysical(),
         ]
 
-        ray_enabled = ConfigurationManager().get_value("experimental", "ray")
+        ray_enabled = config.get_value("experimental", "ray")
         if ray_enabled:
             self._implementation_rules.extend(
                 [
                     LogicalExchangeToPhysical(),
                     LogicalApplyAndMergeToRayPhysical(),
                     LogicalProjectToRayPhysical(),
                 ]
@@ -196,19 +194,19 @@
             elif rule.is_stage_two_rewrite_rules():
                 _add_to_list(self.stage_two_rewrite_rules, rule)
             elif rule.is_logical_rule():
                 _add_to_list(self.logical_rules, rule)
 
 
 @contextmanager
-def disable_rules(rules: List[Rule]):
+def disable_rules(rules_manager: RulesManager, rules: List[Rule]):
     """Use this function to temporarily drop rules.
         Useful for testing and debugging purposes.
     Args:
+        rules_manager (RulesManager)
         rules (List[Rule]): List of rules to temporarily drop
     """
     try:
-        rules_manager = RulesManager()
         rules_manager.disable_rules(rules)
-        yield rules_manager
+        yield
     finally:
         rules_manager.add_rules(rules)
```

### Comparing `evadb-0.2.6/eva/optimizer/statement_to_opr_converter.py` & `evadb-0.2.7/evadb/optimizer/statement_to_opr_converter.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,23 +8,22 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.abstract_expression import AbstractExpression
-from eva.optimizer.operators import (
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.optimizer.operators import (
     LogicalCreate,
     LogicalCreateIndex,
     LogicalCreateMaterializedView,
     LogicalCreateUDF,
     LogicalDelete,
-    LogicalDrop,
-    LogicalDropUDF,
+    LogicalDropObject,
     LogicalExplain,
     LogicalExtractObject,
     LogicalFilter,
     LogicalFunctionScan,
     LogicalGet,
     LogicalGroupBy,
     LogicalInsert,
@@ -35,35 +34,34 @@
     LogicalProject,
     LogicalQueryDerivedGet,
     LogicalRename,
     LogicalSample,
     LogicalShow,
     LogicalUnion,
 )
-from eva.optimizer.optimizer_utils import (
+from evadb.optimizer.optimizer_utils import (
     column_definition_to_udf_io,
     metadata_definition_to_udf_metadata,
 )
-from eva.parser.create_index_statement import CreateIndexStatement
-from eva.parser.create_mat_view_statement import CreateMaterializedViewStatement
-from eva.parser.create_statement import CreateTableStatement
-from eva.parser.create_udf_statement import CreateUDFStatement
-from eva.parser.delete_statement import DeleteTableStatement
-from eva.parser.drop_statement import DropTableStatement
-from eva.parser.drop_udf_statement import DropUDFStatement
-from eva.parser.explain_statement import ExplainStatement
-from eva.parser.insert_statement import InsertTableStatement
-from eva.parser.load_statement import LoadDataStatement
-from eva.parser.rename_statement import RenameTableStatement
-from eva.parser.select_statement import SelectStatement
-from eva.parser.show_statement import ShowStatement
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableRef
-from eva.parser.types import UDFType
-from eva.utils.logging_manager import logger
+from evadb.parser.create_index_statement import CreateIndexStatement
+from evadb.parser.create_mat_view_statement import CreateMaterializedViewStatement
+from evadb.parser.create_statement import CreateTableStatement
+from evadb.parser.create_udf_statement import CreateUDFStatement
+from evadb.parser.delete_statement import DeleteTableStatement
+from evadb.parser.drop_object_statement import DropObjectStatement
+from evadb.parser.explain_statement import ExplainStatement
+from evadb.parser.insert_statement import InsertTableStatement
+from evadb.parser.load_statement import LoadDataStatement
+from evadb.parser.rename_statement import RenameTableStatement
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.show_statement import ShowStatement
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import TableRef
+from evadb.parser.types import UDFType
+from evadb.utils.logging_manager import logger
 
 
 class StatementToPlanConverter:
     def __init__(self):
         self._plan = None
 
     def visit_table_ref(self, table_ref: TableRef):
@@ -254,18 +252,14 @@
         """Converter for parsed rename statement
         Arguments:
             statement(RenameTableStatement): [Rename statement]
         """
         rename_opr = LogicalRename(statement.old_table_ref, statement.new_table_name)
         self._plan = rename_opr
 
-    def visit_drop(self, statement: DropTableStatement):
-        drop_opr = LogicalDrop(statement.table_infos, statement.if_exists)
-        self._plan = drop_opr
-
     def visit_create_udf(self, statement: CreateUDFStatement):
         """Converter for parsed create udf statement
 
         Arguments:
             statement {CreateUDFStatement} - - Create UDF Statement
         """
         annotated_inputs = column_definition_to_udf_io(statement.inputs, True)
@@ -279,21 +273,18 @@
             annotated_outputs,
             statement.impl_path,
             statement.udf_type,
             annotated_metadata,
         )
         self._plan = create_udf_opr
 
-    def visit_drop_udf(self, statement: DropUDFStatement):
-        """Converter for parsed DROP UDF statement
-
-        Arguments:
-            statement {DropUDFStatement} - Drop UDF Statement
-        """
-        self._plan = LogicalDropUDF(statement.name, statement.if_exists)
+    def visit_drop_object(self, statement: DropObjectStatement):
+        self._plan = LogicalDropObject(
+            statement.object_type, statement.name, statement.if_exists
+        )
 
     def visit_load_data(self, statement: LoadDataStatement):
         """Converter for parsed load data statement
         Arguments:
             statement(LoadDataStatement): [Load data statement]
         """
         load_data_opr = LogicalLoadData(
@@ -350,20 +341,18 @@
             self.visit_select(statement)
         elif isinstance(statement, InsertTableStatement):
             self.visit_insert(statement)
         elif isinstance(statement, CreateTableStatement):
             self.visit_create(statement)
         elif isinstance(statement, RenameTableStatement):
             self.visit_rename(statement)
-        elif isinstance(statement, DropTableStatement):
-            self.visit_drop(statement)
         elif isinstance(statement, CreateUDFStatement):
             self.visit_create_udf(statement)
-        elif isinstance(statement, DropUDFStatement):
-            self.visit_drop_udf(statement)
+        elif isinstance(statement, DropObjectStatement):
+            self.visit_drop_object(statement)
         elif isinstance(statement, LoadDataStatement):
             self.visit_load_data(statement)
         elif isinstance(statement, CreateMaterializedViewStatement):
             self.visit_materialized_view(statement)
         elif isinstance(statement, ShowStatement):
             self.visit_show(statement)
         elif isinstance(statement, ExplainStatement):
```

### Comparing `evadb-0.2.6/eva/parser/__init__.py` & `evadb-0.2.7/evadb/optimizer/rules/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/parser/alias.py` & `evadb-0.2.7/evadb/parser/alias.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/parser/create_index_statement.py` & `evadb-0.2.7/evadb/parser/create_index_statement.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,20 +10,20 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.catalog.catalog_type import VectorStoreType
-from eva.expression.function_expression import FunctionExpression
-from eva.parser.create_statement import ColumnDefinition
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableRef
-from eva.parser.types import StatementType
+from evadb.catalog.catalog_type import VectorStoreType
+from evadb.expression.function_expression import FunctionExpression
+from evadb.parser.create_statement import ColumnDefinition
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import TableRef
+from evadb.parser.types import StatementType
 
 
 class CreateIndexStatement(AbstractStatement):
     def __init__(
         self,
         name: str,
         table_ref: TableRef,
```

### Comparing `evadb-0.2.6/eva/parser/create_mat_view_statement.py` & `evadb-0.2.7/evadb/parser/create_mat_view_statement.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,19 +10,19 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.parser.create_statement import ColumnDefinition
-from eva.parser.select_statement import SelectStatement
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableInfo
-from eva.parser.types import StatementType
+from evadb.parser.create_statement import ColumnDefinition
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import TableInfo
+from evadb.parser.types import StatementType
 
 
 class CreateMaterializedViewStatement(AbstractStatement):
     """Create Materialized View Statement constructed after parsing the input query
     Attributes:
         view_ref: table reference to store the view
         if_not_exists: if true overwrite any existing view, else throw an error
```

### Comparing `evadb-0.2.6/eva/parser/create_statement.py` & `evadb-0.2.7/evadb/parser/create_statement.py`

 * *Files 6% similar despite different names*

```diff
@@ -10,19 +10,19 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List, Tuple
 
-from eva.catalog.catalog_type import ColumnType, NdArrayType
-from eva.parser.select_statement import SelectStatement
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableInfo
-from eva.parser.types import StatementType
+from evadb.catalog.catalog_type import ColumnType, NdArrayType
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import TableInfo
+from evadb.parser.types import StatementType
 
 
 class ColConstraintInfo:
     def __init__(self, nullable=False, default_value=None, primary=False, unique=False):
         self.nullable = nullable
         self.default_value = default_value
         self.primary = primary
@@ -132,17 +132,15 @@
 
     def __str__(self) -> str:
         print_str = "CREATE TABLE {} ({}) \n".format(
             self._table_info, self._if_not_exists
         )
 
         if self._query is not None:
-            print_str = "CREATE TABLE {} AS {}\n".format(
-                self._table_info, self._query
-            )
+            print_str = "CREATE TABLE {} AS {}\n".format(self._table_info, self._query)
 
         for column in self.column_list:
             print_str += str(column) + "\n"
 
         return print_str
 
     @property
@@ -178,10 +176,10 @@
     def __hash__(self) -> int:
         return hash(
             (
                 super().__hash__(),
                 self.table_info,
                 self.if_not_exists,
                 tuple(self.column_list or []),
-                self.query
+                self.query,
             )
         )
```

### Comparing `evadb-0.2.6/eva/parser/create_udf_statement.py` & `evadb-0.2.7/evadb/parser/create_udf_statement.py`

 * *Files 8% similar despite different names*

```diff
@@ -11,17 +11,17 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 from typing import List, Tuple
 
-from eva.parser.create_statement import ColumnDefinition
-from eva.parser.statement import AbstractStatement
-from eva.parser.types import StatementType
+from evadb.parser.create_statement import ColumnDefinition
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.types import StatementType
 
 
 class CreateUDFStatement(AbstractStatement):
     """Create UDF Statement constructed after parsing the input query
 
     Attributes:
         name: str
@@ -59,45 +59,33 @@
         self._inputs = inputs
         self._outputs = outputs
         self._impl_path = Path(impl_path) if impl_path else None
         self._udf_type = udf_type
         self._metadata = metadata
 
     def __str__(self) -> str:
-        exists_str = ""
+        exists_str = " "
         if self._if_not_exists:
-            exists_str += "IF NOT EXISTS "
-
-        input_str = ""
-        if self._inputs is not None:
-            input_str += "INPUT ("
-            for expr in self._inputs:
-                input_str += str(expr) + ", "
-            input_str = input_str.rstrip(", ")
-            input_str += ")"
-
-        output_str = ""
-        if self._outputs is not None:
-            output_str += "OUTPUT ("
-            for expr in self._outputs:
-                output_str += str(expr) + ", "
-            output_str = output_str.rstrip(", ")
-            output_str += ")"
+            exists_str = " IF NOT EXISTS "
 
         type_str = ""
         if self._udf_type is not None:
-            type_str += "TYPE " + self._udf_type
+            type_str += "TYPE " + str(self._udf_type)
+
+        impl_str = ""
+        if self._impl_path:
+            impl_str = f" IMPL {self._impl_path.name} "
 
         metadata_str = ""
         if self._metadata is not None:
             for key, value in self._metadata:
-                metadata_str += f"{key}={value}, "
-            metadata_str = metadata_str.rstrip(", ")
+                metadata_str += f"'{key}' '{value}' "
+            metadata_str = metadata_str.rstrip(" ")
 
-        return f"CREATE UDF {self._name} INPUT ({input_str}) OUTPUT ({output_str}) TYPE {self._udf_type} IMPL {self._impl_path.name} ({metadata_str}))"
+        return f"""CREATE UDF {self._name}{exists_str}TYPE {self._udf_type}{impl_str} {metadata_str}"""
 
     @property
     def name(self):
         return self._name
 
     @property
     def if_not_exists(self):
```

### Comparing `evadb-0.2.6/eva/parser/delete_statement.py` & `evadb-0.2.7/evadb/parser/delete_statement.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,18 +8,18 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableRef
-from eva.parser.types import StatementType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import TableRef
+from evadb.parser.types import StatementType
 
 
 class DeleteTableStatement(AbstractStatement):
     """Delete Table Statement constructed after parsing the input query
 
     Attributes:
         TableRef: table reference in the delete table statement
```

### Comparing `evadb-0.2.6/eva/parser/drop_statement.py` & `evadb-0.2.7/evadb/parser/drop_object_statement.py`

 * *Files 20% similar despite different names*

```diff
@@ -8,46 +8,60 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from typing import List
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.types import ObjectType, StatementType
 
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableInfo
-from eva.parser.types import StatementType
 
+class DropObjectStatement(AbstractStatement):
 
-class DropTableStatement(AbstractStatement):
-    """Drop Table Statement constructed after parsing the input query"""
+    """Drop Object Statement constructed after parsing the input query
 
-    def __init__(self, table_infos: List[TableInfo], if_exists: bool):
-        super().__init__(StatementType.DROP)
-        self._table_infos = table_infos
+    Attributes:
+        object_type: ObjectType
+        name (str
+            name of the object to drop
+        if_exists: bool
+            if false, throws an error when no UDF with name exists
+            else logs a warning
+    """
+
+    def __init__(self, object_type: ObjectType, name: str, if_exists: bool):
+        super().__init__(StatementType.DROP_OBJECT)
+        self._object_type = object_type
+        self._name = name
         self._if_exists = if_exists
 
     def __str__(self) -> str:
-        ti_str = [str(t) for t in self._table_infos]
         if self._if_exists:
-            return f"DROP TABLE IF EXISTS {ti_str}"
+            print_str = f"DROP {self._object_type} IF EXISTS {self._name};"
         else:
-            return f"DROP TABLE {ti_str}"
+            print_str = f"DROP {self._object_type} {self._name};"
+        return print_str
 
     @property
-    def table_infos(self):
-        return self._table_infos
+    def object_type(self):
+        return self._object_type
+
+    @property
+    def name(self):
+        return self._name
 
     @property
     def if_exists(self):
         return self._if_exists
 
     def __eq__(self, other):
-        if not isinstance(other, DropTableStatement):
+        if not isinstance(other, DropObjectStatement):
             return False
         return (
-            self.table_infos == other.table_infos and self.if_exists == other.if_exists
+            self.object_type == other.object_type
+            and self.name == other.name
+            and self.if_exists == other.if_exists
         )
 
     def __hash__(self) -> int:
-        return hash((super().__hash__(), tuple(self.table_infos), self.if_exists))
+        return hash((super().__hash__(), self.object_type, self.name, self.if_exists))
```

### Comparing `evadb-0.2.6/eva/parser/drop_udf_statement.py` & `evadb-0.2.7/evadb/parser/statement.py`

 * *Files 24% similar despite different names*

```diff
@@ -8,49 +8,43 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.parser.statement import AbstractStatement
-from eva.parser.types import StatementType
+from copy import deepcopy
 
+from evadb.parser.types import StatementType
 
-class DropUDFStatement(AbstractStatement):
-    """Drop UDF Statement constructed after parsing the input query
 
-    Attributes:
-        name: str
-            name of the udf
-        if_exists: bool
-            if false, throws an error when no UDF with name exists
-            else logs a warning
+class AbstractStatement:
     """
+    Base class for all Statements
 
-    def __init__(self, name: str, if_exists: bool):
-        super().__init__(StatementType.DROP_UDF)
-        self._name = name
-        self._if_exists = if_exists
-
-    def __str__(self) -> str:
-        if self._if_exists:
-            print_str = "DROP UDF IF EXISTS {};".format(self._name)
-        else:
-            print_str = "DROP UDF {};".format(self._name)
-        return print_str
+    Attributes
+    ----------
+    stmt_type : StatementType
+        the type of this statement - Select or Insert etc
+    """
 
-    @property
-    def name(self):
-        return self._name
+    def __init__(self, stmt_type: StatementType):
+        self._stmt_type = stmt_type
 
     @property
-    def if_exists(self):
-        return self._if_exists
-
-    def __eq__(self, other):
-        if not isinstance(other, DropUDFStatement):
-            return False
-        return self.name == other.name and self.if_exists == other.if_exists
+    def stmt_type(self):
+        return self._stmt_type
 
     def __hash__(self) -> int:
-        return hash((super().__hash__(), self.name, self.if_exists))
+        return hash(self.stmt_type)
+
+    def __deepcopy__(self, memo):
+        cls = self.__class__
+        result = cls.__new__(cls)
+        memo[id(self)] = result
+        for k, v in self.__dict__.items():
+            setattr(result, k, deepcopy(v, memo))
+        return result
+
+    def copy(self):
+        """Returns a deepcopy of the statement."""
+        return deepcopy(self)
```

### Comparing `evadb-0.2.6/eva/parser/eva.lark` & `evadb-0.2.7/evadb/parser/evadb.lark`

 * *Files 1% similar despite different names*

```diff
@@ -61,19 +61,19 @@
                  | PRIMARY? KEY   ->primary_key_column_constraint
                  | UNIQUE KEY?    ->unique_key_column_constraint    
 
 //    Drop statements
 
 drop_database: DROP DATABASE if_exists? uid
     
-drop_index: DROP INDEX uid ON table_name
+drop_index: DROP INDEX if_exists? uid
     
-drop_table: DROP TABLE if_exists? table_name
+drop_table: DROP TABLE if_exists? uid
     
-drop_udf: DROP UDF if_exists? udf_name
+drop_udf: DROP UDF if_exists? uid
     
 
 // Data Manipulation Language
 
 //    Primary DML Statements
 
 delete_statement: DELETE FROM table_name (WHERE where_expr)?
```

### Comparing `evadb-0.2.6/eva/parser/explain_statement.py` & `evadb-0.2.7/evadb/parser/explain_statement.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.parser.statement import AbstractStatement
-from eva.parser.types import StatementType
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.types import StatementType
 
 
 class ExplainStatement(AbstractStatement):
     def __init__(self, explainable_stmt: AbstractStatement):
         super().__init__(StatementType.EXPLAIN)
         self._explainable_stmt = explainable_stmt
```

### Comparing `evadb-0.2.6/eva/parser/insert_statement.py` & `evadb-0.2.7/evadb/parser/insert_statement.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,18 +10,18 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableRef
-from eva.parser.types import StatementType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import TableRef
+from evadb.parser.types import StatementType
 
 
 class InsertTableStatement(AbstractStatement):
     """
     Insert Table Statement constructed after parsing the input query
 
     Attributes
```

### Comparing `evadb-0.2.6/eva/parser/lark_parser.py` & `evadb-0.2.7/evadb/parser/lark_parser.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 
 from lark import Lark
 
-from eva.parser.lark_visitor import LarkInterpreter
+from evadb.parser.lark_visitor import LarkInterpreter
 
 
 class LarkParser(object):
     """
     Parser for EVA QL based on Lark
     """
 
@@ -29,15 +29,15 @@
     def __new__(cls):
         if not hasattr(cls, "_instance"):
             cls._instance = super(LarkParser, cls).__new__(cls)
         return cls._instance
 
     def __init__(self):
         dir_path = os.path.dirname(os.path.realpath(__file__))
-        lark_path = os.path.join(dir_path, "eva.lark")
+        lark_path = os.path.join(dir_path, "evadb.lark")
         with open(lark_path) as f:
             sql_grammar = f.read()
         self._parser = Lark(sql_grammar, parser="lalr")
 
     def parse(self, query_string: str) -> list:
         # remove trailing white space
         query_string = query_string.rstrip()
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/__init__.py` & `evadb-0.2.7/evadb/parser/lark_visitor/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -12,27 +12,27 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List, TypeVar
 
 from lark import Tree, visitors
 
-from eva.parser.lark_visitor._common_clauses_ids import CommonClauses
-from eva.parser.lark_visitor._create_statements import CreateTable
-from eva.parser.lark_visitor._delete_statement import Delete
-from eva.parser.lark_visitor._drop_statement import DropTable
-from eva.parser.lark_visitor._explain_statement import Explain
-from eva.parser.lark_visitor._expressions import Expressions
-from eva.parser.lark_visitor._functions import Functions
-from eva.parser.lark_visitor._insert_statements import Insert
-from eva.parser.lark_visitor._load_statement import Load
-from eva.parser.lark_visitor._rename_statement import RenameTable
-from eva.parser.lark_visitor._select_statement import Select
-from eva.parser.lark_visitor._show_statements import Show
-from eva.parser.lark_visitor._table_sources import TableSources
+from evadb.parser.lark_visitor._common_clauses_ids import CommonClauses
+from evadb.parser.lark_visitor._create_statements import CreateTable
+from evadb.parser.lark_visitor._delete_statement import Delete
+from evadb.parser.lark_visitor._drop_statement import DropObject
+from evadb.parser.lark_visitor._explain_statement import Explain
+from evadb.parser.lark_visitor._expressions import Expressions
+from evadb.parser.lark_visitor._functions import Functions
+from evadb.parser.lark_visitor._insert_statements import Insert
+from evadb.parser.lark_visitor._load_statement import Load
+from evadb.parser.lark_visitor._rename_statement import RenameTable
+from evadb.parser.lark_visitor._select_statement import Select
+from evadb.parser.lark_visitor._show_statements import Show
+from evadb.parser.lark_visitor._table_sources import TableSources
 
 # To add new functionality to the parser, create a new file under
 # the lark_visitor directory, and implement a new class which
 # overloads the required visitors' functions.
 # Then make the new class as a parent class for ParserVisitor.
 
 _Leaf_T = TypeVar("_Leaf_T")
@@ -61,15 +61,15 @@
     Expressions,
     Functions,
     Insert,
     Select,
     TableSources,
     Load,
     RenameTable,
-    DropTable,
+    DropObject,
     Show,
     Explain,
     Delete,
 ):
     def __init__(self, query):
         super().__init__()
         self.query = query
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_common_clauses_ids.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_common_clauses_ids.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,18 +9,18 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from eva.catalog.catalog_type import Dimension
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.table_ref import TableInfo
-from eva.utils.logging_manager import logger
+from evadb.catalog.catalog_type import Dimension
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.table_ref import TableInfo
+from evadb.utils.logging_manager import logger
 
 
 class CommonClauses:
     def table_name(self, tree):
         table_name = self.visit(tree.children[0])
         if table_name is not None:
             return TableInfo(table_name=table_name)
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_create_statements.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_create_statements.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,25 +11,25 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from lark import Tree
 
-from eva.catalog.catalog_type import ColumnType, NdArrayType, VectorStoreType
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.create_index_statement import CreateIndexStatement
-from eva.parser.create_mat_view_statement import CreateMaterializedViewStatement
-from eva.parser.create_statement import (
+from evadb.catalog.catalog_type import ColumnType, NdArrayType, VectorStoreType
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.create_index_statement import CreateIndexStatement
+from evadb.parser.create_mat_view_statement import CreateMaterializedViewStatement
+from evadb.parser.create_statement import (
     ColConstraintInfo,
     ColumnDefinition,
     CreateTableStatement,
 )
-from eva.parser.table_ref import TableRef
-from eva.parser.types import ColumnConstraintEnum
+from evadb.parser.table_ref import TableRef
+from evadb.parser.types import ColumnConstraintEnum
 
 
 ##################################################################
 # CREATE STATEMENTS
 ##################################################################
 class CreateTable:
     def create_table(self, tree):
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_delete_statement.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_delete_statement.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,16 +10,16 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from lark.tree import Tree
 
-from eva.parser.delete_statement import DeleteTableStatement
-from eva.parser.table_ref import TableRef
+from evadb.parser.delete_statement import DeleteTableStatement
+from evadb.parser.table_ref import TableRef
 
 
 ##################################################################
 # DELETE STATEMENTS
 ##################################################################
 class Delete:
     def delete_statement(self, tree):
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_drop_statement.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_show_statements.py`

 * *Files 26% similar despite different names*

```diff
@@ -8,29 +8,22 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from lark import Tree
+from evadb.parser.show_statement import ShowStatement
+from evadb.parser.types import ShowType
 
-from eva.parser.drop_statement import DropTableStatement
 
-
-class DropTable:
-    def drop_table(self, tree):
-        table_info = None
-        if_exists = False
-
-        for child in tree.children:
-            if isinstance(child, Tree):
-                if child.data == "if_exists":
-                    if_exists = True
-                elif child.data == "table_name":
-                    table_info = self.visit(child)
-
-        # Need to wrap table in a list
-        table_info_list = [table_info]
-
-        drop_stmt = DropTableStatement(table_info_list, if_exists)
-        return drop_stmt
+##################################################################
+# SHOW STATEMENT
+##################################################################
+class Show:
+    def show_statement(self, tree):
+        token = tree.children[1]
+
+        if str.upper(token) == "UDFS":
+            return ShowStatement(show_type=ShowType.UDFS)
+        elif str.upper(token) == "TABLES":
+            return ShowStatement(show_type=ShowType.TABLES)
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_explain_statement.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_explain_statement.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from lark import Tree
 
-from eva.parser.explain_statement import ExplainStatement
+from evadb.parser.explain_statement import ExplainStatement
 
 
 class Explain:
     def explain_statement(self, tree):
         explainable_stmt = None
 
         for child in tree.children:
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_expressions.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_expressions.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,19 +11,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import numpy as np
 from lark import Tree
 
-from eva.catalog.catalog_type import ColumnType
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.logical_expression import LogicalExpression
+from evadb.catalog.catalog_type import ColumnType
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.logical_expression import LogicalExpression
 
 
 ##################################################################
 # EXPRESSIONS
 ##################################################################
 class Expressions:
     def string_literal(self, tree):
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_functions.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_functions.py`

 * *Files 8% similar despite different names*

```diff
@@ -11,21 +11,20 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from lark import Token, Tree
 
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.aggregation_expression import AggregationExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.function_expression import FunctionExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.create_udf_statement import CreateUDFStatement
-from eva.parser.drop_udf_statement import DropUDFStatement
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.aggregation_expression import AggregationExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.function_expression import FunctionExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.create_udf_statement import CreateUDFStatement
 
 
 ##################################################################
 # Functions - UDFs, Aggregate Windowed functions
 ##################################################################
 class Functions:
     def udf_function(self, tree):
@@ -51,28 +50,14 @@
     def function_args(self, tree):
         args = []
         for child in tree.children:
             if isinstance(child, Tree):
                 args.append(self.visit(child))
         return args
 
-    # Drop UDF
-    def drop_udf(self, tree):
-        udf_name = None
-        if_exists = False
-
-        for child in tree.children:
-            if isinstance(child, Tree):
-                if child.data == "udf_name":
-                    udf_name = self.visit(child)
-                elif child.data == "if_exists":
-                    if_exists = True
-
-        return DropUDFStatement(udf_name, if_exists)
-
     # Create UDF
     def create_udf(self, tree):
         udf_name = None
         if_not_exists = False
         input_definitions = []
         output_definitions = []
         impl_path = None
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_insert_statements.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_insert_statements.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,17 +10,17 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from lark.tree import Tree
 
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.insert_statement import InsertTableStatement
-from eva.parser.table_ref import TableRef
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.insert_statement import InsertTableStatement
+from evadb.parser.table_ref import TableRef
 
 
 ##################################################################
 # INSERT STATEMENTS
 ##################################################################
 class Insert:
     def insert_statement(self, tree):
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_load_statement.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_load_statement.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,16 +10,16 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from lark.tree import Tree
 
-from eva.parser.load_statement import LoadDataStatement
-from eva.parser.types import FileFormatType
+from evadb.parser.load_statement import LoadDataStatement
+from evadb.parser.types import FileFormatType
 
 
 class Load:
     def load_statement(self, tree):
         # Set default file_format
         file_format = FileFormatType.VIDEO
         file_format = self.visit(tree.children[1])
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_rename_statement.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_rename_statement.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,16 +9,16 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from eva.parser.rename_statement import RenameTableStatement
-from eva.parser.table_ref import TableRef
+from evadb.parser.rename_statement import RenameTableStatement
+from evadb.parser.table_ref import TableRef
 
 
 class RenameTable:
     def rename_table(self, tree):
         old_table_info = self.visit(tree.children[2])
         new_table_info = self.visit(tree.children[4])
         return RenameTableStatement(TableRef(old_table_info), new_table_info)
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_select_statement.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_select_statement.py`

 * *Files 14% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from lark.tree import Tree
 
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.parser.types import ParserOrderBySortType
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.parser.types import ParserOrderBySortType
 
 
 ##################################################################
 # SELECT STATEMENT
 ##################################################################
 class Select:
     def simple_select(self, tree):
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_show_statements.py` & `evadb-0.2.7/evadb/plan_nodes/show_info_plan.py`

 * *Files 24% similar despite different names*

```diff
@@ -8,22 +8,29 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.parser.show_statement import ShowStatement
-from eva.parser.types import ShowType
+from evadb.parser.types import ShowType
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
-##################################################################
-# SHOW STATEMENT
-##################################################################
-class Show:
-    def show_statement(self, tree):
-        token = tree.children[1]
+class ShowInfoPlan(AbstractPlan):
+    def __init__(self, show_type: ShowType):
+        self._show_type = show_type
+        super().__init__(PlanOprType.SHOW_INFO)
 
-        if str.upper(token) == "UDFS":
-            return ShowStatement(show_type=ShowType.UDFS)
-        elif str.upper(token) == "TABLES":
-            return ShowStatement(show_type=ShowType.TABLES)
+    @property
+    def show_type(self):
+        return self._show_type
+
+    def __str__(self):
+        if self._show_type == ShowType.UDFS:
+            return "ShowUDFPlan"
+        else:
+            return "ShowTablePlan"
+
+    def __hash__(self) -> int:
+        return hash((super().__hash__(), self.show_type))
```

### Comparing `evadb-0.2.6/eva/parser/lark_visitor/_table_sources.py` & `evadb-0.2.7/evadb/parser/lark_visitor/_table_sources.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,19 +11,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from lark import Token, Tree
 
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.select_statement import SelectStatement
-from eva.parser.table_ref import Alias, JoinNode, TableRef, TableValuedExpression
-from eva.parser.types import JoinType
-from eva.utils.logging_manager import logger
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.table_ref import Alias, JoinNode, TableRef, TableValuedExpression
+from evadb.parser.types import JoinType
+from evadb.utils.logging_manager import logger
 
 ##################################################################
 # TABLE SOURCES
 ##################################################################
 
 
 class TableSources:
```

### Comparing `evadb-0.2.6/eva/parser/load_statement.py` & `evadb-0.2.7/evadb/parser/load_statement.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,18 +11,18 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 from typing import List
 
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableInfo
-from eva.parser.types import StatementType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import TableInfo
+from evadb.parser.types import StatementType
 
 
 class LoadDataStatement(AbstractStatement):
     """
     Load Data Statement constructed after parsing the input query
 
     Arguments:
```

### Comparing `evadb-0.2.6/eva/parser/parser.py` & `evadb-0.2.7/evadb/parser/parser.py`

 * *Files 9% similar despite different names*

```diff
@@ -8,20 +8,20 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.parser.lark_parser import LarkParser
+from evadb.parser.lark_parser import LarkParser
 
 
 class Parser(object):
     """
-    Parser based on EVAQL grammar: eva.lark
+    Parser based on EVAQL grammar: evadb.lark
     """
 
     _lark_parser = None
 
     def __new__(cls):
         if not hasattr(cls, "_instance"):
             cls._instance = super(Parser, cls).__new__(cls)
```

### Comparing `evadb-0.2.6/eva/parser/rename_statement.py` & `evadb-0.2.7/evadb/parser/rename_statement.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,17 +8,17 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.parser.statement import AbstractStatement
-from eva.parser.table_ref import TableInfo, TableRef
-from eva.parser.types import StatementType
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.table_ref import TableInfo, TableRef
+from evadb.parser.types import StatementType
 
 #  Modified
 
 
 class RenameTableStatement(AbstractStatement):
     """Rename Table Statement constructed after parsing the input query
```

### Comparing `evadb-0.2.6/eva/parser/select_statement.py` & `evadb-0.2.7/evadb/parser/select_statement.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,19 +14,19 @@
 # limitations under the License.
 from __future__ import annotations
 
 import typing
 from typing import List, Union
 
 if typing.TYPE_CHECKING:
-    from eva.parser.table_ref import TableRef
+    from evadb.parser.table_ref import TableRef
 
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.statement import AbstractStatement
-from eva.parser.types import ParserOrderBySortType, StatementType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.types import ParserOrderBySortType, StatementType
 
 
 class SelectStatement(AbstractStatement):
     """
     Select Statement constructed after parsing the input query
 
     Attributes
```

### Comparing `evadb-0.2.6/eva/parser/show_statement.py` & `evadb-0.2.7/evadb/parser/show_statement.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,16 +10,16 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from __future__ import annotations
 
-from eva.parser.statement import AbstractStatement
-from eva.parser.types import ShowType, StatementType
+from evadb.parser.statement import AbstractStatement
+from evadb.parser.types import ShowType, StatementType
 
 
 class ShowStatement(AbstractStatement):
     def __init__(self, show_type: ShowType):
         super().__init__(StatementType.SHOW)
         self._show_type = show_type
```

### Comparing `evadb-0.2.6/eva/parser/statement.py` & `evadb-0.2.7/evadb/plan_nodes/function_scan_plan.py`

 * *Files 24% similar despite different names*

```diff
@@ -8,43 +8,41 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from copy import deepcopy
+from evadb.expression.function_expression import FunctionExpression
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
-from eva.parser.types import StatementType
 
-
-class AbstractStatement:
+class FunctionScanPlan(AbstractPlan):
     """
-    Base class for all Statements
+    This plan used to store metadata to perform function table scan.
 
-    Attributes
-    ----------
-    stmt_type : StatementType
-        the type of this statement - Select or Insert etc
+    Arguments:
+        func_expr(FunctionExpression): parameterized function expression that
+            reference columns from a table expression that precedes it.
+        do_unnest(bool): if True perform unnest operation on the output of FunctionScan
     """
 
-    def __init__(self, stmt_type: StatementType):
-        self._stmt_type = stmt_type
+    def __init__(self, func_expr: FunctionExpression, do_unnest: bool = False):
+        self._func_expr = func_expr
+        self._do_unnest = do_unnest
+        super().__init__(PlanOprType.FUNCTION_SCAN)
 
     @property
-    def stmt_type(self):
-        return self._stmt_type
+    def func_expr(self):
+        return self._func_expr
 
-    def __hash__(self) -> int:
-        return hash(self.stmt_type)
+    @property
+    def do_unnest(self):
+        return self._do_unnest
 
-    def __deepcopy__(self, memo):
-        cls = self.__class__
-        result = cls.__new__(cls)
-        memo[id(self)] = result
-        for k, v in self.__dict__.items():
-            setattr(result, k, deepcopy(v, memo))
-        return result
-
-    def copy(self):
-        """Returns a deepcopy of the statement."""
-        return deepcopy(self)
+    def __str__(self):
+        plan = "UnnestFunctionScanPlan" if self._do_unnest else "FunctionScanPlan"
+        return "{}(func_expr={})".format(plan, self._func_expr)
+
+    def __hash__(self) -> int:
+        return hash((super().__hash__(), self.func_expr, self.do_unnest))
```

### Comparing `evadb-0.2.6/eva/parser/table_ref.py` & `evadb-0.2.7/evadb/parser/table_ref.py`

 * *Files 0% similar despite different names*

```diff
@@ -12,19 +12,19 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from __future__ import annotations
 
 from typing import Union
 
-from eva.expression.abstract_expression import AbstractExpression
-from eva.expression.function_expression import FunctionExpression
-from eva.parser.alias import Alias
-from eva.parser.select_statement import SelectStatement
-from eva.parser.types import JoinType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.expression.function_expression import FunctionExpression
+from evadb.parser.alias import Alias
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.types import JoinType
 
 
 class TableInfo:
     """
     stores all the table info, inspired from postgres
     """
```

### Comparing `evadb-0.2.6/eva/parser/types.py` & `evadb-0.2.7/evadb/parser/types.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from eva.utils.generic_utils import EVAEnum
+from evadb.utils.generic_utils import EVAEnum
 
 
 class ColumnConstraintEnum(EVAEnum):
     NOTNULL  # noqa: F821
     DEFAULT  # noqa: F821
     PRIMARY  # noqa: F821
     UNIQUE  # noqa: F821
@@ -27,22 +27,21 @@
     """
     Manages EVAEnums for all the sql-like statements supported
     """
 
     SELECT  # noqa: F821
     CREATE  # noqa: F821
     RENAME  # noqa: F821
-    DROP  # noqa: F821
+    DROP_OBJECT  # noqa: F821
     INSERT  # noqa: F821
     DELETE  # noqa: F821
     CREATE_UDF  # noqa: F821
     LOAD_DATA  # noqa: F821
     CREATE_MATERIALIZED_VIEW  # noqa: F821
     SHOW  # noqa: F821
-    DROP_UDF  # noqa: F821
     EXPLAIN  # noqa: F821
     CREATE_INDEX  # noqa: F821
     # add other types
 
 
 class ParserOrderBySortType(EVAEnum):
     """
@@ -69,7 +68,13 @@
 class ShowType(EVAEnum):
     UDFS  # noqa: F821
     TABLES  # noqa: F821
 
 
 class UDFType(EVAEnum):
     EXTRACT_OBJECT  # noqa: F821
+
+
+class ObjectType(EVAEnum):
+    TABLE  # noqa: F821
+    UDF  # noqa: F821
+    INDEX  # noqa: F821
```

### Comparing `evadb-0.2.6/eva/plan_nodes/__init__.py` & `evadb-0.2.7/evadb/plan_nodes/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/plan_nodes/abstract_join_plan.py` & `evadb-0.2.7/evadb/plan_nodes/abstract_join_plan.py`

 * *Files 6% similar despite different names*

```diff
@@ -10,18 +10,18 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """Abstract class for all the join planners
 """
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.types import JoinType
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.types import JoinType
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class AbstractJoin(AbstractPlan):
     """Abstract class for all the join based planners
 
     Arguments:
         join_type: JoinType
```

### Comparing `evadb-0.2.6/eva/plan_nodes/abstract_plan.py` & `evadb-0.2.7/evadb/plan_nodes/abstract_plan.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from abc import ABC, abstractmethod
 from collections import deque
 from typing import Any, List
 
-from eva.plan_nodes.types import PlanOprType
+from evadb.plan_nodes.types import PlanOprType
 
 
 class AbstractPlan(ABC):
     def __init__(self, opr_type):
         self._children = []
         self._parent = None
         self._opr_type = opr_type
```

### Comparing `evadb-0.2.6/eva/plan_nodes/abstract_scan_plan.py` & `evadb-0.2.7/evadb/plan_nodes/abstract_scan_plan.py`

 * *Files 16% similar despite different names*

```diff
@@ -12,17 +12,17 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """Abstract class for all the scan planners
 https://www.postgresql.org/docs/9.1/using-explain.html
 https://www.postgresql.org/docs/9.5/runtime-config-query.html
 """
-from eva.expression.abstract_expression import AbstractExpression
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class AbstractScan(AbstractPlan):
     """Abstract class for all the scan based planners
 
     Arguments:
         predicate (AbstractExpression): An expression used for filtering
```

### Comparing `evadb-0.2.6/eva/plan_nodes/apply_and_merge_plan.py` & `evadb-0.2.7/evadb/plan_nodes/apply_and_merge_plan.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,18 +8,18 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.function_expression import FunctionExpression
-from eva.parser.alias import Alias
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.function_expression import FunctionExpression
+from evadb.parser.alias import Alias
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class ApplyAndMergePlan(AbstractPlan):
     """
     This dataclass stores metadata to perform apply and merge operation.
 
     Arguments:
```

### Comparing `evadb-0.2.6/eva/plan_nodes/create_index_plan.py` & `evadb-0.2.7/evadb/plan_nodes/create_index_plan.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,20 +10,20 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.catalog.catalog_type import VectorStoreType
-from eva.expression.function_expression import FunctionExpression
-from eva.parser.create_statement import ColumnDefinition
-from eva.parser.table_ref import TableRef
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.catalog.catalog_type import VectorStoreType
+from evadb.expression.function_expression import FunctionExpression
+from evadb.parser.create_statement import ColumnDefinition
+from evadb.parser.table_ref import TableRef
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class CreateIndexPlan(AbstractPlan):
     def __init__(
         self,
         name: str,
         table_ref: TableRef,
```

### Comparing `evadb-0.2.6/eva/plan_nodes/create_mat_view_plan.py` & `evadb-0.2.7/evadb/plan_nodes/create_mat_view_plan.py`

 * *Files 4% similar despite different names*

```diff
@@ -10,18 +10,18 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.parser.create_statement import ColumnDefinition
-from eva.parser.table_ref import TableInfo
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.parser.create_statement import ColumnDefinition
+from evadb.parser.table_ref import TableInfo
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class CreateMaterializedViewPlan(AbstractPlan):
     """
     This plan is used for storing information required for creating
     materialized view.
     Arguments:
```

### Comparing `evadb-0.2.6/eva/plan_nodes/create_plan.py` & `evadb-0.2.7/evadb/plan_nodes/create_plan.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,19 +9,19 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
 
-from eva.parser.table_ref import TableInfo
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.parser.table_ref import TableInfo
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class CreatePlan(AbstractPlan):
     """
     This plan is used for storing information required for create table
     operations.
     Arguments:
```

### Comparing `evadb-0.2.6/eva/plan_nodes/create_udf_plan.py` & `evadb-0.2.7/evadb/plan_nodes/create_udf_plan.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,18 +11,18 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 from typing import List
 
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.catalog.models.udf_metadata_catalog import UdfMetadataCatalogEntry
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.catalog.models.udf_metadata_catalog import UdfMetadataCatalogEntry
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class CreateUDFPlan(AbstractPlan):
     """
     This plan is used for storing information required to create udf operators
 
     Attributes:
```

### Comparing `evadb-0.2.6/eva/plan_nodes/delete_plan.py` & `evadb-0.2.7/evadb/plan_nodes/delete_plan.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,18 +8,18 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.table_ref import TableRef
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.table_ref import TableRef
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class DeletePlan(AbstractPlan):
     """This plan is used for storing information required for insert
     operations.
 
     Args:
```

### Comparing `evadb-0.2.6/eva/plan_nodes/drop_plan.py` & `evadb-0.2.7/evadb/plan_nodes/rename_plan.py`

 * *Files 20% similar despite different names*

```diff
@@ -8,43 +8,43 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from typing import List
+from evadb.parser.table_ref import TableInfo, TableRef
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
-from eva.parser.table_ref import TableInfo
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
 
-
-class DropPlan(AbstractPlan):
+# Modified
+class RenamePlan(AbstractPlan):
     """
-    This plan is used for storing information required for drop table
+    This plan is used for storing information required for rename table
     operations.
     Arguments:
-        table_ref {TableRef} -- table ref for table to be truncated in storage
-        if_exists {bool} -- if True do not throw error if table does not exist
+        old_table {TableRef} -- table ref for table to be renamed in storage
+        new_name {TableInfo} -- new name of old_table
     """
 
-    def __init__(self, table_infos: List[TableInfo], if_exists: bool):
-        super().__init__(PlanOprType.DROP)
-        self._table_infos = table_infos
-        self._if_exists = if_exists
+    def __init__(self, old_table: TableRef, new_name: TableInfo):
+        super().__init__(PlanOprType.RENAME)
+        self._old_table = old_table
+        self._new_name = new_name
 
     @property
-    def table_infos(self):
-        return self._table_infos
+    def old_table(self):
+        return self._old_table
 
     @property
-    def if_exists(self):
-        return self._if_exists
+    def new_name(self):
+        return self._new_name
 
     def __str__(self):
-        return "DropPlan(_table_infos={}, if_exists={})".format(
-            self._table_infos, self._if_exists
+        return "RenamePlan(old_table={}, \
+            new_name={})".format(
+            self._old_table, self._new_name
         )
 
     def __hash__(self) -> int:
-        return hash((super().__hash__(), tuple(self._table_infos), self.if_exists))
+        return hash((super().__hash__(), self.old_table, self.new_name))
```

### Comparing `evadb-0.2.6/eva/plan_nodes/drop_udf_plan.py` & `evadb-0.2.7/evadb/plan_nodes/union_plan.py`

 * *Files 23% similar despite different names*

```diff
@@ -8,41 +8,33 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
-class DropUDFPlan(AbstractPlan):
+class UnionPlan(AbstractPlan):
     """
-    This plan is used for storing information required to create udf operators
+    This plan is used for storing information required for union operations.
 
-    Attributes:
-        name: str
-            udf_name provided by the user required
-        if_exists: bool
-            if false, throws an error when no UDF with name exists
-            else logs a warning
+    Arguments:
+        all: Bool
+            UNION (deduplication) vs UNION ALL (non-deduplication)
     """
 
-    def __init__(self, name: str, if_exists: bool):
-        super().__init__(PlanOprType.DROP_UDF)
-        self._name = name
-        self._if_exists = if_exists
+    def __init__(self, all: bool):
+        self._all = all
+        super().__init__(PlanOprType.UNION)
 
     @property
-    def name(self):
-        return self._name
-
-    @property
-    def if_exists(self):
-        return self._if_exists
+    def all(self):
+        return self._all
 
     def __str__(self):
-        return "DropUDFPlan(name={}, if_exists={})".format(self._name, self._if_exists)
+        return "UnionAllPlan" if self._all else "UnionPlan"
 
     def __hash__(self) -> int:
-        return hash((super().__hash__(), self.name, self.if_exists))
+        return hash((super().__hash__(), self._all))
```

### Comparing `evadb-0.2.6/eva/plan_nodes/exchange_plan.py` & `evadb-0.2.7/evadb/plan_nodes/exchange_plan.py`

 * *Files 8% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import Any, Dict, List
 
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class ExchangePlan(AbstractPlan):
     """
     This plan is used for storing information required for union operations.
 
     Arguments:
```

### Comparing `evadb-0.2.6/eva/plan_nodes/explain_plan.py` & `evadb-0.2.7/evadb/plan_nodes/explain_plan.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class ExplainPlan(AbstractPlan):
     def __init__(self, explainable_plan: AbstractPlan):
         super().__init__(PlanOprType.EXPLAIN)
         self._explainable_plan = explainable_plan
```

### Comparing `evadb-0.2.6/eva/plan_nodes/function_scan_plan.py` & `evadb-0.2.7/evadb/plan_nodes/groupby_plan.py`

 * *Files 23% similar despite different names*

```diff
@@ -8,41 +8,36 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.function_expression import FunctionExpression
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
-class FunctionScanPlan(AbstractPlan):
+class GroupByPlan(AbstractPlan):
     """
-    This plan used to store metadata to perform function table scan.
+    This plan is used for storing information required for group by
+    operations.
 
     Arguments:
-        func_expr(FunctionExpression): parameterized function expression that
-            reference columns from a table expression that precedes it.
-        do_unnest(bool): if True perform unnest operation on the output of FunctionScan
+        groupby_clause: ConstantValueExpression
+            A ConstantValueExpression which is the number of elements to
+            group together.
     """
 
-    def __init__(self, func_expr: FunctionExpression, do_unnest: bool = False):
-        self._func_expr = func_expr
-        self._do_unnest = do_unnest
-        super().__init__(PlanOprType.FUNCTION_SCAN)
+    def __init__(self, groupby_clause: ConstantValueExpression):
+        self._groupby_clause = groupby_clause
+        super().__init__(PlanOprType.GROUP_BY)
 
     @property
-    def func_expr(self):
-        return self._func_expr
-
-    @property
-    def do_unnest(self):
-        return self._do_unnest
+    def groupby_clause(self):
+        return self._groupby_clause
 
     def __str__(self):
-        plan = "UnnestFunctionScanPlan" if self._do_unnest else "FunctionScanPlan"
-        return "{}(func_expr={})".format(plan, self._func_expr)
+        return "GroupByPlan(groupby_clause={})".format(self._groupby_clause)
 
     def __hash__(self) -> int:
-        return hash((super().__hash__(), self.func_expr, self.do_unnest))
+        return hash((super().__hash__(), self.groupby_clause))
```

### Comparing `evadb-0.2.6/eva/plan_nodes/groupby_plan.py` & `evadb-0.2.7/evadb/plan_nodes/sample_plan.py`

 * *Files 21% similar despite different names*

```diff
@@ -8,36 +8,36 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
-class GroupByPlan(AbstractPlan):
+class SamplePlan(AbstractPlan):
     """
-    This plan is used for storing information required for group by
+    This plan is used for storing information required for sample
     operations.
 
     Arguments:
-        groupby_clause: ConstantValueExpression
-            A ConstantValueExpression which is the number of elements to
-            group together.
+        sample_freq: ConstantValueExpression
+            A ConstantValueExpression which is the count of the
+            gap between frames sampled.
     """
 
-    def __init__(self, groupby_clause: ConstantValueExpression):
-        self._groupby_clause = groupby_clause
-        super().__init__(PlanOprType.GROUP_BY)
+    def __init__(self, sample_freq: ConstantValueExpression):
+        self._sample_freq = sample_freq
+        super().__init__(PlanOprType.SAMPLE)
 
     @property
-    def groupby_clause(self):
-        return self._groupby_clause
+    def sample_freq(self):
+        return self._sample_freq
 
     def __str__(self):
-        return "GroupByPlan(groupby_clause={})".format(self._groupby_clause)
+        return "SamplePlan(sample_freq={})".format(self._sample_freq)
 
     def __hash__(self) -> int:
-        return hash((super().__hash__(), self.groupby_clause))
+        return hash((super().__hash__(), self.sample_freq))
```

### Comparing `evadb-0.2.6/eva/plan_nodes/hash_join_build_plan.py` & `evadb-0.2.7/evadb/plan_nodes/hash_join_build_plan.py`

 * *Files 14% similar despite different names*

```diff
@@ -10,18 +10,18 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.parser.types import JoinType
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.parser.types import JoinType
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class HashJoinBuildPlan(AbstractPlan):
     """
     This plan is used for storing information required for hashjoin build side.
     It prepares the hash table of preferably the smaller relation
     which is used by the probe side to find relevant rows.
```

### Comparing `evadb-0.2.6/eva/plan_nodes/hash_join_probe_plan.py` & `evadb-0.2.7/evadb/plan_nodes/hash_join_probe_plan.py`

 * *Files 10% similar despite different names*

```diff
@@ -10,19 +10,19 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.types import JoinType
-from eva.plan_nodes.abstract_join_plan import AbstractJoin
-from eva.plan_nodes.types import PlanOprType
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.types import JoinType
+from evadb.plan_nodes.abstract_join_plan import AbstractJoin
+from evadb.plan_nodes.types import PlanOprType
 
 
 class HashJoinProbePlan(AbstractJoin):
     """
     This plan is used for storing information required for
     hash join probe side. It scans over the preferably larger relation
     and uses build side hash table to join.
```

### Comparing `evadb-0.2.6/eva/plan_nodes/insert_plan.py` & `evadb-0.2.7/evadb/plan_nodes/insert_plan.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,18 +10,18 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.expression.abstract_expression import AbstractExpression
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class InsertPlan(AbstractPlan):
     """This plan is used for storing information required for insert
     operations.
 
     Args:
```

### Comparing `evadb-0.2.6/eva/plan_nodes/lateral_join_plan.py` & `evadb-0.2.7/evadb/plan_nodes/lateral_join_plan.py`

 * *Files 9% similar despite different names*

```diff
@@ -8,18 +8,18 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.types import JoinType
-from eva.plan_nodes.abstract_join_plan import AbstractJoin
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.types import JoinType
+from evadb.plan_nodes.abstract_join_plan import AbstractJoin
+from evadb.plan_nodes.types import PlanOprType
 
 
 class LateralJoinPlan(AbstractJoin):
     """
     This plan is used for storing information required for lateral join
     """
```

### Comparing `evadb-0.2.6/eva/plan_nodes/limit_plan.py` & `evadb-0.2.7/evadb/plan_nodes/limit_plan.py`

 * *Files 17% similar despite different names*

```diff
@@ -8,17 +8,17 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class LimitPlan(AbstractPlan):
     """
     This plan is used for storing information required for limit
     operations.
```

### Comparing `evadb-0.2.6/eva/plan_nodes/load_data_plan.py` & `evadb-0.2.7/evadb/plan_nodes/load_data_plan.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,18 +11,18 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 from typing import List
 
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.table_ref import TableInfo
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.table_ref import TableInfo
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class LoadDataPlan(AbstractPlan):
     """
     This plan is used for storing information required for load data
     operations.
```

### Comparing `evadb-0.2.6/eva/plan_nodes/nested_loop_join_plan.py` & `evadb-0.2.7/evadb/plan_nodes/nested_loop_join_plan.py`

 * *Files 3% similar despite different names*

```diff
@@ -9,18 +9,18 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.types import JoinType
-from eva.plan_nodes.abstract_join_plan import AbstractJoin
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.types import JoinType
+from evadb.plan_nodes.abstract_join_plan import AbstractJoin
+from evadb.plan_nodes.types import PlanOprType
 
 
 class NestedLoopJoinPlan(AbstractJoin):
     """
     This plan is used for storing information required for a nested loop join.
     """
```

### Comparing `evadb-0.2.6/eva/plan_nodes/orderby_plan.py` & `evadb-0.2.7/evadb/plan_nodes/orderby_plan.py`

 * *Files 13% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class OrderByPlan(AbstractPlan):
     """
     This plan is used for storing information required for order by
     operations.
```

### Comparing `evadb-0.2.6/eva/plan_nodes/pp_plan.py` & `evadb-0.2.7/evadb/plan_nodes/pp_plan.py`

 * *Files 3% similar despite different names*

```diff
@@ -8,17 +8,17 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.abstract_expression import AbstractExpression
-from eva.plan_nodes.abstract_scan_plan import AbstractScan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.plan_nodes.abstract_scan_plan import AbstractScan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class PPScanPlan(AbstractScan):
     """
     This plan is used for storing information required for probabilistic
     predicate.
```

### Comparing `evadb-0.2.6/eva/plan_nodes/predicate_plan.py` & `evadb-0.2.7/evadb/plan_nodes/predicate_plan.py`

 * *Files 9% similar despite different names*

```diff
@@ -8,17 +8,17 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.abstract_expression import AbstractExpression
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class PredicatePlan(AbstractPlan):
     """
     Arguments:
         predicate (AbstractExpression): A predicate expression used for
         filtering frames
```

### Comparing `evadb-0.2.6/eva/plan_nodes/project_plan.py` & `evadb-0.2.7/evadb/plan_nodes/project_plan.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,17 +10,17 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.expression.abstract_expression import AbstractExpression
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class ProjectPlan(AbstractPlan):
     """
     Arguments:
         target_list List[(AbstractExpression)]: projection list
     """
```

### Comparing `evadb-0.2.6/eva/plan_nodes/rename_plan.py` & `evadb-0.2.7/evadb/utils/stats.py`

 * *Files 27% similar despite different names*

```diff
@@ -8,43 +8,48 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.parser.table_ref import TableInfo, TableRef
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
-
-
-# Modified
-class RenamePlan(AbstractPlan):
-    """
-    This plan is used for storing information required for rename table
-    operations.
-    Arguments:
-        old_table {TableRef} -- table ref for table to be renamed in storage
-        new_name {TableInfo} -- new name of old_table
-    """
-
-    def __init__(self, old_table: TableRef, new_name: TableInfo):
-        super().__init__(PlanOprType.RENAME)
-        self._old_table = old_table
-        self._new_name = new_name
 
-    @property
-    def old_table(self):
-        return self._old_table
+import time
+from dataclasses import dataclass
+
+from evadb.utils.logging_manager import logger
+
+
+class Timer:
+    """Class used for logging time metrics.
+
+    This is not thread safe"""
+
+    def __init__(self):
+        self._start_time = None
+        self._total_time = 0.0
+
+    def __enter__(self):
+        assert self._start_time is None, "Concurrent calls are not supported"
+        self._start_time = time.perf_counter()
+
+    def __exit__(self, exc_type, exc_val, exc_tb):
+        assert self._start_time is not None, "exit called with starting the context"
+        time_elapsed = time.perf_counter() - self._start_time
+        self._total_time += time_elapsed
+        self._start_time = None
 
     @property
-    def new_name(self):
-        return self._new_name
+    def total_elapsed_time(self):
+        return self._total_time
+
+    def log_elapsed_time(self, context: str):
+        logger.info("{:s}: {:0.4f} sec".format(context, self.total_elapsed_time))
 
-    def __str__(self):
-        return "RenamePlan(old_table={}, \
-            new_name={})".format(
-            self._old_table, self._new_name
-        )
 
-    def __hash__(self) -> int:
-        return hash((super().__hash__(), self.old_table, self.new_name))
+@dataclass
+class UDFStats:
+    def __init__(self) -> None:
+        self.num_calls: int = 0
+        self.timer: Timer = Timer()
+        self.prev_cost: float = 0.0
+        self.cache_misses: int = 0
```

### Comparing `evadb-0.2.6/eva/plan_nodes/sample_plan.py` & `evadb-0.2.7/evadb/plan_nodes/seq_scan_plan.py`

 * *Files 26% similar despite different names*

```diff
@@ -8,36 +8,49 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from typing import List
 
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.plan_nodes.abstract_scan_plan import AbstractScan
+from evadb.plan_nodes.types import PlanOprType
 
-class SamplePlan(AbstractPlan):
+
+class SeqScanPlan(AbstractScan):
     """
-    This plan is used for storing information required for sample
+    This plan is used for storing information required for sequential scan
     operations.
 
     Arguments:
-        sample_freq: ConstantValueExpression
-            A ConstantValueExpression which is the count of the
-            gap between frames sampled.
+        columns: List[AbstractExpression]
+            list of column names string in the plan
+        predicate: AbstractExpression
+            An expression used for filtering
     """
 
-    def __init__(self, sample_freq: ConstantValueExpression):
-        self._sample_freq = sample_freq
-        super().__init__(PlanOprType.SAMPLE)
+    def __init__(
+        self,
+        predicate: AbstractExpression,
+        columns: List[AbstractExpression],
+        alias: str = None,
+    ):
+        self._columns = columns
+        self.alias = alias
+        super().__init__(PlanOprType.SEQUENTIAL_SCAN, predicate)
 
     @property
-    def sample_freq(self):
-        return self._sample_freq
+    def columns(self):
+        return self._columns
 
     def __str__(self):
-        return "SamplePlan(sample_freq={})".format(self._sample_freq)
+        return "SeqScanPlan(predicate={}, \
+            columns={}, \
+            alias={})".format(
+            self._predicate, self._columns, self.alias
+        )
 
     def __hash__(self) -> int:
-        return hash((super().__hash__(), self.sample_freq))
+        return hash((super().__hash__(), tuple(self.columns or []), self.alias))
```

### Comparing `evadb-0.2.6/eva/plan_nodes/storage_plan.py` & `evadb-0.2.7/evadb/plan_nodes/storage_plan.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,19 +8,19 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.expression.abstract_expression import AbstractExpression
-from eva.parser.table_ref import TableRef
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.parser.table_ref import TableRef
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class StoragePlan(AbstractPlan):
     """
     This is the plan used for retrieving the frames from the storage and
     and returning to the higher levels.
```

### Comparing `evadb-0.2.6/eva/plan_nodes/types.py` & `evadb-0.2.7/evadb/plan_nodes/types.py`

 * *Files 6% similar despite different names*

```diff
@@ -21,15 +21,15 @@
     SEQUENTIAL_SCAN = auto()
     STORAGE_PLAN = auto()
     PP_FILTER = auto()
     INSERT = auto()
     DELETE = auto()
     CREATE = auto()
     RENAME = auto()
-    DROP = auto()
+    DROP_OBJECT = auto()
     CREATE_UDF = auto()
     LOAD_DATA = auto()
     UNION = auto()
     GROUP_BY = auto()
     ORDER_BY = auto()
     LIMIT = auto()
     SAMPLE = auto()
@@ -39,13 +39,12 @@
     LATERAL_JOIN = auto()
     HASH_BUILD = auto()
     CREATE_MATERIALIZED_VIEW = auto()
     EXCHANGE = auto()
     PREDICATE_FILTER = auto()
     PROJECT = auto()
     SHOW_INFO = auto()
-    DROP_UDF = auto()
     EXPLAIN = auto()
     CREATE_INDEX = auto()
     APPLY_AND_MERGE = auto()
     VECTOR_INDEX_SCAN = auto()
     # add other types
```

### Comparing `evadb-0.2.6/eva/plan_nodes/vector_index_scan_plan.py` & `evadb-0.2.7/evadb/plan_nodes/vector_index_scan_plan.py`

 * *Files 3% similar despite different names*

```diff
@@ -8,19 +8,19 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.catalog.catalog_type import VectorStoreType
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.function_expression import FunctionExpression
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.types import PlanOprType
+from evadb.catalog.catalog_type import VectorStoreType
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.function_expression import FunctionExpression
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.types import PlanOprType
 
 
 class VectorIndexScanPlan(AbstractPlan):
     """
     The plan first evaluates the `search_query_expr` expression and searches the output
     in the vector index. The plan finally projects `limit_count` number of results.
```

### Comparing `evadb-0.2.6/eva/readers/__init__.py` & `evadb-0.2.7/evadb/parser/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/readers/abstract_reader.py` & `evadb-0.2.7/evadb/readers/abstract_reader.py`

 * *Files 10% similar despite different names*

```diff
@@ -14,17 +14,17 @@
 # limitations under the License.
 from abc import ABCMeta, abstractmethod
 from pathlib import Path
 from typing import Dict, Iterator
 
 import pandas as pd
 
-from eva.models.storage.batch import Batch
-from eva.utils.errors import DatasetFileNotFoundError
-from eva.utils.generic_utils import get_size
+from evadb.models.storage.batch import Batch
+from evadb.utils.errors import DatasetFileNotFoundError
+from evadb.utils.generic_utils import get_size
 
 
 class AbstractReader(metaclass=ABCMeta):
     """
     Abstract class for defining data reader. All other media readers use this
     abstract class. Media readers are expected to return Batch
     in an iterative manner.
```

### Comparing `evadb-0.2.6/eva/readers/csv_reader.py` & `evadb-0.2.7/evadb/readers/csv_reader.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,17 +13,17 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Dict, Iterator
 
 import numpy as np
 import pandas as pd
 
-from eva.catalog.sql_config import IDENTIFIER_COLUMN
-from eva.readers.abstract_reader import AbstractReader
-from eva.utils.logging_manager import logger
+from evadb.catalog.sql_config import IDENTIFIER_COLUMN
+from evadb.readers.abstract_reader import AbstractReader
+from evadb.utils.logging_manager import logger
 
 
 class CSVReader(AbstractReader):
     def __init__(self, *args, column_list, **kwargs):
         """
         Reads a CSV file and yields frame data.
         Args:
```

### Comparing `evadb-0.2.6/eva/readers/decord_reader.py` & `evadb-0.2.7/evadb/readers/decord_reader.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,20 +12,20 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Dict, Iterator
 
 import numpy as np
 
-from eva.catalog.catalog_type import VideoColumnName
-from eva.constants import AUDIORATE, IFRAMES
-from eva.expression.abstract_expression import AbstractExpression
-from eva.expression.expression_utils import extract_range_list_from_predicate
-from eva.readers.abstract_reader import AbstractReader
-from eva.utils.logging_manager import logger
+from evadb.catalog.catalog_type import VideoColumnName
+from evadb.constants import AUDIORATE, IFRAMES
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.expression.expression_utils import extract_range_list_from_predicate
+from evadb.readers.abstract_reader import AbstractReader
+from evadb.utils.logging_manager import logger
 
 # Lazy import to avoid torch init failures
 _decord = None
 
 
 def _lazy_import_decord():
     global _decord
```

### Comparing `evadb-0.2.6/eva/readers/document/__init__.py` & `evadb-0.2.7/evadb/readers/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/readers/document/document_reader.py` & `evadb-0.2.7/evadb/readers/document/document_reader.py`

 * *Files 10% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 from typing import Dict, Iterator
 
-from eva.readers.abstract_reader import AbstractReader
-from eva.readers.document.registry import _lazy_import_loader
+from evadb.readers.abstract_reader import AbstractReader
+from evadb.readers.document.registry import _lazy_import_loader
 
 
 class DocumentReader(AbstractReader):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self._LOADER_MAPPING = _lazy_import_loader()
```

### Comparing `evadb-0.2.6/eva/readers/document/registry.py` & `evadb-0.2.7/evadb/readers/document/registry.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/readers/image/__init__.py` & `evadb-0.2.7/evadb/readers/document/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/readers/image/opencv_image_reader.py` & `evadb-0.2.7/evadb/readers/image/opencv_image_reader.py`

 * *Files 13% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Dict, Iterator
 
 import cv2
 
-from eva.readers.abstract_reader import AbstractReader
+from evadb.readers.abstract_reader import AbstractReader
 
 
 class CVImageReader(AbstractReader):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
     def _read(self) -> Iterator[Dict]:
```

### Comparing `evadb-0.2.6/eva/readers/pdf_reader.py` & `evadb-0.2.7/evadb/readers/pdf_reader.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Dict, Iterator
 
-from eva.readers.abstract_reader import AbstractReader
+from evadb.readers.abstract_reader import AbstractReader
 
 
 class PDFReader(AbstractReader):
     def __init__(self, *args, **kwargs):
         """
         Reads a PDF file and yields frame data.
         Args:
```

### Comparing `evadb-0.2.6/eva/server/__init__.py` & `evadb-0.2.7/test/udfs/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # coding=utf-8
-# Copyright 2018-2023 EVA
+# Copyright 2018-2022 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-"""sets up a local-hosted server"""
+"""user defined functions operating on ndarrays"""
```

### Comparing `evadb-0.2.6/eva/server/command_handler.py` & `evadb-0.2.7/evadb/server/command_handler.py`

 * *Files 10% similar despite different names*

```diff
@@ -11,68 +11,73 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import asyncio
 from typing import Iterator, Optional
 
-from eva.binder.statement_binder import StatementBinder
-from eva.binder.statement_binder_context import StatementBinderContext
-from eva.executor.plan_executor import PlanExecutor
-from eva.models.server.response import Response, ResponseStatus
-from eva.models.storage.batch import Batch
-from eva.optimizer.plan_generator import PlanGenerator
-from eva.optimizer.statement_to_opr_converter import StatementToPlanConverter
-from eva.parser.parser import Parser
-from eva.utils.logging_manager import logger
-from eva.utils.stats import Timer
-
-
-def execute_query(query, report_time: bool = False, **kwargs) -> Iterator[Batch]:
+from evadb.binder.statement_binder import StatementBinder
+from evadb.binder.statement_binder_context import StatementBinderContext
+from evadb.database import EVADatabase
+from evadb.executor.plan_executor import PlanExecutor
+from evadb.models.server.response import Response, ResponseStatus
+from evadb.models.storage.batch import Batch
+from evadb.optimizer.plan_generator import PlanGenerator
+from evadb.optimizer.statement_to_opr_converter import StatementToPlanConverter
+from evadb.parser.parser import Parser
+from evadb.utils.logging_manager import logger
+from evadb.utils.stats import Timer
+
+
+def execute_query(
+    evadb: EVADatabase, query, report_time: bool = False, **kwargs
+) -> Iterator[Batch]:
     """
     Execute the query and return a result generator.
     """
     query_compile_time = Timer()
-    plan_generator = kwargs.pop("plan_generator", PlanGenerator())
+    plan_generator = kwargs.pop("plan_generator", PlanGenerator(evadb))
     with query_compile_time:
         stmt = Parser().parse(query)[0]
-        StatementBinder(StatementBinderContext()).bind(stmt)
+        StatementBinder(StatementBinderContext(evadb.catalog)).bind(stmt)
         l_plan = StatementToPlanConverter().visit(stmt)
         p_plan = asyncio.run(plan_generator.build(l_plan))
-        output = PlanExecutor(p_plan).execute_plan()
+        output = PlanExecutor(evadb, p_plan).execute_plan()
 
     query_compile_time.log_elapsed_time("Query Compile Time")
     return output
 
 
-def execute_query_fetch_all(query, **kwargs) -> Optional[Batch]:
+def execute_query_fetch_all(
+    evadb: EVADatabase, query=None, **kwargs
+) -> Optional[Batch]:
     """
     Execute the query and fetch all results into one Batch object.
     """
-    output = execute_query(query, report_time=True, **kwargs)
+    output = execute_query(evadb, query, report_time=True, **kwargs)
     if output:
         batch_list = list(output)
         return Batch.concat(batch_list, copy=False)
 
 
-async def handle_request(client_writer, request_message):
+async def handle_request(evadb: EVADatabase, client_writer, request_message):
     """
     Reads a request from a client and processes it
 
     If user inputs 'quit' stops the event loop
     otherwise just echoes user input
     """
     logger.debug("Receive request: --|" + str(request_message) + "|--")
 
     error = False
     error_msg = None
     query_runtime = Timer()
     with query_runtime:
         try:
-            output_batch = execute_query_fetch_all(request_message)
+            output_batch = execute_query_fetch_all(evadb, request_message)
         except Exception as e:
             error_msg = str(e)
             logger.exception(error_msg)
             error = True
 
     if not error:
         response = Response(
```

### Comparing `evadb-0.2.6/eva/server/interpreter.py` & `evadb-0.2.7/evadb/server/interpreter.py`

 * *Files 13% similar despite different names*

```diff
@@ -15,16 +15,16 @@
 import asyncio
 import os
 import sys
 from asyncio import StreamReader, StreamWriter
 from collections import deque
 from typing import Dict
 
-from eva.interfaces.relational.db import EVAConnection
-from eva.utils.logging_manager import logger
+from evadb.interfaces.relational.db import EVADBConnection
+from evadb.utils.logging_manager import logger
 
 # version.py defines the VERSION and VERSION_SHORT variables
 VERSION_DICT: Dict[str, str] = {}
 
 current_file_dir = os.path.dirname(__file__)
 current_file_parent_dir = os.path.join(current_file_dir, os.pardir)
 version_file_path = os.path.join(current_file_parent_dir, "version.py")
@@ -57,15 +57,19 @@
 ):
     VERSION = VERSION_DICT["VERSION"]
     intro = f"eva (v{VERSION})\nType 'EXIT;' to exit the client \n"
     print(intro, flush=True)
 
     prompt = "eva=#"
 
-    connection = EVAConnection(server_reader, writer)
+    # The EVADatabase object is not passed from the command line client.
+    # The concept is to always send a SQL query to the server, which is responsible for
+    # executing it and returning the results. However, in the Pythonic interface, we
+    # adopt a serverless approach and don't rely on the EVADatabase object.
+    connection = EVADBConnection(None, server_reader, writer)
     cursor = connection.cursor()
 
     while True:
         sys.stdout.write(prompt)
         sys.stdout.flush()
         query = await read_line(stdin_reader)
         logger.debug("Query: --|" + query + "|--")
```

### Comparing `evadb-0.2.6/eva/server/server.py` & `evadb-0.2.7/evadb/server/server.py`

 * *Files 16% similar despite different names*

```diff
@@ -12,38 +12,48 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import asyncio
 import string
 from asyncio import StreamReader, StreamWriter
 
-from eva.utils.logging_manager import logger
+from evadb.database import init_eva_db_instance
+from evadb.udfs.udf_bootstrap_queries import init_builtin_udfs
+from evadb.utils.logging_manager import logger
 
 
 class EvaServer:
     """
     Receives messages and offloads them to another task for processing them.
     """
 
     def __init__(self):
         self._server = None
         self._clients = {}  # client -> (reader, writer)
+        self._evadb = None
 
-    async def start_eva_server(self, host: string, port: int):
+    async def start_eva_server(
+        self, db_dir: str, host: string, port: int, custom_db_uri: str = None
+    ):
         """
         Start the server
         Server objects are asynchronous context managers.
 
         hostname: hostname of the server
         port: port of the server
         """
-        logger.warn(f"EVA server started at host {host} and port {port}")
+        print(f"EVA server started at host {host} and port {port}")
+        self._evadb = init_eva_db_instance(db_dir, host, port, custom_db_uri)
 
         self._server = await asyncio.start_server(self.accept_client, host, port)
 
+        # load built-in udfs
+        mode = self._evadb.config.get_value("core", "mode")
+        init_builtin_udfs(self._evadb, mode=mode)
+
         async with self._server:
             await self._server.serve_forever()
 
         logger.warn("EVA server stopped")
 
     async def stop_eva_server(self):
         logger.warn("EVA server stopped")
@@ -77,13 +87,13 @@
                 logger.debug("Received --|%s|--", message)
 
                 if message.upper() in ["EXIT;", "QUIT;"]:
                     logger.info("Close client")
                     return
 
                 logger.debug("Handle request")
-                from eva.server.command_handler import handle_request
+                from evadb.server.command_handler import handle_request
 
-                asyncio.create_task(handle_request(client_writer, message))
+                asyncio.create_task(handle_request(self._evadb, client_writer, message))
 
         except Exception as e:
             logger.critical("Error reading from client.", exc_info=e)
```

### Comparing `evadb-0.2.6/eva/storage/__init__.py` & `evadb-0.2.7/evadb/storage/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/storage/abstract_media_storage_engine.py` & `evadb-0.2.7/evadb/storage/abstract_media_storage_engine.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,33 +15,34 @@
 import os
 import re
 import shutil
 from pathlib import Path
 
 import pandas as pd
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.models.storage.batch import Batch
-from eva.parser.table_ref import TableInfo
-from eva.storage.abstract_storage_engine import AbstractStorageEngine
-from eva.storage.sqlite_storage_engine import SQLStorageEngine
-from eva.utils.logging_manager import logger
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.database import EVADatabase
+from evadb.models.storage.batch import Batch
+from evadb.parser.table_ref import TableInfo
+from evadb.storage.abstract_storage_engine import AbstractStorageEngine
+from evadb.storage.sqlite_storage_engine import SQLStorageEngine
+from evadb.utils.logging_manager import logger
 
 
 class AbstractMediaStorageEngine(AbstractStorageEngine):
-    def __init__(self):
-        self._rdb_handler: SQLStorageEngine = SQLStorageEngine()
+    def __init__(self, db: EVADatabase):
+        super().__init__(db)
+        self._rdb_handler: SQLStorageEngine = SQLStorageEngine(db)
 
     def _get_metadata_table(self, table: TableCatalogEntry):
-        return CatalogManager().get_multimedia_metadata_table_catalog_entry(table)
+        return self.db.catalog().get_multimedia_metadata_table_catalog_entry(table)
 
     def _create_metadata_table(self, table: TableCatalogEntry):
         return (
-            CatalogManager().create_and_insert_multimedia_metadata_table_catalog_entry(
+            self.db.catalog().create_and_insert_multimedia_metadata_table_catalog_entry(
                 table
             )
         )
 
     def _xform_file_url_to_file_name(self, file_url: Path) -> str:
         # Convert media_path to file name. This is done to support duplicate media_names with
         # different complete paths. Without conversion, we cannot copy files with same name but
@@ -81,15 +82,15 @@
     def drop(self, table: TableCatalogEntry):
         try:
             dir_path = Path(table.file_url)
             shutil.rmtree(str(dir_path))
             metadata_table = self._get_metadata_table(table)
             self._rdb_handler.drop(metadata_table)
             # remove the metadata table from the catalog
-            CatalogManager().delete_table_catalog_entry(metadata_table)
+            self.db.catalog().delete_table_catalog_entry(metadata_table)
         except Exception as e:
             err_msg = f"Failed to drop the image table {e}"
             logger.exception(err_msg)
             raise Exception(err_msg)
 
     def delete(self, table: TableCatalogEntry, rows: Batch):
         try:
@@ -139,10 +140,10 @@
             logger.exception(str(e))
             raise RuntimeError(str(e))
         else:
             return True
 
     def rename(self, old_table: TableCatalogEntry, new_name: TableInfo):
         try:
-            CatalogManager().rename_table_catalog_entry(old_table, new_name)
+            self.db.catalog().rename_table_catalog_entry(old_table, new_name)
         except Exception as e:
             raise Exception(f"Failed to rename table {new_name} with exception {e}")
```

### Comparing `evadb-0.2.6/eva/storage/abstract_storage_engine.py` & `evadb-0.2.7/evadb/storage/pdf_storage_engine.py`

 * *Files 23% similar despite different names*

```diff
@@ -8,62 +8,32 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from abc import ABCMeta, abstractmethod
+from pathlib import Path
 from typing import Iterator
 
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.expression.abstract_expression import AbstractExpression
-from eva.models.storage.batch import Batch
-
-
-class AbstractStorageEngine(metaclass=ABCMeta):
-    """
-    Abstract class for defining storage engine. Storage engine is responsible
-    for handling data storage and retrieval tasks.
-    This contains a minimal set of APIs that each engine should implement
-
-    """
-
-    @abstractmethod
-    def create(self, table: TableCatalogEntry):
-        """Interface that implements all the necessary task required for
-            creating the basic unit of storage(table or dataframe)
-
-        Attributes:
-            table: storage unit to be created
-        """
-
-    @abstractmethod
-    def write(self, table: TableCatalogEntry, rows: Batch):
-        """Interface responsible for inserting the rows into the required
-        table. Internally calls the _open function and does the required
-        task.
-
-        Attributes:
-            table: storage unit to be created
-            rows : rows data to be written
-        """
-
-    @abstractmethod
-    def read(
-        self,
-        table: TableCatalogEntry,
-        batch_mem_size: int = 30000000,
-        predicate: AbstractExpression = None,
-    ) -> Iterator[Batch]:
-        """Interface responsible for yielding row/rows to the client.
-        This should be implemented as an iterator over of table. Helpful
-        while doing full table scan. `pos` parameter is used if user wants
-        to fetch specific rows.
-
-        Attributes:
-            table: storage unit to be read
-            pos: row position to be returned
-
-        Returns:
-            Batch: an iterator of the batch read
-        """
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.database import EVADatabase
+from evadb.models.storage.batch import Batch
+from evadb.readers.pdf_reader import PDFReader
+from evadb.storage.abstract_media_storage_engine import AbstractMediaStorageEngine
+
+
+class PDFStorageEngine(AbstractMediaStorageEngine):
+    def __init__(self, db: EVADatabase):
+        super().__init__(db)
+
+    def read(self, table: TableCatalogEntry) -> Iterator[Batch]:
+        for image_files in self._rdb_handler.read(self._get_metadata_table(table), 12):
+            for _, (row_id, file_name) in image_files.iterrows():
+                system_file_name = self._xform_file_url_to_file_name(file_name)
+                image_file = Path(table.file_url) / system_file_name
+                # setting batch_mem_size = 1, we need fix it
+                reader = PDFReader(str(image_file), batch_mem_size=1)
+                for batch in reader.read():
+                    batch.frames[table.columns[0].name] = row_id
+                    batch.frames[table.columns[1].name] = str(file_name)
+                    yield batch
```

### Comparing `evadb-0.2.6/eva/storage/document_storage_engine.py` & `evadb-0.2.7/evadb/storage/document_storage_engine.py`

 * *Files 13% similar despite different names*

```diff
@@ -11,23 +11,24 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 from typing import Iterator
 
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.models.storage.batch import Batch
-from eva.readers.document.document_reader import DocumentReader
-from eva.storage.abstract_media_storage_engine import AbstractMediaStorageEngine
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.database import EVADatabase
+from evadb.models.storage.batch import Batch
+from evadb.readers.document.document_reader import DocumentReader
+from evadb.storage.abstract_media_storage_engine import AbstractMediaStorageEngine
 
 
 class DocumentStorageEngine(AbstractMediaStorageEngine):
-    def __init__(self):
-        super().__init__()
+    def __init__(self, db: EVADatabase):
+        super().__init__(db)
 
     def read(self, table: TableCatalogEntry) -> Iterator[Batch]:
         for doc_files in self._rdb_handler.read(self._get_metadata_table(table), 12):
             for _, (row_id, file_name) in doc_files.iterrows():
                 system_file_name = self._xform_file_url_to_file_name(file_name)
                 doc_file = Path(table.file_url) / system_file_name
                 # setting batch_mem_size = 1, we need fix it
```

### Comparing `evadb-0.2.6/eva/storage/image_storage_engine.py` & `evadb-0.2.7/evadb/storage/image_storage_engine.py`

 * *Files 6% similar despite different names*

```diff
@@ -11,23 +11,24 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 from typing import Iterator
 
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.models.storage.batch import Batch
-from eva.readers.image.opencv_image_reader import CVImageReader
-from eva.storage.abstract_media_storage_engine import AbstractMediaStorageEngine
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.database import EVADatabase
+from evadb.models.storage.batch import Batch
+from evadb.readers.image.opencv_image_reader import CVImageReader
+from evadb.storage.abstract_media_storage_engine import AbstractMediaStorageEngine
 
 
 class ImageStorageEngine(AbstractMediaStorageEngine):
-    def __init__(self):
-        super().__init__()
+    def __init__(self, db: EVADatabase):
+        super().__init__(db)
 
     def read(self, table: TableCatalogEntry) -> Iterator[Batch]:
         for image_files in self._rdb_handler.read(self._get_metadata_table(table), 12):
             for _, (row_id, file_name) in image_files.iterrows():
                 system_file_name = self._xform_file_url_to_file_name(file_name)
                 image_file = Path(table.file_url) / system_file_name
                 # setting batch_mem_size = 1, we need fix it
```

### Comparing `evadb-0.2.6/eva/storage/pdf_storage_engine.py` & `evadb-0.2.7/evadb/udfs/ndarray/similarity.py`

 * *Files 27% similar despite different names*

```diff
@@ -8,31 +8,48 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from pathlib import Path
-from typing import Iterator
+import faiss
+import pandas as pd
 
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.models.storage.batch import Batch
-from eva.readers.pdf_reader import PDFReader
-from eva.storage.abstract_media_storage_engine import AbstractMediaStorageEngine
-
-
-class PDFStorageEngine(AbstractMediaStorageEngine):
-    def __init__(self):
-        super().__init__()
-
-    def read(self, table: TableCatalogEntry) -> Iterator[Batch]:
-        for image_files in self._rdb_handler.read(self._get_metadata_table(table), 12):
-            for _, (row_id, file_name) in image_files.iterrows():
-                system_file_name = self._xform_file_url_to_file_name(file_name)
-                image_file = Path(table.file_url) / system_file_name
-                # setting batch_mem_size = 1, we need fix it
-                reader = PDFReader(str(image_file), batch_mem_size=1)
-                for batch in reader.read():
-                    batch.frames[table.columns[0].name] = row_id
-                    batch.frames[table.columns[1].name] = str(file_name)
-                    yield batch
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+
+
+class Similarity(AbstractUDF):
+    def _get_distance(self, numpy_distance):
+        return numpy_distance[0][0]
+
+    def setup(self):
+        pass
+
+    @property
+    def name(self):
+        return "Similarity"
+
+    def forward(self, df: pd.DataFrame) -> pd.DataFrame:
+        """
+        Get similarity score between two feature vectors: 1. feature vector of an opened image;
+        and 2. feature vector from base table.
+        """
+
+        def _similarity(row: pd.Series) -> float:
+            open_feat_np, base_feat_np = (
+                row.iloc[0],
+                row.iloc[1],
+            )
+
+            # TODO: currently system takes care of feature vector shape
+            # transformation. Improve this later on.
+            # Transform to 2D.
+            open_feat_np = open_feat_np.reshape(1, -1)
+            base_feat_np = base_feat_np.reshape(1, -1)
+            distance_np = faiss.pairwise_distances(open_feat_np, base_feat_np)
+
+            return self._get_distance(distance_np)
+
+        ret = pd.DataFrame()
+        ret["distance"] = df.apply(_similarity, axis=1)
+        return ret
```

### Comparing `evadb-0.2.6/eva/storage/sqlite_storage_engine.py` & `evadb-0.2.7/evadb/storage/sqlite_storage_engine.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,37 +15,39 @@
 from typing import Iterator, List
 
 import numpy as np
 import pandas as pd
 from sqlalchemy import Table, inspect
 from sqlalchemy.sql.expression import ColumnElement
 
-from eva.catalog.catalog_type import ColumnType
-from eva.catalog.models.base_model import BaseModel
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.catalog.schema_utils import SchemaUtils
-from eva.catalog.sql_config import IDENTIFIER_COLUMN, SQLConfig
-from eva.models.storage.batch import Batch
-from eva.parser.table_ref import TableInfo
-from eva.storage.abstract_storage_engine import AbstractStorageEngine
-from eva.utils.generic_utils import PickleSerializer, get_size
-from eva.utils.logging_manager import logger
+from evadb.catalog.catalog_type import ColumnType
+from evadb.catalog.models.base_model import BaseModel
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.catalog.schema_utils import SchemaUtils
+from evadb.catalog.sql_config import IDENTIFIER_COLUMN
+from evadb.database import EVADatabase
+from evadb.models.storage.batch import Batch
+from evadb.parser.table_ref import TableInfo
+from evadb.storage.abstract_storage_engine import AbstractStorageEngine
+from evadb.utils.generic_utils import PickleSerializer, get_size
+from evadb.utils.logging_manager import logger
 
 # Leveraging Dynamic schema in SQLAlchemy
 # https://sparrigan.github.io/sql/sqla/2016/01/03/dynamic-tables.html
 
 
 class SQLStorageEngine(AbstractStorageEngine):
-    def __init__(self):
+    def __init__(self, db: EVADatabase):
         """
         Grab the existing sql session
         """
-        self._sql_session = SQLConfig().session
-        self._sql_engine = SQLConfig().engine
+        super().__init__(db)
+        self._sql_session = db.catalog().sql_config.session
+        self._sql_engine = db.catalog().sql_config.engine
         self._serializer = PickleSerializer
 
     def _dict_to_sql_row(self, dict_row: dict, columns: List[ColumnCatalogEntry]):
         # Serialize numpy data
         for col in columns:
             if col.type == ColumnType.NDARRAY:
                 dict_row[col.name] = self._serializer.serialize(dict_row[col.name])
@@ -90,33 +92,43 @@
         """
         attr_dict = {"__tablename__": table.name}
 
         # During table creation, assume row_id is automatically handled by
         # the sqlalchemy engine.
         table_columns = [col for col in table.columns if col.name != IDENTIFIER_COLUMN]
         sqlalchemy_schema = SchemaUtils.xform_to_sqlalchemy_schema(table_columns)
-
         attr_dict.update(sqlalchemy_schema)
+
+        insp = inspect(self._sql_engine)
+        if insp.has_table(table.name):
+            logger.warning("Trying to create an exsiting table {table.name}")
+            return BaseModel.metadata.tables[table.name]
+
         # dynamic schema generation
         # https://sparrigan.github.io/sql/sqla/2016/01/03/dynamic-tables.html
-        new_table = type("__placeholder_class_name__", (BaseModel,), attr_dict)()
+        new_table = type(
+            f"__placeholder_class_name__{table.name}", (BaseModel,), attr_dict
+        )()
         table = BaseModel.metadata.tables[table.name]
-        if not table.exists():
+
+        if not insp.has_table(table.name):
             BaseModel.metadata.tables[table.name].create(self._sql_engine)
         self._sql_session.commit()
         return new_table
 
     def drop(self, table: TableCatalogEntry):
         try:
             table_to_remove = self._try_loading_table_via_reflection(table.name)
-            table_to_remove.drop()
-            # In-memory metadata does not automatically sync with the database
-            # therefore manually removing the table from the in-memory metadata
-            # https://github.com/sqlalchemy/sqlalchemy/issues/5112
-            BaseModel.metadata.remove(table_to_remove)
+            insp = inspect(self._sql_engine)
+            if insp.has_table(table_to_remove.name):
+                table_to_remove.drop(self._sql_engine)
+                # In-memory metadata does not automatically sync with the database
+                # therefore manually removing the table from the in-memory metadata
+                # https://github.com/sqlalchemy/sqlalchemy/issues/5112
+                BaseModel.metadata.remove(table_to_remove)
             self._sql_session.commit()
         except Exception as e:
             err_msg = f"Failed to drop the table {table.name} with Exception {str(e)}"
             logger.exception(err_msg)
             raise Exception(err_msg)
 
     def write(self, table: TableCatalogEntry, rows: Batch):
@@ -139,15 +151,15 @@
                 col for col in table.columns if col.name != IDENTIFIER_COLUMN
             ]
 
             # Todo: validate the data type before inserting into the table
             for record in rows.frames.values:
                 row_data = {col: record[idx] for idx, col in enumerate(columns)}
                 data.append(self._dict_to_sql_row(row_data, table_columns))
-            self._sql_engine.execute(table_to_update.insert(), data)
+            self._sql_session.execute(table_to_update.insert(), data)
             self._sql_session.commit()
         except Exception as e:
             err_msg = f"Failed to update the table {table.name} with exception {str(e)}"
             logger.exception(err_msg)
             raise Exception(err_msg)
 
     def read(
```

### Comparing `evadb-0.2.6/eva/storage/video_storage_engine.py` & `evadb-0.2.7/evadb/storage/video_storage_engine.py`

 * *Files 6% similar despite different names*

```diff
@@ -12,24 +12,25 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import sys
 from pathlib import Path
 from typing import Iterator
 
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.expression.abstract_expression import AbstractExpression
-from eva.models.storage.batch import Batch
-from eva.readers.decord_reader import DecordReader
-from eva.storage.abstract_media_storage_engine import AbstractMediaStorageEngine
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.database import EVADatabase
+from evadb.expression.abstract_expression import AbstractExpression
+from evadb.models.storage.batch import Batch
+from evadb.readers.decord_reader import DecordReader
+from evadb.storage.abstract_media_storage_engine import AbstractMediaStorageEngine
 
 
 class DecordStorageEngine(AbstractMediaStorageEngine):
-    def __init__(self) -> None:
-        super().__init__()
+    def __init__(self, db: EVADatabase):
+        super().__init__(db)
 
     def read(
         self,
         table: TableCatalogEntry,
         batch_mem_size: int,
         predicate: AbstractExpression = None,
         sampling_rate: int = None,
```

### Comparing `evadb-0.2.6/eva/third_party/__init__.py` & `evadb-0.2.7/evadb/third_party/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/third_party/huggingface/__init__.py` & `evadb-0.2.7/evadb/third_party/huggingface/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/third_party/huggingface/binder.py` & `evadb-0.2.7/evadb/third_party/huggingface/binder.py`

 * *Files 10% similar despite different names*

```diff
@@ -8,17 +8,17 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.catalog.catalog_utils import get_metadata_entry_or_val
-from eva.catalog.models.udf_catalog import UdfCatalogEntry
-from eva.third_party.huggingface.create import MODEL_FOR_TASK
+from evadb.catalog.catalog_utils import get_metadata_entry_or_val
+from evadb.catalog.models.udf_catalog import UdfCatalogEntry
+from evadb.third_party.huggingface.create import MODEL_FOR_TASK
 
 
 def assign_hf_udf(udf_obj: UdfCatalogEntry):
     """
     Assigns the correct HF Model to the UDF. The model assigned depends on
     the task type for the UDF. This is done so that we can
     process the input correctly before passing it to the HF model.
```

### Comparing `evadb-0.2.6/eva/third_party/huggingface/create.py` & `evadb-0.2.7/evadb/third_party/huggingface/create.py`

 * *Files 10% similar despite different names*

```diff
@@ -14,18 +14,18 @@
 # limitations under the License.
 from typing import Dict, List, Type, Union
 
 import numpy as np
 from PIL import Image, ImageDraw
 from transformers import pipeline
 
-from eva.catalog.catalog_type import ColumnType, NdArrayType
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.catalog.models.udf_metadata_catalog import UdfMetadataCatalogEntry
-from eva.third_party.huggingface.model import (
+from evadb.catalog.catalog_type import ColumnType, NdArrayType
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.catalog.models.udf_metadata_catalog import UdfMetadataCatalogEntry
+from evadb.third_party.huggingface.model import (
     ASRHFModel,
     AudioHFModel,
     HFInputTypes,
     ImageHFModel,
     TextHFModel,
 )
```

### Comparing `evadb-0.2.6/eva/third_party/huggingface/model.py` & `evadb-0.2.7/evadb/third_party/huggingface/model.py`

 * *Files 5% similar despite different names*

```diff
@@ -14,16 +14,16 @@
 # limitations under the License.
 from typing import Any
 
 import decord
 import numpy as np
 from PIL import Image
 
-from eva.udfs.abstract.hf_abstract_udf import AbstractHFUdf
-from eva.utils.generic_utils import EVAEnum
+from evadb.udfs.abstract.hf_abstract_udf import AbstractHFUdf
+from evadb.utils.generic_utils import EVAEnum
 
 
 class HFInputTypes(EVAEnum):
     TEXT  # noqa: F821
     IMAGE  # noqa: F821
     AUDIO  # noqa: F821
     VIDEO  # noqa: F821
```

### Comparing `evadb-0.2.6/eva/third_party/vector_stores/__init__.py` & `evadb-0.2.7/evadb/third_party/vector_stores/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/third_party/vector_stores/faiss.py` & `evadb-0.2.7/evadb/third_party/vector_stores/faiss.py`

 * *Files 1% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from pathlib import Path
 from typing import List
 
 import numpy as np
 
-from eva.third_party.vector_stores.types import (
+from evadb.third_party.vector_stores.types import (
     FeaturePayload,
     VectorIndexQuery,
     VectorIndexQueryResult,
     VectorStore,
 )
 
 _faiss = None
```

### Comparing `evadb-0.2.6/eva/third_party/vector_stores/qdrant.py` & `evadb-0.2.7/evadb/third_party/vector_stores/qdrant.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
-from eva.third_party.vector_stores.types import (
+from evadb.third_party.vector_stores.types import (
     FeaturePayload,
     VectorIndexQuery,
     VectorIndexQueryResult,
     VectorStore,
 )
 
 _qdrant_client_instance = None
```

### Comparing `evadb-0.2.6/eva/third_party/vector_stores/types.py` & `evadb-0.2.7/evadb/third_party/vector_stores/types.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/third_party/vector_stores/utils.py` & `evadb-0.2.7/evadb/third_party/vector_stores/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,32 +8,32 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from eva.catalog.catalog_type import VectorStoreType
-from eva.third_party.vector_stores.faiss import FaissVectorStore
-from eva.third_party.vector_stores.qdrant import QdrantVectorStore
-from eva.utils.generic_utils import validate_kwargs
+from evadb.catalog.catalog_type import VectorStoreType
+from evadb.third_party.vector_stores.faiss import FaissVectorStore
+from evadb.third_party.vector_stores.qdrant import QdrantVectorStore
+from evadb.utils.generic_utils import validate_kwargs
 
 
 class VectorStoreFactory:
     @staticmethod
     def init_vector_store(
         vector_store_type: VectorStoreType, index_name: str, **kwargs
     ):
         if vector_store_type == VectorStoreType.FAISS:
-            from eva.third_party.vector_stores.faiss import required_params
+            from evadb.third_party.vector_stores.faiss import required_params
 
             validate_kwargs(kwargs, required_params, required_params)
             return FaissVectorStore(index_name, **kwargs)
 
         elif vector_store_type == VectorStoreType.QDRANT:
-            from eva.third_party.vector_stores.qdrant import required_params
+            from evadb.third_party.vector_stores.qdrant import required_params
 
             validate_kwargs(kwargs, required_params, required_params)
             return QdrantVectorStore(index_name, **kwargs)
 
         else:
             raise Exception(f"Vector store {vector_store_type} not supported")
```

### Comparing `evadb-0.2.6/eva/udfs/__init__.py` & `evadb-0.2.7/evadb/udfs/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/udfs/abstract/__init__.py` & `evadb-0.2.7/evadb/udfs/abstract/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/udfs/abstract/abstract_udf.py` & `evadb-0.2.7/evadb/udfs/ndarray/vertical_flip.py`

 * *Files 23% similar despite different names*

```diff
@@ -8,84 +8,62 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from abc import ABCMeta, abstractmethod
-from typing import List, Union
-
+import cv2
+import numpy as np
 import pandas as pd
-from numpy.typing import ArrayLike
-
-InputType = Union[pd.DataFrame, ArrayLike]
-
-
-class AbstractUDF(metaclass=ABCMeta):
-    """
-    Abstract class for UDFs. All the UDFs in EVA will inherit from this.
-
-    Load and initialize the machine learning model in the __init__.
-
-    """
-
-    def __init__(self, *args, **kwargs):
-        self.setup(*args, **kwargs)
 
-    def __call__(self, *args, **kwargs):
-        return self.forward(args[0])
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import PandasDataframe
 
-    def __str__(self):
-        return self.name
 
-    """Abstract Methods all UDFs must implement. """
-
-    @abstractmethod
-    def setup(self, *args, **kwargs) -> None:
-        """
-        Do necessary setup in here. Gets called automatically on initialization.
-        """
-        pass
-
-    @abstractmethod
-    def forward(self, frames: InputType) -> InputType:
-        """
-        Implement UDF function call by overriding this function.
-        Gets called automatically by __call__.
-        """
+class VerticalFlip(AbstractUDF):
+    @setup(cacheable=False, udf_type="cv2-transformation", batchable=True)
+    def setup(self):
         pass
 
     @property
-    @abstractmethod
-    def name(self) -> str:
-        pass
-
-
-class AbstractClassifierUDF(AbstractUDF):
-    @property
-    @abstractmethod
-    def labels(self) -> List[str]:
-        """
-        Returns:
-            List[str]: list of labels the classifier predicts
-        """
-        pass
-
-
-class AbstractTransformationUDF(AbstractUDF):
-    @abstractmethod
-    def transform(self, frames: ArrayLike) -> ArrayLike:
-        """
-        Takes as input a batch of frames and transforms them
-        by applying the frame transformation model.
-
-        Arguments:
-            frames: Input batch of frames on which prediction
-            needs to be made
-
-        Returns:
-            Transformed frames
-        """
+    def name(self):
+        return "VerticalFlip"
 
-    def __call__(self, *args, **kwargs):
-        return self.transform(*args, **kwargs)
+    @forward(
+        input_signatures=[
+            PandasDataframe(
+                columns=["data"],
+                column_types=[NdArrayType.FLOAT32],
+                column_shapes=[(None, None, 3)],
+            )
+        ],
+        output_signatures=[
+            PandasDataframe(
+                columns=["vertically_flipped_frame_array"],
+                column_types=[NdArrayType.FLOAT32],
+                column_shapes=[(None, None, 3)],
+            )
+        ],
+    )
+    def forward(self, frame: pd.DataFrame) -> pd.DataFrame:
+        """
+        Apply vertical flip to the frame
+
+         Returns:
+             ret (pd.DataFrame): The modified frame.
+        """
+
+        def verticalFlip(row: pd.Series) -> np.ndarray:
+            row = row.to_list()
+            frame = row[0]
+
+            frame = cv2.flip(frame, 0)
+            # since cv2 by default reads an image in BGR
+            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
+            return frame
+
+        ret = pd.DataFrame()
+        ret["vertically_flipped_frame_array"] = frame.apply(verticalFlip, axis=1)
+        return ret
```

### Comparing `evadb-0.2.6/eva/udfs/abstract/hf_abstract_udf.py` & `evadb-0.2.7/evadb/udfs/abstract/hf_abstract_udf.py`

 * *Files 1% similar despite different names*

```diff
@@ -13,17 +13,17 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import Any
 
 import pandas as pd
 from transformers import pipeline
 
-from eva.catalog.models.udf_catalog import UdfCatalogEntry
-from eva.udfs.abstract.abstract_udf import AbstractUDF
-from eva.udfs.gpu_compatible import GPUCompatible
+from evadb.catalog.models.udf_catalog import UdfCatalogEntry
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.gpu_compatible import GPUCompatible
 
 
 class AbstractHFUdf(AbstractUDF, GPUCompatible):
     """
     An abstract class for all HuggingFace models.
 
     This is implemented using the pipeline API from HuggingFace. pipeline is an
```

### Comparing `evadb-0.2.6/eva/udfs/abstract/pytorch_abstract_udf.py` & `evadb-0.2.7/evadb/udfs/abstract/pytorch_abstract_udf.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,20 +17,20 @@
 import pandas as pd
 import torch
 from numpy.typing import ArrayLike
 from PIL import Image
 from torch import Tensor, nn
 from torchvision.transforms import Compose, transforms
 
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.udfs.abstract.abstract_udf import (
+from evadb.configuration.configuration_manager import ConfigurationManager
+from evadb.udfs.abstract.abstract_udf import (
     AbstractClassifierUDF,
     AbstractTransformationUDF,
 )
-from eva.udfs.gpu_compatible import GPUCompatible
+from evadb.udfs.gpu_compatible import GPUCompatible
 
 
 class PytorchAbstractClassifierUDF(AbstractClassifierUDF, nn.Module, GPUCompatible):
     """
     A pytorch based classifier. Used to make sure we make maximum
     utilization of features provided by pytorch without reinventing the wheel.
     """
```

### Comparing `evadb-0.2.6/eva/udfs/abstract/tracker_abstract_udf.py` & `evadb-0.2.7/evadb/udfs/abstract/tracker_abstract_udf.py`

 * *Files 3% similar despite different names*

```diff
@@ -13,18 +13,18 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import typing
 
 import numpy
 import pandas as pd
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.udfs.abstract.abstract_udf import AbstractUDF
-from eva.udfs.decorators.decorators import forward, setup
-from eva.udfs.decorators.io_descriptors.data_types import PandasDataframe
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import PandasDataframe
 
 
 class EVATrackerAbstractUDF(AbstractUDF):
     """
     An abstract class for all EVA object trackers.
     """
```

### Comparing `evadb-0.2.6/eva/udfs/asl_action_recognition.py` & `evadb-0.2.7/evadb/udfs/asl_action_recognition.py`

 * *Files 1% similar despite different names*

```diff
@@ -27,15 +27,15 @@
 except ImportError:
     raise ImportError(
         f"torchvision>=0.14.0 is required to use video_resnet, found {torchvision.__version__}"
     )
 import torch.nn as nn
 import torchvision
 
-from eva.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
+from evadb.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
 
 
 class ASLActionRecognition(PytorchAbstractClassifierUDF):
     @property
     def name(self) -> str:
         return "ASLActionRecognition"
```

### Comparing `evadb-0.2.6/eva/udfs/chatgpt.py` & `evadb-0.2.7/evadb/udfs/chatgpt.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,19 +15,19 @@
 
 
 import os
 
 import openai
 import pandas as pd
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.udfs.abstract.abstract_udf import AbstractUDF
-from eva.udfs.decorators.decorators import forward, setup
-from eva.udfs.decorators.io_descriptors.data_types import PandasDataframe
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.configuration.configuration_manager import ConfigurationManager
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import PandasDataframe
 
 _VALID_CHAT_COMPLETION_MODEL = [
     "gpt-4",
     "gpt-4-0314",
     "gpt-4-32k",
     "gpt-4-32k-0314",
     "gpt-3.5-turbo",
@@ -43,23 +43,21 @@
     @setup(cacheable=False, udf_type="chat-completion", batchable=True)
     def setup(
         self,
         model="gpt-3.5-turbo",
         temperature: float = 0,
     ) -> None:
         # Try Configuration Manager
-        openai.api_key = ConfigurationManager().get_value(
-            "third_party", "openai_api_key"
-        )
+        openai.api_key = ConfigurationManager().get_value("third_party", "OPENAI_KEY")
         # If not found, try OS Environment Variable
         if len(openai.api_key) == 0:
-            openai.api_key = os.environ["openai_api_key"]
+            openai.api_key = os.environ.get("OPENAI_KEY", "")
         assert (
             len(openai.api_key) != 0
-        ), "Please set your OpenAI API key in eva.yml file (third_party, open_api_key)"
+        ), "Please set your OpenAI API key in evadb.yml file (third_party, open_api_key) or environment variable (OPENAI_KEY)"
 
         assert model in _VALID_CHAT_COMPLETION_MODEL, f"Unsupported ChatGPT {model}"
 
         self.model = model
         self.temperature = temperature
 
     @forward(
```

### Comparing `evadb-0.2.6/eva/udfs/decorators/__init__.py` & `evadb-0.2.7/evadb/readers/image/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/udfs/decorators/decorators.py` & `evadb-0.2.7/evadb/udfs/decorators/decorators.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 
 from typing import List
 
-from eva.udfs.decorators.io_descriptors.abstract_types import IOArgument
+from evadb.udfs.decorators.io_descriptors.abstract_types import IOArgument
 
 
 def setup(cacheable: bool = False, udf_type: str = "Abstract", batchable: bool = True):
     """decorator for the setup function. It will be used to set the cache, batching and
     udf_type parameters in the catalog
 
     Args:
```

### Comparing `evadb-0.2.6/eva/udfs/decorators/io_descriptors/__init__.py` & `evadb-0.2.7/evadb/udfs/decorators/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/udfs/decorators/io_descriptors/abstract_types.py` & `evadb-0.2.7/evadb/udfs/decorators/io_descriptors/abstract_types.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from abc import ABC, abstractmethod
 from typing import List, Tuple, Type
 
-from eva.catalog.catalog_type import ColumnType, NdArrayType
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.catalog.catalog_type import ColumnType, NdArrayType
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
 
 
 class IOArgument(ABC):
     """
     Base class for representing inputs/outputs (IO) of a UDF using decorators. This class defines methods
     that are common for all the IO arguments.
     """
```

### Comparing `evadb-0.2.6/eva/udfs/decorators/io_descriptors/data_types.py` & `evadb-0.2.7/evadb/udfs/decorators/io_descriptors/data_types.py`

 * *Files 4% similar despite different names*

```diff
@@ -10,21 +10,21 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List, Tuple, Type
 
-from eva.catalog.catalog_type import ColumnType, Dimension, NdArrayType
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.udfs.decorators.io_descriptors.abstract_types import (
+from evadb.catalog.catalog_type import ColumnType, Dimension, NdArrayType
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.udfs.decorators.io_descriptors.abstract_types import (
     IOArgument,
     IOColumnArgument,
 )
-from eva.utils.errors import UDFIODefinitionError
+from evadb.utils.errors import UDFIODefinitionError
 
 
 class NumpyArray(IOColumnArgument):
     """Descriptor data type for Numpy Array"""
 
     def __init__(
         self,
```

### Comparing `evadb-0.2.6/eva/udfs/decorators/utils.py` & `evadb-0.2.7/evadb/udfs/decorators/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,16 +10,16 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List, Type
 
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
-from eva.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
 
 
 def load_io_from_udf_decorators(
     udf: Type[AbstractUDF], is_input=False
 ) -> List[Type[UdfIOCatalogEntry]]:
     """Load the inputs/outputs from the udf decorators and return a list of UdfIOCatalogEntry objects
```

### Comparing `evadb-0.2.6/eva/udfs/emotion_detector.py` & `evadb-0.2.7/evadb/udfs/emotion_detector.py`

 * *Files 0% similar despite different names*

```diff
@@ -21,15 +21,15 @@
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from PIL import Image
 from torch import Tensor
 from torchvision import transforms
 
-from eva.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
+from evadb.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
 
 # VGG configuration
 cfg = {
     "VGG19": [
         64,
         64,
         "M",
```

### Comparing `evadb-0.2.6/eva/udfs/face_detector.py` & `evadb-0.2.7/evadb/udfs/face_detector.py`

 * *Files 3% similar despite different names*

```diff
@@ -16,17 +16,17 @@
 from typing import List
 
 import numpy as np
 import pandas as pd
 import torch
 from facenet_pytorch import MTCNN
 
-from eva.udfs.abstract.abstract_udf import AbstractClassifierUDF
-from eva.udfs.gpu_compatible import GPUCompatible
-from eva.utils.logging_manager import logger
+from evadb.udfs.abstract.abstract_udf import AbstractClassifierUDF
+from evadb.udfs.gpu_compatible import GPUCompatible
+from evadb.utils.logging_manager import logger
 
 
 class FaceDetector(AbstractClassifierUDF, GPUCompatible):
     """
     Arguments:
         threshold (float): Threshold for classifier confidence score
     """
```

### Comparing `evadb-0.2.6/eva/udfs/fastrcnn_object_detector.py` & `evadb-0.2.7/evadb/udfs/fastrcnn_object_detector.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,18 +13,21 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import List
 
 import numpy as np
 import pandas as pd
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
-from eva.udfs.decorators.decorators import forward, setup
-from eva.udfs.decorators.io_descriptors.data_types import PandasDataframe, PyTorchTensor
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import (
+    PandasDataframe,
+    PyTorchTensor,
+)
 
 try:
     from torch import Tensor
 except ImportError as e:
     raise ImportError(
         f"Failed to import with error {e}, \
         please try `pip install torch`"
```

### Comparing `evadb-0.2.6/eva/udfs/feature_extractor.py` & `evadb-0.2.7/evadb/udfs/feature_extractor.py`

 * *Files 0% similar despite different names*

```diff
@@ -16,15 +16,15 @@
 from typing import List
 
 import pandas as pd
 import torch
 from torch import Tensor
 from torchvision import models
 
-from eva.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
+from evadb.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
 
 
 class FeatureExtractor(PytorchAbstractClassifierUDF):
     """ """
 
     def setup(self):
         self.model = models.resnet50(weights="IMAGENET1K_V2", progress=False)
```

### Comparing `evadb-0.2.6/eva/udfs/gpu_compatible.py` & `evadb-0.2.7/evadb/udfs/gpu_compatible.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/udfs/mnist_image_classifier.py` & `evadb-0.2.7/evadb/udfs/mnist_image_classifier.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 import torch
 import torch.nn as nn
 import torch.utils.model_zoo as model_zoo
 from PIL import Image
 from torch import Tensor
 from torchvision.transforms import Compose, Grayscale, Normalize, ToTensor
 
-from eva.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
+from evadb.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
 
 
 class MnistImageClassifier(PytorchAbstractClassifierUDF):
     @property
     def name(self) -> str:
         return "MnistImageClassifier"
```

### Comparing `evadb-0.2.6/eva/udfs/mvit_action_recognition.py` & `evadb-0.2.7/evadb/udfs/mvit_action_recognition.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 
 try:
     from torchvision.models.video import MViT_V2_S_Weights, mvit_v2_s
 except ImportError:
     raise ImportError(
         f"torchvision>=0.14.0 is required to use MVITActionRecognition, found {torchvision.__version__}"
     )
-from eva.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
+from evadb.udfs.abstract.pytorch_abstract_udf import PytorchAbstractClassifierUDF
 
 
 class MVITActionRecognition(PytorchAbstractClassifierUDF):
     @property
     def name(self) -> str:
         return "MVITActionRecognition"
```

### Comparing `evadb-0.2.6/eva/udfs/ndarray/__init__.py` & `evadb-0.2.7/evadb/udfs/ndarray/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/udfs/ndarray/annotate.py` & `evadb-0.2.7/evadb/udfs/ndarray/annotate.py`

 * *Files 3% similar despite different names*

```diff
@@ -12,18 +12,18 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import cv2
 import numpy as np
 import pandas as pd
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.udfs.abstract.abstract_udf import AbstractUDF
-from eva.udfs.decorators.decorators import forward, setup
-from eva.udfs.decorators.io_descriptors.data_types import PandasDataframe
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import PandasDataframe
 
 color = (207, 248, 64)
 thickness = 4
 
 
 class Annotate(AbstractUDF):
     @setup(cacheable=False, udf_type="cv2-transformation", batchable=True)
```

### Comparing `evadb-0.2.6/eva/udfs/ndarray/array_count.py` & `evadb-0.2.7/evadb/udfs/ndarray/array_count.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import numpy as np
 import pandas as pd
 
-from eva.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
 
 
 class ArrayCount(AbstractUDF):
     @property
     def name(self) -> str:
         return "ArrayCount"
```

### Comparing `evadb-0.2.6/eva/udfs/ndarray/crop.py` & `evadb-0.2.7/evadb/udfs/ndarray/crop.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import numpy as np
 import pandas as pd
 
-from eva.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
 
 
 class Crop(AbstractUDF):
     def setup(self):
         pass
 
     @property
```

### Comparing `evadb-0.2.6/eva/udfs/ndarray/fuzzy_join.py` & `evadb-0.2.7/evadb/udfs/ndarray/fuzzy_join.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import pandas as pd
 from thefuzz import fuzz
 
-from eva.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
 
 
 class FuzzDistance(AbstractUDF):
     def setup(self):
         pass
 
     @property
```

### Comparing `evadb-0.2.6/eva/udfs/ndarray/gaussian_blur.py` & `evadb-0.2.7/evadb/udfs/ndarray/gaussian_blur.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,18 +12,18 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import cv2
 import numpy as np
 import pandas as pd
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.udfs.abstract.abstract_udf import AbstractUDF
-from eva.udfs.decorators.decorators import forward, setup
-from eva.udfs.decorators.io_descriptors.data_types import PandasDataframe
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import PandasDataframe
 
 
 class GaussianBlur(AbstractUDF):
     @setup(cacheable=False, udf_type="cv2-transformation", batchable=True)
     def setup(self):
         pass
```

### Comparing `evadb-0.2.6/eva/udfs/ndarray/horizontal_flip.py` & `evadb-0.2.7/evadb/udfs/ndarray/horizontal_flip.py`

 * *Files 7% similar despite different names*

```diff
@@ -12,18 +12,18 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import cv2
 import numpy as np
 import pandas as pd
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.udfs.abstract.abstract_udf import AbstractUDF
-from eva.udfs.decorators.decorators import forward, setup
-from eva.udfs.decorators.io_descriptors.data_types import PandasDataframe
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import PandasDataframe
 
 
 class HorizontalFlip(AbstractUDF):
     @setup(cacheable=False, udf_type="cv2-transformation", batchable=True)
     def setup(self):
         pass
```

### Comparing `evadb-0.2.6/eva/udfs/ndarray/open.py` & `evadb-0.2.7/evadb/udfs/ndarray/open.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import cv2
 import numpy as np
 import pandas as pd
 
-from eva.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
 
 
 class Open(AbstractUDF):
     def setup(self):
         # cache data to avoid expensive open files on disk
         self._data_cache = dict()
```

### Comparing `evadb-0.2.6/eva/udfs/ndarray/to_grayscale.py` & `evadb-0.2.7/evadb/udfs/ndarray/to_grayscale.py`

 * *Files 6% similar despite different names*

```diff
@@ -12,18 +12,18 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import cv2
 import numpy as np
 import pandas as pd
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.udfs.abstract.abstract_udf import AbstractUDF
-from eva.udfs.decorators.decorators import forward, setup
-from eva.udfs.decorators.io_descriptors.data_types import PandasDataframe
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import PandasDataframe
 
 
 class ToGrayscale(AbstractUDF):
     @setup(cacheable=False, udf_type="cv2-transformation", batchable=True)
     def setup(self):
         pass
```

### Comparing `evadb-0.2.6/eva/udfs/ocr_extractor.py` & `evadb-0.2.7/evadb/udfs/ocr_extractor.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,16 +15,16 @@
 
 from typing import List
 
 import easyocr
 import numpy as np
 import pandas as pd
 
-from eva.udfs.abstract.abstract_udf import AbstractClassifierUDF
-from eva.udfs.gpu_compatible import GPUCompatible
+from evadb.udfs.abstract.abstract_udf import AbstractClassifierUDF
+from evadb.udfs.gpu_compatible import GPUCompatible
 
 
 class OCRExtractor(AbstractClassifierUDF, GPUCompatible):
     """
     Arguments:
         threshold (float): Threshold for classifier confidence score
     """
```

### Comparing `evadb-0.2.6/eva/udfs/sift_feature_extractor.py` & `evadb-0.2.7/evadb/udfs/sift_feature_extractor.py`

 * *Files 8% similar despite different names*

```diff
@@ -14,19 +14,19 @@
 # limitations under the License.
 import cv2
 import kornia
 import numpy as np
 import pandas as pd
 import torch
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.udfs.abstract.abstract_udf import AbstractUDF
-from eva.udfs.decorators.decorators import forward, setup
-from eva.udfs.decorators.io_descriptors.data_types import PandasDataframe
-from eva.udfs.gpu_compatible import GPUCompatible
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import PandasDataframe
+from evadb.udfs.gpu_compatible import GPUCompatible
 
 
 class SiftFeatureExtractor(AbstractUDF, GPUCompatible):
     @setup(cacheable=False, udf_type="FeatureExtraction", batchable=False)
     def setup(self):
         self.model = kornia.feature.SIFTDescriptor(100)
```

### Comparing `evadb-0.2.6/eva/udfs/trackers/__init__.py` & `evadb-0.2.7/evadb/udfs/trackers/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/udfs/trackers/nor_fair.py` & `evadb-0.2.7/evadb/udfs/trackers/nor_fair.py`

 * *Files 5% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import numpy as np
 from norfair import Detection, Tracker
 
-from eva.udfs.abstract.tracker_abstract_udf import EVATrackerAbstractUDF
-from eva.utils.math_utils import get_centroid
+from evadb.udfs.abstract.tracker_abstract_udf import EVATrackerAbstractUDF
+from evadb.utils.math_utils import get_centroid
 
 DISTANCE_THRESHOLD_CENTROID: int = 30
 
 
 class NorFairTracker(EVATrackerAbstractUDF):
     @property
     def name(self) -> str:
```

### Comparing `evadb-0.2.6/eva/udfs/tutorials/__init__.py` & `evadb-0.2.7/evadb/udfs/tutorials/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/udfs/udf_bootstrap_queries.py` & `evadb-0.2.7/evadb/udfs/udf_bootstrap_queries.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,18 +9,18 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.configuration.constants import EVA_INSTALLATION_DIR
+from evadb.database import EVADatabase
+from evadb.server.command_handler import execute_query_fetch_all
 
-EVA_INSTALLATION_DIR = ConfigurationManager().get_value("core", "eva_installation_dir")
 NDARRAY_DIR = "ndarray"
 TUTORIALS_DIR = "tutorials"
 
 DummyObjectDetector_udf_query = """CREATE UDF IF NOT EXISTS DummyObjectDetector
                   INPUT  (Frame_Array NDARRAY INT8(3, ANYDIM, ANYDIM))
                   OUTPUT (label NDARRAY STR(1))
                   TYPE  Classification
@@ -169,15 +169,15 @@
         TYPE  Classification
         IMPL  '{}/udfs/mnist_image_classifier.py';
         """.format(
     EVA_INSTALLATION_DIR
 )
 
 
-def init_builtin_udfs(mode: str = "debug") -> None:
+def init_builtin_udfs(db: EVADatabase, mode: str = "debug") -> None:
     """Load the built-in UDFs into the system during system bootstrapping.
 
     The function loads a set of pre-defined UDF queries based on the `mode` argument.
     In 'debug' mode, the function loads debug UDFs along with release UDFs.
     In 'release' mode, only release UDFs are loaded. In addition, in 'debug' mode,
     the function loads a smaller model to accelerate the test suite time.
 
@@ -190,15 +190,15 @@
     queries = [
         Fastrcnn_udf_query,
         ArrayCount_udf_query,
         Crop_udf_query,
         Open_udf_query,
         Similarity_udf_query,
         norfair_obj_tracker_query,
-        mnistcnn_udf_query
+        mnistcnn_udf_query,
         # Disabled because required packages (eg., easy_ocr might not be preinstalled)
         # face_detection_udf_query,
         # ocr_udf_query,
         # Mvit_udf_query, - Disabled as it requires specific pytorch package
         # Sift_udf_query, - requires package kornia
     ]
 
@@ -219,8 +219,8 @@
             TYPE  ultralytics
             'model' 'yolov8n.pt';
         """
         queries.append(yolo8n)
 
     # execute each query in the list of UDF queries
     for query in queries:
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(db, query)
```

### Comparing `evadb-0.2.6/eva/udfs/yolo_object_detector.py` & `evadb-0.2.7/evadb/udfs/yolo_object_detector.py`

 * *Files 4% similar despite different names*

```diff
@@ -11,19 +11,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import numpy as np
 import pandas as pd
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.udfs.abstract.abstract_udf import AbstractUDF
-from eva.udfs.decorators.decorators import forward, setup
-from eva.udfs.decorators.io_descriptors.data_types import PandasDataframe
-from eva.udfs.gpu_compatible import GPUCompatible
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import PandasDataframe
+from evadb.udfs.gpu_compatible import GPUCompatible
 
 try:
     from ultralytics import YOLO
 except ImportError as e:
     raise ImportError(
         f"Failed to import with error {e}, \
         please try `pip install ultralytics`"
```

### Comparing `evadb-0.2.6/eva/utils/__init__.py` & `evadb-0.2.7/evadb/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/utils/errors.py` & `evadb-0.2.7/evadb/utils/errors.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/utils/generic_utils.py` & `evadb-0.2.7/evadb/utils/generic_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,16 +21,15 @@
 import sys
 import uuid
 from pathlib import Path
 from typing import List
 
 from aenum import AutoEnum, unique
 
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.utils.logging_manager import logger
+from evadb.utils.logging_manager import logger
 
 
 def validate_kwargs(
     kwargs,
     allowed_keys: List[str],
     required_keys: List[str],
     error_message="Keyword argument not understood:",
@@ -124,30 +123,26 @@
         import torch
 
         return torch.cuda.device_count()
     except ImportError:
         return 0
 
 
-def generate_file_path(name: str = "") -> Path:
+def generate_file_path(dataset_location: str, name: str = "") -> Path:
     """Generates a arbitrary file_path(md5 hash) based on the a random salt
     and name
 
     Arguments:
+        dataset_location(str): parent directory where a file needs to be created
         name (str): Input file_name.
 
     Returns:
         Path: pathlib.Path object
 
     """
-    dataset_location = ConfigurationManager().get_value("core", "datasets_dir")
-    if dataset_location is None:
-        logger.error("Missing dataset location key in eva.yml")
-        raise KeyError("Missing datasets_dir key in eva.yml")
-
     dataset_location = Path(dataset_location)
     dataset_location.mkdir(parents=True, exist_ok=True)
 
     salt = uuid.uuid4().hex
     file_name = hashlib.md5(salt.encode() + name.encode()).hexdigest()
     path = dataset_location / file_name
     return path.resolve()
```

### Comparing `evadb-0.2.6/eva/utils/kv_cache.py` & `evadb-0.2.7/evadb/utils/kv_cache.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/utils/logging_manager.py` & `evadb-0.2.7/evadb/utils/logging_manager.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/utils/math_utils.py` & `evadb-0.2.7/evadb/utils/math_utils.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/eva/utils/s3_utils.py` & `evadb-0.2.7/evadb/utils/s3_utils.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/evadb.egg-info/PKG-INFO` & `evadb-0.2.7/evadb.egg-info/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: evadb
-Version: 0.2.6
+Version: 0.2.7
 Summary: EVA AI-Relational Database System
 Home-page: https://github.com/georgia-tech-db/eva
 Download-URL: https://github.com/georgia-tech-db/eva
 Author: Georgia Tech Database Group
 Author-email: arulraj@gatech.edu
 License: Apache License 2.0
 Classifier: Development Status :: 5 - Production/Stable
```

#### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: evadb Version: 0.2.6 Summary: EVA AI-Relational
+Metadata-Version: 2.1 Name: evadb Version: 0.2.7 Summary: EVA AI-Relational
 Database System Home-page: https://github.com/georgia-tech-db/eva Download-URL:
 https://github.com/georgia-tech-db/eva Author: Georgia Tech Database Group
 Author-email: arulraj@gatech.edu License: Apache License 2.0 Classifier:
 Development Status :: 5 - Production/Stable Classifier: License :: OSI Approved
 :: Apache Software License Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9 Classifier: Programming
 Language :: Python :: 3.10 Requires-Python: >=3.8 Description-Content-Type:
```

### Comparing `evadb-0.2.6/evadb.egg-info/requires.txt` & `evadb-0.2.7/evadb.egg-info/requires.txt`

 * *Files 9% similar despite different names*

```diff
@@ -12,14 +12,15 @@
 diskcache>=5.4.0
 eva-decord>=0.6.1
 boto3
 nest_asyncio
 langchain
 pymupdf
 pdfminer.six
+sentence-transformers
 torch>=1.10.0
 torchvision>=0.11.1
 faiss-cpu
 facenet-pytorch>=2.5.2
 ipython<8.13.0
 thefuzz
 ultralytics>=8.0.93
@@ -43,14 +44,15 @@
 diskcache>=5.4.0
 eva-decord>=0.6.1
 boto3
 nest_asyncio
 langchain
 pymupdf
 pdfminer.six
+sentence-transformers
 torch>=1.10.0
 torchvision>=0.11.1
 faiss-cpu
 facenet-pytorch>=2.5.2
 ipython<8.13.0
 thefuzz
 ultralytics>=8.0.93
```

### Comparing `evadb-0.2.6/setup.py` & `evadb-0.2.7/setup.py`

 * *Files 3% similar despite different names*

```diff
@@ -27,15 +27,15 @@
     path = os.path.join(os.path.dirname(__file__), path)
     with io.open(path, encoding=encoding) as fp:
         return fp.read()
 
 
 # version.py defines the VERSION and VERSION_SHORT variables
 VERSION_DICT: Dict[str, str] = {}
-with open("eva/version.py", "r") as version_file:
+with open("evadb/version.py", "r") as version_file:
     exec(version_file.read(), VERSION_DICT)
 
 DOWNLOAD_URL = "https://github.com/georgia-tech-db/eva"
 LICENSE = "Apache License 2.0"
 VERSION = VERSION_DICT["VERSION"]
 
 minimal_requirement = [
@@ -52,15 +52,17 @@
     "aenum>=2.2.0",
     "diskcache>=5.4.0",
     "eva-decord>=0.6.1",
     "boto3",
     "nest_asyncio",
     "langchain",
     "pymupdf",
-    "pdfminer.six"
+    "pdfminer.six",
+    "sentence-transformers"
+
 ]
 
 formatter_libs = ["black>=23.1.0", "isort>=5.10.1"]
 
 test_libs = [
     "pytest>=6.1.2",
     "pytest-cov>=2.11.1",
@@ -161,17 +163,17 @@
         "Programming Language :: Python :: 3.10",
         # "Programming Language :: Python :: 3.11",
     ],
     packages=find_packages(exclude=["tests", "tests.*"]),
     # https://python-packaging.readthedocs.io/en/latest/command-line-scripts.html#the-console-scripts-entry-point
     entry_points={
         "console_scripts": [
-            "eva_server=eva.eva_server:main",
-            "eva_client=eva.eva_cmd_client:main",
+            "eva_server=evadb.eva_server:main",
+            "eva_client=evadb.eva_cmd_client:main",
         ]
     },
     python_requires=">=3.8",
     install_requires=INSTALL_REQUIRES,
     extras_require=EXTRA_REQUIRES,
     include_package_data=True,
-    package_data={"eva": ["eva.yml", "parser/eva.lark"]},
+    package_data={"evadb": ["evadb.yml", "parser/evadb.lark"]},
 )
```

### Comparing `evadb-0.2.6/test/__init__.py` & `evadb-0.2.7/test/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/benchmark_tests/__init__.py` & `evadb-0.2.7/test/benchmark_tests/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/benchmark_tests/conftest.py` & `evadb-0.2.7/test/benchmark_tests/conftest.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,29 +1,35 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+from test.util import get_evadb_for_testing
+
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.server.command_handler import execute_query_fetch_all
-from eva.udfs.udf_bootstrap_queries import init_builtin_udfs
+from evadb.server.command_handler import execute_query_fetch_all
+from evadb.udfs.udf_bootstrap_queries import init_builtin_udfs
 
 
 @pytest.fixture(autouse=False)
 def setup_pytorch_tests():
-    CatalogManager().reset()
-    execute_query_fetch_all("LOAD VIDEO 'data/ua_detrac/ua_detrac.mp4' INTO MyVideo;")
-    execute_query_fetch_all("LOAD VIDEO 'data/mnist/mnist.mp4' INTO MNIST;")
-    execute_query_fetch_all("LOAD VIDEO 'data/sample_videos/touchdown.mp4' INTO VIDEOS")
-    init_builtin_udfs(mode="release")
-    yield None
+    evadb = get_evadb_for_testing()
+    evadb.catalog().reset()
+    execute_query_fetch_all(
+        evadb, "LOAD VIDEO 'data/ua_detrac/ua_detrac.mp4' INTO MyVideo;"
+    )
+    execute_query_fetch_all(evadb, "LOAD VIDEO 'data/mnist/mnist.mp4' INTO MNIST;")
+    execute_query_fetch_all(
+        evadb, "LOAD VIDEO 'data/sample_videos/touchdown.mp4' INTO VIDEOS"
+    )
+    init_builtin_udfs(evadb, mode="release")
+    return evadb
```

### Comparing `evadb-0.2.6/test/benchmark_tests/test_benchmark_pytorch.py` & `evadb-0.2.7/test/benchmark_tests/test_benchmark_pytorch.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,29 +13,28 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 from test.util import create_large_scale_image_dataset
 
 import pytest
 
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.server.command_handler import execute_query_fetch_all
 
 
 @pytest.mark.torchtest
 @pytest.mark.benchmark(
     warmup=False,
     warmup_iterations=1,
     min_rounds=1,
 )
 @pytest.mark.notparallel
 def test_should_run_pytorch_and_yolo(benchmark, setup_pytorch_tests):
     select_query = """SELECT Yolo(data) FROM MyVideo
                     WHERE id < 5;"""
-    actual_batch = benchmark(execute_query_fetch_all, select_query)
+    actual_batch = benchmark(execute_query_fetch_all, setup_pytorch_tests, select_query)
     assert len(actual_batch) == 5
 
 
 @pytest.mark.torchtest
 @pytest.mark.benchmark(
     warmup=False,
     warmup_iterations=1,
@@ -44,22 +43,22 @@
 @pytest.mark.notparallel
 def test_should_run_pytorch_and_facenet(benchmark, setup_pytorch_tests):
     create_udf_query = """CREATE UDF IF NOT EXISTS FaceDetector
                 INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
                 OUTPUT (bboxes NDARRAY FLOAT32(ANYDIM, 4),
                         scores NDARRAY FLOAT32(ANYDIM))
                 TYPE  FaceDetection
-                IMPL  'eva/udfs/face_detector.py';
+                IMPL  'evadb/udfs/face_detector.py';
     """
-    execute_query_fetch_all(create_udf_query)
+    execute_query_fetch_all(setup_pytorch_tests, create_udf_query)
 
     select_query = """SELECT FaceDetector(data) FROM MyVideo
                     WHERE id < 5;"""
 
-    actual_batch = benchmark(execute_query_fetch_all, select_query)
+    actual_batch = benchmark(execute_query_fetch_all, setup_pytorch_tests, select_query)
     assert len(actual_batch) == 5
 
 
 @pytest.mark.torchtest
 @pytest.mark.benchmark(
     warmup=False,
     warmup_iterations=1,
@@ -67,21 +66,21 @@
 )
 @pytest.mark.notparallel
 def test_should_run_pytorch_and_resnet50(benchmark, setup_pytorch_tests):
     create_udf_query = """CREATE UDF IF NOT EXISTS FeatureExtractor
                 INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
                 OUTPUT (features NDARRAY FLOAT32(ANYDIM))
                 TYPE  Classification
-                IMPL  'eva/udfs/feature_extractor.py';
+                IMPL  'evadb/udfs/feature_extractor.py';
     """
-    execute_query_fetch_all(create_udf_query)
+    execute_query_fetch_all(setup_pytorch_tests, create_udf_query)
 
     select_query = """SELECT FeatureExtractor(data) FROM MyVideo
                     WHERE id < 5;"""
-    actual_batch = benchmark(execute_query_fetch_all, select_query)
+    actual_batch = benchmark(execute_query_fetch_all, setup_pytorch_tests, select_query)
     assert len(actual_batch) == 5
 
     # non-trivial test case for Resnet50
     res = actual_batch.frames
     assert res["featureextractor.features"][0].shape == (1, 2048)
     # assert res["featureextractor.features"][0][0][0] > 0.3
 
@@ -92,15 +91,15 @@
     warmup_iterations=1,
     min_rounds=1,
 )
 @pytest.mark.notparallel
 def test_lateral_join(benchmark, setup_pytorch_tests):
     select_query = """SELECT id, a FROM MyVideo JOIN LATERAL
                     Yolo(data) AS T(a,b,c) WHERE id < 5;"""
-    actual_batch = benchmark(execute_query_fetch_all, select_query)
+    actual_batch = benchmark(execute_query_fetch_all, setup_pytorch_tests, select_query)
     assert len(actual_batch) == 5
     assert list(actual_batch.columns) == ["myvideo.id", "T.a"]
 
 
 @pytest.mark.benchmark(
     warmup=False,
     warmup_iterations=1,
@@ -108,75 +107,75 @@
 )
 def test_automatic_speech_recognition(benchmark, setup_pytorch_tests):
     udf_name = "SpeechRecognizer"
     create_udf = (
         f"CREATE UDF {udf_name} TYPE HuggingFace "
         "'task' 'automatic-speech-recognition' 'model' 'openai/whisper-base';"
     )
-    execute_query_fetch_all(create_udf)
+    execute_query_fetch_all(setup_pytorch_tests, create_udf)
 
     # TODO: use with SAMPLE AUDIORATE 16000
     select_query = f"SELECT {udf_name}(audio) FROM VIDEOS;"
-    output = benchmark(execute_query_fetch_all, select_query)
+    output = benchmark(execute_query_fetch_all, setup_pytorch_tests, select_query)
 
     # verify that output has one row and one column only
     assert output.frames.shape == (1, 1)
     # verify that speech was converted to text correctly
     assert output.frames.iloc[0][0].count("touchdown") == 2
 
     drop_udf_query = f"DROP UDF {udf_name};"
-    execute_query_fetch_all(drop_udf_query)
+    execute_query_fetch_all(setup_pytorch_tests, drop_udf_query)
 
 
 @pytest.mark.benchmark(
     warmup=False,
     warmup_iterations=1,
     min_rounds=1,
 )
 def test_summarization_from_video(benchmark, setup_pytorch_tests):
     asr_udf = "SpeechRecognizer"
     create_udf = (
         f"CREATE UDF {asr_udf} TYPE HuggingFace "
         "'task' 'automatic-speech-recognition' 'model' 'openai/whisper-base';"
     )
-    execute_query_fetch_all(create_udf)
+    execute_query_fetch_all(setup_pytorch_tests, create_udf)
 
     summary_udf = "Summarizer"
     create_udf = (
         f"CREATE UDF {summary_udf} TYPE HuggingFace "
         "'task' 'summarization' 'model' 'philschmid/bart-large-cnn-samsum' 'min_length' 10 'max_length' 100;"
     )
-    execute_query_fetch_all(create_udf)
+    execute_query_fetch_all(setup_pytorch_tests, create_udf)
 
     # TODO: use with SAMPLE AUDIORATE 16000
     select_query = f"SELECT {summary_udf}({asr_udf}(audio)) FROM VIDEOS;"
-    output = benchmark(execute_query_fetch_all, select_query)
+    output = benchmark(execute_query_fetch_all, setup_pytorch_tests, select_query)
 
     # verify that output has one row and one column only
     assert output.frames.shape == (1, 1)
     # verify that summary is as expected
     assert (
         output.frames.iloc[0][0]
         == "Jalen Hurts has scored his second rushing touchdown of the game."
     )
 
     drop_udf_query = f"DROP UDF {asr_udf};"
-    execute_query_fetch_all(drop_udf_query)
+    execute_query_fetch_all(setup_pytorch_tests, drop_udf_query)
     drop_udf_query = f"DROP UDF {summary_udf};"
-    execute_query_fetch_all(drop_udf_query)
+    execute_query_fetch_all(setup_pytorch_tests, drop_udf_query)
 
 
 @pytest.mark.benchmark(
     warmup=False,
     warmup_iterations=1,
     min_rounds=1,
 )
 def test_load_large_scale_image_dataset(benchmark, setup_pytorch_tests):
     # Test load 1M images.
-    tmp_dir = ConfigurationManager().get_value("storage", "tmp_dir")
+    tmp_dir = setup_pytorch_tests.config.get_value("storage", "tmp_dir")
 
     # Check directory's mounted disk available space.
     statvfs = os.statvfs(tmp_dir)
     available_gb = statvfs.f_frsize * statvfs.f_bavail / (1024**3)
 
     img_dir = os.path.join(tmp_dir, "large_scale_image_dataset_1000000")
 
@@ -186,12 +185,12 @@
         # has more than 5GB disk space.
         if available_gb < 10:
             return
         create_large_scale_image_dataset()
 
     def _execute_query_list(query_list):
         for query in query_list:
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(setup_pytorch_tests, query)
 
     drop_query = "DROP TABLE IF EXISTS benchmarkImageDataset;"
     load_query = f"LOAD IMAGE '{img_dir}/*.jpg' INTO benchmarkImageDataset;"
     benchmark(_execute_query_list, [drop_query, load_query])
```

### Comparing `evadb-0.2.6/test/binder/__init__.py` & `evadb-0.2.7/test/binder/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/binder/test_statement_binder.py` & `evadb-0.2.7/test/binder/test_statement_binder.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,165 +11,171 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from unittest.mock import MagicMock, patch
 
-from eva.binder.binder_utils import BinderError
-from eva.binder.statement_binder import StatementBinder
-from eva.binder.statement_binder_context import StatementBinderContext
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import NdArrayType
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.alias import Alias
-from eva.parser.create_statement import ColumnDefinition
+from evadb.binder.binder_utils import BinderError
+from evadb.binder.statement_binder import StatementBinder
+from evadb.binder.statement_binder_context import StatementBinderContext
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.alias import Alias
+from evadb.parser.create_statement import ColumnDefinition
 
 
 class StatementBinderTests(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
     def test_bind_tuple_value_expression(self):
         with patch.object(StatementBinderContext, "get_binded_column") as mock:
             mock.return_value = ["table_alias", "col_obj"]
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             tve = MagicMock()
             tve.col_name = "col_name"
             binder._bind_tuple_expr(tve)
             col_alias = "{}.{}".format("table_alias", "col_name")
             mock.assert_called_once()
             self.assertEqual(tve.col_object, "col_obj")
             self.assertEqual(tve.col_alias, col_alias)
 
-    @patch("eva.binder.statement_binder.bind_table_info")
+    @patch("evadb.binder.statement_binder.bind_table_info")
     def test_bind_tableref(self, mock_bind_table_info):
         with patch.object(StatementBinderContext, "add_table_alias") as mock:
-            binder = StatementBinder(StatementBinderContext())
+            catalog = MagicMock()
+            binder = StatementBinder(StatementBinderContext(catalog))
             tableref = MagicMock()
             tableref.is_table_atom.return_value = True
             binder._bind_tableref(tableref)
             mock.assert_called_with(
                 tableref.alias.alias_name, tableref.table.table_name
             )
-            mock_bind_table_info.assert_called_once_with(tableref.table)
+            mock_bind_table_info.assert_called_once_with(catalog(), tableref.table)
 
         with patch.object(StatementBinder, "bind") as mock_binder:
             with patch.object(
                 StatementBinderContext, "add_derived_table_alias"
             ) as mock_context:
-                binder = StatementBinder(StatementBinderContext())
+                binder = StatementBinder(StatementBinderContext(MagicMock()))
                 tableref = MagicMock()
                 tableref.is_table_atom.return_value = False
                 tableref.is_select.return_value = True
                 binder._bind_tableref(tableref)
                 mock_context.assert_called_with(
                     tableref.alias.alias_name,
                     tableref.select_statement.target_list,
                 )
                 mock_binder.assert_called_with(tableref.select_statement)
 
     def test_bind_tableref_with_func_expr(self):
         with patch.object(StatementBinder, "bind") as mock_binder:
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             tableref = MagicMock()
             tableref.is_table_atom.return_value = False
             tableref.is_select.return_value = False
             tableref.is_join.return_value = False
             binder._bind_tableref(tableref)
             mock_binder.assert_called_with(tableref.table_valued_expr.func_expr)
 
     def test_bind_tableref_with_join(self):
         with patch.object(StatementBinder, "bind") as mock_binder:
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             tableref = MagicMock()
             tableref.is_table_atom.return_value = False
             tableref.is_select.return_value = False
             tableref.is_join.return_value = True
             binder._bind_tableref(tableref)
             mock_binder.assert_any_call(tableref.join_node.left)
             mock_binder.assert_any_call(tableref.join_node.right)
 
     def test_bind_tableref_should_raise(self):
         with patch.object(StatementBinder, "bind"):
             with self.assertRaises(BinderError):
-                binder = StatementBinder(StatementBinderContext())
+                binder = StatementBinder(StatementBinderContext(MagicMock()))
                 tableref = MagicMock()
                 tableref.is_select.return_value = False
                 tableref.is_table_valued_expr.return_value = False
                 tableref.is_join.return_value = False
                 tableref.is_table_atom.return_value = False
                 binder._bind_tableref(tableref)
 
-    @patch("eva.binder.statement_binder.StatementBinderContext")
+    @patch("evadb.binder.statement_binder.StatementBinderContext")
     def test_bind_tableref_starts_new_context(self, mock_ctx):
         with patch.object(StatementBinder, "bind"):
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             tableref = MagicMock()
             tableref.is_table_atom.return_value = False
             tableref.is_join.return_value = False
             tableref.is_select.return_value = True
             binder._bind_tableref(tableref)
             self.assertEqual(mock_ctx.call_count, 1)
 
     def test_bind_create_mat_statement(self):
         with patch.object(StatementBinder, "bind") as mock_binder:
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             mat_statement = MagicMock()
             binder._bind_create_mat_statement(mat_statement)
             mock_binder.assert_called_with(mat_statement.query)
 
     def test_raises_mismatch_columns_create_mat_statement(self):
         with patch.object(StatementBinder, "bind"):
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             mat_statement = MagicMock()
-            mat_statement.col_list = [ColumnDefinition('id', None, None, None)]
-            mat_statement.query.target_list = [TupleValueExpression(col_name='id'), TupleValueExpression(col_name='label')]
-            with self.assertRaises(Exception, msg='Projected columns mismatch, expected 1 found 2.'):
+            mat_statement.col_list = [ColumnDefinition("id", None, None, None)]
+            mat_statement.query.target_list = [
+                TupleValueExpression(col_name="id"),
+                TupleValueExpression(col_name="label"),
+            ]
+            with self.assertRaises(
+                Exception, msg="Projected columns mismatch, expected 1 found 2."
+            ):
                 binder._bind_create_mat_statement(mat_statement)
 
     def test_bind_explain_statement(self):
         with patch.object(StatementBinder, "bind") as mock_binder:
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             stmt = MagicMock()
             binder._bind_explain_statement(stmt)
             mock_binder.assert_called_with(stmt.explainable_stmt)
 
-    @patch("eva.binder.statement_binder.CatalogManager")
-    @patch("eva.binder.statement_binder.load_udf_class_from_file")
-    @patch("eva.binder.statement_binder.get_file_checksum")
+    @patch("evadb.binder.statement_binder.load_udf_class_from_file")
+    @patch("evadb.binder.statement_binder.get_file_checksum")
     def test_bind_func_expr(
-        self, mock_get_file_checksum, mock_load_udf_class_from_file, mock_catalog
+        self, mock_get_file_checksum, mock_load_udf_class_from_file
     ):
         # setup
         func_expr = MagicMock(
             name="func_expr", alias=Alias("func_expr"), output_col_aliases=[]
         )
         func_expr.name.lower.return_value = "func_expr"
         obj1 = MagicMock()
         obj1.name.lower.return_value = "out1"
         obj2 = MagicMock()
         obj2.name.lower.return_value = "out2"
         func_output_objs = [obj1, obj2]
         udf_obj = MagicMock()
+
+        mock_catalog = MagicMock()
         mock_get_name = mock_catalog().get_udf_catalog_entry_by_name = MagicMock()
         mock_get_name.return_value = udf_obj
 
         mock_get_udf_outputs = (
             mock_catalog().get_udf_io_catalog_output_entries
         ) = MagicMock()
         mock_get_udf_outputs.return_value = func_output_objs
         mock_load_udf_class_from_file.return_value.return_value = (
             "load_udf_class_from_file"
         )
         mock_get_file_checksum.return_value = udf_obj.checksum
 
         # Case 1 set output
         func_expr.output = "out1"
-        binder = StatementBinder(StatementBinderContext())
+        binder = StatementBinder(StatementBinderContext(mock_catalog))
         binder._bind_func_expr(func_expr)
 
         mock_get_file_checksum.assert_called_with(udf_obj.impl_file_path)
         mock_get_name.assert_called_with(func_expr.name)
         mock_get_udf_outputs.assert_called_with(udf_obj)
         mock_load_udf_class_from_file.assert_called_with(
             udf_obj.impl_file_path, udf_obj.name
@@ -181,15 +187,15 @@
             Alias("func_expr", ["out1"]),
         )
         self.assertEqual(func_expr.function(), "load_udf_class_from_file")
 
         # Case 2 output not set
         func_expr.output = None
         func_expr.alias = Alias("func_expr")
-        binder = StatementBinder(StatementBinderContext())
+        binder = StatementBinder(StatementBinderContext(mock_catalog))
         binder._bind_func_expr(func_expr)
 
         mock_get_file_checksum.assert_called_with(udf_obj.impl_file_path)
         mock_get_name.assert_called_with(func_expr.name)
         mock_get_udf_outputs.assert_called_with(udf_obj)
         mock_load_udf_class_from_file.assert_called_with(
             udf_obj.impl_file_path, udf_obj.name
@@ -206,81 +212,83 @@
 
         # Raise error if the class object cannot be created
         mock_load_udf_class_from_file.reset_mock()
         mock_error_msg = "mock_load_udf_class_from_file_error"
         mock_load_udf_class_from_file.side_effect = MagicMock(
             side_effect=RuntimeError(mock_error_msg)
         )
-        binder = StatementBinder(StatementBinderContext())
+        binder = StatementBinder(StatementBinderContext(mock_catalog))
         with self.assertRaises(BinderError) as cm:
             binder._bind_func_expr(func_expr)
         err_msg = (
             f"{mock_error_msg}. Please verify that the UDF class name in the"
             "implementation file matches the UDF name."
         )
         self.assertEqual(str(cm.exception), err_msg)
 
-    @patch("eva.binder.statement_binder.check_table_object_is_video")
-    def test_bind_select_statement(self, is_video_mock):
+    @patch("evadb.binder.statement_binder.check_table_object_is_groupable")
+    @patch("evadb.binder.statement_binder.check_groupby_pattern")
+    def test_bind_select_statement(self, is_groupable_mock, groupby_mock):
         with patch.object(StatementBinder, "bind") as mock_binder:
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             select_statement = MagicMock()
             mocks = [MagicMock(), MagicMock(), MagicMock(), MagicMock(), MagicMock()]
             select_statement.target_list = mocks[:2]
             select_statement.orderby_list = [(mocks[2], 0), (mocks[3], 0)]
             select_statement.groupby_clause = mocks[4]
-            select_statement.groupby_clause.value = "8f"
+            select_statement.groupby_clause.value = "8 frames"
             binder._bind_select_statement(select_statement)
             mock_binder.assert_any_call(select_statement.from_table)
             mock_binder.assert_any_call(select_statement.where_clause)
             mock_binder.assert_any_call(select_statement.groupby_clause)
             mock_binder.assert_any_call(select_statement.union_link)
-            is_video_mock.assert_called()
+            is_groupable_mock.assert_called()
             for mock in mocks:
                 mock_binder.assert_any_call(mock)
 
-    @patch("eva.binder.statement_binder.StatementBinderContext")
+    @patch("evadb.binder.statement_binder.StatementBinderContext")
     def test_bind_select_statement_union_starts_new_context(self, mock_ctx):
         with patch.object(StatementBinder, "bind"):
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             select_statement = MagicMock()
             select_statement.union_link = None
             select_statement.groupby_clause = None
             binder._bind_select_statement(select_statement)
             self.assertEqual(mock_ctx.call_count, 0)
 
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             select_statement = MagicMock()
             select_statement.groupby_clause = None
             binder._bind_select_statement(select_statement)
             self.assertEqual(mock_ctx.call_count, 1)
 
     def test_bind_unknown_object(self):
         class UnknownType:
             pass
 
         with self.assertRaises(NotImplementedError):
-            binder = StatementBinder(StatementBinderContext())
+            binder = StatementBinder(StatementBinderContext(MagicMock()))
             binder.bind(UnknownType())
 
     def test_bind_create_index(self):
         with patch.object(StatementBinder, "bind"):
-            binder = StatementBinder(StatementBinderContext())
+            catalog = MagicMock()
+            binder = StatementBinder(StatementBinderContext(catalog))
             create_index_statement = MagicMock()
 
             with self.assertRaises(AssertionError):
                 binder._bind_create_index_statement(create_index_statement)
 
             create_index_statement.col_list = ["foo"]
             udf_obj = MagicMock()
             output = MagicMock()
             udf_obj.outputs = [output]
 
             with patch.object(
-                CatalogManager, "get_udf_catalog_entry_by_name", return_value=udf_obj
+                catalog(), "get_udf_catalog_entry_by_name", return_value=udf_obj
             ):
                 with self.assertRaises(AssertionError):
                     binder._bind_create_index_statement(create_index_statement)
                 output.array_type = NdArrayType.FLOAT32
                 with self.assertRaises(AssertionError):
                     binder._bind_create_index_statement(create_index_statement)
                 output.array_dimensions = [1, 100]
```

### Comparing `evadb-0.2.6/test/binder/test_statement_binder_context.py` & `evadb-0.2.7/test/binder/test_statement_binder_context.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,161 +1,161 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-from unittest.mock import MagicMock, patch
+from unittest.mock import MagicMock
 
 import pytest
 
-from eva.binder.binder_utils import BinderError
-from eva.binder.statement_binder_context import StatementBinderContext
-from eva.expression.function_expression import FunctionExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
+from evadb.binder.binder_utils import BinderError
+from evadb.binder.statement_binder_context import StatementBinderContext
+from evadb.expression.function_expression import FunctionExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
 
 
 @pytest.mark.notparallel
 class StatementBinderTests(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
     def test_check_duplicate_alias(self):
         with self.assertRaises(BinderError):
-            ctx = StatementBinderContext()
+            ctx = StatementBinderContext(MagicMock())
             ctx._derived_table_alias_map["alias"] = MagicMock()
             ctx._check_duplicate_alias("alias")
 
         with self.assertRaises(BinderError):
-            ctx = StatementBinderContext()
+            ctx = StatementBinderContext(MagicMock())
             ctx._table_alias_map["alias"] = MagicMock()
             ctx._check_duplicate_alias("alias")
 
         # no duplicate
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(MagicMock())
         ctx._check_duplicate_alias("alias")
 
-    @patch("eva.binder.statement_binder_context.CatalogManager")
-    def test_add_table_alias(self, mock_catalog):
+    def test_add_table_alias(self):
+        mock_catalog = MagicMock()
         mock_get = mock_catalog().get_table_catalog_entry = MagicMock()
         mock_get.return_value = "table_obj"
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(mock_catalog)
 
         mock_check = ctx._check_duplicate_alias = MagicMock()
         ctx.add_table_alias("alias", "table_name")
         mock_check.assert_called_with("alias")
         mock_get.assert_called_with("table_name")
         self.assertEqual(ctx._table_alias_map["alias"], "table_obj")
 
     def test_add_derived_table_alias(self):
         objs = [MagicMock(), MagicMock()]
         exprs = [
             MagicMock(spec=TupleValueExpression, col_name="A", col_object="A_obj"),
             MagicMock(spec=FunctionExpression, output_objs=objs),
         ]
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(MagicMock())
 
         mock_check = ctx._check_duplicate_alias = MagicMock()
         ctx.add_derived_table_alias("alias", exprs)
 
         mock_check.assert_called_with("alias")
         col_map = {"A": "A_obj", objs[0].name: objs[0], objs[1].name: objs[1]}
         self.assertEqual(ctx._derived_table_alias_map["alias"], col_map)
 
     def test_get_binded_column_should_search_all(self):
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(MagicMock())
         mock_search_all = ctx._search_all_alias_maps = MagicMock()
         mock_search_all.return_value = ("alias", "col_obj")
 
         result = ctx.get_binded_column("col_name")
         mock_search_all.assert_called_once_with("col_name")
         self.assertEqual(result, ("alias", "col_obj"))
 
     def test_get_binded_column_check_table_alias_map(self):
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(MagicMock())
         mock_table_map = ctx._check_table_alias_map = MagicMock()
         mock_table_map.return_value = "col_obj"
         result = ctx.get_binded_column("col_name", "alias")
         mock_table_map.assert_called_once_with("alias", "col_name")
         self.assertEqual(result, ("alias", "col_obj"))
 
     def test_get_binded_column_check_derived_table_alias_map(self):
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(MagicMock())
         mock_table_map = ctx._check_table_alias_map = MagicMock()
         mock_table_map.return_value = None
         mock_derived_map = ctx._check_derived_table_alias_map = MagicMock()
         mock_derived_map.return_value = "col_obj"
 
         result = ctx.get_binded_column("col_name", "alias")
         mock_table_map.assert_called_once_with("alias", "col_name")
         mock_derived_map.assert_called_once_with("alias", "col_name")
         self.assertEqual(result, ("alias", "col_obj"))
 
     def test_get_binded_column_raise_error(self):
         # no alias
         with self.assertRaises(BinderError):
-            ctx = StatementBinderContext()
+            ctx = StatementBinderContext(MagicMock())
             mock_search_all = ctx._search_all_alias_maps = MagicMock()
             mock_search_all.return_value = (None, None)
             ctx.get_binded_column("col_name")
         # with alias
         with self.assertRaises(BinderError):
-            ctx = StatementBinderContext()
+            ctx = StatementBinderContext(MagicMock())
             mock_table_map = ctx._check_table_alias_map = MagicMock()
             mock_table_map.return_value = None
             mock_derived_map = ctx._check_derived_table_alias_map = MagicMock()
             mock_derived_map.return_value = None
             ctx.get_binded_column("col_name", "alias")
 
-    @patch("eva.binder.statement_binder_context.CatalogManager")
-    def test_check_table_alias_map(self, mock_catalog):
+    def test_check_table_alias_map(self):
+        mock_catalog = MagicMock()
         mock_get_column_object = mock_catalog().get_column_catalog_entry = MagicMock()
         mock_get_column_object.return_value = "catalog_value"
         # key exists
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(mock_catalog)
         ctx._table_alias_map["alias"] = "table_obj"
         result = ctx._check_table_alias_map("alias", "col_name")
         mock_get_column_object.assert_called_once_with("table_obj", "col_name")
         self.assertEqual(result, "catalog_value")
 
         # key does not exist
         mock_get_column_object.reset_mock()
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(mock_catalog)
         result = ctx._check_table_alias_map("alias", "col_name")
         mock_get_column_object.assert_not_called()
         self.assertEqual(result, None)
 
     def test_check_derived_table_alias_map(self):
         # key exists
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(MagicMock())
         obj1 = MagicMock()
         obj2 = MagicMock()
         col_map = {"col1": obj1, "col2": obj2}
         ctx._derived_table_alias_map["alias"] = col_map
         result = ctx._check_derived_table_alias_map("alias", "col1")
         self.assertEqual(result, obj1)
         result = ctx._check_derived_table_alias_map("alias", "col2")
         self.assertEqual(result, obj2)
 
         # key does not exist
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(MagicMock())
         result = ctx._check_derived_table_alias_map("alias", "col3")
         self.assertEqual(result, None)
 
     def test_search_all_alias_maps(self):
-        ctx = StatementBinderContext()
+        ctx = StatementBinderContext(MagicMock())
         check_table_map = ctx._check_table_alias_map = MagicMock()
         check_derived_map = ctx._check_derived_table_alias_map = MagicMock()
 
         # only _table_alias_map has entry
         check_table_map.return_value = "col_obj"
         ctx._table_alias_map["alias"] = "col_name"
         ctx._derived_table_alias_map = {}
@@ -171,14 +171,14 @@
         result = ctx._search_all_alias_maps("col_name")
         check_table_map.assert_called_once_with("alias", "col_name")
         check_table_map.assert_called_once_with("alias", "col_name")
         self.assertEqual(result, ("alias", "derived_col_obj"))
 
     def test_search_all_alias_raise_duplicate_error(self):
         with self.assertRaises(BinderError):
-            ctx = StatementBinderContext()
+            ctx = StatementBinderContext(MagicMock())
             ctx._check_table_alias_map = MagicMock()
             ctx._check_derived_table_alias_map = MagicMock()
             # duplicate
             ctx._table_alias_map["alias"] = "col_name"
             ctx._derived_table_alias_map["alias"] = "col_name"
             ctx._search_all_alias_maps("col_name")
```

### Comparing `evadb-0.2.6/test/catalog/__init__.py` & `evadb-0.2.7/test/catalog/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/catalog/models/__init__.py` & `evadb-0.2.7/test/catalog/models/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/catalog/models/test_models.py` & `evadb-0.2.7/test/catalog/models/test_models.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
-from eva.catalog.catalog_type import ColumnType, NdArrayType, TableType
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.index_catalog import IndexCatalogEntry
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.catalog.models.udf_catalog import UdfCatalogEntry
-from eva.catalog.models.udf_io_catalog import UdfIOCatalogEntry
+from evadb.catalog.catalog_type import ColumnType, NdArrayType, TableType
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.models.index_catalog import IndexCatalogEntry
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.catalog.models.udf_catalog import UdfCatalogEntry
+from evadb.catalog.models.udf_io_catalog import UdfIOCatalogEntry
 
 
 class CatalogModelsTest(unittest.TestCase):
     def test_df_column(self):
         df_col = ColumnCatalogEntry("name", ColumnType.TEXT, is_nullable=False)
         df_col.array_dimensions = [1, 2]
         df_col.table_id = 1
```

### Comparing `evadb-0.2.6/test/catalog/services/__init__.py` & `evadb-0.2.7/test/executor/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/catalog/test_catalog_manager.py` & `evadb-0.2.7/test/catalog/test_catalog_manager.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,80 +14,85 @@
 # limitations under the License.
 import unittest
 
 import mock
 import pytest
 from mock import ANY, MagicMock
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import ColumnType, TableType
-from eva.catalog.catalog_utils import get_video_table_column_definitions
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.udf_catalog import UdfCatalogEntry
-from eva.parser.table_ref import TableInfo
-from eva.parser.types import FileFormatType
+from evadb.catalog.catalog_manager import CatalogManager
+from evadb.catalog.catalog_type import ColumnType, TableType
+from evadb.catalog.catalog_utils import get_video_table_column_definitions
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.models.udf_catalog import UdfCatalogEntry
+from evadb.parser.table_ref import TableInfo
+from evadb.parser.types import FileFormatType
 
 
 @pytest.mark.notparallel
 class CatalogManagerTests(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
-    def test_catalog_manager_singleton_pattern(self):
-        x = CatalogManager()
-        y = CatalogManager()
-        self.assertEqual(x, y)
+    @classmethod
+    def setUpClass(cls) -> None:
+        cls.mocks = [
+            mock.patch("evadb.catalog.catalog_manager.SQLConfig"),
+            mock.patch("evadb.catalog.catalog_manager.init_db"),
+        ]
+        for single_mock in cls.mocks:
+            single_mock.start()
+            cls.addClassCleanup(single_mock.stop)
 
-    @mock.patch("eva.catalog.catalog_manager.init_db")
+    @mock.patch("evadb.catalog.catalog_manager.init_db")
     def test_catalog_bootstrap(self, mocked_db):
-        x = CatalogManager()
+        x = CatalogManager(MagicMock(), MagicMock())
         x._bootstrap_catalog()
         mocked_db.assert_called()
 
     @mock.patch(
-        "eva.catalog.catalog_manager.CatalogManager.create_and_insert_table_catalog_entry"
+        "evadb.catalog.catalog_manager.CatalogManager.create_and_insert_table_catalog_entry"
     )
     def test_create_multimedia_table_catalog_entry(self, mock):
-        x = CatalogManager()
+        x = CatalogManager(MagicMock(), MagicMock())
         name = "myvideo"
         x.create_and_insert_multimedia_table_catalog_entry(
             name=name, format_type=FileFormatType.VIDEO
         )
 
         columns = get_video_table_column_definitions()
 
         mock.assert_called_once_with(
             TableInfo(name),
             columns,
             table_type=TableType.VIDEO_DATA,
         )
 
-    @mock.patch("eva.catalog.catalog_manager.init_db")
-    @mock.patch("eva.catalog.catalog_manager.TableCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.init_db")
+    @mock.patch("evadb.catalog.catalog_manager.TableCatalogService")
     def test_insert_table_catalog_entry_should_create_table_and_columns(
         self, ds_mock, initdb_mock
     ):
-        catalog = CatalogManager()
+        catalog = CatalogManager(MagicMock(), MagicMock())
         file_url = "file1"
         table_name = "name"
 
         columns = [(ColumnCatalogEntry("c1", ColumnType.INTEGER))]
         catalog.insert_table_catalog_entry(table_name, file_url, columns)
         ds_mock.return_value.insert_entry.assert_called_with(
             table_name,
             file_url,
             identifier_column="id",
             table_type=TableType.VIDEO_DATA,
             column_list=[ANY] + columns,
         )
 
-    @mock.patch("eva.catalog.catalog_manager.init_db")
-    @mock.patch("eva.catalog.catalog_manager.TableCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.init_db")
+    @mock.patch("evadb.catalog.catalog_manager.TableCatalogService")
     def test_get_table_catalog_entry_when_table_exists(self, ds_mock, initdb_mock):
-        catalog = CatalogManager()
+        catalog = CatalogManager(MagicMock(), MagicMock())
         table_name = "name"
         database_name = "database"
         row_id = 1
         table_obj = MagicMock(row_id=row_id)
         ds_mock.return_value.get_entry_by_name.return_value = table_obj
 
         actual = catalog.get_table_catalog_entry(
@@ -95,41 +100,41 @@
             database_name,
         )
         ds_mock.return_value.get_entry_by_name.assert_called_with(
             database_name, table_name
         )
         self.assertEqual(actual.row_id, row_id)
 
-    @mock.patch("eva.catalog.catalog_manager.init_db")
-    @mock.patch("eva.catalog.catalog_manager.TableCatalogService")
-    @mock.patch("eva.catalog.catalog_manager.ColumnCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.init_db")
+    @mock.patch("evadb.catalog.catalog_manager.TableCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.ColumnCatalogService")
     def test_get_table_catalog_entry_when_table_doesnot_exists(
         self, dcs_mock, ds_mock, initdb_mock
     ):
-        catalog = CatalogManager()
+        catalog = CatalogManager(MagicMock(), MagicMock())
         table_name = "name"
 
         database_name = "database"
         table_obj = None
 
         ds_mock.return_value.get_entry_by_name.return_value = table_obj
 
         actual = catalog.get_table_catalog_entry(table_name, database_name)
         ds_mock.return_value.get_entry_by_name.assert_called_with(
             database_name, table_name
         )
         dcs_mock.return_value.filter_entries_by_table_id.assert_not_called()
         self.assertEqual(actual, table_obj)
 
-    @mock.patch("eva.catalog.catalog_manager.UdfCatalogService")
-    @mock.patch("eva.catalog.catalog_manager.UdfIOCatalogService")
-    @mock.patch("eva.catalog.catalog_manager.UdfMetadataCatalogService")
-    @mock.patch("eva.catalog.catalog_manager.get_file_checksum")
+    @mock.patch("evadb.catalog.catalog_manager.UdfCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.UdfIOCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.UdfMetadataCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.get_file_checksum")
     def test_insert_udf(self, checksum_mock, udfmetadata_mock, udfio_mock, udf_mock):
-        catalog = CatalogManager()
+        catalog = CatalogManager(MagicMock(), MagicMock())
         udf_io_list = [MagicMock()]
         udf_metadata_list = [MagicMock()]
         actual = catalog.insert_udf_catalog_entry(
             "udf", "sample.py", "classification", udf_io_list, udf_metadata_list
         )
         udfio_mock.return_value.insert_entries.assert_called_with(udf_io_list)
         udfmetadata_mock.return_value.insert_entries.assert_called_with(
@@ -137,32 +142,38 @@
         )
         udf_mock.return_value.insert_entry.assert_called_with(
             "udf", "sample.py", "classification", checksum_mock.return_value
         )
         checksum_mock.assert_called_with("sample.py")
         self.assertEqual(actual, udf_mock.return_value.insert_entry.return_value)
 
-    @mock.patch("eva.catalog.catalog_manager.UdfCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.UdfCatalogService")
     def test_get_udf_catalog_entry_by_name(self, udf_mock):
-        catalog = CatalogManager()
+        catalog = CatalogManager(MagicMock(), MagicMock())
         actual = catalog.get_udf_catalog_entry_by_name("name")
         udf_mock.return_value.get_entry_by_name.assert_called_with("name")
         self.assertEqual(actual, udf_mock.return_value.get_entry_by_name.return_value)
 
-    @mock.patch("eva.catalog.catalog_manager.UdfCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.UdfCatalogService")
     def test_delete_udf(self, udf_mock):
-        CatalogManager().delete_udf_catalog_entry_by_name("name")
+        CatalogManager(MagicMock(), MagicMock()).delete_udf_catalog_entry_by_name(
+            "name"
+        )
         udf_mock.return_value.delete_entry_by_name.assert_called_with("name")
 
-    @mock.patch("eva.catalog.catalog_manager.UdfIOCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.UdfIOCatalogService")
     def test_get_udf_outputs(self, udf_mock):
         mock_func = udf_mock.return_value.get_output_entries_by_udf_id
         udf_obj = MagicMock(spec=UdfCatalogEntry)
-        CatalogManager().get_udf_io_catalog_output_entries(udf_obj)
+        CatalogManager(MagicMock(), MagicMock()).get_udf_io_catalog_output_entries(
+            udf_obj
+        )
         mock_func.assert_called_once_with(udf_obj.row_id)
 
-    @mock.patch("eva.catalog.catalog_manager.UdfIOCatalogService")
+    @mock.patch("evadb.catalog.catalog_manager.UdfIOCatalogService")
     def test_get_udf_inputs(self, udf_mock):
         mock_func = udf_mock.return_value.get_input_entries_by_udf_id
         udf_obj = MagicMock(spec=UdfCatalogEntry)
-        CatalogManager().get_udf_io_catalog_input_entries(udf_obj)
+        CatalogManager(MagicMock(), MagicMock()).get_udf_io_catalog_input_entries(
+            udf_obj
+        )
         mock_func.assert_called_once_with(udf_obj.row_id)
```

### Comparing `evadb-0.2.6/test/catalog/test_column_type.py` & `evadb-0.2.7/test/catalog/test_column_type.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from decimal import Decimal
 
 import numpy as np
 
-from eva.catalog.catalog_type import ColumnType, NdArrayType
+from evadb.catalog.catalog_type import ColumnType, NdArrayType
 
 
 class ColumnTypeTests(unittest.TestCase):
     def test_ndarray_type_to_numpy_type(self):
         expected_type = [
             np.int8,
             np.uint8,
```

### Comparing `evadb-0.2.6/test/configuration/__init__.py` & `evadb-0.2.7/test/expression/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/executor/__init__.py` & `evadb-0.2.7/test/integration_tests/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/executor/test_abstract_executor.py` & `evadb-0.2.7/test/executor/test_abstract_executor.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from inspect import signature
 from test.util import get_all_subclasses
 
-from eva.executor.abstract_executor import AbstractExecutor
+from evadb.executor.abstract_executor import AbstractExecutor
 
 
 class AbstractExecutorTest(unittest.TestCase):
     def test_constructor_args(self):
         derived_executor_classes = list(get_all_subclasses(AbstractExecutor))
         for derived_executor_class in derived_executor_classes:
             sig = signature(derived_executor_class.__init__)
```

### Comparing `evadb-0.2.6/test/executor/test_create_udf_executor.py` & `evadb-0.2.7/test/executor/test_create_udf_executor.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,26 +12,25 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 from mock import MagicMock, patch
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.executor.create_udf_executor import CreateUDFExecutor
-from eva.udfs.decorators.io_descriptors.data_types import PandasDataframe
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.executor.create_udf_executor import CreateUDFExecutor
+from evadb.udfs.decorators.io_descriptors.data_types import PandasDataframe
 
 
 class CreateUdfExecutorTest(unittest.TestCase):
-    @patch("eva.executor.create_udf_executor.CatalogManager")
-    @patch("eva.executor.create_udf_executor.load_udf_class_from_file")
-    def test_should_create_udf(self, load_udf_class_from_file_mock, mock):
-        catalog_instance = mock.return_value
-        catalog_instance.get_udf_catalog_entry_by_name.return_value = None
-        catalog_instance.insert_udf_catalog_entry.return_value = "udf"
+    @patch("evadb.executor.create_udf_executor.load_udf_class_from_file")
+    def test_should_create_udf(self, load_udf_class_from_file_mock):
+        catalog_instance = MagicMock()
+        catalog_instance().get_udf_catalog_entry_by_name.return_value = None
+        catalog_instance().insert_udf_catalog_entry.return_value = "udf"
         impl_path = MagicMock()
         abs_path = impl_path.absolute.return_value = MagicMock()
         abs_path.as_posix.return_value = "test.py"
         load_udf_class_from_file_mock.return_value.return_value = "mock_class"
         plan = type(
             "CreateUDFPlan",
             (),
@@ -41,33 +40,34 @@
                 "inputs": ["inp"],
                 "outputs": ["out"],
                 "impl_path": impl_path,
                 "udf_type": "classification",
                 "metadata": {"key1": "value1", "key2": "value2"},
             },
         )
-
-        create_udf_executor = CreateUDFExecutor(plan)
+        evadb = MagicMock
+        evadb.catalog = catalog_instance
+        evadb.config = MagicMock()
+        create_udf_executor = CreateUDFExecutor(evadb, plan)
         next(create_udf_executor.exec())
-        catalog_instance.insert_udf_catalog_entry.assert_called_with(
+        catalog_instance().insert_udf_catalog_entry.assert_called_with(
             "udf",
             "test.py",
             "classification",
             ["inp", "out"],
             {"key1": "value1", "key2": "value2"},
         )
 
-    @patch("eva.executor.create_udf_executor.CatalogManager")
-    @patch("eva.executor.create_udf_executor.load_udf_class_from_file")
+    @patch("evadb.executor.create_udf_executor.load_udf_class_from_file")
     def test_should_raise_error_on_incorrect_io_definition(
-        self, load_udf_class_from_file_mock, mock
+        self, load_udf_class_from_file_mock
     ):
-        catalog_instance = mock.return_value
-        catalog_instance.get_udf_catalog_entry_by_name.return_value = None
-        catalog_instance.insert_udf_catalog_entry.return_value = "udf"
+        catalog_instance = MagicMock()
+        catalog_instance().get_udf_catalog_entry_by_name.return_value = None
+        catalog_instance().insert_udf_catalog_entry.return_value = "udf"
         impl_path = MagicMock()
         abs_path = impl_path.absolute.return_value = MagicMock()
         abs_path.as_posix.return_value = "test.py"
         load_udf_class_from_file_mock.return_value.return_value = "mock_class"
         incorrect_input_definition = PandasDataframe(
             columns=["Frame_Array", "Frame_Array_2"],
             column_types=[NdArrayType.UINT8],
@@ -85,17 +85,19 @@
                 "if_not_exists": False,
                 "inputs": [],
                 "outputs": [],
                 "impl_path": impl_path,
                 "udf_type": "classification",
             },
         )
-
-        create_udf_executor = CreateUDFExecutor(plan)
+        evadb = MagicMock
+        evadb.catalog = catalog_instance
+        evadb.config = MagicMock()
+        create_udf_executor = CreateUDFExecutor(evadb, plan)
         # check a string in the error message
         with self.assertRaises(RuntimeError) as exc:
             next(create_udf_executor.exec())
         self.assertIn(
             "Error creating UDF, input/output definition incorrect:", str(exc.exception)
         )
 
-        catalog_instance.insert_udf_catalog_entry.assert_not_called()
+        catalog_instance().insert_udf_catalog_entry.assert_not_called()
```

### Comparing `evadb-0.2.6/test/executor/test_execution_context.py` & `evadb-0.2.7/test/executor/test_execution_context.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,92 +12,92 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 from mock import patch
 
-from eva.constants import NO_GPU
-from eva.executor.execution_context import Context
+from evadb.constants import NO_GPU
+from evadb.executor.execution_context import Context
 
 
 class ExecutionContextTest(unittest.TestCase):
-    @patch("eva.executor.execution_context.ConfigurationManager")
-    @patch("eva.executor.execution_context.get_gpu_count")
-    @patch("eva.executor.execution_context.is_gpu_available")
+    @patch("evadb.executor.execution_context.ConfigurationManager")
+    @patch("evadb.executor.execution_context.get_gpu_count")
+    @patch("evadb.executor.execution_context.is_gpu_available")
     def test_CUDA_VISIBLE_DEVICES_gets_populated_from_config(
         self, gpu_check, get_gpu_count, cfm
     ):
         gpu_check.return_value = True
         get_gpu_count.return_value = 3
         cfm.return_value.get_value.return_value = [0, 1]
         context = Context()
 
         self.assertEqual(context.gpus, [0, 1])
 
-    @patch("eva.executor.execution_context.ConfigurationManager")
-    @patch("eva.executor.execution_context.os")
-    @patch("eva.executor.execution_context.get_gpu_count")
-    @patch("eva.executor.execution_context.is_gpu_available")
+    @patch("evadb.executor.execution_context.ConfigurationManager")
+    @patch("evadb.executor.execution_context.os")
+    @patch("evadb.executor.execution_context.get_gpu_count")
+    @patch("evadb.executor.execution_context.is_gpu_available")
     def test_CUDA_VISIBLE_DEVICES_gets_populated_from_environment_if_no_config(
         self, is_gpu, get_gpu_count, os, cfm
     ):
         is_gpu.return_value = True
         cfm.return_value.get_value.return_value = []
         get_gpu_count.return_value = 3
         os.environ.get.return_value = "0,1"
         context = Context()
         os.environ.get.assert_called_with("CUDA_VISIBLE_DEVICES", "")
 
         self.assertEqual(context.gpus, [0, 1])
 
-    @patch("eva.executor.execution_context.ConfigurationManager")
-    @patch("eva.executor.execution_context.os")
-    @patch("eva.executor.execution_context.get_gpu_count")
-    @patch("eva.executor.execution_context.is_gpu_available")
+    @patch("evadb.executor.execution_context.ConfigurationManager")
+    @patch("evadb.executor.execution_context.os")
+    @patch("evadb.executor.execution_context.get_gpu_count")
+    @patch("evadb.executor.execution_context.is_gpu_available")
     def test_CUDA_VISIBLE_DEVICES_should_be_empty_if_nothing_provided(
         self, gpu_check, get_gpu_count, os, cfm
     ):
         gpu_check.return_value = True
         get_gpu_count.return_value = 3
         cfm.return_value.get_value.return_value = []
         os.environ.get.return_value = ""
         context = Context()
         os.environ.get.assert_called_with("CUDA_VISIBLE_DEVICES", "")
 
         self.assertEqual(context.gpus, [])
 
-    @patch("eva.executor.execution_context.ConfigurationManager")
-    @patch("eva.executor.execution_context.os")
-    @patch("eva.executor.execution_context.is_gpu_available")
+    @patch("evadb.executor.execution_context.ConfigurationManager")
+    @patch("evadb.executor.execution_context.os")
+    @patch("evadb.executor.execution_context.is_gpu_available")
     def test_gpus_ignores_config_if_no_gpu_available(self, gpu_check, os, cfm):
         gpu_check.return_value = False
         cfm.return_value.get_value.return_value = [0, 1, 2]
         os.environ.get.return_value = "0,1,2"
         context = Context()
 
         self.assertEqual(context.gpus, [])
 
-    @patch("eva.executor.execution_context.ConfigurationManager")
-    @patch("eva.executor.execution_context.os")
-    @patch("eva.executor.execution_context.is_gpu_available")
+    @patch("evadb.executor.execution_context.ConfigurationManager")
+    @patch("evadb.executor.execution_context.os")
+    @patch("evadb.executor.execution_context.is_gpu_available")
     def test_gpu_device_should_return_NO_GPU_if_GPU_not_available(
         self, gpu_check, os, cfm
     ):
         gpu_check.return_value = True
         cfm.return_value.get_value.return_value = []
         os.environ.get.return_value = ""
         context = Context()
         os.environ.get.assert_called_with("CUDA_VISIBLE_DEVICES", "")
 
         self.assertEqual(context.gpu_device(), NO_GPU)
 
-    @patch("eva.executor.execution_context.ConfigurationManager")
-    @patch("eva.executor.execution_context.get_gpu_count")
-    @patch("eva.executor.execution_context.is_gpu_available")
+    @patch("evadb.executor.execution_context.ConfigurationManager")
+    @patch("evadb.executor.execution_context.get_gpu_count")
+    @patch("evadb.executor.execution_context.is_gpu_available")
     def test_should_return_random_gpu_ID_if_available(
         self, gpu_check, get_gpu_count, cfm
     ):
         gpu_check.return_value = True
         get_gpu_count.return_value = 1
         cfm.return_value.get_value.return_value = [0, 1, 2]
         context = Context()
```

### Comparing `evadb-0.2.6/test/executor/test_limit_executor.py` & `evadb-0.2.7/test/executor/test_limit_executor.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,23 +13,24 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from test.executor.utils import DummyExecutor
 
 import numpy as np
 import pandas as pd
+from mock import MagicMock
 
-from eva.executor.limit_executor import LimitExecutor
-from eva.executor.orderby_executor import OrderByExecutor
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.models.storage.batch import Batch
-from eva.parser.types import ParserOrderBySortType
-from eva.plan_nodes.limit_plan import LimitPlan
-from eva.plan_nodes.orderby_plan import OrderByPlan
+from evadb.executor.limit_executor import LimitExecutor
+from evadb.executor.orderby_executor import OrderByExecutor
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.models.storage.batch import Batch
+from evadb.parser.types import ParserOrderBySortType
+from evadb.plan_nodes.limit_plan import LimitPlan
+from evadb.plan_nodes.orderby_plan import OrderByPlan
 
 
 class LimitExecutorTest(unittest.TestCase):
     def test_should_return_smaller_num_rows(self):
         dfs = [
             pd.DataFrame(np.random.randint(0, 100, size=(100, 4)), columns=list("ABCD"))
             for _ in range(4)
@@ -37,15 +38,15 @@
 
         batches = [Batch(frames=df) for df in dfs]
 
         limit_value = 125
 
         plan = LimitPlan(ConstantValueExpression(limit_value))
 
-        limit_executor = LimitExecutor(plan)
+        limit_executor = LimitExecutor(MagicMock(), plan)
         limit_executor.append_child(DummyExecutor(batches))
         reduced_batches = list(limit_executor.exec())
 
         total_size = 0
         for batch in reduced_batches:
             total_size += len(batch)
 
@@ -67,15 +68,15 @@
         for batch in batches:
             previous_total_size += len(batch)
 
         limit_value = 500
 
         plan = LimitPlan(ConstantValueExpression(limit_value))
 
-        limit_executor = LimitExecutor(plan)
+        limit_executor = LimitExecutor(MagicMock(), plan)
         limit_executor.append_child(DummyExecutor(batches))
         reduced_batches = list(limit_executor.exec())
 
         after_total_size = 0
         for batch in reduced_batches:
             after_total_size += len(batch)
 
@@ -111,22 +112,22 @@
         plan = OrderByPlan(
             [
                 (TupleValueExpression(col_alias="A"), ParserOrderBySortType.ASC),
                 (TupleValueExpression(col_alias="B"), ParserOrderBySortType.DESC),
             ]
         )
 
-        orderby_executor = OrderByExecutor(plan)
+        orderby_executor = OrderByExecutor(MagicMock(), plan)
         orderby_executor.append_child(DummyExecutor(batches))
 
         sorted_batches = list(orderby_executor.exec())
 
         limit_value = 2
         plan = LimitPlan(ConstantValueExpression(limit_value))
-        limit_executor = LimitExecutor(plan)
+        limit_executor = LimitExecutor(MagicMock(), plan)
         limit_executor.append_child(DummyExecutor(sorted_batches))
         reduced_batches = list(limit_executor.exec())
 
         # merge everything into one batch
         aggregated_batch = Batch.concat(reduced_batches, copy=False)
         """
            A  B   C
```

### Comparing `evadb-0.2.6/test/executor/test_orderby_executor.py` & `evadb-0.2.7/test/executor/test_orderby_executor.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,20 +13,21 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from test.executor.utils import DummyExecutor
 
 import numpy as np
 import pandas as pd
+from mock import MagicMock
 
-from eva.executor.orderby_executor import OrderByExecutor
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.models.storage.batch import Batch
-from eva.parser.types import ParserOrderBySortType
-from eva.plan_nodes.orderby_plan import OrderByPlan
+from evadb.executor.orderby_executor import OrderByExecutor
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.models.storage.batch import Batch
+from evadb.parser.types import ParserOrderBySortType
+from evadb.plan_nodes.orderby_plan import OrderByPlan
 
 
 class OrderByExecutorTest(unittest.TestCase):
     def test_should_return_sorted_frames(self):
         """
         data (3 batches):
         'A' 'B' 'C'
@@ -53,15 +54,15 @@
         plan = OrderByPlan(
             [
                 (TupleValueExpression(col_alias="A"), ParserOrderBySortType.ASC),
                 (TupleValueExpression(col_alias="B"), ParserOrderBySortType.DESC),
             ]
         )
 
-        orderby_executor = OrderByExecutor(plan)
+        orderby_executor = OrderByExecutor(MagicMock(), plan)
         orderby_executor.append_child(DummyExecutor(batches))
 
         sorted_batches = list(orderby_executor.exec())
 
         """
            A  B   C
         0  1  5   6
```

### Comparing `evadb-0.2.6/test/executor/test_plan_executor.py` & `evadb-0.2.7/test/executor/test_plan_executor.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,35 +13,33 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from unittest.mock import MagicMock, patch
 
 import pandas as pd
 
-from eva.catalog.catalog_type import TableType
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.executor.create_executor import CreateExecutor
-from eva.executor.create_udf_executor import CreateUDFExecutor
-from eva.executor.drop_udf_executor import DropUDFExecutor
-from eva.executor.insert_executor import InsertExecutor
-from eva.executor.load_executor import LoadDataExecutor
-from eva.executor.plan_executor import PlanExecutor
-from eva.executor.pp_executor import PPExecutor
-from eva.executor.seq_scan_executor import SequentialScanExecutor
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.create_plan import CreatePlan
-from eva.plan_nodes.create_udf_plan import CreateUDFPlan
-from eva.plan_nodes.drop_plan import DropPlan
-from eva.plan_nodes.drop_udf_plan import DropUDFPlan
-from eva.plan_nodes.insert_plan import InsertPlan
-from eva.plan_nodes.load_data_plan import LoadDataPlan
-from eva.plan_nodes.pp_plan import PPScanPlan
-from eva.plan_nodes.rename_plan import RenamePlan
-from eva.plan_nodes.seq_scan_plan import SeqScanPlan
-from eva.plan_nodes.storage_plan import StoragePlan
+from evadb.catalog.catalog_type import TableType
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.executor.create_executor import CreateExecutor
+from evadb.executor.create_udf_executor import CreateUDFExecutor
+from evadb.executor.drop_object_executor import DropObjectExecutor, DropObjectPlan
+from evadb.executor.insert_executor import InsertExecutor
+from evadb.executor.load_executor import LoadDataExecutor
+from evadb.executor.plan_executor import PlanExecutor
+from evadb.executor.pp_executor import PPExecutor
+from evadb.executor.seq_scan_executor import SequentialScanExecutor
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.create_plan import CreatePlan
+from evadb.plan_nodes.create_udf_plan import CreateUDFPlan
+from evadb.plan_nodes.insert_plan import InsertPlan
+from evadb.plan_nodes.load_data_plan import LoadDataPlan
+from evadb.plan_nodes.pp_plan import PPScanPlan
+from evadb.plan_nodes.rename_plan import RenamePlan
+from evadb.plan_nodes.seq_scan_plan import SeqScanPlan
+from evadb.plan_nodes.storage_plan import StoragePlan
 
 
 class PlanExecutorTest(unittest.TestCase):
     def test_tree_structure_for_build_execution_tree(self):
         """
             Build an Abstract Plan with nodes:
          ß               root
@@ -63,17 +61,17 @@
         root_abs_plan.append_child(child_2_abs_plan)
         root_abs_plan.append_child(child_3_abs_plan)
 
         child_1_abs_plan.append_child(child_1_1_abs_plan)
 
         """Build Execution Tree and check the nodes
             are of the same type"""
-        root_abs_executor = PlanExecutor(plan=root_abs_plan)._build_execution_tree(
-            plan=root_abs_plan
-        )
+        root_abs_executor = PlanExecutor(
+            MagicMock(), plan=root_abs_plan
+        )._build_execution_tree(plan=root_abs_plan)
 
         # Root Nodes
         self.assertEqual(root_abs_plan.opr_type, root_abs_executor._node.opr_type)
 
         # Children of Root
         for child_abs, child_exec in zip(
             root_abs_plan.children, root_abs_executor.children
@@ -82,172 +80,154 @@
             # Grand Children of Root
             for gc_abs, gc_exec in zip(child_abs.children, child_exec.children):
                 self.assertEqual(gc_abs.opr_type, gc_exec._node.opr_type)
 
     def test_build_execution_tree_should_create_correct_exec_node(self):
         # SequentialScanExecutor
         plan = SeqScanPlan(MagicMock(), [])
-        executor = PlanExecutor(plan)._build_execution_tree(plan)
+        executor = PlanExecutor(MagicMock(), plan)._build_execution_tree(plan)
         self.assertIsInstance(executor, SequentialScanExecutor)
 
         # PPExecutor
         plan = PPScanPlan(MagicMock())
-        executor = PlanExecutor(plan)._build_execution_tree(plan)
+        executor = PlanExecutor(MagicMock(), plan)._build_execution_tree(plan)
         self.assertIsInstance(executor, PPExecutor)
 
         # CreateExecutor
         plan = CreatePlan(MagicMock(), [], False)
-        executor = PlanExecutor(plan)._build_execution_tree(plan)
+        executor = PlanExecutor(MagicMock(), plan)._build_execution_tree(plan)
         self.assertIsInstance(executor, CreateExecutor)
 
         # InsertExecutor
         plan = InsertPlan(0, [], [])
-        executor = PlanExecutor(plan)._build_execution_tree(plan)
+        executor = PlanExecutor(MagicMock(), plan)._build_execution_tree(plan)
         self.assertIsInstance(executor, InsertExecutor)
 
         # CreateUDFExecutor
         plan = CreateUDFPlan("test", False, [], [], MagicMock(), None)
-        executor = PlanExecutor(plan)._build_execution_tree(plan)
+        executor = PlanExecutor(MagicMock(), plan)._build_execution_tree(plan)
         self.assertIsInstance(executor, CreateUDFExecutor)
 
-        # DropUDFExecutor
-        plan = DropUDFPlan("test", False)
-        executor = PlanExecutor(plan)._build_execution_tree(plan)
-        self.assertIsInstance(executor, DropUDFExecutor)
+        # DropObjectExecutor
+        plan = DropObjectPlan(MagicMock(), "test", False)
+        executor = PlanExecutor(MagicMock(), plan)._build_execution_tree(plan)
+        self.assertIsInstance(executor, DropObjectExecutor)
 
         # LoadDataExecutor
         plan = LoadDataPlan(
             MagicMock(), MagicMock(), MagicMock(), MagicMock(), MagicMock()
         )
-        executor = PlanExecutor(plan)._build_execution_tree(plan)
+        executor = PlanExecutor(MagicMock(), plan)._build_execution_tree(plan)
         self.assertIsInstance(executor, LoadDataExecutor)
 
-    @patch("eva.executor.plan_executor.PlanExecutor._build_execution_tree")
-    @patch("eva.executor.plan_executor.PlanExecutor._clean_execution_tree")
-    def test_execute_plan_for_seq_scan_plan(self, mock_clean, mock_build):
+    @patch("evadb.executor.plan_executor.PlanExecutor._build_execution_tree")
+    def test_execute_plan_for_seq_scan_plan(self, mock_build):
         batch_list = [
             Batch(pd.DataFrame([1])),
             Batch(pd.DataFrame([2])),
             Batch(pd.DataFrame([3])),
         ]
 
         # SequentialScanExecutor
         tree = MagicMock(node=SeqScanPlan(None, []))
         tree.exec.return_value = batch_list
         mock_build.return_value = tree
 
-        actual = list(PlanExecutor(None).execute_plan())
+        actual = list(PlanExecutor(MagicMock(), None).execute_plan())
         mock_build.assert_called_once_with(None)
-        mock_clean.assert_called_once()
+
         tree.exec.assert_called_once()
         self.assertEqual(actual, batch_list)
 
-    @patch("eva.executor.plan_executor.PlanExecutor._build_execution_tree")
-    @patch("eva.executor.plan_executor.PlanExecutor._clean_execution_tree")
-    def test_execute_plan_for_pp_scan_plan(self, mock_clean, mock_build):
+    @patch("evadb.executor.plan_executor.PlanExecutor._build_execution_tree")
+    def test_execute_plan_for_pp_scan_plan(self, mock_build):
         batch_list = [
             Batch(pd.DataFrame([1])),
             Batch(pd.DataFrame([2])),
             Batch(pd.DataFrame([3])),
         ]
         # PPExecutor
         tree = MagicMock(node=PPScanPlan(None))
         tree.exec.return_value = batch_list
         mock_build.return_value = tree
 
-        actual = list(PlanExecutor(None).execute_plan())
+        actual = list(PlanExecutor(MagicMock(), None).execute_plan())
         mock_build.assert_called_once_with(None)
-        mock_clean.assert_called_once()
+
         tree.exec.assert_called_once()
         self.assertEqual(actual, batch_list)
 
-    @patch("eva.executor.plan_executor.PlanExecutor._build_execution_tree")
-    @patch("eva.executor.plan_executor.PlanExecutor._clean_execution_tree")
-    def test_execute_plan_for_create_insert_load_upload_plans(
-        self, mock_clean, mock_build
-    ):
+    @patch("evadb.executor.plan_executor.PlanExecutor._build_execution_tree")
+    def test_execute_plan_for_create_insert_load_upload_plans(self, mock_build):
         # CreateExecutor
         tree = MagicMock(node=CreatePlan(None, [], False))
         mock_build.return_value = tree
-        actual = list(PlanExecutor(None).execute_plan())
+        actual = list(PlanExecutor(MagicMock(), None).execute_plan())
         tree.exec.assert_called_once()
         mock_build.assert_called_once_with(None)
-        mock_clean.assert_called_once()
+
         self.assertEqual(actual, [])
 
         # InsertExecutor
         mock_build.reset_mock()
-        mock_clean.reset_mock()
+
         tree = MagicMock(node=InsertPlan(0, [], []))
         mock_build.return_value = tree
-        actual = list(PlanExecutor(None).execute_plan())
+        actual = list(PlanExecutor(MagicMock(), None).execute_plan())
         tree.exec.assert_called_once()
         mock_build.assert_called_once_with(None)
-        mock_clean.assert_called_once()
+
         self.assertEqual(actual, [])
 
         # CreateUDFExecutor
         mock_build.reset_mock()
-        mock_clean.reset_mock()
+
         tree = MagicMock(node=CreateUDFPlan(None, False, [], [], None))
         mock_build.return_value = tree
-        actual = list(PlanExecutor(None).execute_plan())
+        actual = list(PlanExecutor(MagicMock(), None).execute_plan())
         tree.exec.assert_called_once()
         mock_build.assert_called_once_with(None)
-        mock_clean.assert_called_once()
+
         self.assertEqual(actual, [])
 
         # LoadDataExecutor
         mock_build.reset_mock()
-        mock_clean.reset_mock()
+
         tree = MagicMock(node=LoadDataPlan(None, None, None, None, None))
         mock_build.return_value = tree
-        actual = list(PlanExecutor(None).execute_plan())
+        actual = list(PlanExecutor(MagicMock(), None).execute_plan())
         tree.exec.assert_called_once()
         mock_build.assert_called_once_with(None)
-        mock_clean.assert_called_once()
+
         self.assertEqual(actual, [])
 
-    @patch("eva.executor.plan_executor.PlanExecutor._build_execution_tree")
-    @patch("eva.executor.plan_executor.PlanExecutor._clean_execution_tree")
-    def test_execute_plan_for_rename_plans(self, mock_clean, mock_build):
+    @patch("evadb.executor.plan_executor.PlanExecutor._build_execution_tree")
+    def test_execute_plan_for_rename_plans(self, mock_build):
         # RenameExecutor
         tree = MagicMock(node=RenamePlan(None, None))
         mock_build.return_value = tree
-        actual = list(PlanExecutor(None).execute_plan())
+        actual = list(PlanExecutor(MagicMock(), None).execute_plan())
         tree.exec.assert_called_once()
         mock_build.assert_called_once_with(None)
-        mock_clean.assert_called_once()
+
         self.assertEqual(actual, [])
 
-    @patch("eva.executor.plan_executor.PlanExecutor._build_execution_tree")
-    @patch("eva.executor.plan_executor.PlanExecutor._clean_execution_tree")
-    def test_execute_plan_for_drop_plans(self, mock_clean, mock_build):
+    @patch("evadb.executor.plan_executor.PlanExecutor._build_execution_tree")
+    def test_execute_plan_for_drop_plans(self, mock_build):
         # DropExecutor
-        tree = MagicMock(node=DropPlan(None, None))
+        tree = MagicMock(node=DropObjectPlan(None, None, None))
         mock_build.return_value = tree
-        actual = list(PlanExecutor(None).execute_plan())
+        actual = list(PlanExecutor(MagicMock(), None).execute_plan())
         tree.exec.assert_called_once()
         mock_build.assert_called_once_with(None)
-        mock_clean.assert_called_once()
-        self.assertEqual(actual, [])
 
-        # DropUDFExecutor
-        mock_build.reset_mock()
-        mock_clean.reset_mock()
-        tree = MagicMock(node=DropUDFPlan(None, False))
-        mock_build.return_value = tree
-        actual = list(PlanExecutor(None).execute_plan())
-        tree.exec.assert_called_once()
-        mock_build.assert_called_once_with(None)
-        mock_clean.assert_called_once()
         self.assertEqual(actual, [])
 
     @unittest.skip("disk_based_storage_deprecated")
-    @patch("eva.executor.disk_based_storage_executor.Loader")
+    @patch("evadb.executor.disk_based_storage_executor.Loader")
     def test_should_return_the_new_path_after_execution(self, mock_class):
         class_instance = mock_class.return_value
 
         dummy_expr = type(
             "dummy_expr", (), {"evaluate": lambda x=None: [True, False, True]}
         )
```

### Comparing `evadb-0.2.6/test/executor/test_pp_executor.py` & `evadb-0.2.7/test/executor/utils.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,37 +1,26 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-import unittest
-from test.executor.utils import DummyExecutor
-from test.util import create_dataframe
+from typing import List
 
-from eva.executor.pp_executor import PPExecutor
-from eva.models.storage.batch import Batch
+from evadb.models.storage.batch import Batch
 
 
-class PPScanExecutorTest(unittest.TestCase):
-    def test_should_return_only_frames_satisfy_predicate(self):
-        dataframe = create_dataframe(3)
-        batch = Batch(frames=dataframe)
-        expression = type(
-            "AbstractExpression", (), {"evaluate": lambda x: [False, False, True]}
-        )
+class DummyExecutor:
+    def __init__(self, batch_list: List[Batch]):
+        self.batch_list = batch_list
 
-        plan = type("PPScanPlan", (), {"predicate": expression})
-        predicate_executor = PPExecutor(plan)
-        predicate_executor.append_child(DummyExecutor([batch]))
-
-        expected = batch[[2]]
-        filtered = list(predicate_executor.exec())[0]
-        self.assertEqual(expected, filtered)
+    def exec(self):
+        for batch in self.batch_list:
+            yield batch
```

### Comparing `evadb-0.2.6/test/executor/test_sample_executor.py` & `evadb-0.2.7/test/executor/test_sample_executor.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,19 +13,20 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from test.executor.utils import DummyExecutor
 
 import numpy as np
 import pandas as pd
+from mock import MagicMock
 
-from eva.executor.sample_executor import SampleExecutor
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.models.storage.batch import Batch
-from eva.plan_nodes.sample_plan import SamplePlan
+from evadb.executor.sample_executor import SampleExecutor
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.models.storage.batch import Batch
+from evadb.plan_nodes.sample_plan import SamplePlan
 
 
 class SampleExecutorTest(unittest.TestCase):
     def test_should_return_smaller_num_rows(self):
         dfs = [
             pd.DataFrame(np.random.randint(0, 100, size=(100, 4)), columns=list("ABCD"))
             for _ in range(4)
@@ -33,15 +34,15 @@
 
         batches = [Batch(frames=df) for df in dfs]
 
         sample_value = 3
 
         plan = SamplePlan(ConstantValueExpression(sample_value))
 
-        sample_executor = SampleExecutor(plan)
+        sample_executor = SampleExecutor(MagicMock(), plan)
         sample_executor.append_child(DummyExecutor(batches))
         reduced_batches = list(sample_executor.exec())
 
         original = Batch.concat(batches)
         filter = range(0, len(original), sample_value)
         original = original._get_frames_from_indices(filter)
         original = Batch.concat([original])
```

### Comparing `evadb-0.2.6/test/executor/test_seq_scan_executor.py` & `evadb-0.2.7/test/executor/test_seq_scan_executor.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,65 +13,76 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from test.executor.utils import DummyExecutor
 from test.util import create_dataframe
 
 import pandas as pd
+from mock import MagicMock
 
-from eva.executor.seq_scan_executor import SequentialScanExecutor
-from eva.models.storage.batch import Batch
+from evadb.executor.seq_scan_executor import SequentialScanExecutor
+from evadb.models.storage.batch import Batch
 
 
 class SeqScanExecutorTest(unittest.TestCase):
     def test_should_return_only_frames_satisfy_predicate(self):
         dataframe = create_dataframe(3)
         batch = Batch(frames=dataframe)
         expression = type(
             "AbstractExpression",
             (),
-            {"evaluate": lambda x: Batch(pd.DataFrame([False, False, True]))},
+            {
+                "evaluate": lambda x: Batch(pd.DataFrame([False, False, True])),
+                "find_all": lambda expr: [],
+            },
         )
 
         plan = type(
             "ScanPlan", (), {"predicate": expression, "columns": None, "alias": None}
         )
-        predicate_executor = SequentialScanExecutor(plan)
+        predicate_executor = SequentialScanExecutor(MagicMock(), plan)
         predicate_executor.append_child(DummyExecutor([batch]))
 
         expected = Batch(batch[[2]].frames)
         filtered = list(predicate_executor.exec())[0]
         self.assertEqual(expected, filtered)
 
     def test_should_return_all_frames_when_no_predicate_is_applied(self):
         dataframe = create_dataframe(3)
 
         batch = Batch(frames=dataframe)
 
         plan = type("ScanPlan", (), {"predicate": None, "columns": None, "alias": None})
-        predicate_executor = SequentialScanExecutor(plan)
+        predicate_executor = SequentialScanExecutor(MagicMock(), plan)
         predicate_executor.append_child(DummyExecutor([batch]))
 
         filtered = list(predicate_executor.exec())[0]
         self.assertEqual(batch, filtered)
 
     def test_should_return_projected_columns(self):
         dataframe = create_dataframe(3)
 
         batch = Batch(frames=dataframe)
         proj_batch = Batch(frames=pd.DataFrame(dataframe["data"]))
         expression = [
             type(
                 "AbstractExpression",
                 (),
-                {"evaluate": lambda x: Batch(pd.DataFrame(x.frames["data"]))},
+                {
+                    "evaluate": lambda x: Batch(pd.DataFrame(x.frames["data"])),
+                    "find_all": lambda expr: [],
+                },
             )
         ]
 
         plan = type(
             "ScanPlan", (), {"predicate": None, "columns": expression, "alias": None}
         )
-        proj_executor = SequentialScanExecutor(plan)
+        proj_executor = SequentialScanExecutor(MagicMock(), plan)
         proj_executor.append_child(DummyExecutor([batch]))
 
         actual = list(proj_executor.exec())[0]
         self.assertEqual(proj_batch, actual)
+
+
+if __name__ == "__main__":
+    unittest.main()
```

### Comparing `evadb-0.2.6/test/executor/utils.py` & `evadb-0.2.7/evadb/__init__.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from typing import List
+from evadb.interfaces.relational.db import (  # noqa: E402,F401
+    EVADBConnection,
+    EVADBCursor,
+    connect,
+)
+from evadb.interfaces.relational.relation import EVADBQuery  # noqa: E402,F401
 
-from eva.models.storage.batch import Batch
+from .version import VERSION as __version__  # noqa: E402,F401
 
+PYTHON_APIS = ["connect"]
 
-class DummyExecutor:
-    def __init__(self, batch_list: List[Batch]):
-        self.batch_list = batch_list
-
-    def exec(self):
-        for batch in self.batch_list:
-            yield batch
+__all__ = list(PYTHON_APIS)
```

### Comparing `evadb-0.2.6/test/expression/__init__.py` & `evadb-0.2.7/test/interfaces/relational/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/expression/test_abstract_expression.py` & `evadb-0.2.7/test/expression/test_abstract_expression.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,19 +12,19 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 from mock import patch
 
-from eva.expression.abstract_expression import AbstractExpression, ExpressionType
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.logical_expression import LogicalExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
+from evadb.expression.abstract_expression import AbstractExpression, ExpressionType
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.logical_expression import LogicalExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
 
 
 class AbstractExpressionsTest(unittest.TestCase):
     def test_walk(self):
         const_exp1 = ConstantValueExpression(1)
         const_exp2 = ConstantValueExpression(1)
         const_exp3 = ConstantValueExpression(0)
```

### Comparing `evadb-0.2.6/test/expression/test_aggregation.py` & `evadb-0.2.7/test/expression/test_aggregation.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,18 +14,18 @@
 # limitations under the License.
 import unittest
 
 import numpy as np
 import pandas as pd
 import pytest
 
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.aggregation_expression import AggregationExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.models.storage.batch import Batch
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.aggregation_expression import AggregationExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.models.storage.batch import Batch
 
 
 class AggregationExpressionsTest(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
     def test_aggregation_first(self):
```

### Comparing `evadb-0.2.6/test/expression/test_arithmetic.py` & `evadb-0.2.7/test/expression/test_arithmetic.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,18 +12,18 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 import pandas as pd
 
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.arithmetic_expression import ArithmeticExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.models.storage.batch import Batch
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.arithmetic_expression import ArithmeticExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.models.storage.batch import Batch
 
 
 class ArithmeticExpressionsTest(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.batch = Batch(pd.DataFrame([None]))
```

### Comparing `evadb-0.2.6/test/expression/test_comparison.py` & `evadb-0.2.7/test/expression/test_comparison.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,19 +12,19 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 import pandas as pd
 
-from eva.catalog.catalog_type import ColumnType
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.models.storage.batch import Batch
+from evadb.catalog.catalog_type import ColumnType
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.models.storage.batch import Batch
 
 
 class ComparisonExpressionsTest(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         # create a dummy batch
         self.batch = Batch(pd.DataFrame([0]))
```

### Comparing `evadb-0.2.6/test/expression/test_expression_tree.py` & `evadb-0.2.7/test/expression/test_expression_tree.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.aggregation_expression import AggregationExpression
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.function_expression import FunctionExpression
-from eva.expression.logical_expression import LogicalExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.aggregation_expression import AggregationExpression
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.function_expression import FunctionExpression
+from evadb.expression.logical_expression import LogicalExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
 
 
 class ExpressionEvaluationTest(unittest.TestCase):
     def test_if_expr_tree_is_equal(self):
         const_exp1 = ConstantValueExpression(0)
         const_exp2 = ConstantValueExpression(0)
         columnName1 = TupleValueExpression(col_name="DATA")
```

### Comparing `evadb-0.2.6/test/expression/test_expression_utils.py` & `evadb-0.2.7/test/expression/test_expression_utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,27 +11,27 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from unittest.mock import Mock
 
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.arithmetic_expression import ArithmeticExpression
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.expression_utils import (
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.arithmetic_expression import ArithmeticExpression
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.expression_utils import (
     conjunction_list_to_expression_tree,
     contains_single_column,
     extract_range_list_from_comparison_expr,
     extract_range_list_from_predicate,
     is_simple_predicate,
 )
-from eva.expression.logical_expression import LogicalExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
+from evadb.expression.logical_expression import LogicalExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
 
 
 class ExpressionUtilsTest(unittest.TestCase):
     def gen_cmp_expr(
         self,
         val,
         expr_type=ExpressionType.COMPARE_GREATER,
```

### Comparing `evadb-0.2.6/test/expression/test_function_expression.py` & `evadb-0.2.7/test/expression/test_function_expression.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,23 +13,23 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 import pandas as pd
 from mock import MagicMock, Mock, patch
 
-from eva.constants import NO_GPU
-from eva.expression.function_expression import FunctionExpression
-from eva.models.storage.batch import Batch
-from eva.parser.alias import Alias
-from eva.udfs.gpu_compatible import GPUCompatible
+from evadb.constants import NO_GPU
+from evadb.expression.function_expression import FunctionExpression
+from evadb.models.storage.batch import Batch
+from evadb.parser.alias import Alias
+from evadb.udfs.gpu_compatible import GPUCompatible
 
 
 class FunctionExpressionTest(unittest.TestCase):
-    @patch("eva.expression.function_expression.Context")
+    @patch("evadb.expression.function_expression.Context")
     def test_function_move_the_device_to_gpu_if_compatible(self, context):
         context_instance = context.return_value
         mock_function = MagicMock(spec=GPUCompatible)
         gpu_mock_function = Mock(return_value=pd.DataFrame())
         gpu_device_id = "2"
 
         mock_function.to_device.return_value = gpu_mock_function
@@ -49,15 +49,15 @@
         expression = FunctionExpression(
             lambda: mock_function, name="test", alias=Alias("func_expr")
         )
         input_batch = Batch(frames=pd.DataFrame())
         expression.evaluate(input_batch)
         mock_function.assert_called()
 
-    @patch("eva.expression.function_expression.Context")
+    @patch("evadb.expression.function_expression.Context")
     def test_should_execute_same_function_if_no_gpu(self, context):
         context_instance = context.return_value
         mock_function = MagicMock(spec=GPUCompatible, return_value=pd.DataFrame())
 
         context_instance.gpu_device.return_value = NO_GPU
 
         expression = FunctionExpression(
```

### Comparing `evadb-0.2.6/test/expression/test_logical.py` & `evadb-0.2.7/test/expression/test_logical.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,20 +13,20 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 import pandas as pd
 from mock import Mock
 
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.logical_expression import LogicalExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.models.storage.batch import Batch
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.logical_expression import LogicalExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.models.storage.batch import Batch
 
 
 class LogicalExpressionsTest(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         # create a dummy batch
         self.batch = Batch(pd.DataFrame([0]))
```

### Comparing `evadb-0.2.6/test/integration_tests/__init__.py` & `evadb-0.2.7/test/models/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/integration_tests/test_array_count.py` & `evadb-0.2.7/test/integration_tests/test_array_count.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,78 +13,79 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from test.util import (
     NUM_FRAMES,
     create_sample_video,
     file_remove,
+    get_evadb_for_testing,
     load_udfs_for_testing,
     shutdown_ray,
 )
 
 import pandas as pd
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
 
 
 @pytest.mark.notparallel
 class ArrayCountTests(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        CatalogManager().reset()
+        cls.evadb = get_evadb_for_testing()
+        cls.evadb.catalog().reset()
         video_file_path = create_sample_video(NUM_FRAMES)
         load_query = f"LOAD VIDEO '{video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(load_query)
-        load_udfs_for_testing(mode="debug")
+        execute_query_fetch_all(cls.evadb, load_query)
+        load_udfs_for_testing(cls.evadb, mode="debug")
 
     @classmethod
     def tearDownClass(cls):
         shutdown_ray()
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MyVideo;")
         file_remove("dummy.avi")
 
     # integration test
 
     def test_should_load_and_select_using_udf_video(self):
         # Equality test
         select_query = "SELECT id,DummyObjectDetector(data) FROM MyVideo \
             WHERE DummyObjectDetector(data).label = ['person'] ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected = [
             {"myvideo.id": i * 2, "dummyobjectdetector.label": ["person"]}
             for i in range(NUM_FRAMES // 2)
         ]
         expected_batch = Batch(frames=pd.DataFrame(expected))
         self.assertEqual(actual_batch, expected_batch)
 
         # Contain test
         select_query = "SELECT id, DummyObjectDetector(data) FROM MyVideo \
             WHERE DummyObjectDetector(data).label <@ ['person'] ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(actual_batch, expected_batch)
 
         select_query = "SELECT id FROM MyVideo WHERE \
             DummyMultiObjectDetector(data).labels @> ['person'] ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected = [{"myvideo.id": i} for i in range(0, NUM_FRAMES, 3)]
         expected_batch = Batch(frames=pd.DataFrame(expected))
         self.assertEqual(actual_batch, expected_batch)
 
     def test_array_count_integration_test(self):
         select_query = """SELECT id FROM MyVideo WHERE
             ArrayCount(DummyMultiObjectDetector(data).labels, 'person') = 2
             ORDER BY id;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected = [{"myvideo.id": i} for i in range(0, NUM_FRAMES, 3)]
         expected_batch = Batch(frames=pd.DataFrame(expected))
         self.assertEqual(actual_batch, expected_batch)
 
         select_query = """SELECT id FROM MyVideo
             WHERE ArrayCount(DummyObjectDetector(data).label, 'bicycle') = 1
             ORDER BY id;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected = [{"myvideo.id": i} for i in range(1, NUM_FRAMES, 2)]
         expected_batch = Batch(frames=pd.DataFrame(expected))
         self.assertEqual(actual_batch, expected_batch)
```

### Comparing `evadb-0.2.6/test/integration_tests/test_chatgpt.py` & `evadb-0.2.7/test/integration_tests/test_create_table_executor.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,113 +1,105 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
-
 import unittest
-from test.markers import ray_skip_marker
-from unittest.mock import MagicMock
+from test.util import (
+    DummyObjectDetector,
+    create_sample_video,
+    file_remove,
+    get_evadb_for_testing,
+    load_udfs_for_testing,
+    shutdown_ray,
+)
 
 import pandas as pd
-from mock import patch
+import pytest
+
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.executor.executor_utils import ExecutorError
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
+
+NUM_FRAMES = 10
+
+
+class CreateTableTest(unittest.TestCase):
+    @classmethod
+    def setUpClass(cls):
+        cls.evadb = get_evadb_for_testing()
+        # reset the catalog manager before running each test
+        cls.evadb.catalog().reset()
+        video_file_path = create_sample_video()
+        load_query = f"LOAD VIDEO '{video_file_path}' INTO MyVideo;"
+        execute_query_fetch_all(cls.evadb, load_query)
+        ua_detrac = f"{EVA_ROOT_DIR}/data/ua_detrac/ua_detrac.mp4"
+        execute_query_fetch_all(cls.evadb, f"LOAD VIDEO '{ua_detrac}' INTO UATRAC;")
+        load_udfs_for_testing(cls.evadb)
+
+    @classmethod
+    def tearDownClass(cls):
+        file_remove("dummy.avi")
+        file_remove("ua_detrac.mp4")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS UATRAC;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS uadtrac_fastRCNN;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS dummy_table;")
+        shutdown_ray()
+
+    def _test_currently_cannot_create_boolean_table(self):
+        query = """ CREATE TABLE BooleanTable( A BOOLEAN);"""
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.executor.executor_utils import ExecutorError
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
-
-
-def create_dummy_csv_file() -> str:
-    config = ConfigurationManager()
-    tmp_dir_from_config = config.get_value("storage", "tmp_dir")
-
-    df_dict = {
-        "prompt": ["summarize"],
-        "content": [
-            "There are times when the night sky glows with bands of color. The bands may begin as cloud shapes and then spread into a great arc across the entire sky. They may fall in folds like a curtain drawn across the heavens. The lights usually grow brighter, then suddenly dim. During this time the sky glows with pale yellow, pink, green, violet, blue, and red. These lights are called the Aurora Borealis. Some people call them the Northern Lights. Scientists have been watching them for hundreds of years. They are not quite sure what causes them"
-        ],
-    }
-    df = pd.DataFrame(df_dict, columns=["id", "prompt", "content"])
-
-    dummy_file_path = tmp_dir_from_config + "/queries.csv"
-    df.to_csv(dummy_file_path)
-
-    return dummy_file_path
-
-
-class ChatGPTTest(unittest.TestCase):
-    def setUp(self) -> None:
-        CatalogManager().reset()
-        create_table_query = """CREATE TABLE IF NOT EXISTS MyTextCSV (
-                id INTEGER UNIQUE,
-                prompt TEXT (100),
-                content TEXT (100)
-            );"""
-        execute_query_fetch_all(create_table_query)
-
-        self.csv_file_path = create_dummy_csv_file()
-
-        csv_query = f"""LOAD CSV '{self.csv_file_path}' INTO MyTextCSV;"""
-        execute_query_fetch_all(csv_query)
-
-    def tearDown(self) -> None:
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyTextCSV;")
-
-    @ray_skip_marker
-    @patch("eva.udfs.chatgpt.openai.ChatCompletion.create")
-    def test_openai_chat_completion_udf(self, mock_req):
-        # set dummy api key
-        ConfigurationManager().update_value("third_party", "openai_api_key", "my_key")
-
-        udf_name = "OpenAIChatCompletion"
-        execute_query_fetch_all(f"DROP UDF IF EXISTS {udf_name};")
-
-        create_udf_query = f"""CREATE UDF {udf_name}
-            IMPL 'eva/udfs/chatgpt.py'
-            'model' 'gpt-3.5-turbo'
+        with self.assertRaises(ExecutorError):
+            execute_query_fetch_all(self.evadb, query)
+
+    # @ray_skip_marker
+    def test_should_create_table_from_select(self):
+        create_query = """CREATE TABLE dummy_table
+            AS SELECT id, DummyObjectDetector(data).label FROM MyVideo;
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_query)
 
-        mock_response_obj = MagicMock()
-        mock_response_obj.message.content = "mock message"
-        mock_req.return_value.choices = [mock_response_obj]
-
-        gpt_query = f"SELECT {udf_name}(prompt, content) FROM MyTextCSV;"
-        output_batch = execute_query_fetch_all(gpt_query)
-        expected_output = Batch(
-            pd.DataFrame(["mock message"], columns=["openaichatcompletion.response"])
+        select_query = "SELECT id, label FROM dummy_table;"
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
+        actual_batch.sort()
+
+        labels = DummyObjectDetector().labels
+        expected = [
+            {"dummy_table.id": i, "dummy_table.label": [labels[1 + i % 2]]}
+            for i in range(NUM_FRAMES)
+        ]
+        expected_batch = Batch(frames=pd.DataFrame(expected))
+        self.assertEqual(actual_batch, expected_batch)
+
+    @pytest.mark.torchtest
+    def test_should_create_table_from_select_lateral_join(self):
+        select_query = (
+            "SELECT id, label, bbox FROM UATRAC JOIN LATERAL "
+            "Yolo(data) AS T(label, bbox, score) WHERE id < 5;"
         )
-        self.assertEqual(output_batch, expected_output)
+        query = "CREATE TABLE IF NOT EXISTS " f"uadtrac_fastRCNN AS {select_query};"
+        execute_query_fetch_all(self.evadb, query)
 
-        # test without providing model name
-        execute_query_fetch_all(f"DROP UDF IF EXISTS {udf_name};")
-        create_udf_query = f"""CREATE UDF {udf_name}
-            IMPL 'eva/udfs/chatgpt.py'
-        """
-        execute_query_fetch_all(create_udf_query)
+        select_view_query = "SELECT id, label, bbox FROM uadtrac_fastRCNN"
+        actual_batch = execute_query_fetch_all(self.evadb, select_view_query)
+        actual_batch.sort()
+
+        self.assertEqual(len(actual_batch), 5)
+        # non-trivial test case
+        res = actual_batch.frames
+        for idx in res.index:
+            self.assertTrue("car" in res["uadtrac_fastrcnn.label"][idx])
 
-        gpt_query = f"SELECT {udf_name}(prompt, content) FROM MyTextCSV;"
-        output_batch = execute_query_fetch_all(gpt_query)
-        self.assertEqual(output_batch, expected_output)
-
-    def test_gpt_udf_no_key(self):
-        ConfigurationManager().update_value("third_party", "openai_api_key", "")
-        udf_name = "ChatGPT"
-        execute_query_fetch_all(f"DROP UDF IF EXISTS {udf_name};")
 
-        with self.assertRaises(ExecutorError):
-            create_udf_query = f"""CREATE UDF {udf_name}
-            IMPL 'eva/udfs/chatgpt.py'
-            """
-            execute_query_fetch_all(create_udf_query)
+if __name__ == "__main__":
+    unittest.main()
```

### Comparing `evadb-0.2.6/test/integration_tests/test_create_index_executor.py` & `evadb-0.2.7/test/integration_tests/test_create_index_executor.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,160 +1,156 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from pathlib import Path
-from test.util import load_udfs_for_testing
+from test.util import get_evadb_for_testing, load_udfs_for_testing
 
 import faiss
 import numpy as np
 import pandas as pd
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import VectorStoreType
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
-from eva.storage.storage_engine import StorageEngine
+from evadb.catalog.catalog_type import VectorStoreType
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
+from evadb.storage.storage_engine import StorageEngine
 
 
 @pytest.mark.notparallel
 class CreateIndexTest(unittest.TestCase):
     def _index_save_path(self):
         return str(
-            Path(ConfigurationManager().get_value("storage", "index_dir"))
+            Path(self.evadb.config.get_value("storage", "index_dir"))
             / Path("{}_{}.index".format("FAISS", "testCreateIndexName"))
         )
 
     @classmethod
     def setUpClass(cls):
-        # Bootstrap configuration manager.
-        ConfigurationManager()
-
-        # Reset catalog.
-        CatalogManager().reset()
-        load_udfs_for_testing(mode="debug")
+        cls.evadb = get_evadb_for_testing()
+        load_udfs_for_testing(cls.evadb, mode="debug")
 
         # Create feature vector table and raw input table.
         feat1 = np.array([[0, 0, 0]]).astype(np.float32)
         feat2 = np.array([[100, 100, 100]]).astype(np.float32)
         feat3 = np.array([[200, 200, 200]]).astype(np.float32)
 
         input1 = np.array([[0, 0, 0]]).astype(np.uint8)
         input2 = np.array([[100, 100, 100]]).astype(np.uint8)
         input3 = np.array([[200, 200, 200]]).astype(np.uint8)
 
         # Create table.
         execute_query_fetch_all(
+            cls.evadb,
             """create table if not exists testCreateIndexFeatTable (
                 feat NDARRAY FLOAT32(1,3)
-            );"""
+            );""",
         )
         execute_query_fetch_all(
+            cls.evadb,
             """create table if not exists testCreateIndexInputTable (
                 input NDARRAY UINT8(1,3)
-            );"""
+            );""",
         )
 
         # Create pandas dataframe.
         feat_batch_data = Batch(
             pd.DataFrame(
                 data={
                     "feat": [feat1, feat2, feat3],
                 }
             )
         )
-        feat_tb_entry = CatalogManager().get_table_catalog_entry(
+        feat_tb_entry = cls.evadb.catalog().get_table_catalog_entry(
             "testCreateIndexFeatTable"
         )
-        storage_engine = StorageEngine.factory(feat_tb_entry)
+        storage_engine = StorageEngine.factory(cls.evadb, feat_tb_entry)
         storage_engine.write(feat_tb_entry, feat_batch_data)
 
         input_batch_data = Batch(
             pd.DataFrame(
                 data={
                     "input": [input1, input2, input3],
                 }
             )
         )
-        input_tb_entry = CatalogManager().get_table_catalog_entry(
+        input_tb_entry = cls.evadb.catalog().get_table_catalog_entry(
             "testCreateIndexInputTable"
         )
         storage_engine.write(input_tb_entry, input_batch_data)
 
     @classmethod
     def tearDownClass(cls):
         query = "DROP TABLE testCreateIndexFeatTable;"
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(cls.evadb, query)
         query = "DROP TABLE testCreateIndexInputTable;"
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(cls.evadb, query)
 
     def test_should_create_index_faiss(self):
         query = "CREATE INDEX testCreateIndexName ON testCreateIndexFeatTable (feat) USING FAISS;"
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         # Test index catalog.
-        index_catalog_entry = CatalogManager().get_index_catalog_entry_by_name(
+        index_catalog_entry = self.evadb.catalog().get_index_catalog_entry_by_name(
             "testCreateIndexName"
         )
         self.assertEqual(index_catalog_entry.type, VectorStoreType.FAISS)
         self.assertEqual(
             index_catalog_entry.save_file_path,
             self._index_save_path(),
         )
         self.assertEqual(
             index_catalog_entry.udf_signature,
             None,
         )
 
         # Test referenced column.
-        feat_table_entry = CatalogManager().get_table_catalog_entry(
+        feat_table_entry = self.evadb.catalog().get_table_catalog_entry(
             "testCreateIndexFeatTable"
         )
         feat_column = [col for col in feat_table_entry.columns if col.name == "feat"][0]
         self.assertEqual(index_catalog_entry.feat_column_id, feat_column.row_id)
         self.assertEqual(index_catalog_entry.feat_column, feat_column)
 
         # Test on disk index.
         index = faiss.read_index(index_catalog_entry.save_file_path)
         distance, row_id = index.search(np.array([[0, 0, 0]]).astype(np.float32), 1)
         self.assertEqual(distance[0][0], 0)
         self.assertEqual(row_id[0][0], 1)
 
         # Cleanup.
-        CatalogManager().drop_index_catalog_entry("testCreateIndexName")
+        self.evadb.catalog().drop_index_catalog_entry("testCreateIndexName")
 
     def test_should_create_index_with_udf(self):
         query = "CREATE INDEX testCreateIndexName ON testCreateIndexInputTable (DummyFeatureExtractor(input)) USING FAISS;"
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         # Test index udf signature.
-        index_catalog_entry = CatalogManager().get_index_catalog_entry_by_name(
+        index_catalog_entry = self.evadb.catalog().get_index_catalog_entry_by_name(
             "testCreateIndexName"
         )
         self.assertEqual(index_catalog_entry.type, VectorStoreType.FAISS)
         self.assertEqual(
             index_catalog_entry.save_file_path,
             self._index_save_path(),
         )
 
         # Test referenced column.
-        input_table_entry = CatalogManager().get_table_catalog_entry(
+        input_table_entry = self.evadb.catalog().get_table_catalog_entry(
             "testCreateIndexInputTable"
         )
         input_column = [
             col for col in input_table_entry.columns if col.name == "input"
         ][0]
         self.assertEqual(index_catalog_entry.feat_column_id, input_column.row_id)
         self.assertEqual(index_catalog_entry.feat_column, input_column)
@@ -162,8 +158,8 @@
         # Test on disk index.
         index = faiss.read_index(index_catalog_entry.save_file_path)
         distance, row_id = index.search(np.array([[0, 0, 0]]).astype(np.float32), 1)
         self.assertEqual(distance[0][0], 0)
         self.assertEqual(row_id[0][0], 1)
 
         # Cleanup.
-        CatalogManager().drop_index_catalog_entry("testCreateIndexName")
+        self.evadb.catalog().drop_index_catalog_entry("testCreateIndexName")
```

### Comparing `evadb-0.2.6/test/integration_tests/test_create_table_executor.py` & `evadb-0.2.7/test/integration_tests/test_explain_executor.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,109 +1,91 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-
-import pytest
 from test.util import (
-    DummyObjectDetector,
     create_sample_video,
     file_remove,
+    get_evadb_for_testing,
     load_udfs_for_testing,
-    shutdown_ray,
 )
 
-import pandas as pd
+import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.executor.executor_utils import ExecutorError
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.optimizer.plan_generator import PlanGenerator
+from evadb.optimizer.rules.rules import (
+    EmbedFilterIntoGet,
+    LogicalInnerJoinCommutativity,
+    XformLateralJoinToLinearFlow,
+)
+from evadb.optimizer.rules.rules_manager import RulesManager, disable_rules
+from evadb.server.command_handler import execute_query_fetch_all
 
 NUM_FRAMES = 10
 
 
-class CreateTableTest(unittest.TestCase):
+@pytest.mark.notparallel
+class ExplainExecutorTest(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        # reset the catalog manager before running each test
-        CatalogManager().reset()
-        video_file_path = create_sample_video()
+        cls.evadb = get_evadb_for_testing()
+        cls.evadb.catalog().reset()
+        video_file_path = create_sample_video(NUM_FRAMES)
         load_query = f"LOAD VIDEO '{video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(load_query)
-        ua_detrac = f"{EVA_ROOT_DIR}/data/ua_detrac/ua_detrac.mp4"
-        execute_query_fetch_all(f"LOAD VIDEO '{ua_detrac}' INTO UATRAC;")
-        load_udfs_for_testing()
+        execute_query_fetch_all(cls.evadb, load_query)
+        load_udfs_for_testing(cls.evadb, mode="debug")
 
     @classmethod
     def tearDownClass(cls):
-        shutdown_ray()
         file_remove("dummy.avi")
-        file_remove("ua_detrac.mp4")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS UATRAC;")
-
-    def setUp(self):
-        execute_query_fetch_all("DROP TABLE IF EXISTS dummy_table;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS uadtrac_fastRCNN;")
-
-    def tearDown(self):
-        execute_query_fetch_all("DROP TABLE IF EXISTS dummy_table;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS uadtrac_fastRCNN;")
-
-    def test_currently_cannot_create_boolean_table(self):
-        query = """ CREATE TABLE BooleanTable( A BOOLEAN);"""
-
-        with self.assertRaises(ExecutorError):
-            execute_query_fetch_all(query)
-
-    def test_should_create_table_from_select(self):
-        create_query = """CREATE TABLE dummy_table
-            AS SELECT id, DummyObjectDetector(data).label FROM MyVideo;
-        """
-        execute_query_fetch_all(create_query)
-
-        select_query = "SELECT id, label FROM dummy_table;"
-        actual_batch = execute_query_fetch_all(select_query)
-        actual_batch.sort()
-
-        labels = DummyObjectDetector().labels
-        expected = [
-            {"dummy_table.id": i, "dummy_table.label": [labels[1 + i % 2]]}
-            for i in range(NUM_FRAMES)
-        ]
-        expected_batch = Batch(frames=pd.DataFrame(expected))
-        self.assertEqual(actual_batch, expected_batch)
-
-    @pytest.mark.torchtest
-    def test_should_create_table_from_select_lateral_join(self):
-        select_query = (
-            "SELECT id, label, bbox FROM UATRAC JOIN LATERAL "
-            "Yolo(data) AS T(label, bbox, score) WHERE id < 5;"
-        )
-        query = (
-            "CREATE TABLE IF NOT EXISTS "
-            f"uadtrac_fastRCNN AS {select_query};"
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MyVideo;")
+
+    def test_explain_simple_select(self):
+        select_query = "EXPLAIN SELECT id, data FROM MyVideo"
+        batch = execute_query_fetch_all(self.evadb, select_query)
+        expected_output = (
+            """|__ ProjectPlan\n    |__ SeqScanPlan\n        |__ StoragePlan\n"""
         )
-        execute_query_fetch_all(query)
+        self.assertEqual(batch.frames[0][0], expected_output)
+        rules_manager = RulesManager(self.evadb.config)
+        with disable_rules(rules_manager, [XformLateralJoinToLinearFlow()]):
+            custom_plan_generator = PlanGenerator(self.evadb, rules_manager)
+            select_query = "EXPLAIN SELECT id, data FROM MyVideo JOIN LATERAL DummyObjectDetector(data) AS T ;"
+            batch = execute_query_fetch_all(
+                self.evadb, select_query, plan_generator=custom_plan_generator
+            )
+            expected_output = """|__ ProjectPlan\n    |__ LateralJoinPlan\n        |__ SeqScanPlan\n            |__ StoragePlan\n        |__ FunctionScanPlan\n"""
+            self.assertEqual(batch.frames[0][0], expected_output)
+
+        # Disable more rules
+        rules_manager = RulesManager(self.evadb.config)
+        with disable_rules(
+            rules_manager,
+            [
+                XformLateralJoinToLinearFlow(),
+                EmbedFilterIntoGet(),
+                LogicalInnerJoinCommutativity(),
+            ],
+        ):
+            custom_plan_generator = PlanGenerator(self.evadb, rules_manager)
+            select_query = "EXPLAIN SELECT id, data FROM MyVideo JOIN LATERAL DummyObjectDetector(data) AS T ;"
+            batch = execute_query_fetch_all(
+                self.evadb, select_query, plan_generator=custom_plan_generator
+            )
+            expected_output = """|__ ProjectPlan\n    |__ LateralJoinPlan\n        |__ SeqScanPlan\n            |__ StoragePlan\n        |__ FunctionScanPlan\n"""
+            print(batch.frames[0][0])
+            self.assertEqual(batch.frames[0][0], expected_output)
+
 
-        select_view_query = "SELECT id, label, bbox FROM uadtrac_fastRCNN"
-        actual_batch = execute_query_fetch_all(select_view_query)
-        actual_batch.sort()
-
-        self.assertEqual(len(actual_batch), 5)
-        # non-trivial test case
-        res = actual_batch.frames
-        for idx in res.index:
-            self.assertTrue("car" in res["uadtrac_fastrcnn.label"][idx])
+if __name__ == "__main__":
+    unittest.main()
```

### Comparing `evadb-0.2.6/test/integration_tests/test_delete_executor.py` & `evadb-0.2.7/test/integration_tests/test_delete_executor.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,137 +1,137 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-from test.util import file_remove, load_udfs_for_testing, shutdown_ray
+from test.util import (
+    file_remove,
+    get_evadb_for_testing,
+    load_udfs_for_testing,
+    shutdown_ray,
+)
 
 import numpy as np
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.server.command_handler import execute_query_fetch_all
 
 
 @pytest.mark.notparallel
 class DeleteExecutorTest(unittest.TestCase):
     def setUp(self):
-        # Bootstrap configuration manager.
-        ConfigurationManager()
-
-        # Reset catalog.
-        CatalogManager().reset()
-        load_udfs_for_testing(mode="debug")
+        self.evadb = get_evadb_for_testing()
+        self.evadb.catalog().reset()
+        load_udfs_for_testing(self.evadb, mode="debug")
 
         create_table_query = """
                 CREATE TABLE IF NOT EXISTS testDeleteOne
                 (
                  id INTEGER,
                  dummyfloat FLOAT(5, 3),
                  feat   NDARRAY FLOAT32(1, 3),
                  input  NDARRAY UINT8(1, 3)
                  );
                 """
-        execute_query_fetch_all(create_table_query)
+        execute_query_fetch_all(self.evadb, create_table_query)
 
         insert_query1 = """
                 INSERT INTO testDeleteOne (id, dummyfloat, feat, input)
                 VALUES (5, 1.5, [[0, 0, 0]], [[0, 0, 0]]);
         """
-        execute_query_fetch_all(insert_query1)
+        execute_query_fetch_all(self.evadb, insert_query1)
         insert_query2 = """
                 INSERT INTO testDeleteOne (id, dummyfloat,feat, input)
                 VALUES (15, 2.5, [[100, 100, 100]], [[100, 100, 100]]);
         """
-        execute_query_fetch_all(insert_query2)
+        execute_query_fetch_all(self.evadb, insert_query2)
         insert_query3 = """
                 INSERT INTO testDeleteOne (id, dummyfloat,feat, input)
                 VALUES (25, 3.5, [[200, 200, 200]], [[200, 200, 200]]);
         """
-        execute_query_fetch_all(insert_query3)
+        execute_query_fetch_all(self.evadb, insert_query3)
 
         ####################################################
         # Create a table for testing Delete with Video Data#
         ####################################################
 
         path = f"{EVA_ROOT_DIR}/data/sample_videos/1/*.mp4"
         query = f'LOAD VIDEO "{path}" INTO TestDeleteVideos;'
-        _ = execute_query_fetch_all(query)
+        _ = execute_query_fetch_all(self.evadb, query)
 
     def tearDown(self):
         shutdown_ray()
         file_remove("dummy.avi")
 
     # integration test
     @unittest.skip("Not supported in current version")
     def test_should_delete_single_video_in_table(self):
         path = f"{EVA_ROOT_DIR}/data/sample_videos/1/2.mp4"
         delete_query = f"""DELETE FROM TestDeleteVideos WHERE name="{path}";"""
-        batch = execute_query_fetch_all(delete_query)
+        batch = execute_query_fetch_all(self.evadb, delete_query)
 
         query = "SELECT name FROM MyVideo"
-        batch = execute_query_fetch_all(query)
+        batch = execute_query_fetch_all(self.evadb, query)
         self.assertIsNone(
             np.testing.assert_array_equal(
                 batch.frames["data"][0],
                 np.array([[[40, 40, 40], [40, 40, 40]], [[40, 40, 40], [40, 40, 40]]]),
             )
         )
 
         query = "SELECT id, data FROM MyVideo WHERE id = 41;"
-        batch = execute_query_fetch_all(query)
+        batch = execute_query_fetch_all(self.evadb, query)
         self.assertIsNone(
             np.testing.assert_array_equal(
                 batch.frames["data"][0],
                 np.array([[[41, 41, 41], [41, 41, 41]], [[41, 41, 41], [41, 41, 41]]]),
             )
         )
 
     @unittest.skip("Not supported in current version")
     def test_should_delete_single_image_in_table(self):
         path = f"{EVA_ROOT_DIR}/data/sample_videos/1/2.mp4"
         delete_query = f"""DELETE FROM TestDeleteVideos WHERE name="{path}";"""
-        batch = execute_query_fetch_all(delete_query)
+        batch = execute_query_fetch_all(self.evadb, delete_query)
 
         query = "SELECT name FROM MyVideo"
-        batch = execute_query_fetch_all(query)
+        batch = execute_query_fetch_all(self.evadb, query)
         self.assertIsNone(
             np.testing.assert_array_equal(
                 batch.frames["data"][0],
                 np.array([[[40, 40, 40], [40, 40, 40]], [[40, 40, 40], [40, 40, 40]]]),
             )
         )
 
         query = "SELECT id, data FROM MyVideo WHERE id = 41;"
-        batch = execute_query_fetch_all(query)
+        batch = execute_query_fetch_all(self.evadb, query)
         self.assertIsNone(
             np.testing.assert_array_equal(
                 batch.frames["data"][0],
                 np.array([[[41, 41, 41], [41, 41, 41]], [[41, 41, 41], [41, 41, 41]]]),
             )
         )
 
     def test_should_delete_tuple_in_table(self):
         delete_query = """DELETE FROM testDeleteOne WHERE
                id < 20 OR dummyfloat < 2 AND id < 5 AND 20 > id
                AND id <= 20 AND id >= 5 OR id != 15 OR id = 15;"""
-        batch = execute_query_fetch_all(delete_query)
+        batch = execute_query_fetch_all(self.evadb, delete_query)
 
         query = "SELECT * FROM testDeleteOne;"
-        batch = execute_query_fetch_all(query)
+        batch = execute_query_fetch_all(self.evadb, query)
 
         np.testing.assert_array_equal(
             batch.frames["testdeleteone.id"].array,
             np.array([25], dtype=np.int64),
         )
```

### Comparing `evadb-0.2.6/test/integration_tests/test_drop_executor.py` & `evadb-0.2.7/test/udfs/test_chatgpt.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,126 +1,129 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-import unittest
-from pathlib import Path
-from test.util import create_sample_video, file_remove
-
-import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_utils import get_video_table_column_definitions
-from eva.executor.executor_utils import ExecutorError
-from eva.server.command_handler import execute_query_fetch_all
-
-
-@pytest.mark.notparallel
-class DropExecutorTest(unittest.TestCase):
-    def setUp(self):
-        # reset the catalog manager before running each test
-        CatalogManager().reset()
-        self.video_file_path = create_sample_video()
-
-    def tearDown(self):
-        file_remove("dummy.avi")
-
-    # integration test
-    def test_should_drop_table(self):
-        catalog_manager = CatalogManager()
-        query = f"""LOAD VIDEO '{self.video_file_path}' INTO MyVideo;"""
-        execute_query_fetch_all(query)
-
-        # catalog should contain video table and the metadata table
-        table_catalog_entry = catalog_manager.get_table_catalog_entry("MyVideo")
-        video_dir = table_catalog_entry.file_url
-        self.assertFalse(table_catalog_entry is None)
-        column_objects = catalog_manager.get_column_catalog_entries_by_table(
-            table_catalog_entry
-        )
-        # no of column objects should equal what we have defined plus one for row_id
-        self.assertEqual(
-            len(column_objects), len(get_video_table_column_definitions()) + 1
-        )
-        self.assertTrue(Path(video_dir).exists())
-        video_metadata_table = (
-            catalog_manager.get_multimedia_metadata_table_catalog_entry(
-                table_catalog_entry
-            )
-        )
-        self.assertTrue(video_metadata_table is not None)
-
-        drop_query = """DROP TABLE IF EXISTS MyVideo;"""
-        execute_query_fetch_all(drop_query)
-        self.assertTrue(catalog_manager.get_table_catalog_entry("MyVideo") is None)
-        column_objects = catalog_manager.get_column_catalog_entries_by_table(
-            table_catalog_entry
+import os
+import unittest
+from test.markers import ray_skip_marker
+from test.util import get_evadb_for_testing
+from unittest.mock import MagicMock
+
+import openai
+import pandas as pd
+from mock import patch
+
+from evadb.configuration.configuration_manager import ConfigurationManager
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
+
+
+def create_dummy_csv_file(config) -> str:
+    tmp_dir_from_config = config.get_value("storage", "tmp_dir")
+
+    df_dict = {
+        "prompt": ["summarize"],
+        "content": [
+            "There are times when the night sky glows with bands of color. The bands may begin as cloud shapes and then spread into a great arc across the entire sky. They may fall in folds like a curtain drawn across the heavens. The lights usually grow brighter, then suddenly dim. During this time the sky glows with pale yellow, pink, green, violet, blue, and red. These lights are called the Aurora Borealis. Some people call them the Northern Lights. Scientists have been watching them for hundreds of years. They are not quite sure what causes them"
+        ],
+    }
+    df = pd.DataFrame(df_dict, columns=["id", "prompt", "content"])
+
+    dummy_file_path = tmp_dir_from_config + "/queries.csv"
+    df.to_csv(dummy_file_path)
+
+    return dummy_file_path
+
+
+class ChatGPTTest(unittest.TestCase):
+    def setUp(self) -> None:
+        self.evadb = get_evadb_for_testing()
+        self.evadb.catalog().reset()
+        create_table_query = """CREATE TABLE IF NOT EXISTS MyTextCSV (
+                id INTEGER UNIQUE,
+                prompt TEXT (100),
+                content TEXT (100)
+            );"""
+        execute_query_fetch_all(self.evadb, create_table_query)
+
+        self.csv_file_path = create_dummy_csv_file(self.evadb.config)
+
+        csv_query = f"""LOAD CSV '{self.csv_file_path}' INTO MyTextCSV;"""
+        execute_query_fetch_all(self.evadb, csv_query)
+
+    def tearDown(self) -> None:
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyTextCSV;")
+
+    @ray_skip_marker
+    @patch("evadb.udfs.chatgpt.openai.ChatCompletion.create")
+    def test_openai_chat_completion_udf(self, mock_req):
+        # set dummy api key
+        os.environ["openai_api_key"] = "my_key"
+
+        udf_name = "OpenAIChatCompletion"
+        execute_query_fetch_all(self.evadb, f"DROP UDF IF EXISTS {udf_name};")
+
+        create_udf_query = f"""CREATE UDF {udf_name}
+            IMPL 'evadb/udfs/chatgpt.py'
+            'model' 'gpt-3.5-turbo'
+        """
+        execute_query_fetch_all(self.evadb, create_udf_query)
+
+        mock_response_obj = MagicMock()
+        mock_response_obj.message.content = "mock message"
+        mock_req.return_value.choices = [mock_response_obj]
+
+        gpt_query = f"SELECT {udf_name}(prompt, content) FROM MyTextCSV;"
+        output_batch = execute_query_fetch_all(self.evadb, gpt_query)
+        expected_output = Batch(
+            pd.DataFrame(["mock message"], columns=["openaichatcompletion.response"])
         )
-        self.assertEqual(len(column_objects), 0)
-        self.assertFalse(Path(video_dir).exists())
+        self.assertEqual(output_batch, expected_output)
 
-        # Fail if table already dropped
-        drop_query = """DROP TABLE MyVideo;"""
-        with self.assertRaises(ExecutorError):
-            execute_query_fetch_all(drop_query)
-
-
-@pytest.mark.notparallel
-class DropUDFExecutorTest(unittest.TestCase):
-    def setUp(self):
-        CatalogManager().reset()
-
-    def tearDown(self):
-        pass
-
-    def run_create_udf_query(self):
-        create_udf_query = """CREATE UDF DummyObjectDetector
-            INPUT  (Frame_Array NDARRAY UINT8(3, 256, 256))
-            OUTPUT (label NDARRAY STR(10))
-            TYPE  Classification
-            IMPL  'test/util.py';"""
-        execute_query_fetch_all(create_udf_query)
-
-    def test_should_drop_udf(self):
-        catalog_manager = CatalogManager()
-        self.run_create_udf_query()
-        udf_name = "DummyObjectDetector"
-        udf = catalog_manager.get_udf_catalog_entry_by_name(udf_name)
-        self.assertTrue(udf is not None)
-
-        # Test that dropping the UDF reflects in the catalog
-        drop_query = "DROP UDF IF EXISTS {};".format(udf_name)
-        execute_query_fetch_all(drop_query)
-        udf = catalog_manager.get_udf_catalog_entry_by_name(udf_name)
-        self.assertTrue(udf is None)
-
-    def test_drop_wrong_udf_name(self):
-        catalog_manager = CatalogManager()
-        self.run_create_udf_query()
-        right_udf_name = "DummyObjectDetector"
-        wrong_udf_name = "FakeDummyObjectDetector"
-        udf = catalog_manager.get_udf_catalog_entry_by_name(right_udf_name)
-        self.assertTrue(udf is not None)
-
-        # Test that dropping the wrong UDF:
-        # - does not affect UDFs in the catalog
-        # - raises an appropriate exception
-        drop_query = "DROP UDF {};".format(wrong_udf_name)
-        try:
-            execute_query_fetch_all(drop_query)
-        except Exception as e:
-            err_msg = "UDF {} does not exist, therefore cannot be dropped.".format(
-                wrong_udf_name
-            )
-            self.assertTrue(str(e) == err_msg)
-        udf = catalog_manager.get_udf_catalog_entry_by_name(right_udf_name)
-        self.assertTrue(udf is not None)
+        # test without providing model name
+        execute_query_fetch_all(self.evadb, f"DROP UDF IF EXISTS {udf_name};")
+        create_udf_query = f"""CREATE UDF {udf_name}
+            IMPL 'evadb/udfs/chatgpt.py'
+        """
+        execute_query_fetch_all(self.evadb, create_udf_query)
+
+        gpt_query = f"SELECT {udf_name}(prompt, content) FROM MyTextCSV;"
+        output_batch = execute_query_fetch_all(self.evadb, gpt_query)
+        self.assertEqual(output_batch, expected_output)
+
+    @patch.dict(os.environ, {"OPENAI_KEY": "dummy_openai_key"}, clear=True)
+    def test_gpt_udf_no_key_in_yml_should_read_env(self):
+        ConfigurationManager().update_value("third_party", "OPENAI_KEY", "")
+        udf_name = "ChatGPT"
+        execute_query_fetch_all(self.evadb, f"DROP UDF IF EXISTS {udf_name};")
+
+        create_udf_query = f"""CREATE UDF {udf_name}
+            IMPL 'evadb/udfs/chatgpt.py'
+            """
+        execute_query_fetch_all(self.evadb, create_udf_query)
+        self.assertEqual(openai.api_key, "dummy_openai_key")
+
+    @patch.dict(os.environ, {}, clear=True)
+    def test_gpt_udf_no_key_in_yml_and_env_should_raise(self):
+        ConfigurationManager().update_value("third_party", "OPENAI_KEY", "")
+        udf_name = "ChatGPT"
+        execute_query_fetch_all(self.evadb, f"DROP UDF IF EXISTS {udf_name};")
+
+        with self.assertRaises(
+            Exception,
+            msg="Please set your OpenAI API key in evadb.yml file (third_party, open_api_key) or environment variable (OPENAI_KEY)",
+        ):
+            create_udf_query = f"""CREATE UDF {udf_name}
+                IMPL 'evadb/udfs/chatgpt.py'
+                """
+            execute_query_fetch_all(self.evadb, create_udf_query)
```

### Comparing `evadb-0.2.6/test/integration_tests/test_error_handling_with_ray.py` & `evadb-0.2.7/test/integration_tests/test_error_handling_with_ray.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,73 +1,72 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+import os
 import time
 import unittest
 from pathlib import Path
+from test.markers import ray_only_marker
 from test.util import (
     create_sample_image,
+    get_evadb_for_testing,
     is_ray_stage_running,
     load_udfs_for_testing,
     shutdown_ray,
 )
 
-import pytest
+from evadb.executor.executor_utils import ExecutorError
+from evadb.server.command_handler import execute_query_fetch_all
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.executor.executor_utils import ExecutorError
-from eva.server.command_handler import execute_query_fetch_all
 
-
-@pytest.mark.skipif(
-    not ConfigurationManager().get_value("experimental", "ray"),
-    reason="Only test for ray execution.",
-)
 class ErrorHandlingRayTests(unittest.TestCase):
     def setUp(self):
-        CatalogManager().reset()
-        ConfigurationManager()
+        self.evadb = get_evadb_for_testing()
+        os.environ["ray"] = str(self.evadb.config.get_value("experimental", "ray"))
+        self.evadb.catalog().reset()
         # Load built-in UDFs.
-        load_udfs_for_testing(mode="debug")
+        load_udfs_for_testing(self.evadb, mode="debug")
 
         # Deliberately create a faulty path.
         img_path = create_sample_image()
-        execute_query_fetch_all(f"LOAD IMAGE '{img_path}' INTO testRayErrorHandling;")
+        execute_query_fetch_all(
+            self.evadb, f"LOAD IMAGE '{img_path}' INTO testRayErrorHandling;"
+        )
 
         # Forcefully remove file to cause error.
         Path(img_path).unlink()
 
     def tearDown(self):
         shutdown_ray()
 
         # Drop table.
         drop_table_query = "DROP TABLE testRayErrorHandling;"
-        execute_query_fetch_all(drop_table_query)
+        execute_query_fetch_all(self.evadb, drop_table_query)
 
+    @ray_only_marker
     def test_ray_error_populate_to_all_stages(self):
         udf_name, task = "HFObjectDetector", "image-classification"
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' '{task}'
         """
 
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         select_query = """SELECT HFObjectDetector(data) FROM testRayErrorHandling;"""
 
         with self.assertRaises(ExecutorError):
-            _ = execute_query_fetch_all(select_query)
+            _ = execute_query_fetch_all(self.evadb, select_query)
 
         time.sleep(3)
         self.assertFalse(is_ray_stage_running())
```

### Comparing `evadb-0.2.6/test/integration_tests/test_explain_executor.py` & `evadb-0.2.7/test/integration_tests/test_show_info_executor.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,80 +1,87 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+import os
 import unittest
-from test.util import create_sample_video, file_remove, load_udfs_for_testing
+from test.markers import windows_skip_marker
+from test.util import get_evadb_for_testing
 
+import pandas as pd
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.optimizer.plan_generator import PlanGenerator
-from eva.optimizer.rules.rules import (
-    EmbedFilterIntoGet,
-    LogicalInnerJoinCommutativity,
-    XformLateralJoinToLinearFlow,
-)
-from eva.optimizer.rules.rules_manager import disable_rules
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
+from evadb.udfs.udf_bootstrap_queries import ArrayCount_udf_query, Fastrcnn_udf_query
 
 NUM_FRAMES = 10
 
 
 @pytest.mark.notparallel
-class ExplainExecutorTest(unittest.TestCase):
+class ShowExecutorTest(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        CatalogManager().reset()
-        video_file_path = create_sample_video(NUM_FRAMES)
-        load_query = f"LOAD VIDEO '{video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(load_query)
-        load_udfs_for_testing(mode="debug")
+        cls.evadb = get_evadb_for_testing()
+        cls.evadb.catalog().reset()
+        queries = [Fastrcnn_udf_query, ArrayCount_udf_query]
+        for query in queries:
+            execute_query_fetch_all(cls.evadb, query)
+
+        ua_detrac = f"{EVA_ROOT_DIR}/data/ua_detrac/ua_detrac.mp4"
+        mnist = f"{EVA_ROOT_DIR}/data/mnist/mnist.mp4"
+        actions = f"{EVA_ROOT_DIR}/data/actions/actions.mp4"
+        execute_query_fetch_all(cls.evadb, f"LOAD VIDEO '{ua_detrac}' INTO MyVideo;")
+        execute_query_fetch_all(cls.evadb, f"LOAD VIDEO '{mnist}' INTO MNIST;")
+        execute_query_fetch_all(cls.evadb, f"LOAD VIDEO '{actions}' INTO Actions;")
 
     @classmethod
     def tearDownClass(cls):
-        file_remove("dummy.avi")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS Actions;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MNIST;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MyVideo;")
+
+    # integration test
+    def test_show_udfs(self):
+        result = execute_query_fetch_all(self.evadb, "SHOW UDFS;")
+        self.assertEqual(len(result.columns), 6)
+
+        expected = {
+            "name": ["FastRCNNObjectDetector", "ArrayCount"],
+            "type": ["Classification", "NdarrayUDF"],
+        }
+        expected_df = pd.DataFrame(expected)
+        self.assertTrue(all(expected_df.name == result.frames.name))
+        self.assertTrue(all(expected_df.type == result.frames.type))
+
+    @windows_skip_marker
+    def test_show_tables(self):
+        # Note this test can causes sqlalchemy issues if the eva_server is not stopped
+        result = execute_query_fetch_all(self.evadb, "SHOW TABLES;")
+        self.assertEqual(len(result), 3)
+        expected = {"name": ["MyVideo", "MNIST", "Actions"]}
+        expected_df = pd.DataFrame(expected)
+        self.assertEqual(result, Batch(expected_df))
+
+        # Stop and restart server
+        os.system("nohup eva_server --stop")
+        os.system("nohup eva_server --start &")
+
+        result = execute_query_fetch_all(self.evadb, "SHOW TABLES;")
+        self.assertEqual(len(result), 3)
+        expected = {"name": ["MyVideo", "MNIST", "Actions"]}
+        expected_df = pd.DataFrame(expected)
+        self.assertEqual(result, Batch(expected_df))
 
-    def test_explain_simple_select(self):
-        select_query = "EXPLAIN SELECT id, data FROM MyVideo"
-        batch = execute_query_fetch_all(select_query)
-        expected_output = (
-            """|__ ProjectPlan\n    |__ SeqScanPlan\n        |__ StoragePlan\n"""
-        )
-        self.assertEqual(batch.frames[0][0], expected_output)
-
-        with disable_rules([XformLateralJoinToLinearFlow()]) as rules_manager:
-            custom_plan_generator = PlanGenerator(rules_manager)
-            select_query = "EXPLAIN SELECT id, data FROM MyVideo JOIN LATERAL DummyObjectDetector(data) AS T ;"
-            batch = execute_query_fetch_all(
-                select_query, plan_generator=custom_plan_generator
-            )
-            expected_output = """|__ ProjectPlan\n    |__ LateralJoinPlan\n        |__ SeqScanPlan\n            |__ StoragePlan\n        |__ FunctionScanPlan\n"""
-            self.assertEqual(batch.frames[0][0], expected_output)
-
-        # Disable more rules
-        with disable_rules(
-            [
-                XformLateralJoinToLinearFlow(),
-                EmbedFilterIntoGet(),
-                LogicalInnerJoinCommutativity(),
-            ]
-        ) as rules_manager:
-            custom_plan_generator = PlanGenerator(rules_manager)
-            select_query = "EXPLAIN SELECT id, data FROM MyVideo JOIN LATERAL DummyObjectDetector(data) AS T ;"
-            batch = execute_query_fetch_all(
-                select_query, plan_generator=custom_plan_generator
-            )
-            expected_output = """|__ ProjectPlan\n    |__ LateralJoinPlan\n        |__ SeqScanPlan\n            |__ StoragePlan\n        |__ FunctionScanPlan\n"""
-            print(batch.frames[0][0])
-            self.assertEqual(batch.frames[0][0], expected_output)
+        # stop the server
+        os.system("nohup eva_server --stop")
```

### Comparing `evadb-0.2.6/test/integration_tests/test_fuzzy_join.py` & `evadb-0.2.7/test/integration_tests/test_like.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,86 +1,70 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-from pathlib import Path
-from test.util import create_sample_csv, create_sample_video, file_remove, shutdown_ray
+from test.markers import ocr_skip_marker
+from test.util import get_evadb_for_testing, shutdown_ray
 
-import pytest
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.server.command_handler import execute_query_fetch_all
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.server.command_handler import execute_query_fetch_all
 
-EVA_INSTALLATION_DIR = ConfigurationManager().get_value("core", "eva_installation_dir")
-
-
-@pytest.mark.notparallel
-class FuzzyJoinTests(unittest.TestCase):
+class LikeTest(unittest.TestCase):
     def setUp(self):
-        CatalogManager().reset()
-        self.video_file_path = create_sample_video()
-        self.image_files_path = Path(
-            f"{EVA_ROOT_DIR}/test/data/uadetrac/small-data/MVI_20011/*.jpg"
-        )
-        self.csv_file_path = create_sample_csv()
+        self.evadb = get_evadb_for_testing()
+        # reset the catalog manager before running each test
+        self.evadb.catalog().reset()
+        meme1 = f"{EVA_ROOT_DIR}/data/detoxify/meme1.jpg"
+        meme2 = f"{EVA_ROOT_DIR}/data/detoxify/meme2.jpg"
 
-        # Prepare needed UDFs and data.
-        # loading a csv requires a table to be created first
-        create_table_query = """
-            CREATE TABLE IF NOT EXISTS MyVideoCSV (
-                id INTEGER UNIQUE,
-                frame_id INTEGER,
-                video_id INTEGER,
-                dataset_name TEXT(30),
-                label TEXT(30),
-                bbox NDARRAY FLOAT32(4),
-                object_id INTEGER
-            );
-            """
-        execute_query_fetch_all(create_table_query)
-
-        # load the CSV
-        load_query = f"LOAD CSV '{self.csv_file_path}' INTO MyVideoCSV;"
-        execute_query_fetch_all(load_query)
-
-        # load the video to be joined with the csv
-        query = f"LOAD VIDEO '{self.video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, f"LOAD IMAGE '{meme1}' INTO MemeImages;")
+        execute_query_fetch_all(self.evadb, f"LOAD IMAGE '{meme2}' INTO MemeImages;")
 
     def tearDown(self):
         shutdown_ray()
-
-        file_remove("dummy.avi")
-        file_remove("dummy.csv")
         # clean up
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideoCSV;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MemeImages;")
 
-    def test_fuzzyjoin(self):
-        fuzzy_udf = """CREATE UDF IF NOT EXISTS FuzzDistance
-                    INPUT (Input_Array1 NDARRAY ANYTYPE, Input_Array2 NDARRAY ANYTYPE)
-                    OUTPUT (distance FLOAT(32, 7))
-                    TYPE NdarrayUDF
-                    IMPL "{}/udfs/{}/fuzzy_join.py";
-        """.format(
-            EVA_INSTALLATION_DIR, "ndarray"
+    @ocr_skip_marker
+    def test_like_with_ocr(self):
+        create_udf_query = """CREATE UDF IF NOT EXISTS OCRExtractor
+                  INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
+                  OUTPUT (labels NDARRAY STR(10),
+                          bboxes NDARRAY FLOAT32(ANYDIM, 4),
+                          scores NDARRAY FLOAT32(ANYDIM))
+                  TYPE  OCRExtraction
+                  IMPL  'evadb/udfs/ocr_extractor.py';
+        """
+        execute_query_fetch_all(self.evadb, create_udf_query)
+        select_query = """SELECT X.label, X.x, X.y FROM MemeImages JOIN LATERAL UNNEST(OCRExtractor(data)) AS X(label, x, y) WHERE label LIKE {};""".format(
+            r"""'.*SWAG.*'"""
         )
-        execute_query_fetch_all(fuzzy_udf)
-
-        fuzzy_join_query = """SELECT * FROM MyVideo a JOIN MyVideoCSV b
-                      ON FuzzDistance(a.id, b.id) = 100;"""
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
+        self.assertEqual(len(actual_batch), 1)
 
-        actual_batch = execute_query_fetch_all(fuzzy_join_query)
-        self.assertEqual(len(actual_batch), 10)
+    @ocr_skip_marker
+    def test_like_fails_on_non_string_col(self):
+        create_udf_query = """CREATE UDF IF NOT EXISTS OCRExtractor
+                  INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
+                  OUTPUT (labels NDARRAY STR(10),
+                          bboxes NDARRAY FLOAT32(ANYDIM, 4),
+                          scores NDARRAY FLOAT32(ANYDIM))
+                  TYPE  OCRExtraction
+                  IMPL  'evadb/udfs/ocr_extractor.py';
+        """
+        execute_query_fetch_all(self.evadb, create_udf_query)
+
+        select_query = """SELECT * FROM MemeImages JOIN LATERAL UNNEST(OCRExtractor(data)) AS X(label, x, y) WHERE x LIKE "[A-Za-z]*CANT";"""
+        with self.assertRaises(Exception):
+            execute_query_fetch_all(self.evadb, select_query)
```

### Comparing `evadb-0.2.6/test/integration_tests/test_huggingface_udfs.py` & `evadb-0.2.7/test/integration_tests/test_huggingface_udfs.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,63 +9,62 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-from test.util import create_text_csv, file_remove
+from test.util import create_text_csv, file_remove, get_evadb_for_testing
 
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.executor.executor_utils import ExecutorError
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.executor.executor_utils import ExecutorError
+from evadb.server.command_handler import execute_query_fetch_all
 
 NUM_FRAMES = 10
 
 
 class HuggingFaceTests(unittest.TestCase):
     """
     The tests below essentially check for the output format returned by HF.
     We need to ensure that it is in the format that we expect.
     """
 
     def setUp(self) -> None:
-        CatalogManager().reset()
+        self.evadb = get_evadb_for_testing()
+        self.evadb.catalog().reset()
 
         # Use DETRAC for HF Tests to test variety of models
         query = """LOAD VIDEO 'data/ua_detrac/ua_detrac.mp4' INTO DETRAC;"""
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         query = """LOAD VIDEO 'data/sample_videos/touchdown.mp4' INTO VIDEOS"""
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         query = """LOAD PDF 'data/documents/pdf_sample1.pdf' INTO MyPDFs;"""
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
         # Text CSV for testing HF Text Based Models
         self.csv_file_path = create_text_csv()
 
     def tearDown(self) -> None:
-        execute_query_fetch_all("DROP TABLE IF EXISTS DETRAC;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS VIDEOS;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyCSV;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyPDFs;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS DETRAC;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS VIDEOS;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyCSV;")
         file_remove(self.csv_file_path)
 
     def test_io_catalog_entries_populated(self):
         udf_name, task = "HFObjectDetector", "image-classification"
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' '{task}'
         """
 
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
-        catalog = CatalogManager()
+        catalog = self.evadb.catalog()
         udf = catalog.get_udf_catalog_entry_by_name(udf_name)
         input_entries = catalog.get_udf_io_catalog_input_entries(udf)
         output_entries = catalog.get_udf_io_catalog_output_entries(udf)
 
         # Verify that there is one input entry with the name text
         self.assertEqual(len(input_entries), 1)
         self.assertEqual(input_entries[0].name, f"{udf_name}_IMAGE")
@@ -81,30 +80,30 @@
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' '{task}'
         """
         # catch an assert
 
         with self.assertRaises(ExecutorError) as exc_info:
-            execute_query_fetch_all(create_udf_query)
+            execute_query_fetch_all(self.evadb, create_udf_query)
         self.assertIn(
             f"Task {task} not supported in EVA currently", str(exc_info.exception)
         )
 
     def test_object_detection(self):
         udf_name = "HFObjectDetector"
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' 'object-detection'
             'model' 'facebook/detr-resnet-50';
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         select_query = f"SELECT {udf_name}(data) FROM DETRAC WHERE id < 4;"
-        output = execute_query_fetch_all(select_query)
+        output = execute_query_fetch_all(self.evadb, select_query)
         output_frames = output.frames
 
         # Test that output has 3 columns
         self.assertEqual(len(output_frames.columns), 3)
 
         # Test that number of rows is equal to 10
         self.assertEqual(len(output.frames), 4)
@@ -130,26 +129,26 @@
             self.assertTrue(len(bbox) == 4)
             self.assertTrue("xmin" in bbox)
             self.assertTrue("ymin" in bbox)
             self.assertTrue("xmax" in bbox)
             self.assertTrue("ymax" in bbox)
 
         drop_udf_query = f"DROP UDF {udf_name};"
-        execute_query_fetch_all(drop_udf_query)
+        execute_query_fetch_all(self.evadb, drop_udf_query)
 
     def test_image_classification(self):
         udf_name = "HFImageClassifier"
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' 'image-classification'
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         select_query = f"SELECT {udf_name}(data) FROM DETRAC WHERE id < 3;"
-        output = execute_query_fetch_all(select_query)
+        output = execute_query_fetch_all(self.evadb, select_query)
         print("output: ", output)
 
         # Test that output has 2 columns
         self.assertEqual(len(output.frames.columns), 2)
 
         # Test that there exists a column with udf_name.score and each entry is a list of floats
         self.assertTrue(udf_name.lower() + ".score" in output.frames.columns)
@@ -160,36 +159,36 @@
         # Test that there exists a column with udf_name.label and each entry is a list of strings
         self.assertTrue(udf_name.lower() + ".label" in output.frames.columns)
         self.assertTrue(
             all(isinstance(x, list) for x in output.frames[udf_name.lower() + ".label"])
         )
 
         drop_udf_query = f"DROP UDF {udf_name};"
-        execute_query_fetch_all(drop_udf_query)
+        execute_query_fetch_all(self.evadb, drop_udf_query)
 
     @pytest.mark.benchmark
     def test_text_classification(self):
         create_table_query = """CREATE TABLE IF NOT EXISTS MyCSV (
                 id INTEGER UNIQUE,
                 comment TEXT(30)
             );"""
-        execute_query_fetch_all(create_table_query)
+        execute_query_fetch_all(self.evadb, create_table_query)
 
         load_table_query = f"""LOAD CSV '{self.csv_file_path}' INTO MyCSV;"""
-        execute_query_fetch_all(load_table_query)
+        execute_query_fetch_all(self.evadb, load_table_query)
 
         udf_name = "HFTextClassifier"
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' 'text-classification'
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         select_query = f"SELECT {udf_name}(comment) FROM MyCSV;"
-        output = execute_query_fetch_all(select_query)
+        output = execute_query_fetch_all(self.evadb, select_query)
 
         # Test that output has 2 columns
         self.assertEqual(len(output.frames.columns), 2)
 
         # Test that there exists a column with udf_name.label and each entry is either "POSITIVE" or "NEGATIVE"
         self.assertTrue(udf_name.lower() + ".label" in output.frames.columns)
         self.assertTrue(
@@ -204,95 +203,105 @@
         self.assertTrue(
             all(
                 isinstance(x, float) for x in output.frames[udf_name.lower() + ".score"]
             )
         )
 
         drop_udf_query = f"DROP UDF {udf_name};"
-        execute_query_fetch_all(drop_udf_query)
-        execute_query_fetch_all("DROP TABLE MyCSV;")
+        execute_query_fetch_all(self.evadb, drop_udf_query)
+        execute_query_fetch_all(self.evadb, "DROP TABLE MyCSV;")
 
     @pytest.mark.benchmark
     def test_automatic_speech_recognition(self):
         udf_name = "SpeechRecognizer"
         create_udf = (
             f"CREATE UDF {udf_name} TYPE HuggingFace "
             "'task' 'automatic-speech-recognition' 'model' 'openai/whisper-base';"
         )
-        execute_query_fetch_all(create_udf)
+        execute_query_fetch_all(self.evadb, create_udf)
 
         # TODO: use with SAMPLE AUDIORATE 16000
         select_query = f"SELECT {udf_name}(audio) FROM VIDEOS;"
-        output = execute_query_fetch_all(select_query)
+        output = execute_query_fetch_all(self.evadb, select_query)
 
         # verify that output has one row and one column only
         self.assertTrue(output.frames.shape == (1, 1))
         # verify that speech was converted to text correctly
         self.assertTrue(output.frames.iloc[0][0].count("touchdown") == 2)
 
+        select_query_with_group_by = (
+            f"SELECT {udf_name}(SEGMENT(audio)) FROM VIDEOS GROUP BY '240 samples';"
+        )
+        output = execute_query_fetch_all(self.evadb, select_query_with_group_by)
+
+        # verify that output has one row and one column only
+        self.assertEquals(output.frames.shape, (4, 1))
+        # verify that speech was converted to text correctly
+        self.assertEquals(output.frames.iloc[0][0].count("touchdown"), 1)
+
         drop_udf_query = f"DROP UDF {udf_name};"
-        execute_query_fetch_all(drop_udf_query)
+        execute_query_fetch_all(self.evadb, drop_udf_query)
 
     @pytest.mark.benchmark
     def test_summarization_from_video(self):
         asr_udf = "SpeechRecognizer"
         create_udf = (
             f"CREATE UDF {asr_udf} TYPE HuggingFace "
             "'task' 'automatic-speech-recognition' 'model' 'openai/whisper-base';"
         )
-        execute_query_fetch_all(create_udf)
+        execute_query_fetch_all(self.evadb, create_udf)
 
         summary_udf = "Summarizer"
         create_udf = (
             f"CREATE UDF {summary_udf} TYPE HuggingFace "
-            "'task' 'summarization' 'model' 'philschmid/bart-large-cnn-samsum' 'min_length' 10 'max_length' 100;"
+            "'task' 'summarization' 'model' 'philschmid/bart-large-cnn-samsum' 'min_length' 10 'max_new_tokens' 100;"
         )
-        execute_query_fetch_all(create_udf)
+        execute_query_fetch_all(self.evadb, create_udf)
 
         # TODO: use with SAMPLE AUDIORATE 16000
         select_query = f"SELECT {summary_udf}({asr_udf}(audio)) FROM VIDEOS;"
-        output = execute_query_fetch_all(select_query)
+        output = execute_query_fetch_all(self.evadb, select_query)
 
         # verify that output has one row and one column only
         self.assertTrue(output.frames.shape == (1, 1))
         # verify that summary is as expected
         self.assertTrue(
             output.frames.iloc[0][0]
             == "Jalen Hurts has scored his second rushing touchdown of the game."
         )
 
         drop_udf_query = f"DROP UDF {asr_udf};"
-        execute_query_fetch_all(drop_udf_query)
+        execute_query_fetch_all(self.evadb, drop_udf_query)
         drop_udf_query = f"DROP UDF {summary_udf};"
-        execute_query_fetch_all(drop_udf_query)
+        execute_query_fetch_all(self.evadb, drop_udf_query)
 
     @pytest.mark.benchmark
     def test_toxicity_classification(self):
         udf_name = "HFToxicityClassifier"
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' 'text-classification'
             'model' 'martin-ha/toxic-comment-model'
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         drop_table_query = """DROP TABLE IF EXISTS MyCSV;"""
-        execute_query_fetch_all(drop_table_query)
+        execute_query_fetch_all(self.evadb, drop_table_query)
 
         create_table_query = """CREATE TABLE IF NOT EXISTS MyCSV (
                 id INTEGER UNIQUE,
                 comment TEXT(30)
             );"""
-        execute_query_fetch_all(create_table_query)
+        execute_query_fetch_all(self.evadb, create_table_query)
 
         load_table_query = f"""LOAD CSV '{self.csv_file_path}' INTO MyCSV;"""
-        execute_query_fetch_all(load_table_query)
+        execute_query_fetch_all(self.evadb, load_table_query)
 
         select_query = f"SELECT {udf_name}(comment) FROM MyCSV;"
-        output = execute_query_fetch_all(select_query)
+        output = execute_query_fetch_all(self.evadb, select_query)
 
         # Test that output has 2 columns
         self.assertEqual(len(output.frames.columns), 2)
 
         # Test that there exists a column with udf_name.label and each entry is either "POSITIVE" or "NEGATIVE"
         self.assertTrue(udf_name.lower() + ".label" in output.frames.columns)
         self.assertTrue(
@@ -308,40 +317,40 @@
         self.assertTrue(
             all(
                 isinstance(x, float) for x in output.frames[udf_name.lower() + ".score"]
             )
         )
 
         drop_udf_query = f"DROP UDF {udf_name};"
-        execute_query_fetch_all(drop_udf_query)
+        execute_query_fetch_all(self.evadb, drop_udf_query)
 
     @pytest.mark.benchmark
     def test_multilingual_toxicity_classification(self):
         udf_name = "HFMultToxicityClassifier"
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' 'text-classification'
             'model' 'EIStakovskii/xlm_roberta_base_multilingual_toxicity_classifier_plus'
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         drop_table_query = """DROP TABLE IF EXISTS MyCSV;"""
-        execute_query_fetch_all(drop_table_query)
+        execute_query_fetch_all(self.evadb, drop_table_query)
 
         create_table_query = """CREATE TABLE MyCSV (
                 id INTEGER UNIQUE,
                 comment TEXT(30)
             );"""
-        execute_query_fetch_all(create_table_query)
+        execute_query_fetch_all(self.evadb, create_table_query)
 
         load_table_query = f"""LOAD CSV '{self.csv_file_path}' INTO MyCSV;"""
-        execute_query_fetch_all(load_table_query)
+        execute_query_fetch_all(self.evadb, load_table_query)
 
         select_query = f"SELECT {udf_name}(comment) FROM MyCSV;"
-        output = execute_query_fetch_all(select_query)
+        output = execute_query_fetch_all(self.evadb, select_query)
 
         # Test that output has 2 columns
         self.assertEqual(len(output.frames.columns), 2)
 
         # Test that there exists a column with udf_name.label and each entry is either "POSITIVE" or "NEGATIVE"
         self.assertTrue(udf_name.lower() + ".label" in output.frames.columns)
         self.assertTrue(
@@ -356,58 +365,75 @@
         self.assertTrue(
             all(
                 isinstance(x, float) for x in output.frames[udf_name.lower() + ".score"]
             )
         )
 
         drop_udf_query = f"DROP UDF {udf_name};"
-        execute_query_fetch_all(drop_udf_query)
+        execute_query_fetch_all(self.evadb, drop_udf_query)
 
     @pytest.mark.benchmark
     def test_named_entity_recognition_model_all_pdf_data(self):
         udf_name = "HFNERModel"
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' 'ner'
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         # running test case on all the pdf data
         select_query = f"SELECT data, {udf_name}(data) FROM MyPDFs;"
-        output = execute_query_fetch_all(select_query)
+        output = execute_query_fetch_all(self.evadb, select_query)
 
         # Test that output has 7 columns
         self.assertEqual(len(output.frames.columns), 7)
 
         # Test that there exists a column with udf_name.entity
         self.assertTrue(udf_name.lower() + ".entity" in output.frames.columns)
 
         # Test that there exists a column with udf_name.score
         self.assertTrue(udf_name.lower() + ".score" in output.frames.columns)
 
         drop_udf_query = f"DROP UDF {udf_name};"
-        execute_query_fetch_all(drop_udf_query)
+        execute_query_fetch_all(self.evadb, drop_udf_query)
+
+    def test_select_and_groupby_with_paragraphs(self):
+        segment_size = 10
+        select_query = (
+            "SELECT SEGMENT(data) FROM MyPDFs GROUP BY '{}paragraphs';".format(
+                segment_size
+            )
+        )
+        output = execute_query_fetch_all(self.evadb, select_query)
+        self.assertEqual(len(output.frames), 3)
 
     @pytest.mark.benchmark
     def test_named_entity_recognition_model_no_ner_data_exists(self):
         udf_name = "HFNERModel"
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' 'ner'
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         # running test case where ner gives no data
         select_query = f"""SELECT data, {udf_name}(data)
                   FROM MyPDFs
                   WHERE page = 3
                   AND paragraph >= 1 AND paragraph <= 3;"""
-        output = execute_query_fetch_all(select_query)
+        output = execute_query_fetch_all(self.evadb, select_query)
 
         # Test that output only has 1 column (data)
         self.assertEqual(len(output.frames.columns), 1)
 
         # Test that there does not exist a column with udf_name.entity
         self.assertFalse(udf_name.lower() + ".entity" in output.frames.columns)
 
         drop_udf_query = f"DROP UDF {udf_name};"
-        execute_query_fetch_all(drop_udf_query)
+        execute_query_fetch_all(self.evadb, drop_udf_query)
+
+
+if __name__ == "__main__":
+    suite = unittest.TestSuite()
+    suite.addTest(HuggingFaceTests("test_automatic_speech_recognition"))
+    runner = unittest.TextTestRunner()
+    runner.run(suite)
```

### Comparing `evadb-0.2.6/test/integration_tests/test_insert_executor.py` & `evadb-0.2.7/test/integration_tests/test_insert_executor.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,78 +1,83 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-from test.util import create_sample_video, file_remove, shutdown_ray
+from test.util import (
+    create_sample_video,
+    file_remove,
+    get_evadb_for_testing,
+    shutdown_ray,
+)
 
 import numpy as np
 import pandas as pd
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.server.command_handler import execute_query_fetch_all
-from eva.utils.logging_manager import logger
+from evadb.server.command_handler import execute_query_fetch_all
+from evadb.utils.logging_manager import logger
 
 
 @pytest.mark.notparallel
 class InsertExecutorTest(unittest.TestCase):
     def setUp(self):
+        self.evadb = get_evadb_for_testing()
         # reset the catalog manager before running each test
-        CatalogManager().reset()
+        self.evadb.catalog().reset()
         self.video_file_path = create_sample_video()
 
         query = """CREATE TABLE IF NOT EXISTS CSVTable
             (
                 name TEXT(100)
             );
         """
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
     def tearDown(self):
         shutdown_ray()
         file_remove("dummy.avi")
 
     # integration test
     @unittest.skip("Not supported in current version")
     def test_should_load_video_in_table(self):
         query = f"""LOAD VIDEO '{self.video_file_path}' INTO MyVideo;"""
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         insert_query = """ INSERT INTO MyVideo (id, data) VALUES
             (40, [[40, 40, 40], [40, 40, 40]],
                  [[40, 40, 40], [40, 40, 40]]);"""
-        execute_query_fetch_all(insert_query)
+        execute_query_fetch_all(self.evadb, insert_query)
 
         insert_query_2 = """ INSERT INTO MyVideo (id, data) VALUES
         ( 41, [[41, 41, 41] , [41, 41, 41]],
                 [[41, 41, 41], [41, 41, 41]]);"""
-        execute_query_fetch_all(insert_query_2)
+        execute_query_fetch_all(self.evadb, insert_query_2)
 
         query = "SELECT id, data FROM MyVideo WHERE id = 40"
-        batch = execute_query_fetch_all(query)
+        batch = execute_query_fetch_all(self.evadb, query)
         self.assertIsNone(
             np.testing.assert_array_equal(
                 batch.frames["data"][0],
                 np.array([[[40, 40, 40], [40, 40, 40]], [[40, 40, 40], [40, 40, 40]]]),
             )
         )
 
         query = "SELECT id, data FROM MyVideo WHERE id = 41;"
-        batch = execute_query_fetch_all(query)
+        batch = execute_query_fetch_all(self.evadb, query)
         self.assertIsNone(
             np.testing.assert_array_equal(
                 batch.frames["data"][0],
                 np.array([[[41, 41, 41], [41, 41, 41]], [[41, 41, 41], [41, 41, 41]]]),
             )
         )
 
@@ -80,18 +85,18 @@
         data = pd.read_csv("./test/data/features.csv")
         for i in data.iterrows():
             logger.info(i[1][1])
             query = f"""INSERT INTO CSVTable (name) VALUES (
                             '{i[1][1]}'
                         );"""
             logger.info(query)
-            batch = execute_query_fetch_all(query)
+            batch = execute_query_fetch_all(self.evadb, query)
 
         query = "SELECT name FROM CSVTable;"
-        batch = execute_query_fetch_all(query)
+        batch = execute_query_fetch_all(self.evadb, query)
         logger.info(batch)
 
         self.assertIsNone(
             np.testing.assert_array_equal(
                 batch.frames["csvtable.name"].array,
                 np.array(
                     [
@@ -100,9 +105,9 @@
                         "test_eva/similarity/data/angry.jpg",
                     ]
                 ),
             )
         )
 
         query = """SELECT name FROM CSVTable WHERE name LIKE '.*(sad|happy)';"""
-        batch = execute_query_fetch_all(query)
+        batch = execute_query_fetch_all(self.evadb, query)
         self.assertEqual(len(batch._frames), 2)
```

### Comparing `evadb-0.2.6/test/integration_tests/test_load_executor.py` & `evadb-0.2.7/test/integration_tests/test_load_executor.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,118 +22,119 @@
 from test.util import (
     create_dummy_batches,
     create_dummy_csv_batches,
     create_large_scale_image_dataset,
     create_sample_csv,
     create_sample_video,
     file_remove,
+    get_evadb_for_testing,
     shutdown_ray,
 )
 
 import numpy as np
 import pandas as pd
 import pytest
 
-from eva.binder.binder_utils import BinderError
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.executor.executor_utils import ExecutorError
-from eva.models.storage.batch import Batch
-from eva.parser.types import FileFormatType
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.binder.binder_utils import BinderError
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.executor.executor_utils import ExecutorError
+from evadb.models.storage.batch import Batch
+from evadb.parser.types import FileFormatType
+from evadb.server.command_handler import execute_query_fetch_all
 
 
 @pytest.mark.notparallel
 class LoadExecutorTest(unittest.TestCase):
     def setUp(self):
+        self.evadb = get_evadb_for_testing()
         # reset the catalog manager before running each test
-        CatalogManager().reset()
+        self.evadb.catalog().reset()
         self.video_file_path = create_sample_video()
         self.image_files_path = Path(
             f"{EVA_ROOT_DIR}/test/data/uadetrac/small-data/MVI_20011/*.jpg"
         )
         self.csv_file_path = create_sample_csv()
 
     def tearDown(self):
         shutdown_ray()
 
         file_remove("dummy.avi")
         file_remove("dummy.csv")
         # clean up
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideos;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideos;")
 
     # integration test for load video
     def test_should_load_video_in_table(self):
         query = f"LOAD VIDEO '{self.video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         select_query = """SELECT * FROM MyVideo;"""
 
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_batch = list(create_dummy_batches())[0]
         self.assertEqual(actual_batch, expected_batch)
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideo;")
 
     def test_should_form_symlink_to_individual_video(self):
-        catalog_manager = CatalogManager()
+        catalog_manager = self.evadb.catalog()
         query = f"LOAD VIDEO '{self.video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         table_catalog_entry = catalog_manager.get_table_catalog_entry("MyVideo")
         video_dir = table_catalog_entry.file_url
 
         # the video directory would have only a single file
         self.assertEqual(len(os.listdir(video_dir)), 1)
         video_file = os.listdir(video_dir)[0]
         # check that the file is a symlink to self.video_file_path
         video_file_path = os.path.join(video_dir, video_file)
         self.assertTrue(os.path.islink(video_file_path))
         self.assertEqual(os.readlink(video_file_path), self.video_file_path)
 
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideo;")
 
     def test_should_raise_error_on_removing_symlinked_file(self):
         query = f"LOAD VIDEO '{self.video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         select_query = """SELECT * FROM MyVideo;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_batch = list(create_dummy_batches())[0]
         self.assertEqual(actual_batch, expected_batch)
 
         # remove the source file
         file_remove("dummy.avi")
 
         # try to read the table again
         with self.assertRaises(ExecutorError) as e:
-            execute_query_fetch_all(select_query)
+            execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(
             str(e.exception),
             "The dataset file could not be found. Please verify that the file exists in the specified path.",
         )
 
         # create the file again for other test cases
         create_sample_video()
 
     def test_should_load_videos_in_table(self):
         path = f"{EVA_ROOT_DIR}/data/sample_videos/1/*.mp4"
         query = f"""LOAD VIDEO "{path}" INTO MyVideos;"""
-        result = execute_query_fetch_all(query)
+        result = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame([f"Number of loaded {FileFormatType.VIDEO.name}: 2"])
         )
         self.assertEqual(result, expected)
 
     def test_should_form_symlink_to_multiple_videos(self):
-        catalog_manager = CatalogManager()
+        catalog_manager = self.evadb.catalog()
         path = f"{EVA_ROOT_DIR}/data/sample_videos/1/*.mp4"
         query = f"""LOAD VIDEO "{path}" INTO MyVideos;"""
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         table_catalog_entry = catalog_manager.get_table_catalog_entry("MyVideos")
         video_dir = table_catalog_entry.file_url
 
         # the video directory would have two files
         self.assertEqual(len(os.listdir(video_dir)), 2)
         video_files = os.listdir(video_dir)
@@ -146,69 +147,73 @@
                     f"{EVA_ROOT_DIR}/data/sample_videos/1"
                 )
             )
 
     def test_should_load_videos_with_same_name_but_different_path(self):
         path = f"{EVA_ROOT_DIR}/data/sample_videos/**/*.mp4"
         query = f"""LOAD VIDEO "{path}" INTO MyVideos;"""
-        result = execute_query_fetch_all(query)
+        result = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame([f"Number of loaded {FileFormatType.VIDEO.name}: 4"])
         )
         self.assertEqual(result, expected)
 
     def test_should_fail_to_load_videos_with_same_path(self):
         path = f"{EVA_ROOT_DIR}/data/sample_videos/2/*.mp4"
         query = f"""LOAD VIDEO "{path}" INTO MyVideos;"""
-        result = execute_query_fetch_all(query)
+        result = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame([f"Number of loaded {FileFormatType.VIDEO.name}: 1"])
         )
         self.assertEqual(result, expected)
 
         # original file should be preserved
-        expected_output = execute_query_fetch_all("SELECT id FROM MyVideos;")
+        expected_output = execute_query_fetch_all(
+            self.evadb, "SELECT id FROM MyVideos;"
+        )
 
         # try adding duplicate files to the table
         path = f"{EVA_ROOT_DIR}/data/sample_videos/**/*.mp4"
         query = f"""LOAD VIDEO "{path}" INTO MyVideos;"""
         with self.assertRaises(ExecutorError):
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
 
         # original data should be preserved
-        after_load_fail = execute_query_fetch_all("SELECT id FROM MyVideos;")
+        after_load_fail = execute_query_fetch_all(
+            self.evadb, "SELECT id FROM MyVideos;"
+        )
 
         self.assertEqual(expected_output, after_load_fail)
 
     def test_should_fail_to_load_missing_video(self):
         path = f"{EVA_ROOT_DIR}/data/sample_videos/missing.mp4"
         query = f"""LOAD VIDEO "{path}" INTO MyVideos;"""
         with self.assertRaises(ExecutorError) as exc_info:
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
         self.assertIn(
             "Load VIDEO failed due to no valid files found on path",
             str(exc_info.exception),
         )
 
     def test_should_fail_to_load_corrupt_video(self):
         # should fail on an empty file
         tempfile_name = os.urandom(24).hex()
         tempfile_path = os.path.join(tempfile.gettempdir(), tempfile_name)
         with open(tempfile_path, "wb") as tmp:
             query = f"""LOAD VIDEO "{tmp.name}" INTO MyVideos;"""
             with self.assertRaises(Exception):
-                execute_query_fetch_all(query)
+                execute_query_fetch_all(self.evadb, query)
 
     def test_should_fail_to_load_invalid_files_as_video(self):
         path = f"{EVA_ROOT_DIR}/data/**"
         query = f"""LOAD VIDEO "{path}" INTO MyVideos;"""
         with self.assertRaises(Exception):
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
         with self.assertRaises(BinderError):
-            execute_query_fetch_all("SELECT name FROM MyVideos")
+            execute_query_fetch_all(self.evadb, "SELECT name FROM MyVideos")
 
     def test_should_rollback_if_video_load_fails(self):
         path_regex = Path(f"{EVA_ROOT_DIR}/data/sample_videos/1/*.mp4")
         valid_videos = glob.glob(str(path_regex.expanduser()), recursive=True)
 
         tempfile_name = os.urandom(24).hex()
         tempfile_path = os.path.join(tempfile.gettempdir(), tempfile_name)
@@ -217,118 +222,126 @@
             # nothing should be added
             with tempfile.TemporaryDirectory() as tmp_dir:
                 shutil.copy2(str(valid_videos[0]), tmp_dir)
                 shutil.copy2(str(empty_file.name), tmp_dir)
                 path = Path(tmp_dir) / "*"
                 query = f"""LOAD VIDEO "{path}" INTO MyVideos;"""
                 with self.assertRaises(Exception):
-                    execute_query_fetch_all(query)
+                    execute_query_fetch_all(self.evadb, query)
                 with self.assertRaises(BinderError):
-                    execute_query_fetch_all("SELECT name FROM MyVideos")
+                    execute_query_fetch_all(self.evadb, "SELECT name FROM MyVideos")
 
             # Load two correct file and one empty file
             # nothing should be added
             with tempfile.TemporaryDirectory() as tmp_dir:
                 shutil.copy2(str(valid_videos[0]), tmp_dir)
                 shutil.copy2(str(valid_videos[1]), tmp_dir)
                 shutil.copy2(str(empty_file.name), tmp_dir)
                 path = Path(tmp_dir) / "*"
                 query = f"""LOAD VIDEO "{path}" INTO MyVideos;"""
                 with self.assertRaises(Exception):
-                    execute_query_fetch_all(query)
+                    execute_query_fetch_all(self.evadb, query)
                 with self.assertRaises(BinderError):
-                    execute_query_fetch_all("SELECT name FROM MyVideos")
+                    execute_query_fetch_all(self.evadb, "SELECT name FROM MyVideos")
 
     def test_should_rollback_and_preserve_previous_state(self):
         path_regex = Path(f"{EVA_ROOT_DIR}/data/sample_videos/1/*.mp4")
         valid_videos = glob.glob(str(path_regex.expanduser()), recursive=True)
         # Load one correct file
         # commit
         load_file = f"{EVA_ROOT_DIR}/data/sample_videos/1/1.mp4"
-        execute_query_fetch_all(f"""LOAD VIDEO "{load_file}" INTO MyVideos;""")
+        execute_query_fetch_all(
+            self.evadb, f"""LOAD VIDEO "{load_file}" INTO MyVideos;"""
+        )
 
         # Load one correct file and one empty file
         # original file should remain
         tempfile_name = os.urandom(24).hex()
         tempfile_path = os.path.join(tempfile.gettempdir(), tempfile_name)
         with open(tempfile_path, "wb") as empty_file:
             with tempfile.TemporaryDirectory() as tmp_dir:
                 shutil.copy2(str(valid_videos[1]), tmp_dir)
                 shutil.copy2(str(empty_file.name), tmp_dir)
                 path = Path(tmp_dir) / "*"
                 query = f"""LOAD VIDEO "{path}" INTO MyVideos;"""
                 with self.assertRaises(Exception):
-                    execute_query_fetch_all(query)
-                result = execute_query_fetch_all("SELECT name FROM MyVideos")
+                    execute_query_fetch_all(self.evadb, query)
+                result = execute_query_fetch_all(
+                    self.evadb, "SELECT name FROM MyVideos"
+                )
                 file_names = np.unique(result.frames)
                 self.assertEqual(len(file_names), 1)
 
     ###########################################
     # integration testcases for load image
     def test_should_load_images_in_table(self):
         num_files = len(
             glob.glob(os.path.expanduser(self.image_files_path), recursive=True)
         )
         query = f"""LOAD IMAGE "{self.image_files_path}" INTO MyImages;"""
-        result = execute_query_fetch_all(query)
+        result = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame([f"Number of loaded {FileFormatType.IMAGE.name}: {num_files}"])
         )
         self.assertEqual(result, expected)
 
     def test_should_fail_to_load_missing_image(self):
         path = f"{EVA_ROOT_DIR}/data/sample_images/missing.jpg"
         query = f"""LOAD IMAGE "{path}" INTO MyImages;"""
         with self.assertRaises(ExecutorError) as exc_info:
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
         self.assertIn(
             "Load IMAGE failed due to no valid files found on path",
             str(exc_info.exception),
         )
 
     def test_should_fail_to_load_images_with_same_path(self):
         image_files = glob.glob(
             os.path.expanduser(self.image_files_path), recursive=True
         )
         query = f"""LOAD IMAGE "{image_files[0]}" INTO MyImages;"""
-        result = execute_query_fetch_all(query)
+        result = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame([f"Number of loaded {FileFormatType.IMAGE.name}: 1"])
         )
         self.assertEqual(result, expected)
 
         # original file should be preserved
-        expected_output = execute_query_fetch_all("SELECT name FROM MyImages;")
+        expected_output = execute_query_fetch_all(
+            self.evadb, "SELECT name FROM MyImages;"
+        )
 
         # try adding duplicate files to the table
         query = f"""LOAD IMAGE "{image_files[0]}" INTO MyImages;"""
         with self.assertRaises(Exception):
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
 
         # original data should be preserved
-        after_load_fail = execute_query_fetch_all("SELECT name FROM MyImages;")
+        after_load_fail = execute_query_fetch_all(
+            self.evadb, "SELECT name FROM MyImages;"
+        )
 
         self.assertEqual(expected_output, after_load_fail)
 
     def test_should_fail_to_load_corrupt_image(self):
         # should fail on an empty file
         tempfile_name = os.urandom(24).hex()
         tempfile_path = os.path.join(tempfile.gettempdir(), tempfile_name)
         with open(tempfile_path, "wb") as tmp:
             query = f"""LOAD IMAGE "{tmp.name}" INTO MyImages;"""
             with self.assertRaises(Exception):
-                execute_query_fetch_all(query)
+                execute_query_fetch_all(self.evadb, query)
 
     def test_should_fail_to_load_invalid_files_as_image(self):
         path = f"{EVA_ROOT_DIR}/data/**"
         query = f"""LOAD IMAGE "{path}" INTO MyImages;"""
         with self.assertRaises(Exception):
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
         with self.assertRaises(BinderError):
-            execute_query_fetch_all("SELECT name FROM MyImages;")
+            execute_query_fetch_all(self.evadb, "SELECT name FROM MyImages;")
 
     def test_should_rollback_if_image_load_fails(self):
         valid_images = glob.glob(
             str(self.image_files_path.expanduser()), recursive=True
         )
 
         tempfile_name = os.urandom(24).hex()
@@ -338,52 +351,56 @@
             # nothing should be added
             with tempfile.TemporaryDirectory() as tmp_dir:
                 shutil.copy2(str(valid_images[0]), tmp_dir)
                 shutil.copy2(str(empty_file.name), tmp_dir)
                 path = Path(tmp_dir) / "*"
                 query = f"""LOAD IMAGE "{path}" INTO MyImages;"""
                 with self.assertRaises(Exception):
-                    execute_query_fetch_all(query)
+                    execute_query_fetch_all(self.evadb, query)
                 with self.assertRaises(BinderError):
-                    execute_query_fetch_all("SELECT name FROM MyImages;")
+                    execute_query_fetch_all(self.evadb, "SELECT name FROM MyImages;")
 
             # Load two correct file and one empty file
             # nothing should be added
             with tempfile.TemporaryDirectory() as tmp_dir:
                 shutil.copy2(str(valid_images[0]), tmp_dir)
                 shutil.copy2(str(valid_images[1]), tmp_dir)
                 shutil.copy2(str(empty_file.name), tmp_dir)
                 path = Path(tmp_dir) / "*"
                 query = f"""LOAD IMAGE "{path}" INTO MyImages;"""
                 with self.assertRaises(Exception):
-                    execute_query_fetch_all(query)
+                    execute_query_fetch_all(self.evadb, query)
                 with self.assertRaises(BinderError):
-                    execute_query_fetch_all("SELECT name FROM MyImages;")
+                    execute_query_fetch_all(self.evadb, "SELECT name FROM MyImages;")
 
     def test_should_rollback_and_preserve_previous_state_for_load_images(self):
         valid_images = glob.glob(
             str(self.image_files_path.expanduser()), recursive=True
         )
         # Load one correct file
         # commit
-        execute_query_fetch_all(f"""LOAD IMAGE "{valid_images[0]}" INTO MyImages;""")
+        execute_query_fetch_all(
+            self.evadb, f"""LOAD IMAGE "{valid_images[0]}" INTO MyImages;"""
+        )
 
         # Load one correct file and one empty file
         # original file should remain
         tempfile_name = os.urandom(24).hex()
         tempfile_path = os.path.join(tempfile.gettempdir(), tempfile_name)
         with open(tempfile_path, "wb") as empty_file:
             with tempfile.TemporaryDirectory() as tmp_dir:
                 shutil.copy2(str(valid_images[1]), tmp_dir)
                 shutil.copy2(str(empty_file.name), tmp_dir)
                 path = Path(tmp_dir) / "*"
                 query = f"""LOAD IMAGE "{path}" INTO MyImages;"""
                 with self.assertRaises(Exception):
-                    execute_query_fetch_all(query)
-                result = execute_query_fetch_all("SELECT name FROM MyImages")
+                    execute_query_fetch_all(self.evadb, query)
+                result = execute_query_fetch_all(
+                    self.evadb, "SELECT name FROM MyImages"
+                )
                 self.assertEqual(len(result), 1)
                 expected = Batch(pd.DataFrame([{"myimages.name": valid_images[0]}]))
                 self.assertEqual(expected, result)
 
     ###################################
     # integration tests for csv
     def test_should_load_csv_in_table(self):
@@ -397,85 +414,85 @@
                 dataset_name TEXT(30),
                 label TEXT(30),
                 bbox NDARRAY FLOAT32(4),
                 object_id INTEGER
             );
 
             """
-        execute_query_fetch_all(create_table_query)
+        execute_query_fetch_all(self.evadb, create_table_query)
 
         # load the CSV
         load_query = f"LOAD CSV '{self.csv_file_path}' INTO MyVideoCSV;"
-        execute_query_fetch_all(load_query)
+        execute_query_fetch_all(self.evadb, load_query)
 
         # execute a select query
         select_query = """SELECT id, frame_id, video_id,
                           dataset_name, label, bbox,
                           object_id
                           FROM MyVideoCSV;"""
 
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
 
         # assert the batches are equal
         expected_batch = next(create_dummy_csv_batches())
         expected_batch.modify_column_alias("myvideocsv")
         self.assertEqual(actual_batch, expected_batch)
 
         # clean up
         drop_query = "DROP TABLE IF EXISTS MyVideoCSV;"
-        execute_query_fetch_all(drop_query)
+        execute_query_fetch_all(self.evadb, drop_query)
 
     def test_should_load_csv_with_columns_in_table(self):
         # loading a csv requires a table to be created first
         create_table_query = """
 
             CREATE TABLE IF NOT EXISTS MyVideoCSV (
                 id INTEGER UNIQUE,
                 frame_id INTEGER NOT NULL,
                 video_id INTEGER NOT NULL,
                 dataset_name TEXT(30) NOT NULL
             );
             """
-        execute_query_fetch_all(create_table_query)
+        execute_query_fetch_all(self.evadb, create_table_query)
 
         # load the CSV
         load_query = """LOAD CSV '{}' INTO MyVideoCSV (id, frame_id, video_id, dataset_name);""".format(
             self.csv_file_path
         )
-        execute_query_fetch_all(load_query)
+        execute_query_fetch_all(self.evadb, load_query)
 
         # execute a select query
         select_query = """SELECT id, frame_id, video_id, dataset_name
                           FROM MyVideoCSV;"""
 
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
 
         # assert the batches are equal
         select_columns = ["id", "frame_id", "video_id", "dataset_name"]
         expected_batch = next(create_dummy_csv_batches(target_columns=select_columns))
         expected_batch.modify_column_alias("myvideocsv")
         self.assertEqual(actual_batch, expected_batch)
 
         # clean up
         drop_query = "DROP TABLE IF EXISTS MyVideoCSV;"
-        execute_query_fetch_all(drop_query)
+        execute_query_fetch_all(self.evadb, drop_query)
 
     def test_should_use_parallel_load(self):
         # Create images.
         large_scale_image_files_path = create_large_scale_image_dataset(
             mp.cpu_count() * 10
         )
 
         load_query = f"LOAD IMAGE '{large_scale_image_files_path}/**/*.jpg' INTO MyLargeScaleImages;"
-        execute_query_fetch_all(load_query)
+        execute_query_fetch_all(self.evadb, load_query)
 
         drop_query = "DROP TABLE IF EXISTS MyLargeScaleImages;"
-        execute_query_fetch_all(drop_query)
+        execute_query_fetch_all(self.evadb, drop_query)
 
         # Clean up large scale image directory.
         shutil.rmtree(large_scale_image_files_path)
 
     def test_parallel_load_should_raise_exception(self):
         # Create images.
         large_scale_image_files_path = create_large_scale_image_dataset(
@@ -484,26 +501,27 @@
 
         # Corrupt an image.
         with open(os.path.join(large_scale_image_files_path, "img0.jpg"), "w") as f:
             f.write("aa")
 
         with self.assertRaises(ExecutorError):
             load_query = f"LOAD IMAGE '{large_scale_image_files_path}/**/*.jpg' INTO MyLargeScaleImages;"
-            execute_query_fetch_all(load_query)
+            execute_query_fetch_all(self.evadb, load_query)
 
         drop_query = "DROP TABLE IF EXISTS MyLargeScaleImages;"
-        execute_query_fetch_all(drop_query)
+        execute_query_fetch_all(self.evadb, drop_query)
 
         # Clean up large scale image directory.
         shutil.rmtree(large_scale_image_files_path)
 
     def test_load_pdfs(self):
         execute_query_fetch_all(
-            f"""LOAD DOCUMENT '{EVA_ROOT_DIR}/data/documents/*.pdf' INTO pdfs;"""
+            self.evadb,
+            f"""LOAD DOCUMENT '{EVA_ROOT_DIR}/data/documents/*.pdf' INTO pdfs;""",
         )
-        result = execute_query_fetch_all("SELECT * from pdfs;")
+        result = execute_query_fetch_all(self.evadb, "SELECT * from pdfs;")
         self.assertEqual(len(result.columns), 3)
-        self.assertEqual(len(result), 3)
+        self.assertEqual(len(result), 4)
 
 
 if __name__ == "__main__":
     unittest.main()
```

### Comparing `evadb-0.2.6/test/integration_tests/test_load_pdf_executor.py` & `evadb-0.2.7/test/integration_tests/test_load_pdf_executor.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,55 +1,55 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
+from test.util import get_evadb_for_testing
 
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.server.command_handler import execute_query_fetch_all
 
 
 @pytest.mark.notparallel
 class LoadExecutorTest(unittest.TestCase):
     def setUp(self):
+        self.evadb = get_evadb_for_testing()
         # reset the catalog manager before running each test
-        CatalogManager().reset()
+        self.evadb.catalog().reset()
 
     def tearDown(self):
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyPDFs;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyPDFs;")
 
     def test_load_pdfs(self):
         pdf_path = f"{EVA_ROOT_DIR}/data/documents/pdf_sample1.pdf"
 
         import fitz
+
         doc = fitz.open(pdf_path)
         number_of_paragraphs = 0
         for page in doc:
             blocks = page.get_text("dict")["blocks"]
             for b in blocks:
-                if b['type'] == 0:
+                if b["type"] == 0:
                     block_string = ""
                     for lines in b["lines"]:
                         for span in lines["spans"]:
-                            if span['text'].strip():
-                                block_string += span['text']
+                            if span["text"].strip():
+                                block_string += span["text"]
                     number_of_paragraphs += 1
 
-        execute_query_fetch_all(
-            f"""LOAD PDF '{pdf_path}' INTO MyPDFs;"""
-        )
-        result = execute_query_fetch_all("SELECT * from MyPDFs;")
+        execute_query_fetch_all(self.evadb, f"""LOAD PDF '{pdf_path}' INTO MyPDFs;""")
+        result = execute_query_fetch_all(self.evadb, "SELECT * from MyPDFs;")
         self.assertEqual(len(result.columns), 5)
         self.assertEqual(len(result), number_of_paragraphs)
```

### Comparing `evadb-0.2.6/test/integration_tests/test_mat_executor.py` & `evadb-0.2.7/test/integration_tests/test_mat_executor.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,66 +13,70 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from test.util import (
     DummyObjectDetector,
     create_sample_video,
     file_remove,
+    get_evadb_for_testing,
     load_udfs_for_testing,
     shutdown_ray,
 )
 
 import pandas as pd
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
 
 NUM_FRAMES = 10
 
 
 @pytest.mark.notparallel
 class MaterializedViewTest(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
+        import ray
+
+        ray.init(num_cpus=1)
+        cls.evadb = get_evadb_for_testing()
         # reset the catalog manager before running each test
-        CatalogManager().reset()
+        cls.evadb.catalog().reset()
         video_file_path = create_sample_video()
         load_query = f"LOAD VIDEO '{video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(load_query)
+        execute_query_fetch_all(cls.evadb, load_query)
         ua_detrac = f"{EVA_ROOT_DIR}/data/ua_detrac/ua_detrac.mp4"
-        execute_query_fetch_all(f"LOAD VIDEO '{ua_detrac}' INTO UATRAC;")
-        load_udfs_for_testing()
+        execute_query_fetch_all(cls.evadb, f"LOAD VIDEO '{ua_detrac}' INTO UATRAC;")
+        load_udfs_for_testing(cls.evadb)
 
     @classmethod
     def tearDownClass(cls):
         shutdown_ray()
         file_remove("dummy.avi")
         file_remove("ua_detrac.mp4")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
-        execute_query_fetch_all("DROP TABLE UATRAC;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE UATRAC;")
 
     def setUp(self):
-        execute_query_fetch_all("DROP TABLE IF EXISTS dummy_view;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS uadtrac_fastRCNN;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS dummy_view;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS uadtrac_fastRCNN;")
 
     def tearDown(self):
-        execute_query_fetch_all("DROP TABLE IF EXISTS dummy_view;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS uadtrac_fastRCNN;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS dummy_view;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS uadtrac_fastRCNN;")
 
     def test_should_mat_view_with_dummy(self):
         materialized_query = """CREATE MATERIALIZED VIEW dummy_view (id, label)
             AS SELECT id, DummyObjectDetector(data).label FROM MyVideo;
         """
-        execute_query_fetch_all(materialized_query)
+        execute_query_fetch_all(self.evadb, materialized_query)
 
         select_query = "SELECT id, label FROM dummy_view;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
 
         labels = DummyObjectDetector().labels
         expected = [
             {"dummy_view.id": i, "dummy_view.label": [labels[1 + i % 2]]}
             for i in range(NUM_FRAMES)
         ]
@@ -81,44 +85,44 @@
 
     def test_should_mat_view_to_the_same_table(self):
         materialized_query = """CREATE MATERIALIZED VIEW IF NOT EXISTS
             dummy_view (id, label)
             AS SELECT id, DummyObjectDetector(data).label FROM MyVideo
             WHERE id < 5;
         """
-        execute_query_fetch_all(materialized_query)
+        execute_query_fetch_all(self.evadb, materialized_query)
 
         materialized_query = """CREATE MATERIALIZED VIEW IF NOT EXISTS
             dummy_view (id, label)
             AS SELECT id, DummyObjectDetector(data).label FROM MyVideo
             WHERE id >= 5;
         """
-        execute_query_fetch_all(materialized_query)
+        execute_query_fetch_all(self.evadb, materialized_query)
 
         select_query = "SELECT id, label FROM dummy_view;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
 
         labels = DummyObjectDetector().labels
         expected = [
             {"dummy_view.id": i, "dummy_view.label": [labels[1 + i % 2]]}
             for i in range(5)
         ]
         expected_batch = Batch(frames=pd.DataFrame(expected))
         self.assertEqual(actual_batch, expected_batch)
 
     def test_should_infer_mat_view_column_names_with_dummy(self):
-        execute_query_fetch_all("DROP TABLE IF EXISTS dummy_view;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS dummy_view;")
         materialized_query = """CREATE MATERIALIZED VIEW dummy_view
             AS SELECT id, DummyObjectDetector(data).label FROM MyVideo;
         """
-        execute_query_fetch_all(materialized_query)
+        execute_query_fetch_all(self.evadb, materialized_query)
 
         select_query = "SELECT id, label FROM dummy_view;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
 
         labels = DummyObjectDetector().labels
         expected = [
             {"dummy_view.id": i, "dummy_view.label": [labels[1 + i % 2]]}
             for i in range(NUM_FRAMES)
         ]
@@ -132,18 +136,18 @@
             "Yolo(data).bboxes "
             "FROM UATRAC WHERE id < 5;"
         )
         query = (
             "CREATE MATERIALIZED VIEW IF NOT EXISTS "
             f"uadtrac_fastRCNN (id, labels, bboxes) AS {select_query}"
         )
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         select_view_query = "SELECT id, labels, bboxes FROM uadtrac_fastRCNN"
-        actual_batch = execute_query_fetch_all(select_view_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_view_query)
         actual_batch.sort()
 
         self.assertEqual(len(actual_batch), 5)
         # non-trivial test case
         res = actual_batch.frames
         for idx in res.index:
             self.assertTrue("car" in res["uadtrac_fastrcnn.labels"][idx])
@@ -154,40 +158,48 @@
             "SELECT id, label, bbox FROM UATRAC JOIN LATERAL "
             "Yolo(data) AS T(label, bbox, score) WHERE id < 5;"
         )
         query = (
             "CREATE MATERIALIZED VIEW IF NOT EXISTS "
             f"uadtrac_fastRCNN (id, label, bbox) AS {select_query};"
         )
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         select_view_query = "SELECT id, label, bbox FROM uadtrac_fastRCNN"
-        actual_batch = execute_query_fetch_all(select_view_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_view_query)
         actual_batch.sort()
 
         self.assertEqual(len(actual_batch), 5)
         # non-trivial test case
         res = actual_batch.frames
         for idx in res.index:
             self.assertTrue("car" in res["uadtrac_fastrcnn.label"][idx])
 
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS uadtrac_fastRCNN;")
+
     @pytest.mark.torchtest
     def test_should_infer_mat_view_column_names_with_fastrcnn_lateral_join(self):
         select_query = (
             "SELECT id, label, bbox FROM UATRAC JOIN LATERAL "
             "Yolo(data) AS T(label, bbox, score) WHERE id < 5;"
         )
         query = (
             "CREATE MATERIALIZED VIEW IF NOT EXISTS "
             f"uadtrac_fastRCNN AS {select_query};"
         )
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         select_view_query = "SELECT id, label, bbox FROM uadtrac_fastRCNN"
-        actual_batch = execute_query_fetch_all(select_view_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_view_query)
         actual_batch.sort()
 
         self.assertEqual(len(actual_batch), 5)
         # non-trivial test case
         res = actual_batch.frames
         for idx in res.index:
             self.assertTrue("car" in res["uadtrac_fastrcnn.label"][idx])
+
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS uadtrac_fastRCNN;")
+
+
+if __name__ == "__main__":
+    unittest.main()
```

### Comparing `evadb-0.2.6/test/integration_tests/test_open.py` & `evadb-0.2.7/test/integration_tests/test_open.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,64 +12,65 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from test.util import (
     create_sample_image,
     file_remove,
+    get_evadb_for_testing,
     load_udfs_for_testing,
     shutdown_ray,
 )
 
 import numpy as np
 import pandas as pd
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
-from eva.storage.storage_engine import StorageEngine
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
+from evadb.storage.storage_engine import StorageEngine
 
 
 @pytest.mark.notparallel
 class OpenTests(unittest.TestCase):
     def setUp(self):
-        CatalogManager().reset()
-        ConfigurationManager()
+        self.evadb = get_evadb_for_testing()
+        self.evadb.catalog().reset()
         # Load built-in UDFs.
-        load_udfs_for_testing(mode="debug")
+        load_udfs_for_testing(self.evadb, mode="debug")
 
         # Insert image path.
         self.img_path = create_sample_image()
         create_table_query = "CREATE TABLE IF NOT EXISTS testOpenTable (num INTEGER);"
-        execute_query_fetch_all(create_table_query)
+        execute_query_fetch_all(self.evadb, create_table_query)
 
         # Insert dummy data into table.
-        table_catalog_entry = CatalogManager().get_table_catalog_entry("testOpenTable")
-        storage_engine = StorageEngine().factory(table_catalog_entry)
+        table_catalog_entry = self.evadb.catalog().get_table_catalog_entry(
+            "testOpenTable"
+        )
+        storage_engine = StorageEngine.factory(self.evadb, table_catalog_entry)
         storage_engine.write(
             table_catalog_entry, Batch(pd.DataFrame([{"num": 1}, {"num": 2}]))
         )
 
     def tearDown(self):
         shutdown_ray()
 
         file_remove("dummy.jpg")
 
         # Drop table.
         drop_table_query = "DROP TABLE testOpenTable;"
-        execute_query_fetch_all(drop_table_query)
+        execute_query_fetch_all(self.evadb, drop_table_query)
 
     def test_open_should_open_image(self):
         # Test query runs successfully with Open function call.
         select_query = """SELECT num, Open("{}") FROM testOpenTable;""".format(
             self.img_path
         )
-        batch_res = execute_query_fetch_all(select_query)
+        batch_res = execute_query_fetch_all(self.evadb, select_query)
 
         expected_img = np.array(np.ones((3, 3, 3)), dtype=np.float32)
         expected_img[0] -= 1
         expected_img[2] += 1
 
         expected_batch = Batch(
             pd.DataFrame(
```

### Comparing `evadb-0.2.6/test/integration_tests/test_optimizer_rules.py` & `evadb-0.2.7/test/integration_tests/test_optimizer_rules.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,68 +1,70 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-from test.util import get_physical_query_plan, load_udfs_for_testing, shutdown_ray
+from test.markers import ray_skip_marker
+from test.util import (
+    get_evadb_for_testing,
+    get_physical_query_plan,
+    load_udfs_for_testing,
+    shutdown_ray,
+)
 
 import numpy as np
 import pandas as pd
 import pytest
 from mock import MagicMock, patch
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.models.storage.batch import Batch
-from eva.optimizer.plan_generator import PlanGenerator
-from eva.optimizer.rules.rules import (
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.models.storage.batch import Batch
+from evadb.optimizer.plan_generator import PlanGenerator
+from evadb.optimizer.rules.rules import (
     PushDownFilterThroughApplyAndMerge,
     PushDownFilterThroughJoin,
     ReorderPredicates,
     XformLateralJoinToLinearFlow,
 )
-from eva.optimizer.rules.rules_manager import disable_rules
-from eva.plan_nodes.predicate_plan import PredicatePlan
-from eva.server.command_handler import execute_query_fetch_all
-from eva.utils.stats import Timer
+from evadb.optimizer.rules.rules_manager import RulesManager, disable_rules
+from evadb.plan_nodes.predicate_plan import PredicatePlan
+from evadb.server.command_handler import execute_query_fetch_all
+from evadb.utils.stats import Timer
 
 
 @pytest.mark.notparallel
-@pytest.mark.skipif(
-    ConfigurationManager().get_value("experimental", "ray"),
-    reason="Not necessary for Ray",
-)
+@ray_skip_marker
 class OptimizerRulesTest(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        CatalogManager().reset()
+        cls.evadb = get_evadb_for_testing()
+        cls.evadb.catalog().reset()
         ua_detrac = f"{EVA_ROOT_DIR}/data/ua_detrac/ua_detrac.mp4"
-        execute_query_fetch_all(f"LOAD VIDEO '{ua_detrac}' INTO MyVideo;")
-        execute_query_fetch_all(f"LOAD VIDEO '{ua_detrac}' INTO MyVideo2;")
-        load_udfs_for_testing(mode="debug")
+        execute_query_fetch_all(cls.evadb, f"LOAD VIDEO '{ua_detrac}' INTO MyVideo;")
+        execute_query_fetch_all(cls.evadb, f"LOAD VIDEO '{ua_detrac}' INTO MyVideo2;")
+        load_udfs_for_testing(cls.evadb, mode="debug")
 
     @classmethod
     def tearDownClass(cls):
         shutdown_ray()
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MyVideo;")
 
-    @patch("eva.expression.function_expression.FunctionExpression.evaluate")
-    @patch("eva.models.storage.batch.Batch.merge_column_wise")
+    @patch("evadb.expression.function_expression.FunctionExpression.evaluate")
+    @patch("evadb.models.storage.batch.Batch.merge_column_wise")
     def test_should_benefit_from_pushdown(self, merge_mock, evaluate_mock):
         # added to mock away the
         evaluate_mock.return_value = Batch(
             pd.DataFrame(
                 {
                     "obj.labels": ["car"],
                     "obj.bboxes": [np.array([1, 2, 3, 4])],
@@ -74,86 +76,91 @@
                   FROM MyVideo JOIN LATERAL
                     FastRCNNObjectDetector(data) AS obj(labels, bboxes, scores)
                   WHERE id < 2;"""
 
         time_with_rule = Timer()
         result_with_rule = None
         with time_with_rule:
-            result_with_rule = execute_query_fetch_all(query)
+            result_with_rule = execute_query_fetch_all(self.evadb, query)
 
         evaluate_count_with_rule = evaluate_mock.call_count
 
         time_without_rule = Timer()
         result_without_pushdown_rules = None
+
         with time_without_rule:
+            rules_manager = RulesManager(self.evadb.config)
             with disable_rules(
-                [PushDownFilterThroughApplyAndMerge(), PushDownFilterThroughJoin()]
-            ) as rules_manager:
-                custom_plan_generator = PlanGenerator(rules_manager)
+                rules_manager,
+                [PushDownFilterThroughApplyAndMerge(), PushDownFilterThroughJoin()],
+            ):
+                custom_plan_generator = PlanGenerator(self.evadb, rules_manager)
                 result_without_pushdown_rules = execute_query_fetch_all(
-                    query, plan_generator=custom_plan_generator
+                    self.evadb, query, plan_generator=custom_plan_generator
                 )
 
         self.assertEqual(result_without_pushdown_rules, result_with_rule)
 
         evaluate_count_without_rule = (
             evaluate_mock.call_count - evaluate_count_with_rule
         )
 
         # without rule it should be slow as we end up running the function
         # on all the frames
         self.assertGreater(evaluate_count_without_rule, 3 * evaluate_count_with_rule)
 
         result_without_xform_rule = None
-        with disable_rules([XformLateralJoinToLinearFlow()]) as rules_manager:
-            custom_plan_generator = PlanGenerator(rules_manager)
+        rules_manager = RulesManager(self.evadb.config)
+        with disable_rules(rules_manager, [XformLateralJoinToLinearFlow()]):
+            custom_plan_generator = PlanGenerator(self.evadb, rules_manager)
             result_without_xform_rule = execute_query_fetch_all(
-                query, plan_generator=custom_plan_generator
+                self.evadb, query, plan_generator=custom_plan_generator
             )
 
         self.assertEqual(result_without_xform_rule, result_with_rule)
 
     def test_should_pushdown_without_pushdown_join_rule(self):
         query = """SELECT id, obj.labels
                     FROM MyVideo JOIN LATERAL
                     FastRCNNObjectDetector(data) AS obj(labels, bboxes, scores)
                     WHERE id < 2;"""
 
         time_with_rule = Timer()
         result_with_rule = None
         with time_with_rule:
-            result_with_rule = execute_query_fetch_all(query)
-            query_plan = execute_query_fetch_all(f"EXPLAIN {query}")
+            result_with_rule = execute_query_fetch_all(self.evadb, query)
+            query_plan = execute_query_fetch_all(self.evadb, f"EXPLAIN {query}")
         time_without_rule = Timer()
         result_without_pushdown_join_rule = None
         with time_without_rule:
-            with disable_rules([PushDownFilterThroughJoin()]) as rules_manager:
+            rules_manager = RulesManager(self.evadb.config)
+            with disable_rules(rules_manager, [PushDownFilterThroughJoin()]):
                 # should use PushDownFilterThroughApplyAndMerge()
-                custom_plan_generator = PlanGenerator(rules_manager)
+                custom_plan_generator = PlanGenerator(self.evadb, rules_manager)
                 result_without_pushdown_join_rule = execute_query_fetch_all(
-                    query, plan_generator=custom_plan_generator
+                    self.evadb, query, plan_generator=custom_plan_generator
                 )
                 query_plan_without_pushdown_join_rule = execute_query_fetch_all(
-                    f"EXPLAIN {query}", plan_generator=custom_plan_generator
+                    self.evadb, f"EXPLAIN {query}", plan_generator=custom_plan_generator
                 )
 
         self.assertEqual(result_without_pushdown_join_rule, result_with_rule)
         self.assertEqual(query_plan, query_plan_without_pushdown_join_rule)
 
-    @patch("eva.catalog.catalog_manager.CatalogManager.get_udf_cost_catalog_entry")
+    @patch("evadb.catalog.catalog_manager.CatalogManager.get_udf_cost_catalog_entry")
     def test_should_reorder_predicates(self, mock):
         def _check_reorder(cost_func):
             mock.side_effect = cost_func
 
             pred_1 = "DummyObjectDetector(data).label = ['person']"
             pred_2 = "DummyMultiObjectDetector(data).labels @> ['person']"
 
             query = f"SELECT id FROM MyVideo WHERE {pred_2} AND {pred_1};"
 
-            plan = get_physical_query_plan(query)
+            plan = get_physical_query_plan(self.evadb, query)
             predicate_plans = list(plan.find_all(PredicatePlan))
             self.assertEqual(len(predicate_plans), 1)
 
             left: ComparisonExpression = predicate_plans[0].predicate.children[0]
             right: ComparisonExpression = predicate_plans[0].predicate.children[1]
 
             # predicates reordered based on the cost
@@ -168,23 +175,23 @@
         )
 
         # reordering if first predicate has no cost
         _check_reorder(
             lambda name: MagicMock(cost=5) if name == "DummyObjectDetector" else None
         )
 
-    @patch("eva.catalog.catalog_manager.CatalogManager.get_udf_cost_catalog_entry")
+    @patch("evadb.catalog.catalog_manager.CatalogManager.get_udf_cost_catalog_entry")
     def test_should_not_reorder_predicates(self, mock):
         def _check_no_reorder(cost_func):
             mock.side_effect = cost_func
             cheap_pred = "DummyObjectDetector(data).label = ['person']"
             costly_pred = "DummyMultiObjectDetector(data).labels @> ['person']"
 
             query = f"SELECT id FROM MyVideo WHERE {cheap_pred} AND {costly_pred};"
-            plan = get_physical_query_plan(query)
+            plan = get_physical_query_plan(self.evadb, query)
 
             predicate_plans = list(plan.find_all(PredicatePlan))
             self.assertEqual(len(predicate_plans), 1)
 
             left: ComparisonExpression = predicate_plans[0].predicate.children[0]
             right: ComparisonExpression = predicate_plans[0].predicate.children[1]
 
@@ -210,15 +217,15 @@
         _check_no_reorder(
             lambda name: MagicMock(cost=5) if name == "DummyObjectDetector" else None
         )
 
         # no reordering if default cost is used for both UDF
         _check_no_reorder(lambda name: None)
 
-    @patch("eva.catalog.catalog_manager.CatalogManager.get_udf_cost_catalog_entry")
+    @patch("evadb.catalog.catalog_manager.CatalogManager.get_udf_cost_catalog_entry")
     def test_should_reorder_multiple_predicates(self, mock):
         def side_effect_func(name):
             if name == "DummyMultiObjectDetector":
                 return MagicMock(cost=10)
             else:
                 return MagicMock(cost=5)
 
@@ -229,15 +236,15 @@
         costly_pred = "DummyMultiObjectDetector(data).labels @> ['person']"
 
         query = (
             f"SELECT id FROM MyVideo WHERE {costly_pred} AND {cheap_pred} AND "
             f"{cheapest_pred};"
         )
 
-        plan = get_physical_query_plan(query)
+        plan = get_physical_query_plan(self.evadb, query)
         predicate_plans = list(plan.find_all(PredicatePlan))
         self.assertEqual(len(predicate_plans), 1)
 
         left = predicate_plans[0].predicate.children[0]
         right = predicate_plans[0].predicate.children[1]
 
         # only 2 comparison expressions as id predicate is pushed down
@@ -245,15 +252,16 @@
         self.assertIsInstance(right, ComparisonExpression)
         # predicates reordered based on the cost
         self.assertEqual(left.children[0].name, "DummyObjectDetector")
         self.assertEqual(right.children[0].name, "DummyMultiObjectDetector")
 
     def test_reorder_rule_should_not_have_side_effects(self):
         query = "SELECT id FROM MyVideo WHERE id < 20 AND id > 10;"
-        result = execute_query_fetch_all(query)
+        result = execute_query_fetch_all(self.evadb, query)
 
-        with disable_rules([ReorderPredicates()]) as rules_manager:
-            custom_plan_generator = PlanGenerator(rules_manager)
+        rules_manager = RulesManager(self.evadb.config)
+        with disable_rules(rules_manager, [ReorderPredicates()]):
+            custom_plan_generator = PlanGenerator(self.evadb, rules_manager)
             expected = execute_query_fetch_all(
-                query, plan_generator=custom_plan_generator
+                self.evadb, query, plan_generator=custom_plan_generator
             )
             self.assertEqual(result, expected)
```

### Comparing `evadb-0.2.6/test/integration_tests/test_pytorch.py` & `evadb-0.2.7/test/integration_tests/test_pytorch.py`

 * *Files 22% similar despite different names*

```diff
@@ -10,313 +10,322 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 import unittest
-from test.markers import ocr_skip_marker, windows_skip_marker
+from test.markers import ocr_skip_marker, ray_only_marker, windows_skip_marker
 from test.util import (
     create_sample_video,
     file_remove,
+    get_evadb_for_testing,
     load_udfs_for_testing,
     shutdown_ray,
 )
 
 import cv2
 import numpy as np
 import pandas.testing as pd_testing
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.executor.executor_utils import ExecutorError
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
-from eva.udfs.udf_bootstrap_queries import Asl_udf_query, Mvit_udf_query
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.executor.executor_utils import ExecutorError
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
+from evadb.udfs.udf_bootstrap_queries import Asl_udf_query, Mvit_udf_query
 
 
 @pytest.mark.notparallel
 class PytorchTest(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        CatalogManager().reset()
+        cls.evadb = get_evadb_for_testing()
+        cls.evadb.catalog().reset()
+        os.environ["ray"] = str(cls.evadb.config.get_value("experimental", "ray"))
+
         ua_detrac = f"{EVA_ROOT_DIR}/data/ua_detrac/ua_detrac.mp4"
         mnist = f"{EVA_ROOT_DIR}/data/mnist/mnist.mp4"
         actions = f"{EVA_ROOT_DIR}/data/actions/actions.mp4"
         asl_actions = f"{EVA_ROOT_DIR}/data/actions/computer_asl.mp4"
         meme1 = f"{EVA_ROOT_DIR}/data/detoxify/meme1.jpg"
         meme2 = f"{EVA_ROOT_DIR}/data/detoxify/meme2.jpg"
 
-        execute_query_fetch_all(f"LOAD VIDEO '{ua_detrac}' INTO MyVideo;")
-        execute_query_fetch_all(f"LOAD VIDEO '{mnist}' INTO MNIST;")
-        execute_query_fetch_all(f"LOAD VIDEO '{actions}' INTO Actions;")
-        execute_query_fetch_all(f"LOAD VIDEO '{asl_actions}' INTO Asl_actions;")
-        execute_query_fetch_all(f"LOAD IMAGE '{meme1}' INTO MemeImages;")
-        execute_query_fetch_all(f"LOAD IMAGE '{meme2}' INTO MemeImages;")
-        load_udfs_for_testing()
+        execute_query_fetch_all(cls.evadb, f"LOAD VIDEO '{ua_detrac}' INTO MyVideo;")
+        execute_query_fetch_all(cls.evadb, f"LOAD VIDEO '{mnist}' INTO MNIST;")
+        execute_query_fetch_all(cls.evadb, f"LOAD VIDEO '{actions}' INTO Actions;")
+        execute_query_fetch_all(
+            cls.evadb, f"LOAD VIDEO '{asl_actions}' INTO Asl_actions;"
+        )
+        execute_query_fetch_all(cls.evadb, f"LOAD IMAGE '{meme1}' INTO MemeImages;")
+        execute_query_fetch_all(cls.evadb, f"LOAD IMAGE '{meme2}' INTO MemeImages;")
+        load_udfs_for_testing(cls.evadb)
 
     @classmethod
     def tearDownClass(cls):
-        shutdown_ray()
-
         file_remove("ua_detrac.mp4")
         file_remove("mnist.mp4")
         file_remove("actions.mp4")
         file_remove("computer_asl.mp4")
 
-        execute_query_fetch_all("DROP TABLE IF EXISTS Actions;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MNIST;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS Asl_actions;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MemeImages;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS Actions;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MNIST;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS Asl_actions;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MemeImages;")
 
     def assertBatchEqual(self, a: Batch, b: Batch, msg: str):
         try:
             pd_testing.assert_frame_equal(a.frames, b.frames)
         except AssertionError as e:
             raise self.failureException(msg) from e
 
     def setUp(self):
         self.addTypeEqualityFunc(Batch, self.assertBatchEqual)
 
-    @pytest.mark.skipif(
-        not ConfigurationManager().get_value("experimental", "ray"),
-        reason="Only test for parallel execution",
-    )
+    def tearDown(self) -> None:
+        shutdown_ray()
+
+    @ray_only_marker
     def test_should_apply_parallel_match_sequential(self):
         # Parallel execution
         select_query = """SELECT id, obj.labels
                           FROM MyVideo JOIN LATERAL
                           FastRCNNObjectDetector(data)
                           AS obj(labels, bboxes, scores)
                          WHERE id < 20;"""
-        par_batch = execute_query_fetch_all(select_query)
+        par_batch = execute_query_fetch_all(self.evadb, select_query)
 
         # Sequential execution.
-        ConfigurationManager().update_value("experimental", "ray", False)
+        self.evadb.config.update_value("experimental", "ray", False)
         select_query = """SELECT id, obj.labels
                           FROM MyVideo JOIN LATERAL
                           FastRCNNObjectDetector(data)
                           AS obj(labels, bboxes, scores)
                          WHERE id < 20;"""
-        seq_batch = execute_query_fetch_all(select_query)
+        seq_batch = execute_query_fetch_all(self.evadb, select_query)
         # Recover configuration back.
-        ConfigurationManager().update_value("experimental", "ray", True)
+        self.evadb.config.update_value("experimental", "ray", True)
 
         self.assertEqual(len(par_batch), len(seq_batch))
         self.assertEqual(par_batch, seq_batch)
 
-    @pytest.mark.skipif(
-        not ConfigurationManager().get_value("experimental", "ray"),
-        reason="Only test for Ray",
-    )
+    @ray_only_marker
     def test_should_project_parallel_match_sequential(self):
-        create_udf_query = """CREATE UDF FaceDetector
+        create_udf_query = """CREATE UDF IF NOT EXISTS FaceDetector
                   INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
                   OUTPUT (bboxes NDARRAY FLOAT32(ANYDIM, 4),
                           scores NDARRAY FLOAT32(ANYDIM))
                   TYPE  FaceDetection
-                  IMPL  'eva/udfs/face_detector.py';
+                  IMPL  'evadb/udfs/face_detector.py';
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
-        select_query = """SELECT FaceDetector(data) FROM MyVideo
-                        WHERE id < 5;"""
+        select_query = "SELECT FaceDetector(data) FROM MyVideo WHERE id < 5;"
         # Parallel execution
-        par_batch = execute_query_fetch_all(select_query)
+        par_batch = execute_query_fetch_all(self.evadb, select_query)
 
         # Sequential execution.
-        ConfigurationManager().update_value("experimental", "ray", False)
-        seq_batch = execute_query_fetch_all(select_query)
+        self.evadb.config.update_value("experimental", "ray", False)
+        seq_batch = execute_query_fetch_all(self.evadb, select_query)
         # Recover configuration back.
-        ConfigurationManager().update_value("experimental", "ray", True)
+        self.evadb.config.update_value("experimental", "ray", True)
 
         self.assertEqual(len(par_batch), len(seq_batch))
         self.assertEqual(par_batch, seq_batch)
 
-    @pytest.mark.skipif(
-        not ConfigurationManager().get_value("experimental", "ray"),
-        reason="Only test for Ray",
-    )
     def test_should_raise_exception_with_parallel(self):
         # Deliberately cause error.
         video_path = create_sample_video(100)
         load_query = f"LOAD VIDEO '{video_path}' INTO parallelErrorVideo;"
-        execute_query_fetch_all(load_query)
+        execute_query_fetch_all(self.evadb, load_query)
         file_remove("dummy.avi")
 
         select_query = """SELECT id, obj.labels
                           FROM parallelErrorVideo JOIN LATERAL
                           FastRCNNObjectDetector(data)
                           AS obj(labels, bboxes, scores)
                          WHERE id < 2;"""
         with self.assertRaises(ExecutorError):
-            execute_query_fetch_all(select_query)
+            execute_query_fetch_all(self.evadb, select_query)
 
     @pytest.mark.torchtest
     def test_should_run_pytorch_and_fastrcnn_with_lateral_join(self):
         select_query = """SELECT id, obj.labels
                           FROM MyVideo JOIN LATERAL
                           FastRCNNObjectDetector(data)
                           AS obj(labels, bboxes, scores)
                          WHERE id < 2;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(len(actual_batch), 2)
 
     @pytest.mark.torchtest
     def test_should_run_pytorch_and_yolo_and_mvit(self):
-        execute_query_fetch_all(Mvit_udf_query)
+        execute_query_fetch_all(self.evadb, Mvit_udf_query)
 
         select_query = """SELECT FIRST(id),
                             Yolo(FIRST(data)),
                             MVITActionRecognition(SEGMENT(data))
                             FROM Actions
                             WHERE id < 32
-                            GROUP BY '16f'; """
-        actual_batch = execute_query_fetch_all(select_query)
+                            GROUP BY '16 frames'; """
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(len(actual_batch), 2)
 
         res = actual_batch.frames
         for idx in res.index:
             self.assertTrue(
                 "person" in res["yolo.labels"][idx]
                 and "yoga" in res["mvitactionrecognition.labels"][idx]
             )
 
     @pytest.mark.torchtest
     def test_should_run_pytorch_and_asl(self):
-        execute_query_fetch_all(Asl_udf_query)
+        execute_query_fetch_all(self.evadb, Asl_udf_query)
         select_query = """SELECT FIRST(id), ASLActionRecognition(SEGMENT(data))
                         FROM Asl_actions
                         SAMPLE 5
-                        GROUP BY '16f';"""
-        actual_batch = execute_query_fetch_all(select_query)
+                        GROUP BY '16 frames';"""
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
 
         res = actual_batch.frames
 
         self.assertEqual(len(res), 1)
         for idx in res.index:
             self.assertTrue("computer" in res["aslactionrecognition.labels"][idx])
 
     @pytest.mark.torchtest
+    def test_should_run_pytorch_and_facenet(self):
+        create_udf_query = """CREATE UDF IF NOT EXISTS FaceDetector
+                  INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
+                  OUTPUT (bboxes NDARRAY FLOAT32(ANYDIM, 4),
+                          scores NDARRAY FLOAT32(ANYDIM))
+                  TYPE  FaceDetection
+                  IMPL  'evadb/udfs/face_detector.py';
+        """
+        execute_query_fetch_all(self.evadb, create_udf_query)
+
+        select_query = """SELECT FaceDetector(data) FROM MyVideo
+                        WHERE id < 5;"""
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
+        self.assertEqual(len(actual_batch), 5)
+
+    @pytest.mark.torchtest
     @windows_skip_marker
     @ocr_skip_marker
     def test_should_run_pytorch_and_ocr(self):
         create_udf_query = """CREATE UDF IF NOT EXISTS OCRExtractor
                   INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
                   OUTPUT (labels NDARRAY STR(10),
                           bboxes NDARRAY FLOAT32(ANYDIM, 4),
                           scores NDARRAY FLOAT32(ANYDIM))
                   TYPE  OCRExtraction
-                  IMPL  'eva/udfs/ocr_extractor.py';
+                  IMPL  'evadb/udfs/ocr_extractor.py';
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         select_query = """SELECT OCRExtractor(data) FROM MNIST
                         WHERE id >= 150 AND id < 155;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(len(actual_batch), 5)
 
         # non-trivial test case for MNIST
         res = actual_batch.frames
         self.assertTrue(res["ocrextractor.labels"][0][0] == "4")
         self.assertTrue(res["ocrextractor.scores"][2][0] > 0.9)
 
     @pytest.mark.torchtest
     def test_should_run_pytorch_and_resnet50(self):
         create_udf_query = """CREATE UDF IF NOT EXISTS FeatureExtractor
                   INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
                   OUTPUT (features NDARRAY FLOAT32(ANYDIM))
                   TYPE  Classification
-                  IMPL  'eva/udfs/feature_extractor.py';
+                  IMPL  'evadb/udfs/feature_extractor.py';
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         select_query = """SELECT FeatureExtractor(data) FROM MyVideo
                         WHERE id < 5;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(len(actual_batch), 5)
 
         # non-trivial test case for Resnet50
         res = actual_batch.frames
         self.assertEqual(res["featureextractor.features"][0].shape, (1, 2048))
         # self.assertTrue(res["featureextractor.features"][0][0][0] > 0.3)
 
     @pytest.mark.torchtest
     def test_should_run_pytorch_and_similarity(self):
         create_open_udf_query = """CREATE UDF IF NOT EXISTS Open
                 INPUT (img_path TEXT(1000))
                 OUTPUT (data NDARRAY UINT8(3, ANYDIM, ANYDIM))
                 TYPE NdarrayUDF
-                IMPL "eva/udfs/ndarray/open.py";
+                IMPL "evadb/udfs/ndarray/open.py";
         """
-        execute_query_fetch_all(create_open_udf_query)
+        execute_query_fetch_all(self.evadb, create_open_udf_query)
 
         create_similarity_udf_query = """CREATE UDF IF NOT EXISTS Similarity
                     INPUT (Frame_Array_Open NDARRAY UINT8(3, ANYDIM, ANYDIM),
                            Frame_Array_Base NDARRAY UINT8(3, ANYDIM, ANYDIM),
                            Feature_Extractor_Name TEXT(100))
                     OUTPUT (distance FLOAT(32, 7))
                     TYPE NdarrayUDF
-                    IMPL "eva/udfs/ndarray/similarity.py";
+                    IMPL "evadb/udfs/ndarray/similarity.py";
         """
-        execute_query_fetch_all(create_similarity_udf_query)
+        execute_query_fetch_all(self.evadb, create_similarity_udf_query)
 
         create_feat_udf_query = """CREATE UDF IF NOT EXISTS FeatureExtractor
                   INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
                   OUTPUT (features NDARRAY FLOAT32(ANYDIM))
                   TYPE  Classification
-                  IMPL  "eva/udfs/feature_extractor.py";
+                  IMPL  "evadb/udfs/feature_extractor.py";
         """
-        execute_query_fetch_all(create_feat_udf_query)
+        execute_query_fetch_all(self.evadb, create_feat_udf_query)
 
         select_query = """SELECT data FROM MyVideo WHERE id = 1;"""
-        batch_res = execute_query_fetch_all(select_query)
+        batch_res = execute_query_fetch_all(self.evadb, select_query)
         img = batch_res.frames["myvideo.data"][0]
 
-        config = ConfigurationManager()
-        tmp_dir_from_config = config.get_value("storage", "tmp_dir")
+        tmp_dir_from_config = self.evadb.config.get_value("storage", "tmp_dir")
 
         img_save_path = os.path.join(tmp_dir_from_config, "dummy.jpg")
         try:
             os.remove(img_save_path)
         except FileNotFoundError:
             pass
         cv2.imwrite(img_save_path, img)
 
         similarity_query = """SELECT data FROM MyVideo WHERE id < 5
                     ORDER BY Similarity(FeatureExtractor(Open("{}")),
                                         FeatureExtractor(data))
                     LIMIT 1;""".format(
             img_save_path
         )
-        actual_batch = execute_query_fetch_all(similarity_query)
+        actual_batch = execute_query_fetch_all(self.evadb, similarity_query)
 
         similar_data = actual_batch.frames["myvideo.data"][0]
         self.assertTrue(np.array_equal(img, similar_data))
 
     @pytest.mark.torchtest
     @windows_skip_marker
     @ocr_skip_marker
     def test_should_run_ocr_on_cropped_data(self):
         create_udf_query = """CREATE UDF IF NOT EXISTS OCRExtractor
                   INPUT  (text NDARRAY STR(100))
                   OUTPUT (labels NDARRAY STR(10),
                           bboxes NDARRAY FLOAT32(ANYDIM, 4),
                           scores NDARRAY FLOAT32(ANYDIM))
                   TYPE  OCRExtraction
-                  IMPL  'eva/udfs/ocr_extractor.py';
+                  IMPL  'evadb/udfs/ocr_extractor.py';
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         select_query = """SELECT OCRExtractor(Crop(data, [2, 2, 24, 24])) FROM MNIST
                         WHERE id >= 150 AND id < 155;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(len(actual_batch), 5)
 
         # non-trivial test case for MNIST
         res = actual_batch.frames
         self.assertTrue(res["ocrextractor.labels"][0][0] == "4")
         self.assertTrue(res["ocrextractor.scores"][2][0] > 0.9)
 
@@ -324,32 +333,36 @@
     def test_should_run_extract_object(self):
         select_query = """
             SELECT id, T.iids, T.bboxes, T.scores, T.labels
             FROM MyVideo JOIN LATERAL EXTRACT_OBJECT(data, Yolo, NorFairTracker)
                 AS T(iids, labels, bboxes, scores)
             WHERE id < 30;
             """
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(len(actual_batch), 30)
 
         num_of_entries = actual_batch.frames["T.iids"].apply(lambda x: len(x)).sum()
 
         select_query = """
             SELECT id, T.iid, T.bbox, T.score, T.label
             FROM MyVideo JOIN LATERAL
                 UNNEST(EXTRACT_OBJECT(data, Yolo, NorFairTracker)) AS T(iid, label, bbox, score)
             WHERE id < 30;
             """
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         # do some more meaningful check
         self.assertEqual(len(actual_batch), num_of_entries)
 
     def test_check_unnest_with_predicate_on_yolo(self):
         query = """SELECT id, Yolo.label, Yolo.bbox, Yolo.score
                   FROM MyVideo
                   JOIN LATERAL UNNEST(Yolo(data)) AS Yolo(label, bbox, score)
                   WHERE Yolo.label = 'car' AND id < 2;"""
 
-        actual_batch = execute_query_fetch_all(query)
+        actual_batch = execute_query_fetch_all(self.evadb, query)
 
         # due to unnest the number of returned tuples should be at least > 10
         self.assertTrue(len(actual_batch) > 2)
+
+
+if __name__ == "__main__":
+    unittest.main()
```

### Comparing `evadb-0.2.6/test/integration_tests/test_rename_executor.py` & `evadb-0.2.7/test/integration_tests/test_rename_executor.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,77 +1,82 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-from test.util import create_sample_csv, create_sample_video, file_remove
+from test.util import (
+    create_sample_csv,
+    create_sample_video,
+    file_remove,
+    get_evadb_for_testing,
+)
 
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.server.command_handler import execute_query_fetch_all
 
 
 @pytest.mark.notparallel
 class RenameExecutorTest(unittest.TestCase):
     def setUp(self):
+        self.evadb = get_evadb_for_testing()
         # reset the catalog manager before running each test
-        CatalogManager().reset()
+        self.evadb.catalog().reset()
         self.video_file_path = create_sample_video()
         self.csv_file_path = create_sample_csv()
 
     def tearDown(self):
         file_remove("dummy.avi")
         file_remove("dummy.csv")
 
     # integration test
     def test_should_rename_table(self):
-        catalog_manager = CatalogManager()
+        catalog_manager = self.evadb.catalog()
         query = f"""LOAD VIDEO '{self.video_file_path}' INTO MyVideo;"""
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         self.assertTrue(catalog_manager.get_table_catalog_entry("MyVideo") is not None)
         self.assertTrue(catalog_manager.get_table_catalog_entry("MyVideo1") is None)
 
         rename_query = """RENAME TABLE MyVideo TO MyVideo1;"""
-        execute_query_fetch_all(rename_query)
+        execute_query_fetch_all(self.evadb, rename_query)
 
         self.assertTrue(catalog_manager.get_table_catalog_entry("MyVideo") is None)
         self.assertTrue(catalog_manager.get_table_catalog_entry("MyVideo1") is not None)
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideo;")
 
     # integration test
     def test_should_fail_on_rename_structured_table(self):
         # loading a csv requires a table to be created first
         create_table_query = """
 
             CREATE TABLE IF NOT EXISTS MyVideoCSV (
                 id INTEGER UNIQUE,
                 frame_id INTEGER NOT NULL,
                 video_id INTEGER NOT NULL,
                 dataset_name TEXT(30) NOT NULL
             );
             """
-        execute_query_fetch_all(create_table_query)
+        execute_query_fetch_all(self.evadb, create_table_query)
 
         # load the CSV
         load_query = f"""LOAD CSV '{self.csv_file_path}' INTO MyVideoCSV (id, frame_id, video_id, dataset_name);"""
-        execute_query_fetch_all(load_query)
+        execute_query_fetch_all(self.evadb, load_query)
 
         with self.assertRaises(Exception) as cm:
             rename_query = """RENAME TABLE MyVideoCSV TO MyVideoCSV1;"""
-            execute_query_fetch_all(rename_query)
+            execute_query_fetch_all(self.evadb, rename_query)
 
         self.assertEqual(
             str(cm.exception), "Rename not yet supported on structured data"
         )
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideoCSV;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideoCSV;")
```

### Comparing `evadb-0.2.6/test/integration_tests/test_reuse.py` & `evadb-0.2.7/test/integration_tests/test_reuse.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,66 +13,73 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import gc
 import os
 import unittest
 from pathlib import Path
 from test.markers import duplicate_skip_marker, windows_skip_marker
-from test.util import get_logical_query_plan, load_udfs_for_testing, shutdown_ray
+from test.util import (
+    get_evadb_for_testing,
+    get_logical_query_plan,
+    load_udfs_for_testing,
+    shutdown_ray,
+)
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.optimizer.operators import LogicalFunctionScan
-from eva.optimizer.plan_generator import PlanGenerator
-from eva.optimizer.rules.rules import (
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.optimizer.operators import LogicalFunctionScan
+from evadb.optimizer.plan_generator import PlanGenerator
+from evadb.optimizer.rules.rules import (
     CacheFunctionExpressionInApply,
     CacheFunctionExpressionInFilter,
     CacheFunctionExpressionInProject,
 )
-from eva.optimizer.rules.rules_manager import disable_rules
-from eva.server.command_handler import execute_query_fetch_all
-from eva.utils.stats import Timer
+from evadb.optimizer.rules.rules_manager import RulesManager, disable_rules
+from evadb.server.command_handler import execute_query_fetch_all
+from evadb.utils.stats import Timer
 
 
 class ReuseTest(unittest.TestCase):
     def _load_hf_model(self):
         udf_name = "HFObjectDetector"
         create_udf_query = f"""CREATE UDF {udf_name}
             TYPE HuggingFace
             'task' 'object-detection'
             'model' 'facebook/detr-resnet-50';
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
     def setUp(self):
-        CatalogManager().reset()
+        self.evadb = get_evadb_for_testing()
+        self.evadb.catalog().reset()
         ua_detrac = f"{EVA_ROOT_DIR}/data/ua_detrac/ua_detrac.mp4"
-        execute_query_fetch_all(f"LOAD VIDEO '{ua_detrac}' INTO DETRAC;")
-        load_udfs_for_testing()
+        execute_query_fetch_all(self.evadb, f"LOAD VIDEO '{ua_detrac}' INTO DETRAC;")
+        load_udfs_for_testing(self.evadb)
         self._load_hf_model()
 
     def tearDown(self):
         shutdown_ray()
-        execute_query_fetch_all("DROP TABLE IF EXISTS DETRAC;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS DETRAC;")
 
     def _verify_reuse_correctness(self, query, reuse_batch):
         # Fix memory failures on CI when running reuse test cases. An issue with yolo
         # surfaces when the system is running on low memory. Explicitly calling garbage
         # collection to reduce the memory usage.
         gc.collect()
+        rules_manager = RulesManager(self.evadb.config)
         with disable_rules(
+            rules_manager,
             [
                 CacheFunctionExpressionInApply(),
                 CacheFunctionExpressionInFilter(),
                 CacheFunctionExpressionInProject(),
-            ]
-        ) as rules_manager:
-            custom_plan_generator = PlanGenerator(rules_manager)
+            ],
+        ):
+            custom_plan_generator = PlanGenerator(self.evadb, rules_manager)
             without_reuse_batch = execute_query_fetch_all(
-                query, plan_generator=custom_plan_generator
+                self.evadb, query, plan_generator=custom_plan_generator
             )
 
         # printing the batches so that we can see the mismatch in the logs
         self.assertEqual(
             without_reuse_batch,
             reuse_batch,
             msg=f"Without reuse {without_reuse_batch} \n With reuse{reuse_batch}",
@@ -80,15 +87,15 @@
 
     def _reuse_experiment(self, queries):
         exec_times = []
         batches = []
         for query in queries:
             timer = Timer()
             with timer:
-                batches.append(execute_query_fetch_all(query))
+                batches.append(execute_query_fetch_all(self.evadb, query))
             exec_times.append(timer.total_elapsed_time)
         return batches, exec_times
 
     def test_reuse_when_query_is_duplicate(self):
         select_query = """SELECT id, label FROM DETRAC JOIN
             LATERAL HFObjectDetector(data) AS Obj(score, label, bbox) WHERE id < 15;"""
         batches, exec_times = self._reuse_experiment([select_query, select_query])
@@ -118,20 +125,20 @@
 
         self._verify_reuse_correctness(select_query2, batches[1])
 
         # different query format
         select_query = (
             """SELECT id, HFObjectDetector(data).label FROM DETRAC WHERE id < 15;"""
         )
-        reuse_batch = execute_query_fetch_all(select_query)
+        reuse_batch = execute_query_fetch_all(self.evadb, select_query)
         self._verify_reuse_correctness(select_query, reuse_batch)
 
         # different query format
         select_query = """SELECT id, HFObjectDetector(data).label FROM DETRAC WHERE ['car'] <@ HFObjectDetector(data).label AND id < 20"""
-        reuse_batch = execute_query_fetch_all(select_query)
+        reuse_batch = execute_query_fetch_all(self.evadb, select_query)
         self._verify_reuse_correctness(select_query, reuse_batch)
 
     def test_reuse_logical_project_with_duplicate_query(self):
         project_query = (
             """SELECT id, HFObjectDetector(data).label FROM DETRAC WHERE id < 10;"""
         )
         batches, exec_times = self._reuse_experiment([project_query, project_query])
@@ -179,63 +186,69 @@
         self._verify_reuse_correctness(select_query, batches[1])
         self.assertGreater(exec_times[0], exec_times[1])
 
     @windows_skip_marker
     def test_reuse_after_server_shutdown(self):
         select_query = """SELECT id, label FROM DETRAC JOIN
             LATERAL Yolo(data) AS Obj(label, bbox, conf) WHERE id < 4;"""
-        execute_query_fetch_all(select_query)
+        execute_query_fetch_all(self.evadb, select_query)
 
         # Stop and restart server
         os.system("nohup eva_server --stop")
         os.system("nohup eva_server --start &")
 
         select_query = """SELECT id, label FROM DETRAC JOIN
             LATERAL Yolo(data) AS Obj(label, bbox, conf) WHERE id < 6;"""
 
-        reuse_batch = execute_query_fetch_all(select_query)
+        reuse_batch = execute_query_fetch_all(self.evadb, select_query)
         self._verify_reuse_correctness(select_query, reuse_batch)
 
         # stop the server
         os.system("nohup eva_server --stop")
 
     def test_drop_udf_should_remove_cache(self):
         select_query = """SELECT id, label FROM DETRAC JOIN
             LATERAL Yolo(data) AS Obj(label, bbox, conf) WHERE id < 5;"""
-        execute_query_fetch_all(select_query)
+        execute_query_fetch_all(self.evadb, select_query)
 
-        plan = next(get_logical_query_plan(select_query).find_all(LogicalFunctionScan))
+        plan = next(
+            get_logical_query_plan(self.evadb, select_query).find_all(
+                LogicalFunctionScan
+            )
+        )
         cache_name = plan.func_expr.signature()
-        catalog_manager = CatalogManager()
 
         # cache exists
-        udf_cache = catalog_manager.get_udf_cache_catalog_entry_by_name(cache_name)
+        udf_cache = self.evadb.catalog().get_udf_cache_catalog_entry_by_name(cache_name)
         cache_dir = Path(udf_cache.cache_path)
         self.assertIsNotNone(udf_cache)
         self.assertTrue(cache_dir.exists())
 
         # cache should be removed if the UDF is removed
-        execute_query_fetch_all("DROP UDF Yolo;")
-        udf_cache = catalog_manager.get_udf_cache_catalog_entry_by_name(cache_name)
+        execute_query_fetch_all(self.evadb, "DROP UDF Yolo;")
+        udf_cache = self.evadb.catalog().get_udf_cache_catalog_entry_by_name(cache_name)
         self.assertIsNone(udf_cache)
         self.assertFalse(cache_dir.exists())
 
     def test_drop_table_should_remove_cache(self):
         select_query = """SELECT id, label FROM DETRAC JOIN
             LATERAL Yolo(data) AS Obj(label, bbox, conf) WHERE id < 5;"""
-        execute_query_fetch_all(select_query)
+        execute_query_fetch_all(self.evadb, select_query)
 
-        plan = next(get_logical_query_plan(select_query).find_all(LogicalFunctionScan))
+        plan = next(
+            get_logical_query_plan(self.evadb, select_query).find_all(
+                LogicalFunctionScan
+            )
+        )
         cache_name = plan.func_expr.signature()
-        catalog_manager = CatalogManager()
 
         # cache exists
-        udf_cache = catalog_manager.get_udf_cache_catalog_entry_by_name(cache_name)
+        udf_cache = self.evadb.catalog().get_udf_cache_catalog_entry_by_name(cache_name)
         cache_dir = Path(udf_cache.cache_path)
         self.assertIsNotNone(udf_cache)
         self.assertTrue(cache_dir.exists())
 
         # cache should be removed if the Table is removed
-        execute_query_fetch_all("DROP TABLE DETRAC;")
-        udf_cache = catalog_manager.get_udf_cache_catalog_entry_by_name(cache_name)
+        execute_query_fetch_all(self.evadb, "DROP TABLE DETRAC;")
+        udf_cache = self.evadb.catalog().get_udf_cache_catalog_entry_by_name(cache_name)
         self.assertIsNone(udf_cache)
         self.assertFalse(cache_dir.exists())
```

### Comparing `evadb-0.2.6/test/integration_tests/test_s3_load_executor.py` & `evadb-0.2.7/test/integration_tests/test_s3_load_executor.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,42 +15,40 @@
 import os
 import unittest
 from pathlib import Path
 from test.util import (
     create_dummy_batches,
     create_sample_video,
     file_remove,
+    get_evadb_for_testing,
     shutdown_ray,
 )
 
 import boto3
 import pandas as pd
 import pytest
 from moto import mock_s3
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.models.storage.batch import Batch
-from eva.parser.types import FileFormatType
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.models.storage.batch import Batch
+from evadb.parser.types import FileFormatType
+from evadb.server.command_handler import execute_query_fetch_all
 
 
 @pytest.mark.notparallel
 class S3LoadExecutorTest(unittest.TestCase):
     mock_s3 = mock_s3()
 
     def setUp(self):
+        self.evadb = get_evadb_for_testing()
         # reset the catalog manager before running each test
-        CatalogManager().reset()
+        self.evadb.catalog().reset()
         self.video_file_path = create_sample_video()
         self.multiple_video_file_path = f"{EVA_ROOT_DIR}/data/sample_videos/1"
-        self.s3_download_dir = ConfigurationManager().get_value(
-            "storage", "s3_download_dir"
-        )
+        self.s3_download_dir = self.evadb.config.get_value("storage", "s3_download_dir")
 
         """Mocked AWS Credentials for moto."""
         os.environ["AWS_ACCESS_KEY_ID"] = "testing"
         os.environ["AWS_SECRET_ACCESS_KEY"] = "testing"
         os.environ["AWS_SECURITY_TOKEN"] = "testing"
         os.environ["AWS_SESSION_TOKEN"] = "testing"
         os.environ["AWS_DEFAULT_REGION"] = "us-east-1"
@@ -81,62 +79,64 @@
         self.mock_s3.stop()
 
     def test_s3_single_file_load_executor(self):
         bucket_name = "single-file-bucket"
         self.upload_single_file(bucket_name)
 
         query = f"LOAD VIDEO 's3://{bucket_name}/dummy.avi' INTO MyVideo;"
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         select_query = """SELECT * FROM MyVideo;"""
 
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_batch = list(
             create_dummy_batches(
                 video_dir=os.path.join(self.s3_download_dir, "MyVideo")
             )
         )[0]
         self.assertEqual(actual_batch, expected_batch)
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideo;")
 
     def test_s3_multiple_file_load_executor(self):
         bucket_name = "multiple-file-bucket"
         self.upload_multiple_files(bucket_name)
 
         query = f"""LOAD VIDEO "s3://{bucket_name}/*.mp4" INTO MyVideos;"""
-        result = execute_query_fetch_all(query)
+        result = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame([f"Number of loaded {FileFormatType.VIDEO.name}: 2"])
         )
         self.assertEqual(result, expected)
 
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideos;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideos;")
 
     def test_s3_multiple_file_multiple_load_executor(self):
         bucket_name = "multiple-file-multiple-load-bucket"
         self.upload_single_file(bucket_name)
         self.upload_multiple_files(bucket_name)
 
         insert_query_one = f"""LOAD VIDEO "s3://{bucket_name}/1.mp4" INTO MyVideos;"""
-        execute_query_fetch_all(insert_query_one)
+        execute_query_fetch_all(self.evadb, insert_query_one)
         insert_query_two = f"""LOAD VIDEO "s3://{bucket_name}/2.mp4" INTO MyVideos;"""
-        execute_query_fetch_all(insert_query_two)
+        execute_query_fetch_all(self.evadb, insert_query_two)
         insert_query_three = f"LOAD VIDEO '{self.video_file_path}' INTO MyVideos;"
-        execute_query_fetch_all(insert_query_three)
+        execute_query_fetch_all(self.evadb, insert_query_three)
 
         select_query = """SELECT * FROM MyVideos;"""
-        result = execute_query_fetch_all(select_query)
+        result = execute_query_fetch_all(self.evadb, select_query)
+        print(result.frames["myvideos.name"].unique())
+
         result_videos = [
             Path(video).as_posix() for video in result.frames["myvideos.name"].unique()
         ]
 
         s3_dir_path = Path(self.s3_download_dir)
         expected_videos = [
             (s3_dir_path / "MyVideos/1.mp4").as_posix(),
             (s3_dir_path / "MyVideos/2.mp4").as_posix(),
             Path(self.video_file_path).as_posix(),
         ]
 
         self.assertEqual(result_videos, expected_videos)
 
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideos;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideos;")
```

### Comparing `evadb-0.2.6/test/integration_tests/test_select_executor.py` & `evadb-0.2.7/test/integration_tests/test_select_executor.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,322 +15,323 @@
 import unittest
 from test.util import (  # file_remove,
     create_dummy_4d_batches,
     create_dummy_batches,
     create_sample_video,
     create_table,
     file_remove,
+    get_evadb_for_testing,
     get_logical_query_plan,
     load_udfs_for_testing,
     shutdown_ray,
 )
 
 import numpy as np
 import pandas as pd
 import pytest
 
-from eva.binder.binder_utils import BinderError
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.models.storage.batch import Batch
-from eva.readers.decord_reader import DecordReader
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.binder.binder_utils import BinderError
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.models.storage.batch import Batch
+from evadb.readers.decord_reader import DecordReader
+from evadb.server.command_handler import execute_query_fetch_all
 
 NUM_FRAMES = 10
 
 
 @pytest.mark.notparallel
 class SelectExecutorTest(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        CatalogManager().reset()
+        cls.evadb = get_evadb_for_testing()
+        cls.evadb.catalog().reset()
         video_file_path = create_sample_video(NUM_FRAMES)
         load_query = f"LOAD VIDEO '{video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(load_query)
+        execute_query_fetch_all(cls.evadb, load_query)
         ua_detrac = f"{EVA_ROOT_DIR}/data/ua_detrac/ua_detrac.mp4"
         load_query = f"LOAD VIDEO '{ua_detrac}' INTO DETRAC;"
-        execute_query_fetch_all(load_query)
-        load_udfs_for_testing()
-        cls.table1 = create_table("table1", 100, 3)
-        cls.table2 = create_table("table2", 500, 3)
-        cls.table3 = create_table("table3", 1000, 3)
+        execute_query_fetch_all(cls.evadb, load_query)
+        load_udfs_for_testing(cls.evadb)
+        cls.table1 = create_table(cls.evadb, "table1", 100, 3)
+        cls.table2 = create_table(cls.evadb, "table2", 500, 3)
+        cls.table3 = create_table(cls.evadb, "table3", 1000, 3)
 
         cls.meme1 = f"{EVA_ROOT_DIR}/data/detoxify/meme1.jpg"
         cls.meme2 = f"{EVA_ROOT_DIR}/data/detoxify/meme2.jpg"
 
-        execute_query_fetch_all(f"LOAD IMAGE '{cls.meme1}' INTO MemeImages;")
-        execute_query_fetch_all(f"LOAD IMAGE '{cls.meme2}' INTO MemeImages;")
+        execute_query_fetch_all(cls.evadb, f"LOAD IMAGE '{cls.meme1}' INTO MemeImages;")
+        execute_query_fetch_all(cls.evadb, f"LOAD IMAGE '{cls.meme2}' INTO MemeImages;")
 
     @classmethod
     def tearDownClass(cls):
         shutdown_ray()
 
         file_remove("dummy.avi")
-        execute_query_fetch_all("""DROP TABLE IF EXISTS table1;""")
-        execute_query_fetch_all("""DROP TABLE IF EXISTS table2;""")
-        execute_query_fetch_all("""DROP TABLE IF EXISTS table3;""")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MemeImages;")
+        execute_query_fetch_all(cls.evadb, """DROP TABLE IF EXISTS table1;""")
+        execute_query_fetch_all(cls.evadb, """DROP TABLE IF EXISTS table2;""")
+        execute_query_fetch_all(cls.evadb, """DROP TABLE IF EXISTS table3;""")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MemeImages;")
 
     def test_sort_on_nonprojected_column(self):
         """This tests doing an order by on a column
         that is not projected. The orderby_executor currently
         catches the KeyError, passes, and returns the untouched
         data
         """
         select_query = "SELECT data FROM MyVideo ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
 
         select_query = "SELECT data FROM MyVideo"
-        expected_batch = execute_query_fetch_all(select_query)
+        expected_batch = execute_query_fetch_all(self.evadb, select_query)
 
         self.assertEqual(len(actual_batch), len(expected_batch))
 
     def test_should_load_and_sort_in_table(self):
         select_query = "SELECT data, id FROM MyVideo ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected_rows = [
             {
                 "myvideo.id": i,
                 "myvideo.data": np.array(np.ones((32, 32, 3)) * i, dtype=np.uint8),
             }
             for i in range(NUM_FRAMES)
         ]
         expected_batch = Batch(frames=pd.DataFrame(expected_rows))
         self.assertEqual(actual_batch, expected_batch)
 
         select_query = "SELECT data, id FROM MyVideo ORDER BY id DESC;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected_batch.reverse()
         self.assertEqual(actual_batch, expected_batch)
 
     def test_should_load_and_select_in_table(self):
         select_query = "SELECT id FROM MyVideo;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_rows = [{"myvideo.id": i} for i in range(NUM_FRAMES)]
         expected_batch = Batch(frames=pd.DataFrame(expected_rows))
         self.assertEqual(actual_batch, expected_batch)
 
         select_query = "SELECT * FROM MyVideo;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_batch = list(create_dummy_batches())
         self.assertEqual([actual_batch], expected_batch)
 
     def test_should_select_star_in_table(self):
         select_query = "SELECT * FROM MyVideo;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_batch = list(create_dummy_batches())[0]
         self.assertEqual(actual_batch, expected_batch)
 
         select_query = "SELECT * FROM MyVideo WHERE id = 5;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected_batch = list(create_dummy_batches(filters=[5]))[0]
         self.assertEqual(actual_batch, expected_batch)
 
     def test_should_select_star_in_nested_query(self):
         select_query = """SELECT * FROM (SELECT * FROM MyVideo) AS T;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_batch = list(create_dummy_batches())[0]
         expected_batch.modify_column_alias("T")
         self.assertEqual(actual_batch, expected_batch)
 
         select_query = """SELECT * FROM (SELECT id FROM MyVideo) AS T;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_rows = [{"T.id": i} for i in range(NUM_FRAMES)]
         expected_batch = Batch(frames=pd.DataFrame(expected_rows))
         self.assertEqual(actual_batch, expected_batch)
 
     @unittest.skip("Not supported in current version")
     def test_select_star_in_lateral_join(self):
         select_query = """SELECT * FROM MyVideo JOIN LATERAL
                           Yolo(data);"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(actual_batch.frames.columns, ["myvideo.id"])
 
     def test_should_load_and_select_real_video_in_table(self):
         query = """LOAD VIDEO 'data/mnist/mnist.mp4'
                    INTO MNIST;"""
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         select_query = "SELECT id, data FROM MNIST;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort("mnist.id")
         video_reader = DecordReader("data/mnist/mnist.mp4")
         expected_batch = Batch(frames=pd.DataFrame())
         for batch in video_reader.read():
             batch.frames["name"] = "mnist.mp4"
             expected_batch += batch
         expected_batch.modify_column_alias("mnist")
         expected_batch = expected_batch.project(["mnist.id", "mnist.data"])
         self.assertEqual(actual_batch, expected_batch)
 
     def test_should_load_and_select_real_audio_in_table(self):
         query = """LOAD VIDEO 'data/sample_videos/touchdown.mp4'
                    INTO TOUCHDOWN;"""
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         select_query = "SELECT id, audio FROM TOUCHDOWN;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort("touchdown.id")
         video_reader = DecordReader("data/sample_videos/touchdown.mp4", read_audio=True)
         expected_batch = Batch(frames=pd.DataFrame())
         for batch in video_reader.read():
             batch.frames["name"] = "touchdown.mp4"
             expected_batch += batch
         expected_batch.modify_column_alias("touchdown")
         expected_batch = expected_batch.project(["touchdown.id", "touchdown.audio"])
         self.assertEqual(actual_batch, expected_batch)
 
     def test_should_throw_error_when_both_audio_and_video_selected(self):
         query = """LOAD VIDEO 'data/sample_videos/touchdown.mp4'
                    INTO TOUCHDOWN1;"""
-        execute_query_fetch_all(query)
+        execute_query_fetch_all(self.evadb, query)
 
         select_query = "SELECT id, audio, data FROM TOUCHDOWN1;"
         try:
-            execute_query_fetch_all(select_query)
+            execute_query_fetch_all(self.evadb, select_query)
             self.fail("Didn't raise AssertionError")
         except AssertionError as e:
             self.assertEquals(
                 "Cannot query over both audio and video streams", e.args[0]
             )
 
     def test_select_and_where_video_in_table(self):
         select_query = "SELECT * FROM MyVideo WHERE id = 5;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected_batch = list(create_dummy_batches(filters=[5]))[0]
         self.assertEqual(actual_batch, expected_batch)
 
         select_query = "SELECT data FROM MyVideo WHERE id = 5;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(actual_batch, expected_batch.project(["myvideo.data"]))
 
         select_query = "SELECT id, data FROM MyVideo WHERE id >= 2;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_batch = list(create_dummy_batches(filters=range(2, NUM_FRAMES)))[0]
         self.assertEqual(
             actual_batch,
             expected_batch.project(["myvideo.id", "myvideo.data"]),
         )
 
         select_query = "SELECT * FROM MyVideo WHERE id >= 2 AND id < 5;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_batch = list(create_dummy_batches(filters=range(2, 5)))[0]
 
         self.assertEqual(actual_batch, expected_batch)
 
     def test_nested_select_video_in_table(self):
         nested_select_query = """SELECT * FROM
             (SELECT * FROM MyVideo WHERE id >= 2 AND id < 5) AS T
             WHERE id >= 3;"""
-        actual_batch = execute_query_fetch_all(nested_select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, nested_select_query)
         actual_batch.sort()
         expected_batch = list(create_dummy_batches(filters=range(3, 5)))[0]
         expected_batch.modify_column_alias("T")
         self.assertEqual(actual_batch, expected_batch)
 
         nested_select_query = """SELECT * FROM
             (SELECT * FROM MyVideo WHERE id >= 2 AND id < 5) AS T
             WHERE id >= 3;"""
-        actual_batch = execute_query_fetch_all(nested_select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, nested_select_query)
         actual_batch.sort("T.id")
         expected_batch = list(create_dummy_batches(filters=range(3, 5)))[0]
         expected_batch.modify_column_alias("T")
         self.assertEqual(actual_batch, expected_batch)
 
     def test_select_and_union_video_in_table(self):
         select_query = """SELECT * FROM MyVideo WHERE id < 3
             UNION ALL SELECT * FROM MyVideo WHERE id > 7;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort("myvideo.id")
         expected_batch = list(
             create_dummy_batches(
                 filters=[i for i in range(NUM_FRAMES) if i < 3 or i > 7]
             )
         )[0]
         self.assertEqual(actual_batch, expected_batch)
 
         select_query = """SELECT * FROM MyVideo WHERE id < 2
             UNION ALL SELECT * FROM MyVideo WHERE id > 4 AND id < 6
             UNION ALL SELECT * FROM MyVideo WHERE id > 7;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort("myvideo.id")
         expected_batch = list(
             create_dummy_batches(
                 filters=[i for i in range(NUM_FRAMES) if i < 2 or i == 5 or i > 7]
             )
         )[0]
         self.assertEqual(actual_batch, expected_batch)
 
     def test_select_and_limit(self):
         select_query = "SELECT * FROM MyVideo ORDER BY id LIMIT 5;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected_batch = list(create_dummy_batches(num_frames=10, batch_size=5))
 
         self.assertEqual(len(actual_batch), len(expected_batch[0]))
         self.assertEqual(actual_batch, expected_batch[0])
 
     def test_select_and_aggregate(self):
         simple_aggregate_query = "SELECT COUNT(*), AVG(id) FROM MyVideo;"
-        actual_batch = execute_query_fetch_all(simple_aggregate_query)
+        actual_batch = execute_query_fetch_all(self.evadb, simple_aggregate_query)
 
         self.assertEqual(actual_batch.frames.iat[0, 0], 10)
         self.assertEqual(actual_batch.frames.iat[0, 1], 4.5)
 
     def test_select_and_sample(self):
         select_query = "SELECT id FROM MyVideo SAMPLE 7 ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
 
         expected_batch = list(create_dummy_batches(filters=range(0, NUM_FRAMES, 7)))
         expected_batch[0] = expected_batch[0].project(["myvideo.id"])
 
         self.assertEqual(len(actual_batch), len(expected_batch[0]))
         self.assertEqual(actual_batch, expected_batch[0])
 
     def test_select_and_iframe_sample(self):
         select_query = "SELECT id FROM MyVideo SAMPLE IFRAMES 7 ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
 
         expected_batch = list(create_dummy_batches(filters=range(0, NUM_FRAMES, 7)))
         expected_batch[0] = expected_batch[0].project(["myvideo.id"])
 
         self.assertEqual(len(actual_batch), len(expected_batch[0]))
         self.assertEqual(actual_batch, expected_batch[0])
 
     def test_select_and_iframe_sample_without_sampling_rate(self):
         select_query = "SELECT id FROM MyVideo SAMPLE IFRAMES ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
 
         expected_batch = list(create_dummy_batches(filters=range(0, NUM_FRAMES, 1)))
         expected_batch[0] = expected_batch[0].project(["myvideo.id"])
 
         self.assertEqual(len(actual_batch), len(expected_batch[0]))
         self.assertEqual(actual_batch, expected_batch[0])
 
     def test_select_and_groupby_first(self):
         # groupby and orderby together not tested because groupby
         # only applies to video data which is already sorted
         segment_size = 3
         select_query = (
-            "SELECT FIRST(id), SEGMENT(data) FROM MyVideo GROUP BY '{}f';".format(
+            "SELECT FIRST(id), SEGMENT(data) FROM MyVideo GROUP BY '{} frames';".format(
                 segment_size
             )
         )
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         ids = np.arange(NUM_FRAMES)
         segments = [ids[i : i + segment_size] for i in range(0, len(ids), segment_size)]
         segments = [i for i in segments if len(i) == segment_size]
         expected_batch = list(create_dummy_4d_batches(filters=segments))[0]
         self.assertEqual(len(actual_batch), len(expected_batch))
 
@@ -343,19 +344,19 @@
         )
 
     def test_select_and_groupby_with_last(self):
         # groupby and orderby together not tested because groupby
         # only applies to video data which is already sorted
         segment_size = 3
         select_query = (
-            "SELECT LAST(id), SEGMENT(data) FROM MyVideo GROUP BY '{}f';".format(
+            "SELECT LAST(id), SEGMENT(data) FROM MyVideo GROUP BY '{}frames';".format(
                 segment_size
             )
         )
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         ids = np.arange(NUM_FRAMES)
         segments = [ids[i : i + segment_size] for i in range(0, len(ids), segment_size)]
         segments = [i for i in segments if len(i) == segment_size]
         expected_batch = list(
             create_dummy_4d_batches(filters=segments, start_id=segment_size - 1)
         )[0]
@@ -368,45 +369,49 @@
             actual_batch,
             expected_batch.project(["LAST.id", "SEGMENT.data"]),
         )
 
     def test_select_and_groupby_should_fail_with_incorrect_pattern(self):
         segment_size = "4a"
         select_query = (
-            "SELECT FIRST(id), SEGMENT(data) FROM MyVideo GROUP BY '{}f';".format(
+            "SELECT FIRST(id), SEGMENT(data) FROM MyVideo GROUP BY '{} frames';".format(
                 segment_size
             )
         )
-        self.assertRaises(BinderError, execute_query_fetch_all, select_query)
+        self.assertRaises(
+            BinderError, execute_query_fetch_all, self.evadb, select_query
+        )
 
     def test_select_and_groupby_should_fail_with_seconds(self):
         segment_size = 4
-        select_query = (
-            "SELECT FIRST(id), SEGMENT(data) FROM MyVideo GROUP BY '{}s';".format(
-                segment_size
-            )
+        select_query = "SELECT FIRST(id), SEGMENT(data) FROM MyVideo GROUP BY '{} seconds';".format(
+            segment_size
+        )
+        self.assertRaises(
+            BinderError, execute_query_fetch_all, self.evadb, select_query
         )
-        self.assertRaises(BinderError, execute_query_fetch_all, select_query)
 
     def test_select_and_groupby_should_fail_with_non_video_table(self):
         segment_size = 4
-        select_query = "SELECT FIRST(a1) FROM table1 GROUP BY '{}f';".format(
+        select_query = "SELECT FIRST(a1) FROM table1 GROUP BY '{} frames';".format(
             segment_size
         )
-        self.assertRaises(BinderError, execute_query_fetch_all, select_query)
+        self.assertRaises(
+            BinderError, execute_query_fetch_all, self.evadb, select_query
+        )
 
     def test_select_and_groupby_with_sample(self):
         # TODO ACTION: groupby and orderby together not tested because groupby
         # only applies to video data which is already sorted
         segment_size = 2
         sampling_rate = 2
-        select_query = "SELECT FIRST(id), SEGMENT(data) FROM MyVideo SAMPLE {} GROUP BY '{}f';".format(
+        select_query = "SELECT FIRST(id), SEGMENT(data) FROM MyVideo SAMPLE {} GROUP BY '{} frames';".format(
             sampling_rate, segment_size
         )
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         ids = np.arange(0, NUM_FRAMES, sampling_rate)
 
         segments = [ids[i : i + segment_size] for i in range(0, len(ids), segment_size)]
         segments = [i for i in segments if len(i) == segment_size]
         expected_batch = list(create_dummy_4d_batches(filters=segments))[0]
         self.assertEqual(len(actual_batch), len(expected_batch))
@@ -418,52 +423,52 @@
         self.assertEqual(
             actual_batch,
             expected_batch.project(["FIRST.id", "SEGMENT.data"]),
         )
 
     def test_select_and_sample_with_predicate(self):
         select_query = "SELECT id FROM MyVideo SAMPLE 2 WHERE id > 5 ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected_batch = list(create_dummy_batches(filters=range(6, NUM_FRAMES, 2)))
         self.assertEqual(actual_batch, expected_batch[0].project(["myvideo.id"]))
 
         select_query = "SELECT id FROM MyVideo SAMPLE 4 WHERE id > 2 ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected_batch = list(create_dummy_batches(filters=range(4, NUM_FRAMES, 4)))
         self.assertEqual(actual_batch, expected_batch[0].project(["myvideo.id"]))
 
         select_query = (
             "SELECT id FROM MyVideo SAMPLE 2 WHERE id > 2 AND id < 8 ORDER BY id;"
         )
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected_batch = list(create_dummy_batches(filters=range(4, 8, 2)))
         self.assertEqual(actual_batch, expected_batch[0].project(["myvideo.id"]))
 
     @pytest.mark.torchtest
     def test_lateral_join(self):
         select_query = """SELECT id, a FROM DETRAC JOIN LATERAL
                         Yolo(data) AS T(a,b,c) WHERE id < 5;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(list(actual_batch.columns), ["detrac.id", "T.a"])
         self.assertEqual(len(actual_batch), 5)
 
     @pytest.mark.torchtest
     def test_lateral_join_with_multiple_projects(self):
         select_query = """SELECT id, T.labels FROM DETRAC JOIN LATERAL
                         Yolo(data) AS T WHERE id < 5;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertTrue(all(actual_batch.frames.columns == ["detrac.id", "T.labels"]))
         self.assertEqual(len(actual_batch), 5)
 
     def test_lateral_join_with_unnest(self):
         query = """SELECT id, label
                   FROM MyVideo JOIN LATERAL
                     UNNEST(DummyObjectDetector(data)) AS T(label)
                   WHERE id < 2 ORDER BY id;"""
-        unnest_batch = execute_query_fetch_all(query)
+        unnest_batch = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame(
                 {
                     "myvideo.id": np.array([0, 1], dtype=np.intp),
                     "T.label": np.array(["person", "bicycle"]),
                 }
             )
@@ -471,15 +476,15 @@
 
         self.assertEqual(unnest_batch, expected)
 
         query = """SELECT id, label
                   FROM MyVideo JOIN LATERAL
                     UNNEST(DummyObjectDetector(data)) AS T
                   WHERE id < 2 ORDER BY id;"""
-        unnest_batch = execute_query_fetch_all(query)
+        unnest_batch = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame(
                 {
                     "myvideo.id": np.array([0, 1], dtype=np.intp),
                     "T.label": np.array(["person", "bicycle"]),
                 }
             )
@@ -488,15 +493,15 @@
         self.assertEqual(unnest_batch, expected)
 
     def test_lateral_join_with_unnest_and_sample(self):
         query = """SELECT id, label
                   FROM MyVideo SAMPLE 2 JOIN LATERAL
                     UNNEST(DummyMultiObjectDetector(data).labels) AS T(label)
                   WHERE id < 10 ORDER BY id;"""
-        unnest_batch = execute_query_fetch_all(query)
+        unnest_batch = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame(
                 {
                     "myvideo.id": np.array(
                         [0, 0, 2, 2, 4, 4, 6, 6, 8, 8], dtype=np.intp
                     ),
                     "T.label": np.array(
@@ -520,15 +525,15 @@
         self.assertEqual(unnest_batch, expected)
 
     def test_lateral_join_with_unnest_on_subset_of_outputs(self):
         query = """SELECT id, label
                   FROM MyVideo JOIN LATERAL
                     UNNEST(DummyMultiObjectDetector(data).labels) AS T(label)
                   WHERE id < 2 ORDER BY id;"""
-        unnest_batch = execute_query_fetch_all(query)
+        unnest_batch = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame(
                 {
                     "myvideo.id": np.array([0, 0, 1, 1], np.intp),
                     "T.label": np.array(["person", "person", "bicycle", "bicycle"]),
                 }
             )
@@ -536,15 +541,15 @@
         self.assertEqual(unnest_batch, expected)
 
         # unnest with predicate on function expression
         query = """SELECT id, label
                 FROM MyVideo JOIN LATERAL
                 UNNEST(DummyMultiObjectDetector(data).labels) AS T(label)
                 WHERE id < 2 AND T.label = "person" ORDER BY id;"""
-        unnest_batch = execute_query_fetch_all(query)
+        unnest_batch = execute_query_fetch_all(self.evadb, query)
         expected = Batch(
             pd.DataFrame(
                 {
                     "myvideo.id": np.array([0, 0], np.intp),
                     "T.label": np.array(["person", "person"]),
                 }
             )
@@ -552,64 +557,64 @@
         self.assertEqual(unnest_batch, expected)
 
     def test_should_raise_error_with_missing_alias_in_lateral_join(self):
         udf_name = "DummyMultiObjectDetector"
         query = """SELECT id, labels
                   FROM MyVideo JOIN LATERAL DummyMultiObjectDetector(data).labels;"""
         with self.assertRaises(SyntaxError) as cm:
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
         self.assertEqual(
             str(cm.exception),
             f"TableValuedFunction {udf_name} should have alias.",
         )
 
         query = """SELECT id, labels
                   FROM MyVideo JOIN LATERAL
                     UNNEST(DummyMultiObjectDetector(data).labels);"""
         with self.assertRaises(SyntaxError) as cm:
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
         self.assertEqual(
             str(cm.exception),
             f"TableValuedFunction {udf_name} should have alias.",
         )
 
         query = """SELECT id, labels
                   FROM MyVideo JOIN LATERAL DummyMultiObjectDetector(data);"""
         with self.assertRaises(SyntaxError) as cm:
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
         self.assertEqual(
             str(cm.exception),
             f"TableValuedFunction {udf_name} should have alias.",
         )
 
     def test_should_raise_error_with_invalid_number_of_aliases(self):
         udf_name = "DummyMultiObjectDetector"
         query = """SELECT id, labels
                   FROM MyVideo JOIN LATERAL
                     DummyMultiObjectDetector(data).bboxes AS T;"""
         with self.assertRaises(BinderError) as cm:
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
         self.assertEqual(
             str(cm.exception),
             f"Output bboxes does not exist for {udf_name}.",
         )
 
     def test_should_raise_error_with_invalid_output_lateral_join(self):
         query = """SELECT id, a
                   FROM MyVideo JOIN LATERAL
                     DummyMultiObjectDetector(data) AS T(a, b);
                 """
         with self.assertRaises(AssertionError) as cm:
-            execute_query_fetch_all(query)
+            execute_query_fetch_all(self.evadb, query)
         self.assertEqual(str(cm.exception), "Expected 1 output columns for T, got 2.")
 
     def test_hash_join_with_one_on(self):
         select_query = """SELECT * FROM table1 JOIN
                         table2 ON table1.a1 = table2.a1;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected = pd.merge(
             self.table1,
             self.table2,
             left_on=["table1.a1"],
             right_on=["table2.a1"],
             how="inner",
         )
@@ -620,15 +625,15 @@
                 actual_batch.sort_orderby(["table1.a2"]),
             )
 
     def test_hash_join_with_multiple_on(self):
         select_query = """SELECT * FROM table1 JOIN
                         table1 AS table2 ON table1.a1 = table2.a1 AND
                         table1.a0 = table2.a0;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected = pd.merge(
             self.table1,
             self.table1,
             left_on=["table1.a1", "table1.a0"],
             right_on=["table1.a1", "table1.a0"],
             how="inner",
         )
@@ -639,15 +644,15 @@
                 actual_batch.sort_orderby(["table1.a1"]),
             )
 
     def test_hash_join_with_multiple_tables(self):
         select_query = """SELECT * FROM table1 JOIN table2
                           ON table2.a0 = table1.a0 JOIN table3
                           ON table3.a1 = table1.a1 WHERE table1.a2 > 50;"""
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         tmp = pd.merge(
             self.table1,
             self.table2,
             left_on=["table1.a0"],
             right_on=["table2.a0"],
             how="inner",
         )
@@ -664,90 +669,100 @@
             self.assertEqual(
                 expected_batch.sort_orderby(["table1.a0"]),
                 actual_batch.sort_orderby(["table1.a0"]),
             )
 
     def test_expression_tree_signature(self):
         plan = get_logical_query_plan(
-            "SELECT DummyMultiObjectDetector(data).labels FROM MyVideo"
+            self.evadb, "SELECT DummyMultiObjectDetector(data).labels FROM MyVideo"
         )
         signature = plan.target_list[0].signature()
         udf_id = (
-            CatalogManager()
+            self.evadb.catalog()
             .get_udf_catalog_entry_by_name("DummyMultiObjectDetector")
             .row_id
         )
-        table_entry = CatalogManager().get_table_catalog_entry("MyVideo")
-        col_id = CatalogManager().get_column_catalog_entry(table_entry, "data").row_id
+        table_entry = self.evadb.catalog().get_table_catalog_entry("MyVideo")
+        col_id = (
+            self.evadb.catalog().get_column_catalog_entry(table_entry, "data").row_id
+        )
         self.assertEqual(
             signature, f"DummyMultiObjectDetector[{udf_id}](MyVideo.data[{col_id}])"
         )
 
     def test_complex_logical_expressions(self):
         query = """SELECT id FROM MyVideo
             WHERE DummyObjectDetector(data).label = ['{}']  ORDER BY id;"""
-        persons = execute_query_fetch_all(query.format("person")).frames.to_numpy()
-        bicycles = execute_query_fetch_all(query.format("bicycle")).frames.to_numpy()
+        persons = execute_query_fetch_all(
+            self.evadb, query.format("person")
+        ).frames.to_numpy()
+        bicycles = execute_query_fetch_all(
+            self.evadb, query.format("bicycle")
+        ).frames.to_numpy()
         import numpy as np
 
         self.assertTrue(len(np.intersect1d(persons, bicycles)) == 0)
 
         query_or = """SELECT id FROM MyVideo \
             WHERE DummyObjectDetector(data).label = ['person']
                 OR DummyObjectDetector(data).label = ['bicycle']
             ORDER BY id;"""
-        actual = execute_query_fetch_all(query_or)
-        expected = execute_query_fetch_all("SELECT id FROM MyVideo ORDER BY id")
+        actual = execute_query_fetch_all(self.evadb, query_or)
+        expected = execute_query_fetch_all(
+            self.evadb, "SELECT id FROM MyVideo ORDER BY id"
+        )
         self.assertEqual(expected, actual)
 
         query_and = """SELECT id FROM MyVideo \
             WHERE DummyObjectDetector(data).label = ['person']
                 AND DummyObjectDetector(data).label = ['bicycle']
             ORDER BY id;"""
 
-        expected = execute_query_fetch_all(query_and)
+        expected = execute_query_fetch_all(self.evadb, query_and)
         self.assertEqual(len(expected), 0)
 
     def test_project_identifier_column(self):
         # test for video table
-        batch = execute_query_fetch_all("SELECT _row_id, id FROM MyVideo;")
+        batch = execute_query_fetch_all(self.evadb, "SELECT _row_id, id FROM MyVideo;")
         expected = Batch(
             pd.DataFrame(
                 {
                     "myvideo._row_id": [1] * NUM_FRAMES,
                     "myvideo.id": range(NUM_FRAMES),
                 }
             )
         )
         self.assertEqual(batch, expected)
 
-        batch = execute_query_fetch_all("SELECT * FROM MyVideo;")
+        batch = execute_query_fetch_all(self.evadb, "SELECT * FROM MyVideo;")
         self.assertTrue("myvideo._row_id" in batch.columns)
 
         # test for image table
-        batch = execute_query_fetch_all("SELECT _row_id, name FROM MemeImages;")
+        batch = execute_query_fetch_all(
+            self.evadb, "SELECT _row_id, name FROM MemeImages;"
+        )
         expected = Batch(
             pd.DataFrame(
                 {
                     "memeimages._row_id": [1, 2],
                     "memeimages.name": [self.meme1, self.meme2],
                 }
             )
         )
         self.assertEqual(batch, expected)
 
-        batch = execute_query_fetch_all("SELECT * FROM MemeImages;")
+        batch = execute_query_fetch_all(self.evadb, "SELECT * FROM MemeImages;")
         self.assertTrue("memeimages._row_id" in batch.columns)
 
         # test for structural table
-        batch = execute_query_fetch_all("SELECT _row_id FROM table1;")
+        batch = execute_query_fetch_all(self.evadb, "SELECT _row_id FROM table1;")
         expected = Batch(
             pd.DataFrame(
                 {
                     "table1._row_id": range(1, 101),
                 }
             )
         )
         self.assertEqual(batch, expected)
 
-        batch = execute_query_fetch_all("SELECT * FROM table1;")
+        batch = execute_query_fetch_all(self.evadb, "SELECT * FROM table1;")
         self.assertTrue("table1._row_id" in batch.columns)
```

### Comparing `evadb-0.2.6/test/integration_tests/test_show_info_executor.py` & `evadb-0.2.7/test/integration_tests/test_fuzzy_join.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,86 +1,92 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-import os
 import unittest
-from test.markers import windows_skip_marker
+from pathlib import Path
+from test.util import (
+    create_sample_csv,
+    create_sample_video,
+    file_remove,
+    get_evadb_for_testing,
+    shutdown_ray,
+)
 
-import pandas as pd
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
-from eva.udfs.udf_bootstrap_queries import ArrayCount_udf_query, Fastrcnn_udf_query
-
-NUM_FRAMES = 10
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.server.command_handler import execute_query_fetch_all
 
 
 @pytest.mark.notparallel
-class ShowExecutorTest(unittest.TestCase):
-    @classmethod
-    def setUpClass(cls):
-        CatalogManager().reset()
-        queries = [Fastrcnn_udf_query, ArrayCount_udf_query]
-        for query in queries:
-            execute_query_fetch_all(query)
-
-        ua_detrac = f"{EVA_ROOT_DIR}/data/ua_detrac/ua_detrac.mp4"
-        mnist = f"{EVA_ROOT_DIR}/data/mnist/mnist.mp4"
-        actions = f"{EVA_ROOT_DIR}/data/actions/actions.mp4"
-        execute_query_fetch_all(f"LOAD VIDEO '{ua_detrac}' INTO MyVideo;")
-        execute_query_fetch_all(f"LOAD VIDEO '{mnist}' INTO MNIST;")
-        execute_query_fetch_all(f"LOAD VIDEO '{actions}' INTO Actions;")
-
-    @classmethod
-    def tearDownClass(cls):
-        execute_query_fetch_all("DROP TABLE IF EXISTS Actions;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MNIST;")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
-
-    # integration test
-    def test_show_udfs(self):
-        result = execute_query_fetch_all("SHOW UDFS;")
-        self.assertEqual(len(result.columns), 6)
-
-        expected = {
-            "name": ["FastRCNNObjectDetector", "ArrayCount"],
-            "type": ["Classification", "NdarrayUDF"],
-        }
-        expected_df = pd.DataFrame(expected)
-        self.assertTrue(all(expected_df.name == result.frames.name))
-        self.assertTrue(all(expected_df.type == result.frames.type))
-
-    @windows_skip_marker
-    def test_show_tables(self):
-        # Note this test can causes sqlalchemy issues if the eva_server is not stopped
-        result = execute_query_fetch_all("SHOW TABLES;")
-        self.assertEqual(len(result), 3)
-        expected = {"name": ["MyVideo", "MNIST", "Actions"]}
-        expected_df = pd.DataFrame(expected)
-        self.assertEqual(result, Batch(expected_df))
-
-        # Stop and restart server
-        os.system("nohup eva_server --stop")
-        os.system("nohup eva_server --start &")
-
-        result = execute_query_fetch_all("SHOW TABLES;")
-        self.assertEqual(len(result), 3)
-        expected = {"name": ["MyVideo", "MNIST", "Actions"]}
-        expected_df = pd.DataFrame(expected)
-        self.assertEqual(result, Batch(expected_df))
+class FuzzyJoinTests(unittest.TestCase):
+    def setUp(self):
+        self.evadb = get_evadb_for_testing()
+        self.evadb.catalog().reset()
+        self.video_file_path = create_sample_video()
+        self.image_files_path = Path(
+            f"{EVA_ROOT_DIR}/test/data/uadetrac/small-data/MVI_20011/*.jpg"
+        )
+        self.csv_file_path = create_sample_csv()
+
+        # Prepare needed UDFs and data.
+        # loading a csv requires a table to be created first
+        create_table_query = """
+            CREATE TABLE IF NOT EXISTS MyVideoCSV (
+                id INTEGER UNIQUE,
+                frame_id INTEGER,
+                video_id INTEGER,
+                dataset_name TEXT(30),
+                label TEXT(30),
+                bbox NDARRAY FLOAT32(4),
+                object_id INTEGER
+            );
+            """
+        execute_query_fetch_all(self.evadb, create_table_query)
+
+        # load the CSV
+        load_query = f"LOAD CSV '{self.csv_file_path}' INTO MyVideoCSV;"
+        execute_query_fetch_all(self.evadb, load_query)
+
+        # load the video to be joined with the csv
+        query = f"LOAD VIDEO '{self.video_file_path}' INTO MyVideo;"
+        execute_query_fetch_all(self.evadb, query)
+
+    def tearDown(self):
+        shutdown_ray()
+
+        file_remove("dummy.avi")
+        file_remove("dummy.csv")
+        # clean up
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideoCSV;")
+
+    def test_fuzzyjoin(self):
+        EVA_INSTALLATION_DIR = self.evadb.config.get_value(
+            "core", "eva_installation_dir"
+        )
+        fuzzy_udf = """CREATE UDF IF NOT EXISTS FuzzDistance
+                    INPUT (Input_Array1 NDARRAY ANYTYPE, Input_Array2 NDARRAY ANYTYPE)
+                    OUTPUT (distance FLOAT(32, 7))
+                    TYPE NdarrayUDF
+                    IMPL "{}/udfs/{}/fuzzy_join.py";
+        """.format(
+            EVA_INSTALLATION_DIR, "ndarray"
+        )
+        execute_query_fetch_all(self.evadb, fuzzy_udf)
+
+        fuzzy_join_query = """SELECT * FROM MyVideo a JOIN MyVideoCSV b
+                      ON FuzzDistance(a.id, b.id) = 100;"""
 
-        # stop the server
-        os.system("nohup eva_server --stop")
+        actual_batch = execute_query_fetch_all(self.evadb, fuzzy_join_query)
+        self.assertEqual(len(actual_batch), 10)
```

### Comparing `evadb-0.2.6/test/integration_tests/test_similarity.py` & `evadb-0.2.7/test/integration_tests/test_similarity.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,65 +11,69 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 import unittest
 from test.markers import ray_skip_marker
-from test.util import create_sample_image, load_udfs_for_testing, shutdown_ray
+from test.util import (
+    create_sample_image,
+    get_evadb_for_testing,
+    load_udfs_for_testing,
+    shutdown_ray,
+)
 
 import cv2
 import numpy as np
 import pandas as pd
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
-from eva.storage.storage_engine import StorageEngine
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
+from evadb.storage.storage_engine import StorageEngine
 
 
 @pytest.mark.notparallel
 class SimilarityTests(unittest.TestCase):
     def setUp(self):
-        CatalogManager().reset()
+        self.evadb = get_evadb_for_testing()
+        self.evadb.catalog().reset()
 
         # Prepare needed UDFs and data_col.
-        load_udfs_for_testing(mode="debug")
+        load_udfs_for_testing(self.evadb, mode="debug")
         self.img_path = create_sample_image()
 
         # Create base comparison table.
         create_table_query = """CREATE TABLE IF NOT EXISTS testSimilarityTable
                                   (data_col NDARRAY UINT8(3, ANYDIM, ANYDIM),
                                    dummy INTEGER);"""
-        execute_query_fetch_all(create_table_query)
+        execute_query_fetch_all(self.evadb, create_table_query)
 
         # Create feature table.
         create_table_query = """CREATE TABLE IF NOT EXISTS testSimilarityFeatureTable
                                   (feature_col NDARRAY FLOAT32(1, ANYDIM),
                                    dummy INTEGER);"""
-        execute_query_fetch_all(create_table_query)
+        execute_query_fetch_all(self.evadb, create_table_query)
 
         # Prepare injected data_col.
         base_img = np.array(np.ones((3, 3, 3)), dtype=np.uint8)
         base_img[0] -= 1
         base_img[2] += 1
 
         # id: 1 -> most dissimilar, id: 5 -> most similar
         base_img += 4
 
         # Inject data_col.
-        base_table_catalog_entry = CatalogManager().get_table_catalog_entry(
+        base_table_catalog_entry = self.evadb.catalog().get_table_catalog_entry(
             "testSimilarityTable"
         )
-        feature_table_catalog_entry = CatalogManager().get_table_catalog_entry(
+        feature_table_catalog_entry = self.evadb.catalog().get_table_catalog_entry(
             "testSimilarityFeatureTable"
         )
-        storage_engine = StorageEngine.factory(base_table_catalog_entry)
+        storage_engine = StorageEngine.factory(self.evadb, base_table_catalog_entry)
         for i in range(5):
             storage_engine.write(
                 base_table_catalog_entry,
                 Batch(
                     pd.DataFrame(
                         [
                             {
@@ -94,47 +98,47 @@
                         ]
                     )
                 ),
             )
 
             # Create an actual image dataset.
             img_save_path = os.path.join(
-                ConfigurationManager().get_value("storage", "tmp_dir"),
+                self.evadb.config.get_value("storage", "tmp_dir"),
                 f"test_similar_img{i}.jpg",
             )
             cv2.imwrite(img_save_path, base_img)
             load_image_query = (
                 f"LOAD IMAGE '{img_save_path}' INTO testSimilarityImageDataset;"
             )
-            execute_query_fetch_all(load_image_query)
+            execute_query_fetch_all(self.evadb, load_image_query)
 
             base_img -= 1
 
     def tearDown(self):
         shutdown_ray()
 
         drop_table_query = "DROP TABLE testSimilarityTable;"
-        execute_query_fetch_all(drop_table_query)
+        execute_query_fetch_all(self.evadb, drop_table_query)
         drop_table_query = "DROP TABLE testSimilarityFeatureTable;"
-        execute_query_fetch_all(drop_table_query)
+        execute_query_fetch_all(self.evadb, drop_table_query)
         drop_table_query = "DROP TABLE IF EXISTS testSimilarityImageDataset;"
-        execute_query_fetch_all(drop_table_query)
+        execute_query_fetch_all(self.evadb, drop_table_query)
 
     def test_similarity_should_work_in_order(self):
         ###############################################
         # Test case runs with UDF on raw input table. #
         ###############################################
 
         # Top 1 - assume table contains base data_col.
         select_query = """SELECT data_col FROM testSimilarityTable
                             ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), DummyFeatureExtractor(data_col))
                             LIMIT 1;""".format(
             self.img_path
         )
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
 
         base_img = np.array(np.ones((3, 3, 3)), dtype=np.uint8)
         base_img[0] -= 1
         base_img[2] += 1
 
         actual_open = actual_batch.frames["testsimilaritytable.data_col"].to_numpy()[0]
         self.assertTrue(np.array_equal(actual_open, base_img))
@@ -143,15 +147,15 @@
 
         # Top 2 - assume table contains base data.
         select_query = """SELECT data_col FROM testSimilarityTable
                             ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), DummyFeatureExtractor(data_col))
                             LIMIT 2;""".format(
             self.img_path
         )
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
 
         actual_open = actual_batch.frames["testsimilaritytable.data_col"].to_numpy()[0]
         self.assertTrue(np.array_equal(actual_open, base_img))
         actual_open = actual_batch.frames["testsimilaritytable.data_col"].to_numpy()[1]
         self.assertTrue(np.array_equal(actual_open, base_img + 1))
         # actual_distance = actual_batch.frames["similarity.distance"].to_numpy()[0]
         # self.assertEqual(actual_distance, 0)
@@ -164,15 +168,15 @@
 
         # Top 1 - assume table contains feature data.
         select_query = """SELECT feature_col FROM testSimilarityFeatureTable
                             ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), feature_col)
                             LIMIT 1;""".format(
             self.img_path
         )
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
 
         base_img = np.array(np.ones((3, 3, 3)), dtype=np.uint8)
         base_img[0] -= 1
         base_img[2] += 1
         base_img = base_img.astype(np.float32).reshape(1, -1)
 
         actual_open = actual_batch.frames[
@@ -184,15 +188,15 @@
 
         # Top 2 - assume table contains feature data.
         select_query = """SELECT feature_col FROM testSimilarityFeatureTable
                             ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), feature_col)
                             LIMIT 2;""".format(
             self.img_path
         )
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
 
         actual_open = actual_batch.frames[
             "testsimilarityfeaturetable.feature_col"
         ].to_numpy()[0]
         self.assertTrue(np.array_equal(actual_open, base_img))
         actual_open = actual_batch.frames[
             "testsimilarityfeaturetable.feature_col"
@@ -210,30 +214,30 @@
 
         # Execution without index scan.
         select_query = """SELECT feature_col FROM testSimilarityFeatureTable
                             ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), feature_col)
                             LIMIT 3;""".format(
             self.img_path
         )
-        expected_batch = execute_query_fetch_all(select_query)
+        expected_batch = execute_query_fetch_all(self.evadb, select_query)
 
         # Execution with index scan.
         create_index_query = """CREATE INDEX testFaissIndexScanRewrite1
                                     ON testSimilarityFeatureTable (feature_col)
                                     USING FAISS;"""
-        execute_query_fetch_all(create_index_query)
+        execute_query_fetch_all(self.evadb, create_index_query)
         select_query = """SELECT feature_col FROM testSimilarityFeatureTable
                             ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), feature_col)
                             LIMIT 3;""".format(
             self.img_path
         )
         explain_query = """EXPLAIN {}""".format(select_query)
-        explain_batch = execute_query_fetch_all(explain_query)
+        explain_batch = execute_query_fetch_all(self.evadb, explain_query)
         self.assertTrue("VectorIndexScan" in explain_batch.frames[0][0])
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
 
         self.assertEqual(len(actual_batch), 3)
         for i in range(3):
             self.assertTrue(
                 np.array_equal(
                     expected_batch.frames[
                         "testsimilarityfeaturetable.feature_col"
@@ -250,92 +254,92 @@
 
         # Execution without index scan.
         select_query = """SELECT data_col FROM testSimilarityTable
                             ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), DummyFeatureExtractor(data_col))
                             LIMIT 3;""".format(
             self.img_path
         )
-        expected_batch = execute_query_fetch_all(select_query)
+        expected_batch = execute_query_fetch_all(self.evadb, select_query)
 
         # Execution with index scan.
         create_index_query = """CREATE INDEX testFaissIndexScanRewrite2
                                     ON testSimilarityTable (DummyFeatureExtractor(data_col))
                                     USING FAISS;"""
-        execute_query_fetch_all(create_index_query)
+        execute_query_fetch_all(self.evadb, create_index_query)
         select_query = """SELECT data_col FROM testSimilarityTable
                             ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), DummyFeatureExtractor(data_col))
                             LIMIT 3;""".format(
             self.img_path
         )
         explain_query = """EXPLAIN {}""".format(select_query)
-        explain_batch = execute_query_fetch_all(explain_query)
+        explain_batch = execute_query_fetch_all(self.evadb, explain_query)
         self.assertTrue("VectorIndexScan" in explain_batch.frames[0][0])
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
 
         self.assertEqual(len(actual_batch), 3)
         for i in range(3):
             self.assertTrue(
                 np.array_equal(
                     expected_batch.frames["testsimilaritytable.data_col"].to_numpy()[i],
                     actual_batch.frames["testsimilaritytable.data_col"].to_numpy()[i],
                 )
             )
 
         # Cleanup
-        CatalogManager().drop_index_catalog_entry("testFaissIndexScanRewrite1")
-        CatalogManager().drop_index_catalog_entry("testFaissIndexScanRewrite2")
+        self.evadb.catalog().drop_index_catalog_entry("testFaissIndexScanRewrite1")
+        self.evadb.catalog().drop_index_catalog_entry("testFaissIndexScanRewrite2")
 
     def test_should_not_do_vector_index_scan_with_predicate(self):
         # Execution with index scan.
         create_index_query = """CREATE INDEX testFaissIndexScanRewrite
                                     ON testSimilarityTable (DummyFeatureExtractor(data_col))
                                     USING FAISS;"""
-        execute_query_fetch_all(create_index_query)
+        execute_query_fetch_all(self.evadb, create_index_query)
 
         explain_query = """
             EXPLAIN
                 SELECT data_col FROM testSimilarityTable WHERE dummy = 0
                   ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), DummyFeatureExtractor(data_col))
                   LIMIT 3;
         """.format(
             "dummypath"
         )
-        batch = execute_query_fetch_all(explain_query)
+        batch = execute_query_fetch_all(self.evadb, explain_query)
 
         # Index scan should not be used.
         self.assertFalse("FaissIndexScan" in batch.frames[0][0])
 
         # Cleanup
-        CatalogManager().drop_index_catalog_entry("testFaissIndexScanRewrite")
+        self.evadb.catalog().drop_index_catalog_entry("testFaissIndexScanRewrite")
 
     def test_end_to_end_index_scan_should_work_correctly_on_image_dataset(self):
         create_index_query = """CREATE INDEX testFaissIndexImageDataset
                                     ON testSimilarityImageDataset (DummyFeatureExtractor(data))
                                     USING FAISS;"""
-        execute_query_fetch_all(create_index_query)
+        execute_query_fetch_all(self.evadb, create_index_query)
         select_query = """SELECT _row_id FROM testSimilarityImageDataset
                             ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), DummyFeatureExtractor(data))
                             LIMIT 1;""".format(
             self.img_path
         )
-        res_batch = execute_query_fetch_all(select_query)
+        res_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(res_batch.frames["testsimilarityimagedataset._row_id"][0], 5)
 
     @ray_skip_marker
     def test_end_to_end_index_scan_should_work_correctly_on_image_dataset_qdrant(self):
         create_index_query = """CREATE INDEX testFaissIndexImageDataset
                                     ON testSimilarityImageDataset (DummyFeatureExtractor(data))
                                     USING QDRANT;"""
-        execute_query_fetch_all(create_index_query)
+        execute_query_fetch_all(self.evadb, create_index_query)
         select_query = """SELECT _row_id FROM testSimilarityImageDataset
                             ORDER BY Similarity(DummyFeatureExtractor(Open("{}")), DummyFeatureExtractor(data))
                             LIMIT 1;""".format(
             self.img_path
         )
 
         """|__ ProjectPlan
             |__ VectorIndexScanPlan
                 |__ SeqScanPlan
                     |__ StoragePlan"""
 
-        res_batch = execute_query_fetch_all(select_query)
+        res_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(res_batch.frames["testsimilarityimagedataset._row_id"][0], 5)
```

### Comparing `evadb-0.2.6/test/integration_tests/test_udf_executor.py` & `evadb-0.2.7/test/integration_tests/test_udf_executor.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,58 +15,59 @@
 import tempfile
 import unittest
 from test.util import (
     DummyObjectDetector,
     create_dummy_batches,
     create_sample_video,
     file_remove,
+    get_evadb_for_testing,
     shutdown_ray,
 )
 
 import numpy as np
 import pandas as pd
 import pytest
 
-from eva.binder.binder_utils import BinderError
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import ColumnType, NdArrayType
-from eva.executor.executor_utils import ExecutorError
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.binder.binder_utils import BinderError
+from evadb.catalog.catalog_type import ColumnType, NdArrayType
+from evadb.executor.executor_utils import ExecutorError
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
 
 NUM_FRAMES = 10
 
 
 @pytest.mark.notparallel
 class UDFExecutorTest(unittest.TestCase):
     def setUp(self):
-        CatalogManager().reset()
+        self.evadb = get_evadb_for_testing()
+        self.evadb.catalog().reset()
         video_file_path = create_sample_video(NUM_FRAMES)
         load_query = f"LOAD VIDEO '{video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(load_query)
+        execute_query_fetch_all(self.evadb, load_query)
 
         create_udf_query = """CREATE UDF DummyObjectDetector
                   INPUT  (Frame_Array NDARRAY UINT8(3, 256, 256))
                   OUTPUT (label NDARRAY STR(10))
                   TYPE  Classification
                   IMPL  'test/util.py';
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
     def tearDown(self):
         shutdown_ray()
         file_remove("dummy.avi")
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideo;")
 
     # integration test
 
     def test_should_load_and_select_using_udf_video_in_table(self):
         select_query = "SELECT id,DummyObjectDetector(data) FROM MyVideo \
             ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         labels = DummyObjectDetector().labels
         expected = [
             {
                 "myvideo.id": i,
                 "dummyobjectdetector.label": np.array([labels[1 + i % 2]]),
             }
             for i in range(NUM_FRAMES)
@@ -74,37 +75,37 @@
         expected_batch = Batch(frames=pd.DataFrame(expected))
         self.assertEqual(actual_batch, expected_batch)
 
     def test_should_load_and_select_using_udf_video(self):
         # Equality test
         select_query = "SELECT id,DummyObjectDetector(data) FROM MyVideo \
             WHERE DummyObjectDetector(data).label = ['person'] ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected = [
             {
                 "myvideo.id": i * 2,
                 "dummyobjectdetector.label": np.array(["person"]),
             }
             for i in range(NUM_FRAMES // 2)
         ]
         expected_batch = Batch(frames=pd.DataFrame(expected))
         self.assertEqual(actual_batch, expected_batch)
 
         # Contain test
         select_query = "SELECT id,DummyObjectDetector(data) FROM MyVideo \
             WHERE DummyObjectDetector(data).label @> ['person'] ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         self.assertEqual(actual_batch, expected_batch)
 
         # Multi element contain test
 
         select_query = "SELECT id,DummyObjectDetector(data) FROM MyVideo \
             WHERE DummyObjectDetector(data).label <@ ['person', 'bicycle'] \
             ORDER BY id;"
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         expected = [
             {
                 "myvideo.id": i * 2,
                 "dummyobjectdetector.label": np.array(["person"]),
             }
             for i in range(NUM_FRAMES // 2)
         ]
@@ -122,15 +123,15 @@
         self.assertEqual(actual_batch, expected_batch)
         nested_select_query = """SELECT name, id, data FROM
             (SELECT name, id, data, DummyObjectDetector(data) FROM MyVideo
                 WHERE id >= 2
             ) AS T
             WHERE ['person'] <@ label;
             """
-        actual_batch = execute_query_fetch_all(nested_select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, nested_select_query)
         actual_batch.sort()
         expected_batch = list(
             create_dummy_batches(
                 filters=[i for i in range(2, NUM_FRAMES) if i % 2 == 0]
             )
         )[0]
         expected_batch = expected_batch.project(
@@ -145,81 +146,83 @@
                   INPUT  (Frame_Array NDARRAY UINT8(3, 256, 256))
                   OUTPUT (label NDARRAY STR(10))
                   TYPE  Classification
                   IMPL  'test/util.py';
         """
         # Try to create duplicate UDF
         with self.assertRaises(ExecutorError):
-            actual = execute_query_fetch_all(create_udf_query.format(udf_name))
+            actual = execute_query_fetch_all(
+                self.evadb, create_udf_query.format(udf_name)
+            )
             expected = Batch(pd.DataFrame([f"UDF {udf_name} already exists."]))
             self.assertEqual(actual, expected)
 
         # Try to create UDF if not exists
         actual = execute_query_fetch_all(
-            create_udf_query.format("IF NOT EXISTS " + udf_name)
+            self.evadb, create_udf_query.format("IF NOT EXISTS " + udf_name)
         )
         expected = Batch(
             pd.DataFrame([f"UDF {udf_name} already exists, nothing added."])
         )
         self.assertEqual(actual, expected)
 
     def test_should_create_udf_with_metadata(self):
         udf_name = "DummyObjectDetector"
-        execute_query_fetch_all(f"DROP UDF {udf_name};")
+        execute_query_fetch_all(self.evadb, f"DROP UDF {udf_name};")
         create_udf_query = """CREATE UDF {}
                   INPUT  (Frame_Array NDARRAY UINT8(3, 256, 256))
                   OUTPUT (label NDARRAY STR(10))
                   TYPE  Classification
                   IMPL  'test/util.py'
                   'CACHE' 'TRUE'
                   'BATCH' 'FALSE';
         """
-        execute_query_fetch_all(create_udf_query.format(udf_name))
+        execute_query_fetch_all(self.evadb, create_udf_query.format(udf_name))
 
         # try fetching the metadata values
-        entries = CatalogManager().get_udf_metadata_entries_by_udf_name(udf_name)
+        entries = self.evadb.catalog().get_udf_metadata_entries_by_udf_name(udf_name)
         self.assertEqual(len(entries), 2)
         metadata = [(entry.key, entry.value) for entry in entries]
 
         expected_metadata = [("CACHE", "TRUE"), ("BATCH", "FALSE")]
         self.assertEqual(set(metadata), set(expected_metadata))
 
     def test_should_return_empty_metadata_list_for_missing_udf(self):
         # missing udf should return empty list
-        entries = CatalogManager().get_udf_metadata_entries_by_udf_name("randomUDF")
+        entries = self.evadb.catalog().get_udf_metadata_entries_by_udf_name("randomUDF")
         self.assertEqual(len(entries), 0)
 
     def test_should_return_empty_metadata_list_if_udf_is_removed(self):
         udf_name = "DummyObjectDetector"
-        execute_query_fetch_all(f"DROP UDF {udf_name};")
+        execute_query_fetch_all(self.evadb, f"DROP UDF {udf_name};")
         create_udf_query = """CREATE UDF {}
                   INPUT  (Frame_Array NDARRAY UINT8(3, 256, 256))
                   OUTPUT (label NDARRAY STR(10))
                   TYPE  Classification
                   IMPL  'test/util.py'
                   'CACHE' 'TRUE'
                   'BATCH' 'FALSE';
         """
-        execute_query_fetch_all(create_udf_query.format(udf_name))
+        execute_query_fetch_all(self.evadb, create_udf_query.format(udf_name))
 
         # try fetching the metadata values
-        entries = CatalogManager().get_udf_metadata_entries_by_udf_name(udf_name)
+        entries = self.evadb.catalog().get_udf_metadata_entries_by_udf_name(udf_name)
         self.assertEqual(len(entries), 2)
 
         # remove the udf
-        execute_query_fetch_all(f"DROP UDF {udf_name};")
+        execute_query_fetch_all(self.evadb, f"DROP UDF {udf_name};")
         # try fetching the metadata values
-        entries = CatalogManager().get_udf_metadata_entries_by_udf_name(udf_name)
+        entries = self.evadb.catalog().get_udf_metadata_entries_by_udf_name(udf_name)
         self.assertEqual(len(entries), 0)
 
     def test_should_raise_using_missing_udf(self):
         select_query = "SELECT id,DummyObjectDetector1(data) FROM MyVideo \
             ORDER BY id;"
         with self.assertRaises(BinderError) as cm:
-            execute_query_fetch_all(select_query)
+            execute_query_fetch_all(self.evadb, select_query)
 
         err_msg = (
             "UDF with name DummyObjectDetector1 does not exist in the catalog. "
             "Please create the UDF using CREATE UDF command."
         )
         self.assertEqual(str(cm.exception), err_msg)
 
@@ -227,57 +230,61 @@
         create_udf_query = """CREATE UDF TestUDF
                   INPUT  (Frame_Array NDARRAY UINT8(3, 256, 256))
                   OUTPUT (label NDARRAY STR(10))
                   TYPE  Classification
                   IMPL  'test/util.py';
         """
         with self.assertRaises(ExecutorError):
-            execute_query_fetch_all(create_udf_query)
+            execute_query_fetch_all(self.evadb, create_udf_query)
 
     def test_should_raise_if_udf_file_is_modified(self):
-        execute_query_fetch_all("DROP UDF DummyObjectDetector;")
+        execute_query_fetch_all(self.evadb, "DROP UDF DummyObjectDetector;")
 
         # Test IF EXISTS
-        execute_query_fetch_all("DROP UDF IF EXISTS DummyObjectDetector;")
+        execute_query_fetch_all(self.evadb, "DROP UDF IF EXISTS DummyObjectDetector;")
 
         with tempfile.NamedTemporaryFile(mode="w", suffix=".py") as tmp_file:
             with open("test/util.py", "r") as file:
                 tmp_file.write(file.read())
 
             tmp_file.seek(0)
 
             udf_name = "DummyObjectDetector"
             create_udf_query = """CREATE UDF {}
                     INPUT  (Frame_Array NDARRAY UINT8(3, 256, 256))
                     OUTPUT (label NDARRAY STR(10))
                     TYPE  Classification
                     IMPL  '{}';
             """
-            execute_query_fetch_all(create_udf_query.format(udf_name, tmp_file.name))
+            execute_query_fetch_all(
+                self.evadb, create_udf_query.format(udf_name, tmp_file.name)
+            )
 
             # Modify the udf file by appending
             tmp_file.seek(0, 2)
             tmp_file.write("#comment")
             tmp_file.seek(0)
 
             select_query = (
                 "SELECT id,DummyObjectDetector(data) FROM MyVideo ORDER BY id;"
             )
 
             with self.assertRaises(AssertionError):
-                execute_query_fetch_all(select_query)
+                execute_query_fetch_all(self.evadb, select_query)
 
     def test_create_udf_with_decorators(self):
-        execute_query_fetch_all("DROP UDF IF EXISTS DummyObjectDetectorDecorators;")
+        execute_query_fetch_all(
+            self.evadb, "DROP UDF IF EXISTS DummyObjectDetectorDecorators;"
+        )
         create_udf_query = """CREATE UDF DummyObjectDetectorDecorators
                   IMPL  'test/util.py';
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
-        catalog_manager = CatalogManager()
+        catalog_manager = self.evadb.catalog()
         udf_obj = catalog_manager.get_udf_catalog_entry_by_name(
             "DummyObjectDetectorDecorators"
         )
         udf_inputs = catalog_manager.get_udf_io_catalog_input_entries(udf_obj)
         self.assertEquals(len(udf_inputs), 1)
 
         udf_input = udf_inputs[0]
@@ -309,10 +316,12 @@
 
         for attr in expected_output_attributes:
             self.assertEquals(
                 getattr(udf_output, attr), expected_output_attributes[attr]
             )
 
     def test_udf_cost_entry_created(self):
-        execute_query_fetch_all("SELECT DummyObjectDetector(data) FROM MyVideo")
-        entry = CatalogManager().get_udf_cost_catalog_entry("DummyObjectDetector")
+        execute_query_fetch_all(
+            self.evadb, "SELECT DummyObjectDetector(data) FROM MyVideo"
+        )
+        entry = self.evadb.catalog().get_udf_cost_catalog_entry("DummyObjectDetector")
         self.assertIsNotNone(entry)
```

### Comparing `evadb-0.2.6/test/markers.py` & `evadb-0.2.7/test/markers.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,28 +1,27 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+import os
 import sys
 
 import pytest
 
-from eva.configuration.configuration_manager import ConfigurationManager
-
 asyncio_skip_marker = pytest.mark.skipif(
     sys.version_info < (3, 8), reason="Test case requires asyncio support"
 )
 
 windows_skip_marker = pytest.mark.skipif(
     sys.platform == "win32", reason="Test case not supported on Windows"
 )
@@ -32,18 +31,22 @@
 )
 
 memory_skip_marker = pytest.mark.skipif(
     sys.platform == "linux", reason="Test case consumes too much memory"
 )
 
 ray_skip_marker = pytest.mark.skipif(
-    ConfigurationManager().get_value("experimental", "ray"),
+    os.environ.get("ray") is None,
     reason="Skip test for ray execution.",
 )
 
+ray_only_marker = pytest.mark.skipif(
+    os.environ.get("ray") is not None,
+    reason="Run only if ray is enabled",
+)
 
 duplicate_skip_marker = pytest.mark.skipif(
     sys.platform == "linux",
     reason="Test case is duplicate. Disabling to speed up test suite",
 )
 
 ocr_skip_marker = pytest.mark.skipif(
```

### Comparing `evadb-0.2.6/test/models/__init__.py` & `evadb-0.2.7/test/models/catalog/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/models/catalog/__init__.py` & `evadb-0.2.7/test/models/storage/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/models/catalog/test_frame_info.py` & `evadb-0.2.7/test/models/catalog/test_frame_info.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
-from eva.models.catalog.frame_info import FrameInfo
-from eva.models.catalog.properties import ColorSpace
+from evadb.models.catalog.frame_info import FrameInfo
+from evadb.models.catalog.properties import ColorSpace
 
 
 class FrameInfoTest(unittest.TestCase):
     def test_frame_info_equality(self):
         info1 = FrameInfo(
             height=250, width=250, channels=3, color_space=ColorSpace.GRAY
         )
```

### Comparing `evadb-0.2.6/test/models/storage/__init__.py` & `evadb-0.2.7/test/optimizer/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/models/storage/test_batch.py` & `evadb-0.2.7/test/models/storage/test_batch.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,16 +14,16 @@
 # limitations under the License.
 import unittest
 from test.util import create_dataframe, create_dataframe_same
 
 import numpy as np
 import pandas as pd
 
-from eva.models.storage.batch import Batch
-from eva.parser.alias import Alias
+from evadb.models.storage.batch import Batch
+from evadb.parser.alias import Alias
 
 
 class BatchTest(unittest.TestCase):
     def test_batch_serialize_deserialize(self):
         batch = Batch(frames=create_dataframe())
         batch2 = Batch.deserialize(batch.serialize())
         self.assertEqual(batch, batch2)
```

### Comparing `evadb-0.2.6/test/optimizer/__init__.py` & `evadb-0.2.7/test/optimizer/rules/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/optimizer/rules/__init__.py` & `evadb-0.2.7/test/parser/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/optimizer/rules/test_rules.py` & `evadb-0.2.7/test/optimizer/rules/test_rules.py`

 * *Files 10% similar despite different names*

```diff
@@ -9,30 +9,28 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-from test.util import create_sample_video
+from test.util import create_sample_video, get_evadb_for_testing
 
 import pytest
 from mock import MagicMock, patch
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import TableType
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.optimizer.operators import (
+from evadb.catalog.catalog_type import TableType
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.optimizer.operators import (
     LogicalFilter,
     LogicalGet,
     LogicalJoin,
     LogicalSample,
 )
-from eva.optimizer.rules.rules import (
+from evadb.optimizer.rules.rules import (
     CacheFunctionExpressionInApply,
     CacheFunctionExpressionInFilter,
     CacheFunctionExpressionInProject,
     CombineSimilarityOrderByAndLimitToVectorIndexScan,
     EmbedFilterIntoGet,
     EmbedSampleIntoGet,
     LogicalApplyAndMergeToPhysical,
@@ -40,16 +38,15 @@
     LogicalCreateFromSelectToPhysical,
     LogicalCreateIndexToVectorIndex,
     LogicalCreateMaterializedViewToPhysical,
     LogicalCreateToPhysical,
     LogicalCreateUDFToPhysical,
     LogicalDeleteToPhysical,
     LogicalDerivedGetToPhysical,
-    LogicalDropToPhysical,
-    LogicalDropUDFToPhysical,
+    LogicalDropObjectToPhysical,
     LogicalExchangeToPhysical,
     LogicalExplainToPhysical,
     LogicalFilterToPhysical,
     LogicalFunctionScanToPhysical,
     LogicalGetToSeqScan,
     LogicalGroupByToPhysical,
     LogicalInnerJoinCommutativity,
@@ -71,32 +68,33 @@
     PushDownFilterThroughJoin,
     ReorderPredicates,
     Rule,
     RuleType,
     XformExtractObjectToLinearFlow,
     XformLateralJoinToLinearFlow,
 )
-from eva.optimizer.rules.rules_manager import RulesManager, disable_rules
-from eva.parser.types import JoinType
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.optimizer.rules.rules_manager import RulesManager, disable_rules
+from evadb.parser.types import JoinType
+from evadb.server.command_handler import execute_query_fetch_all
 
 
 @pytest.mark.notparallel
 class RulesTest(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
+        cls.evadb = get_evadb_for_testing()
         # reset the catalog manager before running each test
-        CatalogManager().reset()
+        cls.evadb.catalog().reset()
         video_file_path = create_sample_video()
         load_query = f"LOAD VIDEO '{video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(load_query)
+        execute_query_fetch_all(cls.evadb, load_query)
 
     @classmethod
     def tearDownClass(cls):
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(cls.evadb, "DROP TABLE IF EXISTS MyVideo;")
 
     def test_rules_promises_order(self):
         # Promise of all rewrite should be greater than implementation
         rewrite_promises = [
             Promise.LOGICAL_INNER_JOIN_COMMUTATIVITY,
             Promise.EMBED_FILTER_INTO_GET,
             Promise.EMBED_SAMPLE_INTO_GET,
@@ -118,30 +116,29 @@
             Promise.LOGICAL_MATERIALIZED_VIEW_TO_PHYSICAL,
             Promise.LOGICAL_GROUPBY_TO_PHYSICAL,
             Promise.LOGICAL_ORDERBY_TO_PHYSICAL,
             Promise.LOGICAL_LIMIT_TO_PHYSICAL,
             Promise.LOGICAL_INSERT_TO_PHYSICAL,
             Promise.LOGICAL_DELETE_TO_PHYSICAL,
             Promise.LOGICAL_RENAME_TO_PHYSICAL,
-            Promise.LOGICAL_DROP_TO_PHYSICAL,
+            Promise.LOGICAL_DROP_OBJECT_TO_PHYSICAL,
             Promise.LOGICAL_LOAD_TO_PHYSICAL,
             Promise.LOGICAL_CREATE_TO_PHYSICAL,
             Promise.LOGICAL_CREATE_FROM_SELECT_TO_PHYSICAL,
             Promise.LOGICAL_CREATE_UDF_TO_PHYSICAL,
             Promise.LOGICAL_SAMPLE_TO_UNIFORMSAMPLE,
             Promise.LOGICAL_GET_TO_SEQSCAN,
             Promise.LOGICAL_DERIVED_GET_TO_PHYSICAL,
             Promise.LOGICAL_LATERAL_JOIN_TO_PHYSICAL,
             Promise.LOGICAL_JOIN_TO_PHYSICAL_HASH_JOIN,
             Promise.LOGICAL_JOIN_TO_PHYSICAL_NESTED_LOOP_JOIN,
             Promise.LOGICAL_FUNCTION_SCAN_TO_PHYSICAL,
             Promise.LOGICAL_FILTER_TO_PHYSICAL,
             Promise.LOGICAL_PROJECT_TO_PHYSICAL,
             Promise.LOGICAL_SHOW_TO_PHYSICAL,
-            Promise.LOGICAL_DROP_UDF_TO_PHYSICAL,
             Promise.LOGICAL_EXPLAIN_TO_PHYSICAL,
             Promise.LOGICAL_CREATE_INDEX_TO_VECTOR_INDEX,
             Promise.LOGICAL_APPLY_AND_MERGE_TO_PHYSICAL,
             Promise.LOGICAL_VECTOR_INDEX_SCAN_TO_PHYSICAL,
         ]
 
         for promise in implementation_promises:
@@ -164,16 +161,16 @@
             PushDownFilterThroughApplyAndMerge(),
             PushDownFilterThroughJoin(),
             CombineSimilarityOrderByAndLimitToVectorIndexScan(),
             ReorderPredicates(),
             XformExtractObjectToLinearFlow(),
         ]
         rewrite_rules = (
-            RulesManager().stage_one_rewrite_rules
-            + RulesManager().stage_two_rewrite_rules
+            RulesManager(self.evadb.config).stage_one_rewrite_rules
+            + RulesManager(self.evadb.config).stage_two_rewrite_rules
         )
         self.assertEqual(
             len(supported_rewrite_rules),
             len(rewrite_rules),
         )
         # check all the rule instance exists
         for rule in supported_rewrite_rules:
@@ -182,36 +179,39 @@
         supported_logical_rules = [
             LogicalInnerJoinCommutativity(),
             CacheFunctionExpressionInApply(),
             CacheFunctionExpressionInFilter(),
             CacheFunctionExpressionInProject(),
         ]
         self.assertEqual(
-            len(supported_logical_rules), len(RulesManager().logical_rules)
+            len(supported_logical_rules),
+            len(RulesManager(self.evadb.config).logical_rules),
         )
 
         for rule in supported_logical_rules:
             self.assertTrue(
-                any(isinstance(rule, type(x)) for x in RulesManager().logical_rules)
+                any(
+                    isinstance(rule, type(x))
+                    for x in RulesManager(self.evadb.config).logical_rules
+                )
             )
 
-        ray_enabled = ConfigurationManager().get_value("experimental", "ray")
+        ray_enabled = self.evadb.config.get_value("experimental", "ray")
 
         # For the current version, we choose either the distributed or the
         # sequential rule, because we do not have a logic to choose one over
         # the other in the current optimizer. Sequential rewrite is currently
         # embedded inside distributed rule if ray is enabled. The rule itself
         # has some simple heuristics to choose one over the other.
         supported_implementation_rules = [
             LogicalCreateToPhysical(),
             LogicalCreateFromSelectToPhysical(),
             LogicalRenameToPhysical(),
-            LogicalDropToPhysical(),
             LogicalCreateUDFToPhysical(),
-            LogicalDropUDFToPhysical(),
+            LogicalDropObjectToPhysical(),
             LogicalInsertToPhysical(),
             LogicalDeleteToPhysical(),
             LogicalLoadToPhysical(),
             LogicalGetToSeqScan(),
             LogicalProjectToRayPhysical()
             if ray_enabled
             else LogicalProjectToPhysical(),
@@ -235,22 +235,22 @@
             LogicalVectorIndexScanToPhysical(),
         ]
 
         if ray_enabled:
             supported_implementation_rules.append(LogicalExchangeToPhysical())
         self.assertEqual(
             len(supported_implementation_rules),
-            len(RulesManager().implementation_rules),
+            len(RulesManager(self.evadb.config).implementation_rules),
         )
 
         for rule in supported_implementation_rules:
             self.assertTrue(
                 any(
                     isinstance(rule, type(x))
-                    for x in RulesManager().implementation_rules
+                    for x in RulesManager(self.evadb.config).implementation_rules
                 )
             )
 
     # EmbedFilterIntoGet
     def test_simple_filter_into_get(self):
         rule = EmbedFilterIntoGet()
         predicate = MagicMock()
@@ -271,15 +271,16 @@
 
         logi_get = LogicalGet(MagicMock(), table_obj, MagicMock(), MagicMock())
         logi_sample = LogicalSample(MagicMock(), MagicMock(), children=[logi_get])
 
         self.assertFalse(rule.check(logi_sample, MagicMock()))
 
     def test_disable_rules(self):
-        with disable_rules([PushDownFilterThroughApplyAndMerge()]) as rules_manager:
+        rules_manager = RulesManager(self.evadb.config)
+        with disable_rules(rules_manager, [PushDownFilterThroughApplyAndMerge()]):
             self.assertFalse(
                 any(
                     isinstance(PushDownFilterThroughApplyAndMerge, type(x))
                     for x in rules_manager.stage_two_rewrite_rules
                 )
             )
```

### Comparing `evadb-0.2.6/test/optimizer/test_binder.py` & `evadb-0.2.7/test/optimizer/test_binder.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,19 +13,19 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import copy
 import unittest
 
 from mock import MagicMock
 
-from eva.optimizer.binder import Binder
-from eva.optimizer.cost_model import CostModel
-from eva.optimizer.operators import Dummy, LogicalFilter, LogicalGet, OperatorType
-from eva.optimizer.optimizer_context import OptimizerContext
-from eva.optimizer.rules.pattern import Pattern
+from evadb.optimizer.binder import Binder
+from evadb.optimizer.cost_model import CostModel
+from evadb.optimizer.operators import Dummy, LogicalFilter, LogicalGet, OperatorType
+from evadb.optimizer.optimizer_context import OptimizerContext
+from evadb.optimizer.rules.pattern import Pattern
 
 
 class TestBinder(unittest.TestCase):
     def helper_pre_order_match(self, cur_opr, res_opr):
         print(cur_opr)
         self.assertEqual(cur_opr.opr_type, res_opr.opr_type)
         self.assertEqual(len(cur_opr.children), len(res_opr.children))
@@ -51,15 +51,15 @@
 
         child1_ptn = Pattern(OperatorType.LOGICALGET)
         child2_ptn = Pattern(OperatorType.LOGICALGET)
         root_ptn = Pattern(OperatorType.LOGICALFILTER)
         root_ptn.append_child(child1_ptn)
         root_ptn.append_child(child2_ptn)
 
-        opt_ctxt = OptimizerContext(CostModel())
+        opt_ctxt = OptimizerContext(MagicMock(), CostModel())
         root_grp_expr = opt_ctxt.add_opr_to_group(root_opr)
 
         binder = Binder(root_grp_expr, root_ptn, opt_ctxt.memo)
 
         for match in iter(binder):
             self.helper_pre_order_match(root_opr, match)
 
@@ -86,22 +86,22 @@
         root_opr = LogicalFilter(MagicMock(), [child_opr, sub_root_opr])
 
         child_ptn = Pattern(OperatorType.LOGICALGET)
         root_ptn = Pattern(OperatorType.LOGICALFILTER)
         root_ptn.append_child(child_ptn)
         root_ptn.append_child(Pattern(OperatorType.DUMMY))
 
-        opt_ctxt = OptimizerContext(CostModel())
+        opt_ctxt = OptimizerContext(MagicMock(), CostModel())
         root_grp_expr = opt_ctxt.add_opr_to_group(root_opr)
         binder = Binder(root_grp_expr, root_ptn, opt_ctxt.memo)
         expected_match = copy.copy(root_opr)
         expected_match.children = [child_opr, Dummy(2, None)]
         for match in iter(binder):
             self.helper_pre_order_match(expected_match, match)
 
-        opt_ctxt = OptimizerContext(CostModel())
+        opt_ctxt = OptimizerContext(MagicMock(), CostModel())
         sub_root_grp_expr = opt_ctxt.add_opr_to_group(sub_root_opr)
         expected_match = copy.copy(sub_root_opr)
         expected_match.children = [sub_child_opr, Dummy(1, None)]
         binder = Binder(sub_root_grp_expr, root_ptn, opt_ctxt.memo)
         for match in iter(binder):
             self.helper_pre_order_match(expected_match, match)
```

### Comparing `evadb-0.2.6/test/optimizer/test_cascade_optimizer.py` & `evadb-0.2.7/test/optimizer/test_cascade_optimizer.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,61 +1,67 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-from test.util import NUM_FRAMES, create_sample_video, file_remove, shutdown_ray
+from test.util import (
+    NUM_FRAMES,
+    create_sample_video,
+    file_remove,
+    get_evadb_for_testing,
+    shutdown_ray,
+)
 
 import pandas as pd
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.models.storage.batch import Batch
-from eva.server.command_handler import execute_query_fetch_all
+from evadb.models.storage.batch import Batch
+from evadb.server.command_handler import execute_query_fetch_all
 
 
 @pytest.mark.notparallel
 class CascadeOptimizer(unittest.TestCase):
     def setUp(self):
-        CatalogManager().reset()
+        self.evadb = get_evadb_for_testing()
+        self.evadb.catalog().reset()
         self.video_file_path = create_sample_video(NUM_FRAMES)
 
     def tearDown(self):
         shutdown_ray()
         file_remove("dummy.avi")
 
     def test_logical_to_physical_udf(self):
         load_query = f"LOAD VIDEO '{self.video_file_path}' INTO MyVideo;"
-        execute_query_fetch_all(load_query)
+        execute_query_fetch_all(self.evadb, load_query)
 
         create_udf_query = """CREATE UDF DummyObjectDetector
                   INPUT  (Frame_Array NDARRAY UINT8(3, 256, 256))
                   OUTPUT (label NDARRAY STR(10))
                   TYPE  Classification
                   IMPL  'test/util.py';
         """
-        execute_query_fetch_all(create_udf_query)
+        execute_query_fetch_all(self.evadb, create_udf_query)
 
         select_query = """SELECT id, DummyObjectDetector(data)
                     FROM MyVideo
                     WHERE DummyObjectDetector(data).label = ['person'];
         """
-        actual_batch = execute_query_fetch_all(select_query)
+        actual_batch = execute_query_fetch_all(self.evadb, select_query)
         actual_batch.sort()
         expected = [
             {"myvideo.id": i * 2, "dummyobjectdetector.label": ["person"]}
             for i in range(NUM_FRAMES // 2)
         ]
         expected_batch = Batch(frames=pd.DataFrame(expected))
         self.assertEqual(actual_batch, expected_batch)
 
-        execute_query_fetch_all("DROP TABLE IF EXISTS MyVideo;")
+        execute_query_fetch_all(self.evadb, "DROP TABLE IF EXISTS MyVideo;")
```

### Comparing `evadb-0.2.6/test/optimizer/test_cost_model.py` & `evadb-0.2.7/test/optimizer/test_cost_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,20 +13,20 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from copy import copy
 
 from mock import MagicMock
 
-from eva.optimizer.group_expression import GroupExpression
-from eva.optimizer.operators import Operator
-from eva.optimizer.optimizer_context import OptimizerContext
-from eva.optimizer.optimizer_tasks import OptimizeGroup
-from eva.optimizer.plan_generator import PlanGenerator
-from eva.optimizer.property import PropertyType
+from evadb.optimizer.group_expression import GroupExpression
+from evadb.optimizer.operators import Operator
+from evadb.optimizer.optimizer_context import OptimizerContext
+from evadb.optimizer.optimizer_tasks import OptimizeGroup
+from evadb.optimizer.plan_generator import PlanGenerator
+from evadb.optimizer.property import PropertyType
 
 
 class CostModel(unittest.TestCase):
     def execute_task_stack(self, task_stack):
         while not task_stack.empty():
             task = task_stack.pop()
             task.execute()
@@ -37,27 +37,29 @@
             if value is grp_expr1:
                 return 1
             elif value is grp_expr2:
                 return 2
 
         cm = CostModel()
         cm.calculate_cost = MagicMock(side_effect=side_effect_func)
-        opt_cxt = OptimizerContext(cm)
+        opt_cxt = OptimizerContext(MagicMock(), cm)
 
         grp_expr1 = GroupExpression(MagicMock())
         grp_expr1.opr.is_logical = lambda: False
 
         grp_expr2 = GroupExpression(MagicMock())
         grp_expr2.opr.is_logical = lambda: False
         opt_cxt.memo.add_group_expr(grp_expr1)
         opt_cxt.memo.add_group_expr(grp_expr2, grp_expr1.group_id)
         grp = opt_cxt.memo.get_group_by_id(grp_expr1.group_id)
         opt_cxt.task_stack.push(OptimizeGroup(grp, opt_cxt))
         self.execute_task_stack(opt_cxt.task_stack)
-        plan = PlanGenerator().build_optimal_physical_plan(grp_expr1.group_id, opt_cxt)
+        plan = PlanGenerator(MagicMock()).build_optimal_physical_plan(
+            grp_expr1.group_id, opt_cxt
+        )
         self.assertEqual(plan, grp_expr1.opr)
         self.assertEqual(grp.get_best_expr_cost(PropertyType.DEFAULT), 1)
 
     def test_should_select_cheap_plan_with_tree(self):
         # mocking the cost model
         def side_effect_func(value):
             cost = dict(
@@ -69,15 +71,15 @@
                     grp_expr20: 5,
                 }
             )
             return cost[value]
 
         cm = CostModel()
         cm.calculate_cost = MagicMock(side_effect=side_effect_func)
-        opt_cxt = OptimizerContext(cm)
+        opt_cxt = OptimizerContext(MagicMock(), cm)
 
         # group 0
         grp_expr00 = GroupExpression(Operator(MagicMock()))
         grp_expr00.opr.is_logical = lambda: False
         grp_expr01 = GroupExpression(Operator(MagicMock()))
         grp_expr01.opr.is_logical = lambda: False
         opt_cxt.memo.add_group_expr(grp_expr00)
@@ -100,15 +102,17 @@
         # tree:  2->1->0
         grp_expr10.children = [grp_expr01.group_id]
         grp_expr11.children = [grp_expr01.group_id]
         grp_expr20.children = [grp_expr10.group_id]
 
         opt_cxt.task_stack.push(OptimizeGroup(grp, opt_cxt))
         self.execute_task_stack(opt_cxt.task_stack)
-        plan = PlanGenerator().build_optimal_physical_plan(grp_expr20.group_id, opt_cxt)
+        plan = PlanGenerator(MagicMock()).build_optimal_physical_plan(
+            grp_expr20.group_id, opt_cxt
+        )
         subplan = copy(grp_expr11.opr)
         subplan.children = [copy(grp_expr01.opr)]
         expected_plan = copy(grp_expr20.opr)
         expected_plan.children = [subplan]
 
         self.assertEqual(plan, expected_plan)
         self.assertEqual(grp.get_best_expr_cost(PropertyType.DEFAULT), 9)
```

### Comparing `evadb-0.2.6/test/optimizer/test_group.py` & `evadb-0.2.7/test/optimizer/test_group.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,17 +12,17 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 from mock import MagicMock
 
-from eva.optimizer.group import Group
-from eva.optimizer.group_expression import GroupExpression
-from eva.optimizer.property import Property, PropertyType
+from evadb.optimizer.group import Group
+from evadb.optimizer.group_expression import GroupExpression
+from evadb.optimizer.property import Property, PropertyType
 
 
 class TestGroup(unittest.TestCase):
     def test_simple_add_group_expr(self):
         grp = Group(0)
 
         grp_expr1 = GroupExpression(MagicMock())
```

### Comparing `evadb-0.2.6/test/optimizer/test_memo.py` & `evadb-0.2.7/test/optimizer/test_memo.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,16 +12,16 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 from mock import MagicMock
 
-from eva.constants import UNDEFINED_GROUP_ID
-from eva.optimizer.memo import Memo
+from evadb.constants import UNDEFINED_GROUP_ID
+from evadb.optimizer.memo import Memo
 
 
 class MemoTest(unittest.TestCase):
     def test_memo_add_with_no_id(self):
         group_expr = MagicMock()
         group_expr.group_id = UNDEFINED_GROUP_ID
         memo = Memo()
```

### Comparing `evadb-0.2.6/test/optimizer/test_optimizer_context.py` & `evadb-0.2.7/test/optimizer/test_optimizer_context.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,19 +12,19 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 from mock import MagicMock
 
-from eva.optimizer.cost_model import CostModel
-from eva.optimizer.optimizer_context import OptimizerContext
+from evadb.optimizer.cost_model import CostModel
+from evadb.optimizer.optimizer_context import OptimizerContext
 
 
 class TestOptimizerContext(unittest.TestCase):
     def test_add_root(self):
         fake_opr = MagicMock()
         fake_opr.children = []
 
-        opt_ctxt = OptimizerContext(CostModel())
+        opt_ctxt = OptimizerContext(MagicMock(), CostModel())
         opt_ctxt.add_opr_to_group(fake_opr)
         self.assertEqual(len(opt_ctxt.memo.group_exprs), 1)
```

### Comparing `evadb-0.2.6/test/optimizer/test_optimizer_task.py` & `evadb-0.2.7/test/optimizer/test_optimizer_task.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,33 +13,33 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from unittest.mock import patch
 
 from mock import MagicMock
 
-from eva.optimizer.cost_model import CostModel
-from eva.optimizer.operators import (
+from evadb.optimizer.cost_model import CostModel
+from evadb.optimizer.operators import (
     LogicalFilter,
     LogicalGet,
     LogicalProject,
     LogicalQueryDerivedGet,
 )
-from eva.optimizer.optimizer_context import OptimizerContext
-from eva.optimizer.optimizer_tasks import (
+from evadb.optimizer.optimizer_context import OptimizerContext
+from evadb.optimizer.optimizer_tasks import (
     BottomUpRewrite,
     OptimizeGroup,
     OptimizerTask,
     TopDownRewrite,
 )
-from eva.optimizer.property import PropertyType
-from eva.optimizer.rules.rules_manager import RulesManager
-from eva.plan_nodes.predicate_plan import PredicatePlan
-from eva.plan_nodes.project_plan import ProjectPlan
-from eva.plan_nodes.seq_scan_plan import SeqScanPlan
+from evadb.optimizer.property import PropertyType
+from evadb.optimizer.rules.rules_manager import RulesManager
+from evadb.plan_nodes.predicate_plan import PredicatePlan
+from evadb.plan_nodes.project_plan import ProjectPlan
+from evadb.plan_nodes.seq_scan_plan import SeqScanPlan
 
 
 class TestOptimizerTask(unittest.TestCase):
     def execute_task_stack(self, task_stack):
         while not task_stack.empty():
             task = task_stack.pop()
             task.execute()
@@ -47,27 +47,31 @@
     def test_abstract_optimizer_task(self):
         task = OptimizerTask(MagicMock(), MagicMock())
 
         with self.assertRaises(NotImplementedError):
             task.execute()
 
     def top_down_rewrite(self, opr):
-        opt_cxt = OptimizerContext(CostModel())
+        opt_cxt = OptimizerContext(MagicMock(), CostModel(), RulesManager(MagicMock()))
         grp_expr = opt_cxt.add_opr_to_group(opr)
         root_grp_id = grp_expr.group_id
         opt_cxt.task_stack.push(
-            TopDownRewrite(grp_expr, RulesManager().stage_one_rewrite_rules, opt_cxt)
+            TopDownRewrite(
+                grp_expr, RulesManager(MagicMock()).stage_one_rewrite_rules, opt_cxt
+            )
         )
         self.execute_task_stack(opt_cxt.task_stack)
         return opt_cxt, root_grp_id
 
     def bottom_up_rewrite(self, root_grp_id, opt_cxt):
         grp_expr = opt_cxt.memo.groups[root_grp_id].logical_exprs[0]
         opt_cxt.task_stack.push(
-            BottomUpRewrite(grp_expr, RulesManager().stage_two_rewrite_rules, opt_cxt)
+            BottomUpRewrite(
+                grp_expr, RulesManager(MagicMock()).stage_two_rewrite_rules, opt_cxt
+            )
         )
         self.execute_task_stack(opt_cxt.task_stack)
         return opt_cxt, root_grp_id
 
     def implement_group(self, root_grp_id, opt_cxt):
         grp = opt_cxt.memo.groups[root_grp_id]
         opt_cxt.task_stack.push(OptimizeGroup(grp, opt_cxt))
@@ -87,16 +91,16 @@
         best_root_grp_expr = root_grp.get_best_expr(PropertyType.DEFAULT)
 
         self.assertEqual(type(best_root_grp_expr.opr), PredicatePlan)
 
     def test_nested_implementation(self):
         child_predicate = MagicMock()
         root_predicate = MagicMock()
-        with patch("eva.optimizer.rules.rules.extract_pushdown_predicate") as mock:
-            with patch("eva.optimizer.rules.rules.is_video_table") as mock_vid:
+        with patch("evadb.optimizer.rules.rules.extract_pushdown_predicate") as mock:
+            with patch("evadb.optimizer.rules.rules.is_video_table") as mock_vid:
                 mock_vid.return_value = True
                 mock.side_effect = [
                     (child_predicate, None),
                     (root_predicate, None),
                 ]
 
                 child_get_opr = LogicalGet(MagicMock(), MagicMock(), MagicMock())
```

### Comparing `evadb-0.2.6/test/optimizer/test_optimizer_utils.py` & `evadb-0.2.7/test/optimizer/test_optimizer_utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
-from eva.catalog.catalog_type import ColumnType, NdArrayType
-from eva.optimizer.optimizer_utils import column_definition_to_udf_io
-from eva.parser.create_statement import ColumnDefinition
+from evadb.catalog.catalog_type import ColumnType, NdArrayType
+from evadb.optimizer.optimizer_utils import column_definition_to_udf_io
+from evadb.parser.create_statement import ColumnDefinition
 
 
 class OptimizerUtilsTest(unittest.TestCase):
     def test_column_definition_to_udf_io(self):
         col = ColumnDefinition(
             "data", ColumnType.NDARRAY, NdArrayType.UINT8, (None, None, None)
         )
```

### Comparing `evadb-0.2.6/test/optimizer/test_statement_to_opr_converter.py` & `evadb-0.2.7/test/optimizer/test_statement_to_opr_converter.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,24 +14,23 @@
 # limitations under the License.
 import unittest
 from inspect import signature
 from test.util import get_all_subclasses
 
 from mock import MagicMock, patch
 
-from eva.optimizer.operators import (
+from evadb.optimizer.operators import (
     Dummy,
     LogicalApplyAndMerge,
     LogicalCreate,
     LogicalCreateIndex,
     LogicalCreateMaterializedView,
     LogicalCreateUDF,
     LogicalDelete,
-    LogicalDrop,
-    LogicalDropUDF,
+    LogicalDropObject,
     LogicalExchange,
     LogicalExplain,
     LogicalExtractObject,
     LogicalFilter,
     LogicalFunctionScan,
     LogicalGet,
     LogicalGroupBy,
@@ -45,49 +44,48 @@
     LogicalRename,
     LogicalSample,
     LogicalShow,
     LogicalUnion,
     LogicalVectorIndexScan,
     Operator,
 )
-from eva.optimizer.statement_to_opr_converter import StatementToPlanConverter
-from eva.parser.create_index_statement import CreateIndexStatement
-from eva.parser.create_statement import CreateTableStatement
-from eva.parser.create_udf_statement import CreateUDFStatement
-from eva.parser.drop_statement import DropTableStatement
-from eva.parser.drop_udf_statement import DropUDFStatement
-from eva.parser.explain_statement import ExplainStatement
-from eva.parser.insert_statement import InsertTableStatement
-from eva.parser.rename_statement import RenameTableStatement
-from eva.parser.select_statement import SelectStatement
-from eva.parser.table_ref import TableRef
+from evadb.optimizer.statement_to_opr_converter import StatementToPlanConverter
+from evadb.parser.create_index_statement import CreateIndexStatement
+from evadb.parser.create_statement import CreateTableStatement
+from evadb.parser.create_udf_statement import CreateUDFStatement
+from evadb.parser.drop_object_statement import DropObjectStatement
+from evadb.parser.explain_statement import ExplainStatement
+from evadb.parser.insert_statement import InsertTableStatement
+from evadb.parser.rename_statement import RenameTableStatement
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.table_ref import TableRef
 
 
 class StatementToOprTest(unittest.TestCase):
-    @patch("eva.optimizer.statement_to_opr_converter.LogicalGet")
+    @patch("evadb.optimizer.statement_to_opr_converter.LogicalGet")
     def test_visit_table_ref_should_create_logical_get_opr(self, mock_lget):
         converter = StatementToPlanConverter()
         table_ref = MagicMock(spec=TableRef, alias="alias")
         table_ref.is_select.return_value = False
         table_ref.sample_freq = None
         converter.visit_table_ref(table_ref)
         mock_lget.assert_called_with(table_ref, table_ref.table.table_obj, "alias")
         self.assertEqual(mock_lget.return_value, converter._plan)
 
-    @patch("eva.optimizer.statement_to_opr_converter.LogicalFilter")
+    @patch("evadb.optimizer.statement_to_opr_converter.LogicalFilter")
     def test_visit_select_predicate_should_add_logical_filter(self, mock_lfilter):
         converter = StatementToPlanConverter()
         select_predicate = MagicMock()
         converter._visit_select_predicate(select_predicate)
 
         mock_lfilter.assert_called_with(select_predicate)
         mock_lfilter.return_value.append_child.assert_called()
         self.assertEqual(mock_lfilter.return_value, converter._plan)
 
-    @patch("eva.optimizer.statement_to_opr_converter.LogicalProject")
+    @patch("evadb.optimizer.statement_to_opr_converter.LogicalProject")
     def test_visit_projection_should_add_logical_predicate(self, mock_lproject):
         converter = StatementToPlanConverter()
         projects = MagicMock()
 
         converter._visit_projection(projects)
         mock_lproject.assert_called_with(projects)
         mock_lproject.return_value.append_child.assert_called()
@@ -119,21 +117,21 @@
 
         converter.visit_select(statement)
 
         converter.visit_table_ref.assert_not_called()
         converter._visit_projection.assert_not_called()
         converter._visit_select_predicate.assert_not_called()
 
-    @patch("eva.optimizer.statement_to_opr_converter.LogicalCreateUDF")
+    @patch("evadb.optimizer.statement_to_opr_converter.LogicalCreateUDF")
     @patch(
-        "eva.optimizer.\
+        "evadb.optimizer.\
 statement_to_opr_converter.column_definition_to_udf_io"
     )
     @patch(
-        "eva.optimizer.\
+        "evadb.optimizer.\
 statement_to_opr_converter.metadata_definition_to_udf_metadata"
     )
     def test_visit_create_udf(self, metadata_def_mock, col_def_mock, l_create_udf_mock):
         converter = StatementToPlanConverter()
         stmt = MagicMock()
         stmt.name = "name"
         stmt.if_not_exists = True
@@ -165,37 +163,24 @@
         mock = MagicMock()
         converter.visit_create_udf = mock
 
         converter.visit(stmt)
         mock.assert_called_once()
         mock.assert_called_with(stmt)
 
-    @patch("eva.optimizer.statement_to_opr_converter.LogicalDropUDF")
-    @patch(
-        "eva.optimizer.\
-statement_to_opr_converter.column_definition_to_udf_io"
-    )
-    def test_visit_drop_udf(self, mock, l_drop_udf_mock):
+    @patch("evadb.optimizer.statement_to_opr_converter.LogicalDropObject")
+    def test_visit_drop_object(self, l_drop_obj_mock):
         converter = StatementToPlanConverter()
         stmt = MagicMock()
         stmt.name = "name"
+        stmt.object_type = "object_type"
         stmt.if_exists = True
-        converter.visit_drop_udf(stmt)
-        l_drop_udf_mock.assert_called_once()
-        l_drop_udf_mock.assert_called_with(stmt.name, stmt.if_exists)
-
-    def test_visit_should_call_drop_udf(self):
-        stmt = MagicMock(spec=DropUDFStatement)
-        converter = StatementToPlanConverter()
-        mock = MagicMock()
-        converter.visit_drop_udf = mock
-
-        converter.visit(stmt)
-        mock.assert_called_once()
-        mock.assert_called_with(stmt)
+        converter.visit_drop_object(stmt)
+        l_drop_obj_mock.assert_called_once()
+        l_drop_obj_mock.assert_called_with(stmt.object_type, stmt.name, stmt.if_exists)
 
     def test_visit_should_call_insert(self):
         stmt = MagicMock(spec=InsertTableStatement)
         converter = StatementToPlanConverter()
         mock = MagicMock()
         converter.visit_insert = mock
 
@@ -230,18 +215,18 @@
         converter.visit_explain = mock
 
         converter.visit(stmt)
         mock.assert_called_once()
         mock.assert_called_once_with(stmt)
 
     def test_visit_should_call_drop(self):
-        stmt = MagicMock(spec=DropTableStatement)
+        stmt = MagicMock(spec=DropObjectStatement)
         converter = StatementToPlanConverter()
         mock = MagicMock()
-        converter.visit_drop = mock
+        converter.visit_drop_object = mock
         converter.visit(stmt)
         mock.assert_called_once()
         mock.assert_called_with(stmt)
 
     def test_visit_should_call_create_index(self):
         stmt = MagicMock(spec=CreateIndexStatement)
         converter = StatementToPlanConverter()
@@ -277,16 +262,15 @@
         load_plan = LogicalLoadData(MagicMock(), MagicMock(), MagicMock(), MagicMock())
         limit_plan = LogicalLimit(MagicMock())
         rename_plan = LogicalRename(MagicMock(), MagicMock())
 
         explain_plan = LogicalExplain([MagicMock()])
         exchange_plan = LogicalExchange(MagicMock())
         show_plan = LogicalShow(MagicMock())
-        drop_plan = LogicalDrop(MagicMock(), MagicMock())
-        drop_udf_plan = LogicalDropUDF(MagicMock(), MagicMock())
+        drop_plan = LogicalDropObject(MagicMock(), MagicMock(), MagicMock())
         get_plan = LogicalGet(MagicMock(), MagicMock(), MagicMock())
         sample_plan = LogicalSample(MagicMock(), MagicMock())
         filter_plan = LogicalFilter(MagicMock())
         faiss_plan = LogicalVectorIndexScan(
             MagicMock(), MagicMock(), MagicMock(), MagicMock()
         )
         groupby_plan = LogicalGroupBy(MagicMock())
@@ -309,15 +293,14 @@
         plans.append(delete_plan)
         plans.append(insert_plan)
         plans.append(query_derived_plan)
         plans.append(load_plan)
         plans.append(limit_plan)
         plans.append(rename_plan)
         plans.append(drop_plan)
-        plans.append(drop_udf_plan)
         plans.append(get_plan)
         plans.append(sample_plan)
         plans.append(filter_plan)
         plans.append(groupby_plan)
         plans.append(order_by_plan)
         plans.append(union_plan)
         plans.append(function_scan_plan)
```

### Comparing `evadb-0.2.6/test/parser/__init__.py` & `evadb-0.2.7/test/plan_nodes/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/parser/test_parser.py` & `evadb-0.2.7/test/parser/test_parser.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,40 +11,44 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from pathlib import Path
 
-from eva.catalog.catalog_type import ColumnType, NdArrayType, VectorStoreType
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.function_expression import FunctionExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.parser.alias import Alias
-from eva.parser.create_index_statement import CreateIndexStatement
-from eva.parser.create_mat_view_statement import CreateMaterializedViewStatement
-from eva.parser.create_statement import (
+from evadb.catalog.catalog_type import ColumnType, NdArrayType, VectorStoreType
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.function_expression import FunctionExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.parser.alias import Alias
+from evadb.parser.create_index_statement import CreateIndexStatement
+from evadb.parser.create_mat_view_statement import CreateMaterializedViewStatement
+from evadb.parser.create_statement import (
     ColConstraintInfo,
     ColumnDefinition,
     CreateTableStatement,
 )
-from eva.parser.create_udf_statement import CreateUDFStatement
-from eva.parser.delete_statement import DeleteTableStatement
-from eva.parser.drop_statement import DropTableStatement
-from eva.parser.drop_udf_statement import DropUDFStatement
-from eva.parser.insert_statement import InsertTableStatement
-from eva.parser.load_statement import LoadDataStatement
-from eva.parser.parser import Parser
-from eva.parser.rename_statement import RenameTableStatement
-from eva.parser.select_statement import SelectStatement
-from eva.parser.statement import AbstractStatement, StatementType
-from eva.parser.table_ref import JoinNode, TableInfo, TableRef, TableValuedExpression
-from eva.parser.types import FileFormatType, JoinType, ParserOrderBySortType
+from evadb.parser.create_udf_statement import CreateUDFStatement
+from evadb.parser.delete_statement import DeleteTableStatement
+from evadb.parser.drop_object_statement import DropObjectStatement
+from evadb.parser.insert_statement import InsertTableStatement
+from evadb.parser.load_statement import LoadDataStatement
+from evadb.parser.parser import Parser
+from evadb.parser.rename_statement import RenameTableStatement
+from evadb.parser.select_statement import SelectStatement
+from evadb.parser.statement import AbstractStatement, StatementType
+from evadb.parser.table_ref import JoinNode, TableInfo, TableRef, TableValuedExpression
+from evadb.parser.types import (
+    FileFormatType,
+    JoinType,
+    ObjectType,
+    ParserOrderBySortType,
+)
 
 
 class ParserTests(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
     def test_create_index_statement(self):
@@ -245,39 +249,27 @@
 
         rename_stmt = eva_statement_list[0]
         self.assertEqual(rename_stmt, expected_stmt)
 
     def test_drop_table_statement(self):
         parser = Parser()
         drop_queries = "DROP TABLE student_info"
-        expected_stmt = DropTableStatement([TableInfo("student_info")], False)
+        expected_stmt = DropObjectStatement(ObjectType.TABLE, "student_info", False)
         eva_statement_list = parser.parse(drop_queries)
         self.assertIsInstance(eva_statement_list, list)
         self.assertEqual(len(eva_statement_list), 1)
-        self.assertEqual(eva_statement_list[0].stmt_type, StatementType.DROP)
+        self.assertEqual(eva_statement_list[0].stmt_type, StatementType.DROP_OBJECT)
         drop_stmt = eva_statement_list[0]
         self.assertEqual(drop_stmt, expected_stmt)
 
-    def test_drop_udf_statement(self):
-        parser = Parser()
-        drop_udf_query = """DROP UDF FastRCNN;"""
-
-        expected_stmt = DropUDFStatement("FastRCNN", False)
-        eva_statement_list = parser.parse(drop_udf_query)
-        self.assertIsInstance(eva_statement_list, list)
-        self.assertEqual(len(eva_statement_list), 1)
-        self.assertEqual(eva_statement_list[0].stmt_type, StatementType.DROP_UDF)
-        drop_udf_stmt = eva_statement_list[0]
-        self.assertEqual(drop_udf_stmt, expected_stmt)
-
     def test_drop_udf_statement_str(self):
         drop_udf_query1 = """DROP UDF MyUDF;"""
         drop_udf_query2 = """DROP UDF IF EXISTS MyUDF;"""
-        expected_stmt1 = DropUDFStatement("MyUDF", False)
-        expected_stmt2 = DropUDFStatement("MyUDF", True)
+        expected_stmt1 = DropObjectStatement(ObjectType.UDF, "MyUDF", False)
+        expected_stmt2 = DropObjectStatement(ObjectType.UDF, "MyUDF", True)
         self.assertEqual(str(expected_stmt1), drop_udf_query1)
         self.assertEqual(str(expected_stmt2), drop_udf_query2)
 
     def test_single_statement_queries(self):
         parser = Parser()
 
         single_queries = []
@@ -391,15 +383,15 @@
         self.assertEqual(str(select_stmt_new), str(select_stmt))
 
     def test_select_statement_groupby_class(self):
         """Testing sample frequency"""
 
         parser = Parser()
 
-        select_query = "SELECT FIRST(id) FROM TAIPAI GROUP BY '8f';"
+        select_query = "SELECT FIRST(id) FROM TAIPAI GROUP BY '8 frames';"
 
         eva_statement_list = parser.parse(select_query)
         self.assertIsInstance(eva_statement_list, list)
         self.assertEqual(len(eva_statement_list), 1)
         self.assertEqual(eva_statement_list[0].stmt_type, StatementType.SELECT)
 
         select_stmt = eva_statement_list[0]
@@ -415,15 +407,15 @@
         self.assertIsNotNone(select_stmt.from_table)
         self.assertIsInstance(select_stmt.from_table, TableRef)
         self.assertEqual(select_stmt.from_table.table.table_name, "TAIPAI")
 
         # sample_freq
         self.assertEqual(
             select_stmt.groupby_clause,
-            ConstantValueExpression("8f", v_type=ColumnType.TEXT),
+            ConstantValueExpression("8 frames", v_type=ColumnType.TEXT),
         )
 
     def test_select_statement_orderby_class(self):
         """Testing order by clause in select statement
         Class: SelectStatement"""
 
         parser = Parser()
@@ -890,11 +882,11 @@
 
     def test_lark(self):
         query = """CREATE UDF FaceDetector
                   INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
                   OUTPUT (bboxes NDARRAY FLOAT32(ANYDIM, 4),
                           scores NDARRAY FLOAT32(ANYDIM))
                   TYPE  FaceDetection
-                  IMPL  'eva/udfs/face_detector.py';
+                  IMPL  'evadb/udfs/face_detector.py';
                   """
         parser = Parser()
         parser.parse(query)
```

### Comparing `evadb-0.2.6/test/parser/test_parser_statements.py` & `evadb-0.2.7/test/parser/test_parser_statements.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from pprint import pprint
 
-from eva.parser.parser import Parser
+from evadb.parser.parser import Parser
 
 
 class ParserStatementTests(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
     def test_parser_statement_types(self):
@@ -40,15 +40,15 @@
             "SELECT MIN(id), MAX(id), SUM(id) FROM ABC",
             "SELECT CLASS FROM TAIPAI \
                 WHERE (CLASS = 'VAN' AND REDNESS < 300)  OR REDNESS > 500;",
             "SELECT CLASS, REDNESS FROM TAIPAI \
             UNION ALL SELECT CLASS, REDNESS FROM SHANGHAI;",
             "SELECT CLASS, REDNESS FROM TAIPAI \
             UNION SELECT CLASS, REDNESS FROM SHANGHAI;",
-            "SELECT FIRST(id) FROM TAIPAI GROUP BY '8f';",
+            "SELECT FIRST(id) FROM TAIPAI GROUP BY '8 frames';",
             "SELECT CLASS, REDNESS FROM TAIPAI \
                     WHERE (CLASS = 'VAN' AND REDNESS < 400 ) OR REDNESS > 700 \
                     ORDER BY CLASS, REDNESS DESC;",
             "INSERT INTO MyVideo (Frame_ID, Frame_Path)\
                                     VALUES    (1, '/mnt/frames/1.png');",
             """INSERT INTO testDeleteOne (id, feat, salary, input)
                 VALUES (15, 2.5, [[100, 100, 100]], [[100, 100, 100]]);""",
@@ -73,15 +73,15 @@
             """SELECT frame FROM MyVideo JOIN LATERAL
                             ObjectDet(frame) AS OD;""",
             """CREATE UDF FaceDetector
                   INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
                   OUTPUT (bboxes NDARRAY FLOAT32(ANYDIM, 4),
                           scores NDARRAY FLOAT32(ANYDIM))
                   TYPE  FaceDetection
-                  IMPL  'eva/udfs/face_detector.py';
+                  IMPL  'evadb/udfs/face_detector.py';
             """,
             "SHOW TABLES;",
             "SHOW UDFS;",
             "EXPLAIN SELECT a FROM foo;",
             """SELECT data FROM MyVideo WHERE id < 5
                     ORDER BY Similarity(FeatureExtractor(Open("abc.jpg")),
                                         FeatureExtractor(data))
@@ -133,15 +133,15 @@
             """Select Frame from MyVideo Join Lateral
                 ObjectDet(Frame) as OD;""",
             """Create UDF FaceDetector
                 Input (Frame ndArray uint8(3, anydim, anydim))
                 Output (bboxes ndArray float32(anydim, 4),
                 scores ndArray float32(ANYdim))
                 Type FaceDetection
-                Impl 'eva/udfs/face_detector.py';
+                Impl 'evadb/udfs/face_detector.py';
             """,
         ]
         queries = queries + randomized_cases
         ref_stmt = parser.parse(queries[0])[0]
         self.assertNotEqual(ref_stmt, None)
         self.assertNotEqual(ref_stmt.__str__(), None)
```

### Comparing `evadb-0.2.6/test/plan_nodes/__init__.py` & `evadb-0.2.7/test/readers/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/plan_nodes/test_plan.py` & `evadb-0.2.7/test/plan_nodes/test_plan.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,41 +14,38 @@
 # limitations under the License.
 import unittest
 from inspect import isabstract, signature
 from test.util import get_all_subclasses, get_mock_object
 
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import ColumnType
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.parser.table_ref import TableInfo, TableRef
-from eva.parser.types import FileFormatType
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.plan_nodes.create_mat_view_plan import CreateMaterializedViewPlan
-from eva.plan_nodes.create_plan import CreatePlan
-from eva.plan_nodes.create_udf_plan import CreateUDFPlan
-from eva.plan_nodes.drop_plan import DropPlan
-from eva.plan_nodes.drop_udf_plan import DropUDFPlan
-from eva.plan_nodes.insert_plan import InsertPlan
-from eva.plan_nodes.load_data_plan import LoadDataPlan
-from eva.plan_nodes.rename_plan import RenamePlan
-from eva.plan_nodes.types import PlanOprType
-from eva.plan_nodes.union_plan import UnionPlan
+from evadb.catalog.catalog_type import ColumnType
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.parser.table_ref import TableInfo, TableRef
+from evadb.parser.types import FileFormatType, ObjectType
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.plan_nodes.create_mat_view_plan import CreateMaterializedViewPlan
+from evadb.plan_nodes.create_plan import CreatePlan
+from evadb.plan_nodes.create_udf_plan import CreateUDFPlan
+from evadb.plan_nodes.drop_object_plan import DropObjectPlan
+from evadb.plan_nodes.insert_plan import InsertPlan
+from evadb.plan_nodes.load_data_plan import LoadDataPlan
+from evadb.plan_nodes.rename_plan import RenamePlan
+from evadb.plan_nodes.types import PlanOprType
+from evadb.plan_nodes.union_plan import UnionPlan
 
 
 @pytest.mark.notparallel
 class PlanNodeTests(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
     def test_create_plan(self):
         dummy_info = TableInfo("dummy")
 
-        CatalogManager().reset()
         columns = [
             ColumnCatalogEntry("id", ColumnType.INTEGER),
             ColumnCatalogEntry("name", ColumnType.TEXT, array_dimensions=[50]),
         ]
         dummy_plan_node = CreatePlan(dummy_info, columns, False)
         self.assertEqual(dummy_plan_node.opr_type, PlanOprType.CREATE)
         self.assertEqual(dummy_plan_node.if_not_exists, False)
@@ -57,29 +54,19 @@
         self.assertEqual(dummy_plan_node.column_list[1].name, "name")
 
     def test_rename_plan(self):
         dummy_info = TableInfo("old")
         dummy_old = TableRef(dummy_info)
         dummy_new = TableInfo("new")
 
-        CatalogManager().reset()
         dummy_plan_node = RenamePlan(dummy_old, dummy_new)
         self.assertEqual(dummy_plan_node.opr_type, PlanOprType.RENAME)
         self.assertEqual(dummy_plan_node.old_table.table.table_name, "old")
         self.assertEqual(dummy_plan_node.new_name.table_name, "new")
 
-    def test_drop_plan(self):
-        dummy_info = TableInfo("dummy")
-
-        CatalogManager().reset()
-        dummy_plan_node = DropPlan([dummy_info], False)
-
-        self.assertEqual(dummy_plan_node.opr_type, PlanOprType.DROP)
-        self.assertEqual(dummy_plan_node.table_infos[0].table_name, "dummy")
-
     def test_insert_plan(self):
         video_id = 0
         column_ids = [0, 1]
         expression = type("AbstractExpression", (), {"evaluate": lambda: 1})
         values = [expression, expression]
         dummy_plan_node = InsertPlan(video_id, column_ids, values)
         self.assertEqual(dummy_plan_node.opr_type, PlanOprType.INSERT)
@@ -96,20 +83,22 @@
         self.assertEqual(node.opr_type, PlanOprType.CREATE_UDF)
         self.assertEqual(node.if_not_exists, True)
         self.assertEqual(node.inputs, [udfIO, udfIO])
         self.assertEqual(node.outputs, [udfIO])
         self.assertEqual(node.impl_path, impl_path)
         self.assertEqual(node.udf_type, ty)
 
-    def test_drop_udf_plan(self):
+    def test_drop_object_plan(self):
+        object_type = ObjectType.TABLE
         udf_name = "udf"
         if_exists = True
-        node = DropUDFPlan(udf_name, if_exists)
-        self.assertEqual(node.opr_type, PlanOprType.DROP_UDF)
+        node = DropObjectPlan(object_type, udf_name, if_exists)
+        self.assertEqual(node.opr_type, PlanOprType.DROP_OBJECT)
         self.assertEqual(node.if_exists, True)
+        self.assertEqual(node.object_type, ObjectType.TABLE)
 
     def test_load_data_plan(self):
         table_info = "info"
         file_path = "test.mp4"
         file_format = FileFormatType.VIDEO
         file_options = {}
         file_options["file_format"] = file_format
```

### Comparing `evadb-0.2.6/test/readers/__init__.py` & `evadb-0.2.7/test/server/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/readers/test_csv_reader.py` & `evadb-0.2.7/test/readers/test_csv_reader.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,16 +11,16 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 from test.util import create_dummy_csv_batches, create_sample_csv, file_remove
 
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.readers.csv_reader import CSVReader
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.readers.csv_reader import CSVReader
 
 
 class CSVLoaderTest(unittest.TestCase):
     def setUp(self):
         self.csv_file_path = create_sample_csv()
 
     def tearDown(self):
```

### Comparing `evadb-0.2.6/test/readers/test_decord_reader.py` & `evadb-0.2.7/test/readers/test_decord_reader.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,22 +20,22 @@
     create_sample_video,
     file_remove,
 )
 
 import numpy as np
 import pytest
 
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.constants import AUDIORATE, IFRAMES
-from eva.expression.abstract_expression import ExpressionType
-from eva.expression.comparison_expression import ComparisonExpression
-from eva.expression.constant_value_expression import ConstantValueExpression
-from eva.expression.logical_expression import LogicalExpression
-from eva.expression.tuple_value_expression import TupleValueExpression
-from eva.readers.decord_reader import DecordReader
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.constants import AUDIORATE, IFRAMES
+from evadb.expression.abstract_expression import ExpressionType
+from evadb.expression.comparison_expression import ComparisonExpression
+from evadb.expression.constant_value_expression import ConstantValueExpression
+from evadb.expression.logical_expression import LogicalExpression
+from evadb.expression.tuple_value_expression import TupleValueExpression
+from evadb.readers.decord_reader import DecordReader
 
 
 @pytest.mark.notparallel
 class DecordLoaderTest(unittest.TestCase):
     @classmethod
     def setUpClass(self):
         self.video_file_url = create_sample_video()
```

### Comparing `evadb-0.2.6/test/server/__init__.py` & `evadb-0.2.7/test/storage/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/server/test_command_handler.py` & `evadb-0.2.7/test/server/test_command_handler.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 # limitations under the License.
 import asyncio
 import unittest
 from unittest.mock import MagicMock
 
 import mock
 
-from eva.server.command_handler import handle_request
+from evadb.server.command_handler import handle_request
 
 
 class CommandHandlerTests(unittest.TestCase):
     def setUp(self):
         self.loop = asyncio.new_event_loop()
         self.stop_server_future = self.loop.create_future()
         asyncio.set_event_loop(None)
@@ -31,8 +31,8 @@
         super().__init__(*args, **kwargs)
 
     def test_command_handler(self):
         transport = mock.Mock()
         transport.write = MagicMock(return_value="response_message")
         request_message = "SELECT id FROM foo;"
 
-        asyncio.run(handle_request(transport, request_message))
+        asyncio.run(handle_request(None, transport, request_message))
```

### Comparing `evadb-0.2.6/test/server/test_db_api.py` & `evadb-0.2.7/test/server/test_db_api.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,70 +12,70 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import asyncio
 import os
 import sys
 import unittest
-from test.util import prefix_worker_id
+from test.util import suffix_pytest_xdist_worker_id_to_dir
 
 from mock import MagicMock, patch
 
-from eva.models.server.response import Response
-from eva.interfaces.relational.db import EVACursor, connect
+from evadb.interfaces.relational.db import EVADBCursor, connect_remote
+from evadb.models.server.response import Response
 
 # Check for Python 3.8+ for IsolatedAsyncioTestCase support
 if sys.version_info >= (3, 8):
     from unittest.mock import AsyncMock
 
     class DBAPITests(unittest.IsolatedAsyncioTestCase):
         def __init__(self, *args, **kwargs):
             super().__init__(*args, **kwargs)
 
         def setUp(self) -> None:
             print("setUp")
-            f = open(prefix_worker_id("upload.txt"), "w")
+            f = open(suffix_pytest_xdist_worker_id_to_dir("upload.txt"), "w")
             f.write("dummy data")
             f.close()
             return super().setUp()
 
         def tearDown(self) -> None:
             print("tearDown")
-            os.remove(prefix_worker_id("upload.txt"))
+            os.remove(suffix_pytest_xdist_worker_id_to_dir("upload.txt"))
             return super().tearDown()
 
         def test_eva_cursor_execute_async(self):
             connection = AsyncMock()
-            eva_cursor = EVACursor(connection)
+            eva_cursor = EVADBCursor(connection)
             query = "test_query"
             asyncio.run(eva_cursor.execute_async(query))
             self.assertEqual(eva_cursor._pending_query, True)
 
             # concurrent queries not allowed
             with self.assertRaises(SystemError):
                 asyncio.run(eva_cursor.execute_async(query))
 
         def test_eva_cursor_fetch_all_async(self):
             connection = AsyncMock()
-            eva_cursor = EVACursor(connection)
+            eva_cursor = EVADBCursor(connection)
             message = "test_response"
             serialized_message = Response.serialize("test_response")
             serialized_message_length = b"%d" % len(serialized_message)
             connection._reader.readline.side_effect = [serialized_message_length]
             connection._reader.readexactly.side_effect = [serialized_message]
             response = asyncio.run(eva_cursor.fetch_all_async())
             self.assertEqual(eva_cursor._pending_query, False)
             self.assertEqual(message, response)
 
         def test_eva_cursor_fetch_one_sync(self):
             loop = asyncio.new_event_loop()
             asyncio.set_event_loop(loop)
 
             connection = AsyncMock()
-            eva_cursor = EVACursor(connection)
+            eva_cursor = EVADBCursor(connection)
 
             message = "test_response"
             serialized_message = Response.serialize("test_response")
             serialized_message_length = b"%d" % len(serialized_message)
             connection._reader.readline.side_effect = [serialized_message_length]
             connection._reader.readexactly.side_effect = [serialized_message]
 
@@ -86,54 +86,54 @@
         def test_eva_connection(self):
             hostname = "localhost"
 
             loop = asyncio.new_event_loop()
             asyncio.set_event_loop(loop)
 
             connection = AsyncMock()
-            eva_cursor = EVACursor(connection)
+            eva_cursor = EVADBCursor(connection)
 
             # test attr
             with self.assertRaises(AttributeError):
                 eva_cursor.__getattr__("foo")
 
             # test connection error with incorrect port
             with self.assertRaises(OSError):
-                connect(hostname, port=1)
+                connect_remote(hostname, port=1)
 
         async def test_eva_signal(self):
             loop = asyncio.new_event_loop()
             asyncio.set_event_loop(loop)
 
             connection = AsyncMock()
-            eva_cursor = EVACursor(connection)
+            eva_cursor = EVADBCursor(connection)
 
             query = "test_query"
             await eva_cursor.execute_async(query)
 
         def test_client_stop_query(self):
             connection = AsyncMock()
             loop = asyncio.new_event_loop()
             asyncio.set_event_loop(loop)
             connection.protocol.loop = loop
 
-            eva_cursor = EVACursor(connection)
+            eva_cursor = EVADBCursor(connection)
             eva_cursor.execute("test_query")
             eva_cursor.stop_query()
             self.assertEqual(eva_cursor._pending_query, False)
 
         def test_get_attr(self):
             connection = AsyncMock()
 
-            eva_cursor = EVACursor(connection)
+            eva_cursor = EVADBCursor(connection)
             with self.assertRaises(AttributeError):
                 eva_cursor.missing_function()
 
         @patch("asyncio.open_connection")
         def test_get_connection(self, mock_open):
             server_reader = asyncio.StreamReader()
             server_writer = MagicMock()
             mock_open.return_value = (server_reader, server_writer)
 
-            connection = connect("localhost", port=1)
+            connection = connect_remote("localhost", port=1)
 
             self.assertNotEqual(connection, None)
```

### Comparing `evadb-0.2.6/test/server/test_interpreter.py` & `evadb-0.2.7/test/server/test_interpreter.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,27 +15,27 @@
 import asyncio
 import sys
 import unittest
 from test.util import find_free_port
 
 from mock import MagicMock, patch
 
-from eva.server.interpreter import create_stdin_reader, start_cmd_client
+from evadb.server.interpreter import create_stdin_reader, start_cmd_client
 
 # Check for Python 3.8+ for IsolatedAsyncioTestCase support
 if sys.version_info >= (3, 8):
 
     class InterpreterTests(unittest.IsolatedAsyncioTestCase):
         def __init__(self, *args, **kwargs):
             super().__init__(*args, **kwargs)
 
         @patch("asyncio.open_connection")
-        @patch("eva.server.interpreter.create_stdin_reader")
-        @patch("eva.interfaces.relational.db.EVACursor.execute_async")
-        @patch("eva.interfaces.relational.db.EVACursor.fetch_all_async")
+        @patch("evadb.server.interpreter.create_stdin_reader")
+        @patch("evadb.interfaces.relational.db.EVADBCursor.execute_async")
+        @patch("evadb.interfaces.relational.db.EVADBCursor.fetch_all_async")
         async def test_start_cmd_client(
             self, mock_fetch, mock_execute, mock_stdin_reader, mock_open
         ):
             host = "localhost"
             port = find_free_port()
 
             server_reader = asyncio.StreamReader()
```

### Comparing `evadb-0.2.6/test/server/test_server.py` & `evadb-0.2.7/test/server/test_server.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,30 +14,30 @@
 # limitations under the License.
 import asyncio
 import sys
 import unittest
 
 from mock import MagicMock, patch
 
-from eva.server.server import EvaServer
+from evadb.server.server import EvaServer
 
 # Check for Python 3.8+ for IsolatedAsyncioTestCase support
 if sys.version_info >= (3, 8):
 
     class ServerTests(unittest.IsolatedAsyncioTestCase):
         def __init__(self, *args, **kwargs):
             super().__init__(*args, **kwargs)
 
         @patch("asyncio.start_server")
         async def test_server_functions(self, mock_start):
             eva_server = EvaServer()
             host = "localhost"
             port = 8803
 
-            await eva_server.start_eva_server(host, port)
+            await eva_server.start_eva_server("eva_db", host, port)
 
             # connection made
             client_reader1 = asyncio.StreamReader()
             client_writer1 = MagicMock()
             client_reader2 = asyncio.StreamReader()
             client_writer2 = MagicMock()
```

### Comparing `evadb-0.2.6/test/storage/__init__.py` & `evadb-0.2.7/test/udfs/decorators/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/storage/test_sqlite_storage_engine.py` & `evadb-0.2.7/test/storage/test_sqlite_storage_engine.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,43 +1,47 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import shutil
 import unittest
-from test.util import create_dummy_batches, prefix_worker_id
+from test.util import (
+    create_dummy_batches,
+    get_evadb_for_testing,
+    suffix_pytest_xdist_worker_id_to_dir,
+)
 
 import pytest
 
-from eva.catalog.catalog_type import ColumnType, NdArrayType, TableType
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.storage.sqlite_storage_engine import SQLStorageEngine
+from evadb.catalog.catalog_type import ColumnType, NdArrayType, TableType
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.storage.sqlite_storage_engine import SQLStorageEngine
 
 
 @pytest.mark.notparallel
 class SQLStorageEngineTest(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.table = None
 
     def create_sample_table(self):
         table_info = TableCatalogEntry(
-            prefix_worker_id("dataset"),
-            prefix_worker_id("dataset"),
+            str(suffix_pytest_xdist_worker_id_to_dir("dataset")),
+            str(suffix_pytest_xdist_worker_id_to_dir("dataset")),
             table_type=TableType.VIDEO_DATA,
         )
         column_0 = ColumnCatalogEntry("name", ColumnType.TEXT, is_nullable=False)
         column_1 = ColumnCatalogEntry("id", ColumnType.INTEGER, is_nullable=False)
         column_2 = ColumnCatalogEntry(
             "data", ColumnType.NDARRAY, False, NdArrayType.UINT8, [2, 2, 3]
         )
@@ -45,52 +49,58 @@
         return table_info
 
     def setUp(self):
         self.table = self.create_sample_table()
 
     def tearDown(self):
         try:
-            shutil.rmtree(prefix_worker_id("dataset"), ignore_errors=True)
+            shutil.rmtree(
+                suffix_pytest_xdist_worker_id_to_dir("dataset"), ignore_errors=True
+            )
         except ValueError:
             pass
 
     def test_should_create_empty_table(self):
-        sqlengine = SQLStorageEngine()
+        evadb = get_evadb_for_testing()
+        sqlengine = SQLStorageEngine(evadb)
         sqlengine.create(self.table)
         records = list(sqlengine.read(self.table, batch_mem_size=3000))
-        self.assertEqual(records, [])
+        self.assertEqual(len(records), 0)
         # clean up
         sqlengine.drop(self.table)
 
     def test_should_write_rows_to_table(self):
         dummy_batches = list(create_dummy_batches())
         # drop the _row_id
         dummy_batches = [batch.project(batch.columns[1:]) for batch in dummy_batches]
-        sqlengine = SQLStorageEngine()
+        evadb = get_evadb_for_testing()
+        sqlengine = SQLStorageEngine(evadb)
         sqlengine.create(self.table)
         for batch in dummy_batches:
             batch.drop_column_alias()
             sqlengine.write(self.table, batch)
 
         read_batch = list(sqlengine.read(self.table, batch_mem_size=3000))
         self.assertTrue(read_batch, dummy_batches)
         # clean up
         sqlengine.drop(self.table)
 
     def test_rename(self):
         table_info = TableCatalogEntry(
             "new_name", "new_name", table_type=TableType.VIDEO_DATA
         )
-        sqlengine = SQLStorageEngine()
+        evadb = get_evadb_for_testing()
+        sqlengine = SQLStorageEngine(evadb)
 
         with pytest.raises(Exception):
             sqlengine.rename(self.table, table_info)
 
     def test_sqlite_storage_engine_exceptions(self):
-        sqlengine = SQLStorageEngine()
+        evadb = get_evadb_for_testing()
+        sqlengine = SQLStorageEngine(evadb)
 
         missing_table_info = TableCatalogEntry(
             "missing_table", None, table_type=TableType.VIDEO_DATA
         )
 
         with self.assertRaises(Exception):
             sqlengine.drop(missing_table_info)
@@ -102,15 +112,16 @@
             read_batch = list(sqlengine.read(missing_table_info))
             self.assertEqual(read_batch, None)
 
         with self.assertRaises(Exception):
             sqlengine.delete(missing_table_info, None)
 
     def test_cannot_delete_missing_column(self):
-        sqlengine = SQLStorageEngine()
+        evadb = get_evadb_for_testing()
+        sqlengine = SQLStorageEngine(evadb)
         sqlengine.create(self.table)
 
         incorrect_where_clause = {"foo": None}
 
         with self.assertRaises(Exception):
             sqlengine.delete(self.table, incorrect_where_clause)
         # clean up
```

### Comparing `evadb-0.2.6/test/storage/test_video_storage.py` & `evadb-0.2.7/test/storage/test_video_storage.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,59 +1,63 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
-from test.util import create_sample_video, prefix_worker_id
+from test.util import (
+    create_sample_video,
+    get_evadb_for_testing,
+    suffix_pytest_xdist_worker_id_to_dir,
+)
 from unittest.mock import MagicMock
 
 import mock
 import pandas as pd
 import pytest
 
-from eva.catalog.catalog_type import ColumnType, NdArrayType, TableType
-from eva.catalog.models.column_catalog import ColumnCatalogEntry
-from eva.catalog.models.table_catalog import TableCatalogEntry
-from eva.models.storage.batch import Batch
-from eva.storage.storage_engine import StorageEngine
+from evadb.catalog.catalog_type import ColumnType, NdArrayType, TableType
+from evadb.catalog.models.column_catalog import ColumnCatalogEntry
+from evadb.catalog.models.table_catalog import TableCatalogEntry
+from evadb.models.storage.batch import Batch
+from evadb.storage.storage_engine import StorageEngine
 
 
 @pytest.mark.notparallel
 class VideoStorageEngineTest(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.table = None
 
     def create_sample_table(self):
         table_info = TableCatalogEntry(
-            prefix_worker_id("dataset"),
-            prefix_worker_id("dataset"),
+            str(suffix_pytest_xdist_worker_id_to_dir("dataset")),
+            str(suffix_pytest_xdist_worker_id_to_dir("dataset")),
             table_type=TableType.VIDEO_DATA,
         )
         column_1 = ColumnCatalogEntry("id", ColumnType.INTEGER, False)
         column_2 = ColumnCatalogEntry(
             "data", ColumnType.NDARRAY, False, NdArrayType.UINT8, [2, 2, 3]
         )
         table_info.schema = [column_1, column_2]
         return table_info
 
     def setUp(self):
-        mock = MagicMock()
+        evadb = get_evadb_for_testing()
         mock.table_type = TableType.VIDEO_DATA
-        self.video_engine = StorageEngine.factory(mock)
+        self.video_engine = StorageEngine.factory(evadb, mock)
         self.table = self.create_sample_table()
 
     def tearDown(self):
         pass
 
     @mock.patch("pathlib.Path.mkdir")
     def test_should_raise_file_exist_error(self, m):
```

### Comparing `evadb-0.2.6/test/test_eva_cmd_client.py` & `evadb-0.2.7/test/test_eva_cmd_client.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,30 +14,30 @@
 # limitations under the License.
 import argparse
 import asyncio
 import unittest
 
 from mock import call, patch
 
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.eva_cmd_client import eva_client, main
+from evadb.configuration.configuration_manager import ConfigurationManager
+from evadb.eva_cmd_client import eva_client, main
 
 
 class CMDClientTest(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
     def get_mock_stdin_reader(self) -> asyncio.StreamReader:
         stdin_reader = asyncio.StreamReader()
         stdin_reader.feed_data(b"EXIT;\n")
         stdin_reader.feed_eof()
         return stdin_reader
 
-    @patch("eva.eva_cmd_client.start_cmd_client")
-    @patch("eva.server.interpreter.create_stdin_reader")
+    @patch("evadb.eva_cmd_client.start_cmd_client")
+    @patch("evadb.server.interpreter.create_stdin_reader")
     def test_eva_client(self, mock_stdin_reader, mock_client):
         mock_stdin_reader.return_value = self.get_mock_stdin_reader()
         mock_client.side_effect = Exception("Test")
 
         async def test():
             with self.assertRaises(Exception):
                 await eva_client("0.0.0.0", 8803)
@@ -50,30 +50,30 @@
         async def test2():
             # Pass exception
             await eva_client("0.0.0.0", 8803)
 
         asyncio.run(test2())
 
     @patch("argparse.ArgumentParser.parse_known_args")
-    @patch("eva.eva_cmd_client.start_cmd_client")
+    @patch("evadb.eva_cmd_client.start_cmd_client")
     def test_eva_client_with_cmd_arguments(
         self, mock_start_cmd_client, mock_parse_known_args
     ):
         # Set up the mock to simulate command-line arguments
         mock_parse_known_args.return_value = (
             argparse.Namespace(host="127.0.0.1", port="8800"),
             [],
         )
 
         # Call the function under test
         main()
         mock_start_cmd_client.assert_called_once_with("127.0.0.1", "8800")
 
     @patch("argparse.ArgumentParser.parse_known_args")
-    @patch("eva.eva_cmd_client.start_cmd_client")
+    @patch("evadb.eva_cmd_client.start_cmd_client")
     def test_main_without_cmd_arguments(
         self, mock_start_cmd_client, mock_parse_known_args
     ):
         # Set up the mock to simulate missing command-line arguments
         mock_parse_known_args.return_value = (
             argparse.Namespace(host=None, port=None),
             [],
```

### Comparing `evadb-0.2.6/test/test_eva_imports.py` & `evadb-0.2.7/test/test_eva_imports.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -28,11 +28,11 @@
         when current working directory is changed.
         """
         cur_dir = os.getcwd()
         new_dir = os.path.join("test_eva", "test")
         if not os.path.exists(new_dir):
             os.makedirs(new_dir)
         os.chdir(new_dir)
-        _ = importlib.import_module("eva.eva_cmd_client")
-        _ = importlib.import_module("eva.eva_server")
+        _ = importlib.import_module("evadb.eva_cmd_client")
+        _ = importlib.import_module("evadb.eva_server")
         os.chdir(cur_dir)
         shutil.rmtree(new_dir)
```

### Comparing `evadb-0.2.6/test/test_eva_server.py` & `evadb-0.2.7/test/test_eva_server.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,46 +1,37 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-import sys
 import unittest
 
-from mock import MagicMock, patch
+from mock import patch
 
-from eva.eva_server import main, start_eva_server
+from evadb.eva_server import main, start_eva_server
 
-# Check for Python 3.8+ for IsolatedAsyncioTestCase support
-if sys.version_info >= (3, 8):
 
-    class EVAServerTest(unittest.IsolatedAsyncioTestCase):
-        def __init__(self, *args, **kwargs):
-            super().__init__(*args, **kwargs)
-
-        @patch("eva.udfs.udf_bootstrap_queries.init_builtin_udfs")
-        @patch("eva.eva_server.start_eva_server")
-        @patch("eva.eva_server.ConfigurationManager")
-        @patch("asyncio.run")
-        def test_main(self, mock_run, mock_config, mock_start_eva_server, mock_udfs):
-            mock_obj_1 = MagicMock()
-            mock_config.return_value.get_value = mock_obj_1
-            main()
-            mock_obj_1.assert_called_with("core", "mode")
-            mock_udfs.assert_called_with(mode=mock_obj_1())
-            mock_start_eva_server.assert_called_once()
-            mock_run.assert_called_once()
-
-        @patch("eva.eva_server.start_eva_server")
-        @patch("asyncio.start_server")
-        async def test_start_eva_server(self, mock_start_eva_server, mock_start):
-            await start_eva_server("0.0.0.0", 8803)
-            mock_start_eva_server.assert_called_once()
+class EVAServerTest(unittest.IsolatedAsyncioTestCase):
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+    @patch("evadb.eva_server.start_eva_server")
+    @patch("asyncio.run")
+    def test_main(self, mock_run, mock_start_eva_server):
+        main()
+        mock_start_eva_server.assert_called_once()
+        mock_run.assert_called_once()
+
+    @patch("evadb.eva_server.start_eva_server")
+    @patch("asyncio.start_server")
+    async def test_start_eva_server(self, mock_start_eva_server, mock_start):
+        await start_eva_server("eva_data", "0.0.0.0", 8803)
+        mock_start_eva_server.assert_called_once()
```

### Comparing `evadb-0.2.6/test/udfs/__init__.py` & `evadb-0.2.7/test/udfs/decorators/io_descriptors/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -8,8 +8,7 @@
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-"""user defined functions operating on ndarrays"""
```

### Comparing `evadb-0.2.6/test/udfs/decorators/__init__.py` & `evadb-0.2.7/test/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/udfs/decorators/io_descriptors/__init__.py` & `evadb-0.2.7/evadb/udfs/decorators/io_descriptors/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `evadb-0.2.6/test/udfs/decorators/io_descriptors/test_descriptors.py` & `evadb-0.2.7/test/udfs/decorators/io_descriptors/test_descriptors.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
-from eva.catalog.catalog_type import ColumnType, Dimension, NdArrayType
-from eva.udfs.decorators.io_descriptors.data_types import (
+from evadb.catalog.catalog_type import ColumnType, Dimension, NdArrayType
+from evadb.udfs.decorators.io_descriptors.data_types import (
     NumpyArray,
     PandasDataframe,
     PyTorchTensor,
 )
-from eva.utils.errors import UDFIODefinitionError
+from evadb.utils.errors import UDFIODefinitionError
 
 
 class UDFIODescriptorsTests(unittest.TestCase):
     def test_catalog_entry_for_numpy_entry(self):
         numpy_array = NumpyArray(
             name="input", is_nullable=False, type=NdArrayType.UINT8, dimensions=(2, 2)
         )
```

### Comparing `evadb-0.2.6/test/udfs/decorators/test_decorators.py` & `evadb-0.2.7/test/udfs/decorators/test_decorators.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
-from eva.catalog.catalog_type import NdArrayType
-from eva.udfs.decorators.decorators import forward, setup
-from eva.udfs.decorators.io_descriptors.data_types import NumpyArray, PandasDataframe
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.udfs.decorators.decorators import forward, setup
+from evadb.udfs.decorators.io_descriptors.data_types import NumpyArray, PandasDataframe
 
 
 class DecoratorTests(unittest.TestCase):
     def test_setup_flags_are_updated(self):
         @setup(cacheable=True, udf_type="classification", batchable=True)
         def setup_func():
             pass
```

### Comparing `evadb-0.2.6/test/udfs/ndarray/__init__.py` & `evadb-0.2.7/test/udfs/ndarray/__init__.py`

 * *Files identical despite different names*

### Comparing `evadb-0.2.6/test/udfs/ndarray/test_annotate.py` & `evadb-0.2.7/test/udfs/ndarray/test_annotate.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,16 +15,16 @@
 import unittest
 
 import numpy as np
 import pandas as pd
 from numpy import asarray
 from PIL import Image
 
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.udfs.ndarray.annotate import Annotate
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.udfs.ndarray.annotate import Annotate
 
 
 class AnnotateTests(unittest.TestCase):
     def setUp(self):
         self.annotate_instance = Annotate()
 
     def test_annotate_name_exists(self):
```

### Comparing `evadb-0.2.6/test/udfs/ndarray/test_array_count.py` & `evadb-0.2.7/test/udfs/ndarray/test_array_count.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
-from eva.udfs.ndarray.array_count import ArrayCount
+from evadb.udfs.ndarray.array_count import ArrayCount
 
 
 class CropTests(unittest.TestCase):
     def setUp(self):
         self.array_count = ArrayCount()
 
     def test_array_count_name_exists(self):
```

### Comparing `evadb-0.2.6/test/udfs/ndarray/test_crop.py` & `evadb-0.2.7/test/udfs/ndarray/test_crop.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import unittest
 
 import numpy as np
 import pandas as pd
 
-from eva.udfs.ndarray.crop import Crop
+from evadb.udfs.ndarray.crop import Crop
 
 
 class CropTests(unittest.TestCase):
     def setUp(self):
         self.crop_instance = Crop()
 
     def test_crop_name_exists(self):
```

### Comparing `evadb-0.2.6/test/udfs/ndarray/test_flips.py` & `evadb-0.2.7/test/udfs/ndarray/test_flips.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,17 +15,17 @@
 import unittest
 
 import numpy as np
 import pandas as pd
 from numpy import asarray
 from PIL import Image
 
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.udfs.ndarray.horizontal_flip import HorizontalFlip
-from eva.udfs.ndarray.vertical_flip import VerticalFlip
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.udfs.ndarray.horizontal_flip import HorizontalFlip
+from evadb.udfs.ndarray.vertical_flip import VerticalFlip
 
 
 class FlipTests(unittest.TestCase):
     def setUp(self):
         self.horizontal_flip_instance = HorizontalFlip()
         self.vertical_flip_instance = VerticalFlip()
```

### Comparing `evadb-0.2.6/test/udfs/ndarray/test_gaussian_blur.py` & `evadb-0.2.7/test/udfs/ndarray/test_gaussian_blur.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,33 +16,32 @@
 from pathlib import Path
 from test.util import file_remove
 
 import cv2
 import numpy as np
 import pandas as pd
 
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.udfs.ndarray.gaussian_blur import GaussianBlur
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.udfs.ndarray.gaussian_blur import GaussianBlur
 
 
 class GaussianBlurTests(unittest.TestCase):
     def setUp(self):
         self.gb_instance = GaussianBlur()
-
-    def tearDown(self):
-        file_remove(Path(f"{EVA_ROOT_DIR}/test/udfs/data/tmp.jpeg"))
+        self.tmp_file = f"{EVA_ROOT_DIR}/test/udfs/data/tmp.jpeg"
 
     def test_gb_name_exists(self):
         assert hasattr(self.gb_instance, "name")
 
     def test_should_blur_image(self):
         arr = cv2.imread(f"{EVA_ROOT_DIR}/test/udfs/data/dog.jpeg")
         df = pd.DataFrame([[arr]])
         modified_arr = self.gb_instance(df)["blurred_frame_array"]
         cv2.imwrite(
-            f"{EVA_ROOT_DIR}/test/udfs/data/tmp.jpeg",
+            self.tmp_file,
             cv2.cvtColor(modified_arr[0], cv2.COLOR_RGB2BGR),
         )
 
-        actual_array = cv2.imread(f"{EVA_ROOT_DIR}/test/udfs/data/tmp.jpeg")
+        actual_array = cv2.imread(self.tmp_file)
         expected_array = cv2.imread(f"{EVA_ROOT_DIR}/test/udfs/data/blurred_dog.jpeg")
         self.assertEqual(np.sum(actual_array - expected_array), 0)
+        file_remove(Path(self.tmp_file))
```

### Comparing `evadb-0.2.6/test/udfs/ndarray/test_open.py` & `evadb-0.2.7/test/udfs/ndarray/test_open.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,23 +16,21 @@
 from test.util import create_sample_image
 
 import numpy as np
 import pandas as pd
 import pytest
 from mock import patch
 
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.udfs.ndarray.open import Open
+from evadb.udfs.ndarray.open import Open
 
 
 @pytest.mark.notparallel
 class OpenTests(unittest.TestCase):
     def setUp(self):
         self.open_instance = Open()
-        self.config = ConfigurationManager()
         self.image_file_path = create_sample_image()
 
     def test_open_name_exists(self):
         assert hasattr(self.open_instance, "name")
 
     def test_should_open_image(self):
         df = self.open_instance(pd.DataFrame([self.image_file_path]))
@@ -45,19 +43,19 @@
         self.assertEqual(actual_img.shape, expected_img.shape)
         self.assertEqual(np.sum(actual_img[0]), np.sum(expected_img[0]))
         self.assertEqual(np.sum(actual_img[1]), np.sum(expected_img[1]))
         self.assertEqual(np.sum(actual_img[2]), np.sum(expected_img[2]))
 
     def test_open_same_path_should_use_cache(self):
         # un-cached open
-        with patch("eva.udfs.ndarray.open.cv2") as mock_cv2:
+        with patch("evadb.udfs.ndarray.open.cv2") as mock_cv2:
             self.open_instance(pd.DataFrame([self.image_file_path]))
             mock_cv2.imread.assert_called_once_with(self.image_file_path)
 
         # cached open
-        with patch("eva.udfs.ndarray.open.cv2") as mock_cv2:
+        with patch("evadb.udfs.ndarray.open.cv2") as mock_cv2:
             self.open_instance(pd.DataFrame([self.image_file_path]))
             mock_cv2.imread.assert_not_called()
 
     def test_open_path_should_raise_error(self):
         with self.assertRaises((AssertionError, FileNotFoundError)):
             self.open_instance(pd.DataFrame(["incorrect_path"]))
```

### Comparing `evadb-0.2.6/test/udfs/ndarray/test_to_grayscale.py` & `evadb-0.2.7/test/udfs/ndarray/test_to_grayscale.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,29 +16,27 @@
 from pathlib import Path
 from test.util import file_remove
 
 import cv2
 import numpy as np
 import pandas as pd
 
-from eva.configuration.constants import EVA_ROOT_DIR
-from eva.udfs.ndarray.to_grayscale import ToGrayscale
+from evadb.configuration.constants import EVA_ROOT_DIR
+from evadb.udfs.ndarray.to_grayscale import ToGrayscale
 
 
 class ToGrayscaleTests(unittest.TestCase):
     def setUp(self):
         self.to_grayscale_instance = ToGrayscale()
 
-    def tearDown(self):
-        file_remove(Path(f"{EVA_ROOT_DIR}/test/udfs/data/tmp.jpeg"))
-
     def test_gray_scale_name_exists(self):
         assert hasattr(self.to_grayscale_instance, "name")
 
     def test_should_convert_to_grayscale(self):
         arr = cv2.imread(f"{EVA_ROOT_DIR}/test/udfs/data/dog.jpeg")
         df = pd.DataFrame([[arr]])
         modified_arr = self.to_grayscale_instance(df)["grayscale_frame_array"]
         cv2.imwrite(f"{EVA_ROOT_DIR}/test/udfs/data/tmp.jpeg", modified_arr[0])
         actual_array = cv2.imread(f"{EVA_ROOT_DIR}/test/udfs/data/tmp.jpeg")
         expected_arr = cv2.imread(f"{EVA_ROOT_DIR}/test/udfs/data/grayscale_dog.jpeg")
         self.assertEqual(np.sum(actual_array - expected_arr), 0)
+        file_remove(Path(f"{EVA_ROOT_DIR}/test/udfs/data/tmp.jpeg"))
```

### Comparing `evadb-0.2.6/test/udfs/test_abstract_udf.py` & `evadb-0.2.7/test/udfs/test_abstract_udf.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,18 +14,18 @@
 # limitations under the License.
 import inspect
 import unittest
 from enum import Enum
 from inspect import isabstract
 from test.util import get_all_subclasses, get_mock_object
 
-import eva
-from eva.udfs.abstract.abstract_udf import AbstractUDF
-from eva.udfs.abstract.hf_abstract_udf import AbstractHFUdf
-from eva.udfs.yolo_object_detector import Yolo
+import evadb
+from evadb.udfs.abstract.abstract_udf import AbstractUDF
+from evadb.udfs.abstract.hf_abstract_udf import AbstractHFUdf
+from evadb.udfs.yolo_object_detector import Yolo
 
 
 class AbstractUDFTest(unittest.TestCase):
     def test_udf_abstract_functions(self):
         derived_udf_classes = list(get_all_subclasses(AbstractUDF))
         # Go over each derived class of AbstractUDF
         for derived_udf_class in derived_udf_classes:
@@ -75,15 +75,15 @@
                                 class_list.append([obj])
                         except OSError:
                             pass
 
             flat_class_list = [item for sublist in class_list for item in sublist]
             return set(flat_class_list)
 
-        class_list = get_all_classes(eva, 1)
+        class_list = get_all_classes(evadb, 1)
 
         base_id = 0
         ref_object = None
         for class_type in class_list:
             base_id = base_id + 1
             sig = inspect.signature(class_type.__init__)
             params = sig.parameters
```

### Comparing `evadb-0.2.6/test/udfs/test_emotion_detector.py` & `evadb-0.2.7/test/udfs/test_emotion_detector.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,30 +16,30 @@
 import unittest
 from pathlib import Path
 from test.util import EVA_TEST_DATA_DIR
 
 import cv2
 import pandas as pd
 
-from eva.models.storage.batch import Batch
+from evadb.models.storage.batch import Batch
 
 
 class EmotionDetector(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.base_path = Path(EVA_TEST_DATA_DIR) / "data" / "emotion_detector"
 
     def _load_image(self, path):
         assert path.exists(), f"File does not exist at the path {str(path)}"
         img = cv2.imread(str(path))
         return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
 
     @unittest.skip("disable test due to model downloading time")
     def test_should_return_correct_emotion(self):
-        from eva.udfs.emotion_detector import EmotionDetector
+        from evadb.udfs.emotion_detector import EmotionDetector
 
         happy_img = self.base_path / "happy.jpg"
         sad_img = self.base_path / "sad.jpg"
         angry_img = self.base_path / "angry.jpg"
 
         frame_happy = {
             "id": 1,
```

### Comparing `evadb-0.2.6/test/udfs/test_facenet_udf.py` & `evadb-0.2.7/test/udfs/test_facenet_udf.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 from test.markers import windows_skip_marker
 from test.util import EVA_TEST_DATA_DIR
 from unittest.mock import patch
 
 import cv2
 import pandas as pd
 
-from eva.models.storage.batch import Batch
+from evadb.models.storage.batch import Batch
 
 NUM_FRAMES = 10
 
 
 class FaceNet(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
@@ -34,15 +34,15 @@
     def _load_image(self, path):
         assert path.exists(), f"File does not exist at the path {str(path)}"
         img = cv2.imread(str(path))
         return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
 
     @windows_skip_marker
     def test_should_return_batches_equivalent_to_number_of_frames(self):
-        from eva.udfs.face_detector import FaceDetector
+        from evadb.udfs.face_detector import FaceDetector
 
         single_face_img = Path("data/facenet/one.jpg")
         multi_face_img = Path("data/facenet/multiface.jpg")
         frame_single_face = {
             "id": 1,
             "data": self._load_image(single_face_img),
         }
@@ -59,15 +59,15 @@
         frame_batch = Batch(pd.DataFrame([frame_multifaces]))
         detector = FaceDetector()
         result = detector(frame_batch.project(["data"]).frames)
         self.assertEqual(6, len(result.iloc[0]["bboxes"]))
 
     @unittest.skip("Needs GPU")
     def test_should_run_on_gpu(self):
-        from eva.udfs.face_detector import FaceDetector
+        from evadb.udfs.face_detector import FaceDetector
 
         single_face_img = Path("data/facenet/one.jpg")
         frame_single_face = {
             "id": 1,
             "data": self._load_image(single_face_img),
         }
         frame_batch = Batch(pd.DataFrame([frame_single_face, frame_single_face]))
@@ -75,16 +75,16 @@
         # test on GPU
         detector = FaceDetector().to_device(0)
         result = detector(frame_batch.project(["data"]).frames)
         self.assertEqual(6, len(result.iloc[0]["bboxes"]))
 
     def test_mock_to_device(self):
         device = 10
-        from eva.udfs.face_detector import FaceDetector
+        from evadb.udfs.face_detector import FaceDetector
 
-        with patch("eva.udfs.face_detector.MTCNN") as mock_mtcnn:
-            with patch("eva.udfs.face_detector.torch") as mock_torch:
+        with patch("evadb.udfs.face_detector.MTCNN") as mock_mtcnn:
+            with patch("evadb.udfs.face_detector.torch") as mock_torch:
                 mock_torch.device.return_value = "cuda:10"
                 detector = FaceDetector()
                 detector = detector.to_device(device)
                 mock_torch.device.assert_called_once()
             mock_mtcnn.assert_called_with(device=f"cuda:{device}")
```

### Comparing `evadb-0.2.6/test/udfs/test_fastrcnn_object_detector.py` & `evadb-0.2.7/test/udfs/test_fastrcnn_object_detector.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 import sys
 import unittest
 
 import cv2
 import mock
 import pandas as pd
 
-from eva.models.storage.batch import Batch
+from evadb.models.storage.batch import Batch
 
 NUM_FRAMES = 10
 
 
 class FastRCNNObjectDetectorTest(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
@@ -33,32 +33,32 @@
     def _load_image(self, path):
         img = cv2.imread(path)
         return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
 
     def test_should_raise_import_error_with_missing_torch(self):
         with self.assertRaises(ImportError):
             with mock.patch.dict(sys.modules, {"torch": None}):
-                from eva.udfs.fastrcnn_object_detector import (  # noqa: F401
+                from evadb.udfs.fastrcnn_object_detector import (  # noqa: F401
                     FastRCNNObjectDetector,
                 )
 
                 pass
 
     def test_should_raise_import_error_with_missing_torchvision(self):
         with self.assertRaises(ImportError):
             with mock.patch.dict(sys.modules, {"torchvision": None}):
-                from eva.udfs.fastrcnn_object_detector import (  # noqa: F401
+                from evadb.udfs.fastrcnn_object_detector import (  # noqa: F401
                     FastRCNNObjectDetector,
                 )
 
                 pass
 
     @unittest.skip("disable test due to model downloading time")
     def test_should_return_batches_equivalent_to_number_of_frames(self):
-        from eva.udfs.fastrcnn_object_detector import FastRCNNObjectDetector
+        from evadb.udfs.fastrcnn_object_detector import FastRCNNObjectDetector
 
         frame_dog = {
             "id": 1,
             "data": self._load_image(os.path.join(self.base_path, "data", "dog.jpeg")),
         }
         frame_dog_cat = {
             "id": 2,
```

### Comparing `evadb-0.2.6/test/udfs/test_yolo_object_detector.py` & `evadb-0.2.7/test/udfs/test_yolo_object_detector.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -44,23 +44,23 @@
     def _load_image(self, path):
         img = cv2.imread(path)
         return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
 
     def test_should_raise_import_error_with_missing_torch(self):
         with self.assertRaises(ImportError):
             with mock.patch.dict(sys.modules, {"torch": None}):
-                from eva.udfs.decorators.yolo_object_detection_decorators import (  # noqa: F401
+                from evadb.udfs.decorators.yolo_object_detection_decorators import (  # noqa: F401
                     Yolo,
                 )
 
                 pass
 
     @unittest.skip("disable test due to model downloading time")
     def test_should_return_batches_equivalent_to_number_of_frames(self):
-        from eva.udfs.decorators.yolo_object_detection_decorators import Yolo
+        from evadb.udfs.decorators.yolo_object_detection_decorators import Yolo
 
         frame_dog = {
             "id": 1,
             "data": self._load_image(os.path.join(self.base_path, "data", "dog.jpeg")),
         }
         frame_dog_cat = {
             "id": 2,
```

### Comparing `evadb-0.2.6/test/util.py` & `evadb-0.2.7/test/util.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,22 +1,23 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import asyncio
+import gc
 import multiprocessing as mp
 import os
 import shutil
 import socket
 from contextlib import closing
 from itertools import repeat
 from multiprocessing import Pool
@@ -25,61 +26,80 @@
 import cv2
 import numpy as np
 import pandas as pd
 import psutil
 import ray
 from mock import MagicMock
 
-from eva.binder.statement_binder import StatementBinder
-from eva.binder.statement_binder_context import StatementBinderContext
-from eva.catalog.catalog_manager import CatalogManager
-from eva.catalog.catalog_type import NdArrayType
-from eva.configuration.configuration_manager import ConfigurationManager
-from eva.expression.function_expression import FunctionExpression
-from eva.models.storage.batch import Batch
-from eva.optimizer.operators import LogicalFilter, Operator
-from eva.optimizer.plan_generator import PlanGenerator
-from eva.optimizer.statement_to_opr_converter import StatementToPlanConverter
-from eva.parser.parser import Parser
-from eva.plan_nodes.abstract_plan import AbstractPlan
-from eva.server.command_handler import execute_query_fetch_all
-from eva.udfs.abstract.abstract_udf import AbstractClassifierUDF
-from eva.udfs.decorators import decorators
-from eva.udfs.decorators.io_descriptors.data_types import NumpyArray, PandasDataframe
-from eva.udfs.udf_bootstrap_queries import init_builtin_udfs
+from evadb.binder.statement_binder import StatementBinder
+from evadb.binder.statement_binder_context import StatementBinderContext
+from evadb.catalog.catalog_type import NdArrayType
+from evadb.configuration.configuration_manager import ConfigurationManager
+from evadb.configuration.constants import EVA_DATABASE_DIR, EVA_INSTALLATION_DIR
+from evadb.database import init_eva_db_instance
+from evadb.expression.function_expression import FunctionExpression
+from evadb.models.storage.batch import Batch
+from evadb.optimizer.operators import LogicalFilter, Operator
+from evadb.optimizer.plan_generator import PlanGenerator
+from evadb.optimizer.statement_to_opr_converter import StatementToPlanConverter
+from evadb.parser.parser import Parser
+from evadb.plan_nodes.abstract_plan import AbstractPlan
+from evadb.server.command_handler import execute_query_fetch_all
+from evadb.udfs.abstract.abstract_udf import AbstractClassifierUDF
+from evadb.udfs.decorators import decorators
+from evadb.udfs.decorators.io_descriptors.data_types import NumpyArray, PandasDataframe
+from evadb.udfs.udf_bootstrap_queries import init_builtin_udfs
+from evadb.utils.generic_utils import remove_directory_contents
 
 NUM_FRAMES = 10
 FRAME_SIZE = (32, 32)
-config = ConfigurationManager()
-tmp_dir_from_config = config.get_value("storage", "tmp_dir")
-s3_dir_from_config = config.get_value("storage", "s3_download_dir")
 
 
-EVA_TEST_DATA_DIR = Path(config.get_value("core", "eva_installation_dir")).parent
+def suffix_pytest_xdist_worker_id_to_dir(path: str):
+    try:
+        worker_id = os.environ["PYTEST_XDIST_WORKER"]
+        path = Path(str(worker_id) + "_" + path)
+    except KeyError:
+        pass
+    return path
+
+
+def get_evadb_for_testing(uri: str = None):
+    db_dir = suffix_pytest_xdist_worker_id_to_dir(EVA_DATABASE_DIR)
+    remove_directory_contents(db_dir)
+    gc.collect()
+    return init_eva_db_instance(db_dir, custom_db_uri=uri)
+
+
+def get_tmp_dir():
+    db_dir = suffix_pytest_xdist_worker_id_to_dir(EVA_DATABASE_DIR)
+    config = ConfigurationManager(Path(db_dir))
+    return config.get_value("storage", "tmp_dir")
+
+
+def s3_dir():
+    db_dir = suffix_pytest_xdist_worker_id_to_dir(EVA_DATABASE_DIR)
+    config = ConfigurationManager(Path(db_dir))
+    return config.get_value("storage", "s3_download_dir")
+
+
+EVA_TEST_DATA_DIR = Path(EVA_INSTALLATION_DIR).parent
 
 
 def is_ray_stage_running():
     return "ray::ray_stage" in (p.name() for p in psutil.process_iter())
 
 
 def shutdown_ray():
-    if ConfigurationManager().get_value("experimental", "ray"):
+    db_dir = suffix_pytest_xdist_worker_id_to_dir(EVA_DATABASE_DIR)
+    config = ConfigurationManager(Path(db_dir))
+    if config.get_value("experimental", "ray"):
         ray.shutdown()
 
 
-def prefix_worker_id(base: str):
-    try:
-        worker_id = os.environ["PYTEST_XDIST_WORKER"]
-        prefixed_base = str(worker_id) + "_" + base
-    except KeyError:
-        # Single threaded mode
-        prefixed_base = base
-    return prefixed_base
-
-
 # Ref: https://stackoverflow.com/a/63851681
 def get_all_subclasses(cls):
     subclass_list = []
 
     def recurse(klass):
         for subclass in klass.__subclasses__():
             subclass_list.append(subclass)
@@ -176,52 +196,35 @@
 def find_free_port():
     with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:
         s.bind(("", 0))
         s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
         return s.getsockname()[1]
 
 
-def get_logical_query_plan(query: str) -> Operator:
-    """Get the query plan
-
-    Args:
-        query (str): evaql query
-
-    Returns:
-        Operator: Logical plan generated by eva
-    """
+def get_logical_query_plan(db, query: str) -> Operator:
     stmt = Parser().parse(query)[0]
-    StatementBinder(StatementBinderContext()).bind(stmt)
+    StatementBinder(StatementBinderContext(db.catalog)).bind(stmt)
     l_plan = StatementToPlanConverter().visit(stmt)
     return l_plan
 
 
 def get_physical_query_plan(
-    query: str, rule_manager=None, cost_model=None
+    db, query: str, rule_manager=None, cost_model=None
 ) -> AbstractPlan:
-    """Get the query plan
-
-    Args:
-        query (str): evaql query
-
-    Returns:
-        AbstractPlan: Optimal query plan generated by optimizer
-    """
-    l_plan = get_logical_query_plan(query)
-    p_plan = asyncio.run(PlanGenerator(rule_manager, cost_model).build(l_plan))
+    l_plan = get_logical_query_plan(db, query)
+    p_plan = asyncio.run(PlanGenerator(db, rule_manager, cost_model).build(l_plan))
     return p_plan
 
 
-def remove_udf_cache(query):
-    plan = next(get_logical_query_plan(query).find_all(LogicalFilter))
-    catalog_manager = CatalogManager()
+def remove_udf_cache(db, query):
+    plan = next(get_logical_query_plan(db, query).find_all(LogicalFilter))
     func_exprs = plan.predicate.find_all(FunctionExpression)
     for expr in func_exprs:
         cache_name = expr.signature()
-        udf_cache = catalog_manager.get_udf_cache_catalog_entry_by_name(cache_name)
+        udf_cache = db.catalog.get_udf_cache_catalog_entry_by_name(cache_name)
         if udf_cache is not None:
             cache_dir = Path(udf_cache.cache_path)
             if cache_dir.exists():
                 shutil.rmtree(cache_dir)
 
 
 def create_dataframe(num_frames=1) -> pd.DataFrame:
@@ -256,15 +259,15 @@
 
 def convert_bbox(bbox):
     return np.array([np.float32(coord) for coord in bbox.split(",")])
 
 
 def create_sample_csv(num_frames=NUM_FRAMES):
     try:
-        os.remove(os.path.join(tmp_dir_from_config, "dummy.csv"))
+        os.remove(os.path.join(get_tmp_dir(), "dummy.csv"))
     except FileNotFoundError:
         pass
 
     sample_meta = {}
 
     index = 0
     sample_labels = ["car", "pedestrian", "bicycle"]
@@ -281,36 +284,36 @@
                 "bbox": ",".join([str(coord) for coord in random_coords]),
                 "object_id": np.random.choice(3),
             }
 
             index += 1
 
     df_sample_meta = pd.DataFrame.from_dict(sample_meta, "index")
-    df_sample_meta.to_csv(os.path.join(tmp_dir_from_config, "dummy.csv"), index=False)
-    return os.path.join(tmp_dir_from_config, "dummy.csv")
+    df_sample_meta.to_csv(os.path.join(get_tmp_dir(), "dummy.csv"), index=False)
+    return os.path.join(get_tmp_dir(), "dummy.csv")
 
 
 def create_dummy_csv_batches(target_columns=None):
     if target_columns:
         df = pd.read_csv(
-            os.path.join(tmp_dir_from_config, "dummy.csv"),
+            os.path.join(get_tmp_dir(), "dummy.csv"),
             converters={"bbox": convert_bbox},
             usecols=target_columns,
         )
     else:
         df = pd.read_csv(
-            os.path.join(tmp_dir_from_config, "dummy.csv"),
+            os.path.join(get_tmp_dir(), "dummy.csv"),
             converters={"bbox": convert_bbox},
         )
 
     yield Batch(df)
 
 
 def create_csv(num_rows, columns):
-    csv_path = os.path.join(tmp_dir_from_config, "dummy.csv")
+    csv_path = os.path.join(get_tmp_dir(), "dummy.csv")
     try:
         os.remove(csv_path)
     except FileNotFoundError:
         pass
     df = pd.DataFrame(columns=columns)
     for col in columns:
         df[col] = np.random.randint(1, 100, num_rows)
@@ -319,45 +322,45 @@
 
 
 def create_text_csv(num_rows=30):
     """
     Creates a csv with 2 columns: id and comment
     The comment column has 2 values: "I like this" and "I don't like this" that are alternated
     """
-    csv_path = os.path.join(tmp_dir_from_config, "dummy.csv")
+    csv_path = os.path.join(get_tmp_dir(), "dummy.csv")
     try:
         os.remove(csv_path)
     except FileNotFoundError:
         pass
     df = pd.DataFrame(columns=["id", "comment"])
     df["id"] = np.arange(num_rows)
     df["comment"] = np.where(df["id"] % 2 == 0, "I like this", "I don't like this")
     df.to_csv(csv_path, index=False)
     return csv_path
 
 
-def create_table(table_name, num_rows, num_columns):
+def create_table(db, table_name, num_rows, num_columns):
     # creates a table with num_rows tuples and columns = [a1, a2, a3, ...]
     columns = "".join("a{} INTEGER, ".format(i) for i in range(num_columns - 1))
     columns += "a{} INTEGER".format(num_columns - 1)
     create_table_query = "CREATE TABLE IF NOT EXISTS {} ( {} );".format(
         table_name, columns
     )
-    execute_query_fetch_all(create_table_query)
+    execute_query_fetch_all(db, create_table_query)
     columns = ["a{}".format(i) for i in range(num_columns)]
     df, csv_file_path = create_csv(num_rows, columns)
     # load the CSV
     load_query = f"LOAD CSV '{csv_file_path}' INTO {table_name};"
-    execute_query_fetch_all(load_query)
+    execute_query_fetch_all(db, load_query)
     df.columns = [f"{table_name}.{col}" for col in df.columns]
     return df
 
 
 def create_sample_image():
-    img_path = os.path.join(tmp_dir_from_config, "dummy.jpg")
+    img_path = os.path.join(get_tmp_dir(), "dummy.jpg")
     try:
         os.remove(img_path)
     except FileNotFoundError:
         pass
 
     img = np.array(np.ones((3, 3, 3)), dtype=np.uint8)
     img[0] -= 1
@@ -368,28 +371,28 @@
 
 def create_random_image(i, path):
     img = np.random.random_sample([400, 400, 3]).astype(np.uint8)
     cv2.imwrite(os.path.join(path, f"img{i}.jpg"), img)
 
 
 def create_large_scale_image_dataset(num=1000000):
-    img_dir = os.path.join(tmp_dir_from_config, f"large_scale_image_dataset_{num}")
+    img_dir = os.path.join(get_tmp_dir(), f"large_scale_image_dataset_{num}")
     Path(img_dir).mkdir(parents=True, exist_ok=True)
 
     # Generate images in parallel.
     image_idx_list = list(range(num))
     Pool(mp.cpu_count()).starmap(
         create_random_image, zip(image_idx_list, repeat(img_dir))
     )
 
     return img_dir
 
 
 def create_sample_video(num_frames=NUM_FRAMES):
-    file_name = os.path.join(tmp_dir_from_config, "dummy.avi")
+    file_name = os.path.join(get_tmp_dir(), "dummy.avi")
     try:
         os.remove(file_name)
     except FileNotFoundError:
         pass
 
     duration = 1
     fps = NUM_FRAMES
@@ -397,31 +400,34 @@
         file_name, cv2.VideoWriter_fourcc("M", "J", "P", "G"), fps, (32, 32), False
     )
     for i in range(fps * duration):
         data = np.array(np.ones((FRAME_SIZE[1], FRAME_SIZE[0])) * i, dtype=np.uint8)
         out.write(data)
     out.release()
 
-    return os.path.join(tmp_dir_from_config, file_name)
+    return file_name
 
 
-def file_remove(path, parent_dir=tmp_dir_from_config):
+def file_remove(path, parent_dir=None):
+    parent_dir = parent_dir or get_tmp_dir()
     try:
         os.remove(os.path.join(parent_dir, path))
     except FileNotFoundError:
         pass
 
 
 def create_dummy_batches(
     num_frames=NUM_FRAMES,
     filters=[],
     batch_size=10,
     start_id=0,
-    video_dir=tmp_dir_from_config,
+    video_dir=None,
 ):
+    video_dir = video_dir or get_tmp_dir()
+
     if not filters:
         filters = range(num_frames)
     data = []
     for i in filters:
         data.append(
             {
                 "myvideo._row_id": 1,
@@ -468,17 +474,17 @@
             data = []
     if data:
         df = pd.DataFrame(data)
         df = df.astype({"myvideo.id": np.intp})
         yield Batch(df)
 
 
-def load_udfs_for_testing(mode="debug"):
+def load_udfs_for_testing(db, mode="debug"):
     # DEBUG MODE: ALL UDFs
-    init_builtin_udfs(mode=mode)
+    init_builtin_udfs(db, mode=mode)
 
 
 class DummyObjectDetector(AbstractClassifierUDF):
     def setup(self, *args, **kwargs):
         pass
 
     @property
```

### Comparing `evadb-0.2.6/test/utils/__init__.py` & `evadb-0.2.7/test/interfaces/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `evadb-0.2.6/test/utils/test_generic_utils.py` & `evadb-0.2.7/test/utils/test_generic_utils.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,61 +12,59 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import unittest
 from test.markers import windows_skip_marker
 
-from mock import MagicMock, patch
-
-from eva.readers.decord_reader import DecordReader
-from eva.utils.generic_utils import (
+from evadb.readers.decord_reader import DecordReader
+from evadb.utils.generic_utils import (
     generate_file_path,
     is_gpu_available,
     load_udf_class_from_file,
     str_to_class,
     validate_kwargs,
 )
 
 
 class ModulePathTest(unittest.TestCase):
     def test_helper_validates_kwargs(self):
         with self.assertRaises(TypeError):
             validate_kwargs({"a": 1, "b": 2}, ["a"], "Invalid keyword argument:")
 
     def test_should_return_correct_class_for_string(self):
-        vl = str_to_class("eva.readers.decord_reader.DecordReader")
+        vl = str_to_class("evadb.readers.decord_reader.DecordReader")
         self.assertEqual(vl, DecordReader)
 
     def test_should_return_correct_class_for_path(self):
-        vl = load_udf_class_from_file("eva/readers/decord_reader.py", "DecordReader")
-        # Can't check that v1 = DecordReader because the above function returns decord_reader.DecordReader instead of eva.readers.decord_reader.DecordReader
+        vl = load_udf_class_from_file("evadb/readers/decord_reader.py", "DecordReader")
+        # Can't check that v1 = DecordReader because the above function returns decord_reader.DecordReader instead of evadb.readers.decord_reader.DecordReader
         # So we check the qualname instead, qualname is the path to the class including the module name
         # Ref: https://peps.python.org/pep-3155/#rationale
         assert vl.__qualname__ == DecordReader.__qualname__
 
     def test_should_return_correct_class_for_path_without_classname(self):
-        vl = load_udf_class_from_file("eva/readers/decord_reader.py")
+        vl = load_udf_class_from_file("evadb/readers/decord_reader.py")
         assert vl.__qualname__ == DecordReader.__qualname__
 
     def test_should_raise_on_missing_file(self):
         with self.assertRaises(RuntimeError):
-            load_udf_class_from_file("eva/readers/opencv_reader_abdfdsfds.py")
+            load_udf_class_from_file("evadb/readers/opencv_reader_abdfdsfds.py")
 
     def test_should_raise_if_class_does_not_exists(self):
         with self.assertRaises(RuntimeError):
-            # eva/utils/s3_utils.py has no class in it
+            # evadb/utils/s3_utils.py has no class in it
             # if this test fails due to change in s3_utils.py, change the file to something else
-            load_udf_class_from_file("eva/utils/s3_utils.py")
+            load_udf_class_from_file("evadb/utils/s3_utils.py")
 
     def test_should_raise_if_multiple_classes_exist_and_no_class_mentioned(self):
         with self.assertRaises(RuntimeError):
-            # eva/utils/generic_utils.py has multiple classes in it
+            # evadb/utils/generic_utils.py has multiple classes in it
             # if this test fails due to change in generic_utils.py, change the file to something else
-            load_udf_class_from_file("eva/utils/generic_utils.py")
+            load_udf_class_from_file("evadb/utils/generic_utils.py")
 
     def test_should_use_torch_to_check_if_gpu_is_available(self):
         # Emulate a missing import
         # Ref: https://stackoverflow.com/a/2481588
         try:
             import builtins
         except ImportError:
@@ -82,19 +80,12 @@
         self.assertFalse(is_gpu_available())
 
         # Switch back to builtin import
         builtins.__import__ = realimport
         is_gpu_available()
 
     @windows_skip_marker
-    @patch("eva.utils.generic_utils.ConfigurationManager")
-    def test_should_return_a_random_full_path(self, mock_conf):
-        mock_conf_inst = MagicMock()
-        mock_conf.return_value = mock_conf_inst
-        mock_conf_inst.get_value.return_value = "eva_datasets"
-        actual = generate_file_path("test")
+    def test_should_return_a_random_full_path(self):
+        actual = generate_file_path("eva_datasets", "test")
         self.assertTrue(actual.is_absolute())
         # Root directory must be the same, filename is random
         self.assertTrue("eva_datasets" in str(actual.parent))
-
-        mock_conf_inst.get_value.return_value = None
-        self.assertRaises(KeyError, generate_file_path)
```

### Comparing `evadb-0.2.6/test/utils/test_timer.py` & `evadb-0.2.7/test/utils/test_timer.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # coding=utf-8
-# Copyright 2018-2022 EVA
+# Copyright 2018-2023 EVA
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,22 +13,21 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import asyncio
 import time
 import unittest
 from test.markers import windows_skip_marker
-from test.util import create_sample_video, file_remove
+from test.util import create_sample_video, file_remove, get_evadb_for_testing
 from unittest.mock import MagicMock
 
 import pytest
 
-from eva.catalog.catalog_manager import CatalogManager
-from eva.server.command_handler import handle_request
-from eva.utils.stats import Timer
+from evadb.server.command_handler import handle_request
+from evadb.utils.stats import Timer
 
 NUM_FRAMES = 10
 
 
 class TimerTests(unittest.TestCase):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
@@ -40,25 +39,26 @@
             time.sleep(5)
 
         self.assertTrue(sleep_time.total_elapsed_time < 5.2)
         self.assertTrue(sleep_time.total_elapsed_time > 4.9)
 
     @pytest.mark.notparallel
     def test_timer_with_query(self):
-        CatalogManager().reset()
+        evadb = get_evadb_for_testing()
+        evadb.catalog().reset()
         video_file_path = create_sample_video(NUM_FRAMES)
         load_query = f"LOAD VIDEO '{video_file_path}' INTO MyVideo;"
         transport = MagicMock()
         transport.write = MagicMock(return_value="response_message")
-        response = asyncio.run(handle_request(transport, load_query))
+        response = asyncio.run(handle_request(evadb, transport, load_query))
         self.assertTrue(response.error is None)
         self.assertTrue(response.query_time is not None)
 
         # If response is an error, we do not report time
         load_query = """LOAD INFILE 'dummy.avi' INTO MyVideo;"""
         transport = MagicMock()
         transport.write = MagicMock(return_value="response_message")
-        response = asyncio.run(handle_request(transport, load_query))
+        response = asyncio.run(handle_request(evadb, transport, load_query))
         self.assertTrue(response.error is not None)
         self.assertTrue(response.query_time is None)
 
         file_remove("dummy.avi")
```

