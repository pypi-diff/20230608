# Comparing `tmp/zensols.deeplearn-1.6.0-py3-none-any.whl.zip` & `tmp/zensols.deeplearn-1.6.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,75 +1,75 @@
-Zip file size: 160172 bytes, number of entries: 73
--rw-rw-r--  2.0 unx       43 b- defN 23-Feb-02 14:40 zensols/dataframe/__init__.py
--rw-rw-r--  2.0 unx     2290 b- defN 23-Feb-02 14:40 zensols/dataframe/config.py
--rw-rw-r--  2.0 unx     8983 b- defN 23-Feb-02 14:40 zensols/dataframe/stash.py
--rw-rw-r--  2.0 unx      139 b- defN 23-Feb-02 14:40 zensols/dataset/__init__.py
--rw-rw-r--  2.0 unx     6619 b- defN 23-Feb-02 14:40 zensols/dataset/dimreduce.py
--rw-rw-r--  2.0 unx     3266 b- defN 23-Feb-02 14:40 zensols/dataset/interface.py
--rw-rw-r--  2.0 unx     3211 b- defN 23-Feb-02 14:40 zensols/dataset/leaveout.py
--rw-rw-r--  2.0 unx     8343 b- defN 23-Feb-02 14:40 zensols/dataset/outlier.py
--rw-rw-r--  2.0 unx    10965 b- defN 23-Feb-02 14:40 zensols/dataset/split.py
--rw-rw-r--  2.0 unx     9725 b- defN 23-Feb-02 14:40 zensols/dataset/stash.py
--rw-rw-r--  2.0 unx      202 b- defN 23-Feb-02 14:40 zensols/deeplearn/__init__.py
--rw-rw-r--  2.0 unx    16052 b- defN 23-Feb-02 14:40 zensols/deeplearn/domain.py
--rw-rw-r--  2.0 unx     8475 b- defN 23-Feb-02 14:40 zensols/deeplearn/observer.py
--rw-rw-r--  2.0 unx    21749 b- defN 23-Feb-02 14:40 zensols/deeplearn/torchconfig.py
--rw-rw-r--  2.0 unx     5141 b- defN 23-Feb-02 14:40 zensols/deeplearn/torchtype.py
--rw-rw-r--  2.0 unx      208 b- defN 23-Feb-02 14:40 zensols/deeplearn/batch/__init__.py
--rw-rw-r--  2.0 unx    21605 b- defN 23-Feb-02 14:40 zensols/deeplearn/batch/domain.py
--rw-rw-r--  2.0 unx     1569 b- defN 23-Feb-02 14:40 zensols/deeplearn/batch/interface.py
--rw-rw-r--  2.0 unx     7202 b- defN 23-Feb-02 14:40 zensols/deeplearn/batch/mapping.py
--rw-rw-r--  2.0 unx     2904 b- defN 23-Feb-02 14:40 zensols/deeplearn/batch/meta.py
--rw-rw-r--  2.0 unx     1738 b- defN 23-Feb-02 14:40 zensols/deeplearn/batch/multi.py
--rw-rw-r--  2.0 unx    15680 b- defN 23-Feb-02 14:40 zensols/deeplearn/batch/stash.py
--rw-rw-r--  2.0 unx       19 b- defN 23-Feb-02 14:40 zensols/deeplearn/cli/__init__.py
--rw-rw-r--  2.0 unx    30223 b- defN 23-Feb-02 14:40 zensols/deeplearn/cli/app.py
--rw-rw-r--  2.0 unx      212 b- defN 23-Feb-02 14:40 zensols/deeplearn/dataframe/__init__.py
--rw-rw-r--  2.0 unx     3720 b- defN 23-Feb-02 14:40 zensols/deeplearn/dataframe/batch.py
--rw-rw-r--  2.0 unx     1122 b- defN 23-Feb-02 14:40 zensols/deeplearn/dataframe/util.py
--rw-rw-r--  2.0 unx     9426 b- defN 23-Feb-02 14:40 zensols/deeplearn/dataframe/vectorize.py
--rw-rw-r--  2.0 unx      359 b- defN 23-Feb-02 14:40 zensols/deeplearn/layer/__init__.py
--rw-rw-r--  2.0 unx     9186 b- defN 23-Feb-02 14:40 zensols/deeplearn/layer/conv.py
--rw-rw-r--  2.0 unx    17314 b- defN 23-Feb-02 14:40 zensols/deeplearn/layer/crf.py
--rw-rw-r--  2.0 unx     8331 b- defN 23-Feb-02 14:40 zensols/deeplearn/layer/linear.py
--rw-rw-r--  2.0 unx     4297 b- defN 23-Feb-02 14:40 zensols/deeplearn/layer/recur.py
--rw-rw-r--  2.0 unx     7346 b- defN 23-Feb-02 14:40 zensols/deeplearn/layer/recurcrf.py
--rw-rw-r--  2.0 unx      491 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/__init__.py
--rw-rw-r--  2.0 unx     4613 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/analyze.py
--rw-rw-r--  2.0 unx    10586 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/batchiter.py
--rw-rw-r--  2.0 unx    36975 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/executor.py
--rw-rw-r--  2.0 unx    29753 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/facade.py
--rw-rw-r--  2.0 unx    10076 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/format.py
--rw-rw-r--  2.0 unx    10601 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/manager.py
--rw-rw-r--  2.0 unx      958 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/meta.py
--rw-rw-r--  2.0 unx     8413 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/module.py
--rw-rw-r--  2.0 unx      516 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/optimizer.py
--rw-rw-r--  2.0 unx     3496 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/pack.py
--rw-rw-r--  2.0 unx     3817 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/pred.py
--rw-rw-r--  2.0 unx     7204 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/sequence.py
--rw-rw-r--  2.0 unx    10544 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/trainmng.py
--rw-rw-r--  2.0 unx     3710 b- defN 23-Feb-02 14:40 zensols/deeplearn/model/wgtexecutor.py
--rw-rw-r--  2.0 unx     3865 b- defN 23-Feb-02 14:40 zensols/deeplearn/resources/batch.conf
--rw-rw-r--  2.0 unx      329 b- defN 23-Feb-02 14:40 zensols/deeplearn/resources/cli-pack.conf
--rw-rw-r--  2.0 unx     1004 b- defN 23-Feb-02 14:40 zensols/deeplearn/resources/cli.conf
--rw-rw-r--  2.0 unx      297 b- defN 23-Feb-02 14:40 zensols/deeplearn/resources/default.conf
--rw-rw-r--  2.0 unx     4391 b- defN 23-Feb-02 14:40 zensols/deeplearn/resources/model.conf
--rw-rw-r--  2.0 unx      316 b- defN 23-Feb-02 14:40 zensols/deeplearn/resources/obj.conf
--rw-rw-r--  2.0 unx     1015 b- defN 23-Feb-02 14:40 zensols/deeplearn/resources/observer.conf
--rw-rw-r--  2.0 unx      399 b- defN 23-Feb-02 14:40 zensols/deeplearn/resources/torch.conf
--rw-rw-r--  2.0 unx      269 b- defN 23-Feb-02 14:40 zensols/deeplearn/result/__init__.py
--rw-rw-r--  2.0 unx     1371 b- defN 23-Feb-02 14:40 zensols/deeplearn/result/compare.py
--rw-rw-r--  2.0 unx    34957 b- defN 23-Feb-02 14:40 zensols/deeplearn/result/domain.py
--rw-rw-r--  2.0 unx     8940 b- defN 23-Feb-02 14:40 zensols/deeplearn/result/manager.py
--rw-rw-r--  2.0 unx     3631 b- defN 23-Feb-02 14:40 zensols/deeplearn/result/plot.py
--rw-rw-r--  2.0 unx    11379 b- defN 23-Feb-02 14:40 zensols/deeplearn/result/pred.py
--rw-rw-r--  2.0 unx     4395 b- defN 23-Feb-02 14:40 zensols/deeplearn/result/report.py
--rw-rw-r--  2.0 unx      198 b- defN 23-Feb-02 14:40 zensols/deeplearn/vectorize/__init__.py
--rw-rw-r--  2.0 unx     6708 b- defN 23-Feb-02 14:40 zensols/deeplearn/vectorize/domain.py
--rw-rw-r--  2.0 unx    13990 b- defN 23-Feb-02 14:40 zensols/deeplearn/vectorize/manager.py
--rw-rw-r--  2.0 unx     2061 b- defN 23-Feb-02 14:40 zensols/deeplearn/vectorize/util.py
--rw-rw-r--  2.0 unx    14594 b- defN 23-Feb-02 14:40 zensols/deeplearn/vectorize/vectorizers.py
--rw-rw-r--  2.0 unx    10552 b- defN 23-Feb-02 14:40 zensols.deeplearn-1.6.0.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Feb-02 14:40 zensols.deeplearn-1.6.0.dist-info/WHEEL
--rw-rw-r--  2.0 unx       52 b- defN 23-Feb-02 14:40 zensols.deeplearn-1.6.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     6571 b- defN 23-Feb-02 14:40 zensols.deeplearn-1.6.0.dist-info/RECORD
-73 files, 520793 bytes uncompressed, 149666 bytes compressed:  71.3%
+Zip file size: 161491 bytes, number of entries: 73
+-rw-rw-r--  2.0 unx       43 b- defN 23-Jun-08 01:16 zensols/dataframe/__init__.py
+-rw-rw-r--  2.0 unx     2290 b- defN 23-Jun-08 01:16 zensols/dataframe/config.py
+-rw-rw-r--  2.0 unx     8983 b- defN 23-Jun-08 01:16 zensols/dataframe/stash.py
+-rw-rw-r--  2.0 unx      139 b- defN 23-Jun-08 01:16 zensols/dataset/__init__.py
+-rw-rw-r--  2.0 unx     6619 b- defN 23-Jun-08 01:16 zensols/dataset/dimreduce.py
+-rw-rw-r--  2.0 unx     3266 b- defN 23-Jun-08 01:16 zensols/dataset/interface.py
+-rw-rw-r--  2.0 unx     3211 b- defN 23-Jun-08 01:16 zensols/dataset/leaveout.py
+-rw-rw-r--  2.0 unx     8343 b- defN 23-Jun-08 01:16 zensols/dataset/outlier.py
+-rw-rw-r--  2.0 unx    10965 b- defN 23-Jun-08 01:16 zensols/dataset/split.py
+-rw-rw-r--  2.0 unx     9725 b- defN 23-Jun-08 01:16 zensols/dataset/stash.py
+-rw-rw-r--  2.0 unx      202 b- defN 23-Jun-08 01:16 zensols/deeplearn/__init__.py
+-rw-rw-r--  2.0 unx    16052 b- defN 23-Jun-08 01:16 zensols/deeplearn/domain.py
+-rw-rw-r--  2.0 unx     8475 b- defN 23-Jun-08 01:16 zensols/deeplearn/observer.py
+-rw-rw-r--  2.0 unx    22070 b- defN 23-Jun-08 01:16 zensols/deeplearn/torchconfig.py
+-rw-rw-r--  2.0 unx     5141 b- defN 23-Jun-08 01:16 zensols/deeplearn/torchtype.py
+-rw-rw-r--  2.0 unx      208 b- defN 23-Jun-08 01:16 zensols/deeplearn/batch/__init__.py
+-rw-rw-r--  2.0 unx    21605 b- defN 23-Jun-08 01:16 zensols/deeplearn/batch/domain.py
+-rw-rw-r--  2.0 unx     1569 b- defN 23-Jun-08 01:16 zensols/deeplearn/batch/interface.py
+-rw-rw-r--  2.0 unx     7202 b- defN 23-Jun-08 01:16 zensols/deeplearn/batch/mapping.py
+-rw-rw-r--  2.0 unx     2904 b- defN 23-Jun-08 01:16 zensols/deeplearn/batch/meta.py
+-rw-rw-r--  2.0 unx     1738 b- defN 23-Jun-08 01:16 zensols/deeplearn/batch/multi.py
+-rw-rw-r--  2.0 unx    15680 b- defN 23-Jun-08 01:16 zensols/deeplearn/batch/stash.py
+-rw-rw-r--  2.0 unx       19 b- defN 23-Jun-08 01:16 zensols/deeplearn/cli/__init__.py
+-rw-rw-r--  2.0 unx    30885 b- defN 23-Jun-08 01:16 zensols/deeplearn/cli/app.py
+-rw-rw-r--  2.0 unx      212 b- defN 23-Jun-08 01:16 zensols/deeplearn/dataframe/__init__.py
+-rw-rw-r--  2.0 unx     3720 b- defN 23-Jun-08 01:16 zensols/deeplearn/dataframe/batch.py
+-rw-rw-r--  2.0 unx     1122 b- defN 23-Jun-08 01:16 zensols/deeplearn/dataframe/util.py
+-rw-rw-r--  2.0 unx     9426 b- defN 23-Jun-08 01:16 zensols/deeplearn/dataframe/vectorize.py
+-rw-rw-r--  2.0 unx      359 b- defN 23-Jun-08 01:16 zensols/deeplearn/layer/__init__.py
+-rw-rw-r--  2.0 unx     9186 b- defN 23-Jun-08 01:16 zensols/deeplearn/layer/conv.py
+-rw-rw-r--  2.0 unx    17314 b- defN 23-Jun-08 01:16 zensols/deeplearn/layer/crf.py
+-rw-rw-r--  2.0 unx     8331 b- defN 23-Jun-08 01:16 zensols/deeplearn/layer/linear.py
+-rw-rw-r--  2.0 unx     4297 b- defN 23-Jun-08 01:16 zensols/deeplearn/layer/recur.py
+-rw-rw-r--  2.0 unx     7346 b- defN 23-Jun-08 01:16 zensols/deeplearn/layer/recurcrf.py
+-rw-rw-r--  2.0 unx      491 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/__init__.py
+-rw-rw-r--  2.0 unx     4613 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/analyze.py
+-rw-rw-r--  2.0 unx    10586 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/batchiter.py
+-rw-rw-r--  2.0 unx    36975 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/executor.py
+-rw-rw-r--  2.0 unx    30926 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/facade.py
+-rw-rw-r--  2.0 unx    10075 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/format.py
+-rw-rw-r--  2.0 unx    10602 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/manager.py
+-rw-rw-r--  2.0 unx      958 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/meta.py
+-rw-rw-r--  2.0 unx     8506 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/module.py
+-rw-rw-r--  2.0 unx      516 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/optimizer.py
+-rw-rw-r--  2.0 unx     3496 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/pack.py
+-rw-rw-r--  2.0 unx     3816 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/pred.py
+-rw-rw-r--  2.0 unx     7204 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/sequence.py
+-rw-rw-r--  2.0 unx    10544 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/trainmng.py
+-rw-rw-r--  2.0 unx     3710 b- defN 23-Jun-08 01:16 zensols/deeplearn/model/wgtexecutor.py
+-rw-rw-r--  2.0 unx     3865 b- defN 23-Jun-08 01:16 zensols/deeplearn/resources/batch.conf
+-rw-rw-r--  2.0 unx      329 b- defN 23-Jun-08 01:16 zensols/deeplearn/resources/cli-pack.conf
+-rw-rw-r--  2.0 unx     1004 b- defN 23-Jun-08 01:16 zensols/deeplearn/resources/cli.conf
+-rw-rw-r--  2.0 unx      297 b- defN 23-Jun-08 01:16 zensols/deeplearn/resources/default.conf
+-rw-rw-r--  2.0 unx     4391 b- defN 23-Jun-08 01:16 zensols/deeplearn/resources/model.conf
+-rw-rw-r--  2.0 unx      316 b- defN 23-Jun-08 01:16 zensols/deeplearn/resources/obj.conf
+-rw-rw-r--  2.0 unx     1015 b- defN 23-Jun-08 01:16 zensols/deeplearn/resources/observer.conf
+-rw-rw-r--  2.0 unx      399 b- defN 23-Jun-08 01:16 zensols/deeplearn/resources/torch.conf
+-rw-rw-r--  2.0 unx      269 b- defN 23-Jun-08 01:16 zensols/deeplearn/result/__init__.py
+-rw-rw-r--  2.0 unx     1371 b- defN 23-Jun-08 01:16 zensols/deeplearn/result/compare.py
+-rw-rw-r--  2.0 unx    34990 b- defN 23-Jun-08 01:16 zensols/deeplearn/result/domain.py
+-rw-rw-r--  2.0 unx     8940 b- defN 23-Jun-08 01:16 zensols/deeplearn/result/manager.py
+-rw-rw-r--  2.0 unx     3631 b- defN 23-Jun-08 01:16 zensols/deeplearn/result/plot.py
+-rw-rw-r--  2.0 unx    13719 b- defN 23-Jun-08 01:16 zensols/deeplearn/result/pred.py
+-rw-rw-r--  2.0 unx     5130 b- defN 23-Jun-08 01:16 zensols/deeplearn/result/report.py
+-rw-rw-r--  2.0 unx      198 b- defN 23-Jun-08 01:16 zensols/deeplearn/vectorize/__init__.py
+-rw-rw-r--  2.0 unx     6708 b- defN 23-Jun-08 01:16 zensols/deeplearn/vectorize/domain.py
+-rw-rw-r--  2.0 unx    13990 b- defN 23-Jun-08 01:16 zensols/deeplearn/vectorize/manager.py
+-rw-rw-r--  2.0 unx     2061 b- defN 23-Jun-08 01:16 zensols/deeplearn/vectorize/util.py
+-rw-rw-r--  2.0 unx    14594 b- defN 23-Jun-08 01:16 zensols/deeplearn/vectorize/vectorizers.py
+-rw-rw-r--  2.0 unx    10565 b- defN 23-Jun-08 01:16 zensols.deeplearn-1.6.1.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jun-08 01:16 zensols.deeplearn-1.6.1.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       52 b- defN 23-Jun-08 01:16 zensols.deeplearn-1.6.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     6571 b- defN 23-Jun-08 01:16 zensols.deeplearn-1.6.1.dist-info/RECORD
+73 files, 526162 bytes uncompressed, 150985 bytes compressed:  71.3%
```

## zipnote {}

```diff
@@ -201,20 +201,20 @@
 
 Filename: zensols/deeplearn/vectorize/util.py
 Comment: 
 
 Filename: zensols/deeplearn/vectorize/vectorizers.py
 Comment: 
 
-Filename: zensols.deeplearn-1.6.0.dist-info/METADATA
+Filename: zensols.deeplearn-1.6.1.dist-info/METADATA
 Comment: 
 
-Filename: zensols.deeplearn-1.6.0.dist-info/WHEEL
+Filename: zensols.deeplearn-1.6.1.dist-info/WHEEL
 Comment: 
 
-Filename: zensols.deeplearn-1.6.0.dist-info/top_level.txt
+Filename: zensols.deeplearn-1.6.1.dist-info/top_level.txt
 Comment: 
 
-Filename: zensols.deeplearn-1.6.0.dist-info/RECORD
+Filename: zensols.deeplearn-1.6.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## zensols/deeplearn/torchconfig.py

```diff
@@ -78,34 +78,41 @@
 
     """
     _CPU_DEVICE: str = 'cpu'
     _RANDOM_SEED: dict = None
     _CPU_WARN: bool = False
 
     def __init__(self, use_gpu: bool = True, data_type: type = torch.float32,
-                 cuda_device_index: int = None):
+                 cuda_device_index: int = None, device_name: str = None):
         """Initialize this configuration.
 
         :param use_gpu: whether or not to use CUDA/GPU
 
         :param data_type: the default data type to use when creating new
                           tensors in this configuration
 
         :param cuda_device_index: the CUDA device to use, which defaults to 0
                                   if CUDA if ``use_gpu`` is ``True``
 
+        :param device_name: the string name of the device to use (i.e. ``cpu``
+                            or ``mps``); if provided, overrides
+                            ``cuda_device_index``
+
         """
         super().__init__()
         logger.debug(f'use_gpu: {use_gpu}')
         self.use_gpu = use_gpu
         self.data_type = data_type
+        if device_name is not None:
+            self._device = torch.device(device_name)
         # we can't globally cache this in case there are multiple instances of
         # this class for which have different values of `use_gpu`
         self._init_device_pw = PersistedWork('_init_device_pw', self)
-        self._cpu_device_pw = PersistedWork('_cpu_device_pw', self, cache_global=True)
+        self._cpu_device_pw = PersistedWork(
+            '_cpu_device_pw', self, cache_global=True)
         self._cpu_device_pw._mark_deallocated()
         self._cuda_device_index = cuda_device_index
 
     @persisted('_init_device_pw')
     def _init_device(self) -> torch.device:
         """Attempt to initialize CUDA, and if successful, return the CUDA device.
```

## zensols/deeplearn/cli/app.py

```diff
@@ -9,22 +9,24 @@
 import logging
 import gc
 import sys
 import itertools as it
 import copy as cp
 from io import TextIOBase
 from pathlib import Path
+import pandas as pd
 from zensols.persist import dealloc, Deallocatable, PersistedWork, persisted
 from zensols.config import (
     Writable, Configurable, ImportConfigFactory, DictionaryConfig
 )
 from zensols.cli import (
     ApplicationError, Application, ApplicationFactory,
     ActionCliManager, Invokable, CliHarness,
 )
+from zensols.datdesc import DataDescriber
 from zensols.dataset import (
     SplitStashContainer, StratifiedStashSplitKeyContainer
 )
 from zensols.deeplearn import DeepLearnError, TorchConfig, ModelSettings
 from zensols.deeplearn.model import ModelFacade, ModelError, ModelPacker
 from zensols.deeplearn.result import (
     ModelResultManager, ModelResultReporter, PredictionsDataFrameFactory,
@@ -223,18 +225,20 @@
 
     """
     CLI_META = ActionCliManager.combine_meta(
         FacadeApplication,
         {'mnemonic_overrides': {'result_summary': 'summary',
                                 'result_ids': 'resids',
                                 'metrics': 'results',
+                                #'save_results': 'save',
                                 'majority_label_metrics': 'majlab',
                                 'compare_results': 'cmpres'},
          'option_overrides': {'include_validation': {'long_name': 'validation',
                                                      'short_name': None},
+                              'describe': {'short_name': None},
                               'out_file': {'long_name': 'outfile',
                                            'short_name': 'o'}}})
 
     def result_summary(self, out_file: Path = None,
                        include_validation: bool = False):
         """Create a summary of all archived results.
 
@@ -249,33 +253,44 @@
             rm: ModelResultManager = facade.result_manager
             self._enable_cli_logging(facade)
             reporter = ModelResultReporter(rm)
             reporter.include_validation = include_validation
             return reporter.dump(out_file)
 
     def metrics(self, sort: str = 'wF1', res_id: str = None,
-                out_file: Path = None):
+                out_file: Path = None, describe: bool = False):
         """Write a spreadhseet of label performance metrics for a previously
         trained and tested model.
 
         :param sort_col: the column to sort results
 
         :param res_id: the result ID or use the last if not given
 
         :param out_file: the output path
 
+        :param describe: whether to create Zensols LaTeX ready results
+
         """
-        if out_file is None:
-            out_file = Path('metrics.csv')
-        with dealloc(self.create_facade()) as facade:
-            df = facade.get_predictions_factory(name=res_id).metrics_dataframe
-            df = df.sort_values(sort, ascending=False).reset_index(drop=True)
-            df.to_csv(out_file)
-            self._enable_cli_logging(facade)
-            logger.info(f'wrote: {out_file}')
+        if describe:
+            if out_file is None:
+                out_file = Path('model-results')
+            with dealloc(self.create_facade()) as facade:
+                dd: DataDescriber = facade.get_described_results(res_id)
+                dd.output_dir = out_file
+                dd.save(include_excel=True)
+        else:
+            if out_file is None:
+                out_file = Path('metrics.csv')
+            with dealloc(self.create_facade()) as facade:
+                df: pd.DataFrame = facade.get_predictions_factory(name=res_id).\
+                    metrics_dataframe.sort_values(sort, ascending=False).\
+                    reset_index(drop=True)
+                df.to_csv(out_file)
+        self._enable_cli_logging(facade)
+        logger.info(f'wrote: {out_file}')
 
     def result_ids(self):
         """Show all archived result IDs."""
         with dealloc(self.create_facade()) as facade:
             rm: ModelResultManager = facade.result_manager
             print('\n'.join(rm.results_stash.keys()))
```

## zensols/deeplearn/model/facade.py

```diff
@@ -1,14 +1,14 @@
-from __future__ import annotations
 """Client entry point to the model.
 
 """
-__author__ = 'Paul Landes'
 
-from typing import Any, Callable, List, Union, Iterable, Type
+from __future__ import annotations
+__author__ = 'Paul Landes'
+from typing import Any, Callable, List, Union, Iterable, Type, Dict, ClassVar
 from dataclasses import dataclass, field, InitVar
 import sys
 import os
 import logging
 import pandas as pd
 from io import TextIOBase
 from pathlib import Path
@@ -19,24 +19,26 @@
     Writable,
     ImportConfigFactory,
 )
 from zensols.persist import (
     persisted, PersistableContainer, PersistedWork,
     Deallocatable, Stash,
 )
+from zensols.datdesc import DataDescriber, DataFrameDescriber
 from zensols.dataset import DatasetSplitStash
 from zensols.deeplearn import ModelError, NetworkSettings, ModelSettings
 from zensols.deeplearn.vectorize import (
     SparseTensorFeatureContext, FeatureVectorizerManagerSet,
 )
 from zensols.deeplearn.batch import (
     Batch, DataPoint, BatchStash, BatchMetadata, BatchFeatureMapping
 )
 from zensols.deeplearn.result import (
-    EpochResult, ModelResult, ModelResultManager, PredictionsDataFrameFactory
+    EpochResult, ModelResult, ModelResultManager,
+    PredictionsDataFrameFactory, ModelResultReporter,
 )
 from . import (
     ModelManager, ModelExecutor, PredictionMapper,
     FacadeClassExplorer, ResultAnalyzer, ModelPacker
 )
 
 logger = logging.getLogger(__name__)
@@ -50,15 +52,15 @@
     More common attributes, such as the learning rate and number of epochs, are
     properties that dispatch to :py:obj:`executor`.  For the others, go
     directly to the property.
 
     :see: :class:`zensols.deeplearn.domain.ModelSettings`
 
     """
-    SINGLETONS = {}
+    _SINGLETONS: ClassVar[Dict[str, ModelFacade]] = {}
 
     config: Configurable = field()
     """The configuraiton used to create the facade, and used to create a new
     configuration factory to load models.
 
     """
     config_factory: InitVar[ConfigFactory] = field(default=None)
@@ -105,20 +107,24 @@
                 self.progress_bar_cols = term_width - 5
             except OSError:
                 logger.debug('unable to automatically determine ' +
                              'terminal width--skipping')
                 self.progress_bar_cols = None
 
     @classmethod
-    def get_singleton(cls, *args, **kwargs) -> Any:
-        key = str(cls)
-        inst = cls.SINGLETONS.get(key)
+    def get_singleton(cls, *args, **kwargs) -> ModelFacade:
+        """Return the singleton application using ``args`` and ``kwargs`` as
+        initializer arguments.
+
+        """
+        key: str = str(cls)
+        inst: ModelFacade = cls._SINGLETONS.get(key)
         if inst is None:
             inst = cls(*args, **kwargs)
-            cls.SINGLETONS[key] = inst
+            cls._SINGLETONS[key] = inst
         return inst
 
     def _init_config_factory(self, config_factory: ConfigFactory):
         if isinstance(config_factory, ImportConfigFactory):
             params = config_factory.__dict__
             keeps = set('reload shared reload_pattern'.split())
             params = {k: params[k] for k in set(params.keys()) & keeps}
@@ -332,15 +338,15 @@
 
         """
         self.clear()
         self.config.reload()
 
     def deallocate(self):
         super().deallocate()
-        self.SINGLETONS.pop(str(self.__class__), None)
+        self._SINGLETONS.pop(str(self.__class__), None)
 
     @classmethod
     def load_from_path(cls, path: Path, *args, **kwargs) -> ModelFacade:
         """Construct a new facade from the data saved in a persisted model file.
         This uses the :py:meth:`.ModelManager.load_from_path` to reconstruct the
         returned facade, which means some attributes are taken from default if
         not taken from ``*args`` or ``**kwargs``.
@@ -647,14 +653,33 @@
 
         """
         rm: ModelResultManager = self.result_manager
         if key is None:
             key = rm.get_last_key()
         return ResultAnalyzer(self.executor, key, cache_previous_results)
 
+    def get_described_results(self, res_id: str = None) -> DataDescriber:
+        """Create Zensols LaTeX ready results.  This includes a summary from the
+        :class:`.ModelResultReporter` and detailed results using ``res_id``.
+
+        :param res_id: the result ID or use the last if not given
+
+        """
+        rm: ModelResultManager = self.result_manager
+        pfac: PredictionsDataFrameFactory = \
+            self.get_predictions_factory(name=res_id)
+        reporter = ModelResultReporter(rm, include_validation=True)
+        summary: DataFrameDescriber = reporter.dataframe_describer
+        res: DataFrameDescriber = pfac.metrics_dataframe_describer
+        summary.name = 'Summary'
+        res.name = f'Run {pfac.result.index}'
+        return DataDescriber(
+            name=f'{self.model_settings.model_name} Model Results',
+            describers=(summary, res))
+
     @property
     def class_explorer(self) -> FacadeClassExplorer:
         return self._create_facade_explorer()
 
     def _create_facade_explorer(self) -> FacadeClassExplorer:
         """Return a facade explorer used to print the facade's object graph.
```

## zensols/deeplearn/model/format.py

```diff
@@ -37,27 +37,27 @@
     """The columns used in the summary report."""
 
     by_label_columns: Tuple[str] = field(
         default=tuple('mF1 mP mR MF1 MP MR acc count'.split()))
     """The columns used in the by-label report."""
 
     name_replace: Tuple[str, str] = field(default=None)
-    """If provided, a tuple of ``(regular expression, replacement)`` string given
-    to :func:`re.sub` in the name column of generated tables.
+    """If provided, a tuple of ``(regular expression, replacement)`` string
+    given to :func:`re.sub` in the name column of generated tables.
 
     """
     sort_column: str = field(default='mF1')
     """The column to sort, with the exception of the majority label, which is
     always first.
 
     """
     majority_label_res_id: Union[str, bool] = field(default=True)
-    """Indicates how to create (if any) the majority label performance metrics.  If
-    a string, use as the result id (``res_id``) of previous result set used to
-    compute the majority label statitics to include in the summary.  If
+    """Indicates how to create (if any) the majority label performance metrics.
+    If a string, use as the result id (``res_id``) of previous result set used
+    to compute the majority label statitics to include in the summary.  If
     ``True`` use the results from the last tested model.  If ``None`` the
     majority label is not added.
 
     """
     precision: int = field(default=3)
     """The number of signification digits to format results."""
```

## zensols/deeplearn/model/manager.py

```diff
@@ -35,33 +35,34 @@
     config_factory: ConfigFactory = field()
     """The configuration factory to be used to create the ``ModelExecutor``."""
 
     model_executor_name: str = field(default=None)
     """The configuration entry and name of the ``ModelExecutor`` instance."""
 
     persist_random_seed_context: bool = field(default=True)
-    """If ``True`` persist the current random seed state, which helps in creating
-    consistent results across train/test/validate.
+    """If ``True`` persist the current random seed state, which helps in
+    creating consistent results across train/test/validate.
 
     """
     keep_last_state_dict: bool = field(default=False)
     """Whether or not to store the PyTorch module state in attribute
     ``last_saved_state_dict``.
 
     """
     @staticmethod
     def _get_paths(path: Path) -> Tuple[Path, Path]:
         return (path / 'state.pt', path / 'weight.pt')
 
     @classmethod
     def load_from_path(cls, path: Path) -> ModelManager:
-        """Load and return an instance of this class from a previously saved model.
-        This method exists to recreate a :class:`.ModelManager` from a saved
-        file from scratch.  The returned model manager can be used to create
-        the executor or :class:`ModelFacade` using :obj:``config_factory``.
+        """Load and return an instance of this class from a previously saved
+        model.  This method exists to recreate a :class:`.ModelManager` from a
+        saved file from scratch.  The returned model manager can be used to
+        create the executor or :class:`ModelFacade` using
+        :obj:``config_factory``.
 
         :param path: points to the model file persisted with
                      :py:meth:`_save_executor`
 
         :return: an instance of :class:`.ModelManager` that was used to save
                  the executor pointed by ``path``
 
@@ -71,16 +72,16 @@
             logger.debug(f'keys: {checkpoint.keys()}')
         config_factory = checkpoint['config_factory']
         model_executor_name = checkpoint['model_executor_name']
         persist_random = checkpoint['random_seed_context'] is not None
         return cls(path, config_factory, model_executor_name, persist_random)
 
     def load_executor(self) -> 'ModelExecutor':
-        """Load the model the last saved model from the disk.  This is used load an
-        instance of a ``ModelExecutor`` with all previous state completely in
+        """Load the model the last saved model from the disk.  This is used load
+        an instance of a ``ModelExecutor`` with all previous state completely in
         tact.  It does this by using an instance of
         :class:`zensols.config.factory.Configurable` and a
         :class:`zensols.config.factory.ImportConfigFactory` to reconstruct the
         executor and it's state by recreating all instances.
 
         After the executor has been recreated with the factory, the previous
         model results and model weights are restored.
@@ -115,16 +116,16 @@
         if scheduler is not None and scheduler_state is not None:
             scheduler.load_state_dict(scheduler_state)
         if logger.isEnabledFor(logging.INFO):
             logger.info(f'loaded model from {executor.model_settings.path} ' +
                         f'on device {model.device}')
 
     def _load_model_optim_weights(self, executor):
-        """Load the model and optimizer weights from the last check point.  A side
-        effect is that the optimizer is recreated.
+        """Load the model and optimizer weights from the last check point.  A
+        side effect is that the optimizer is recreated.
 
         """
         model = executor._get_or_create_model()
         checkpoint = self._get_checkpoint(True)
         self._load_optimizer_state(executor, model, checkpoint)
 
     def _save_executor(self, executor: Any):
@@ -177,19 +178,18 @@
 
     def _set_random_seed(self, checkpoint: Dict[str, Any]):
         random_seed_context = checkpoint['random_seed_context']
         if random_seed_context is not None:
             TorchConfig.set_random_seed(**random_seed_context)
 
     def _save_final_trained_results(self, executor):
-        """Save the results of the :class:`.ModelResult`, which is typically called
-        when the validation loss decreases.  Note this does not save the model
-        weights since doing so might clobber with an overtrained model
-        (assuming the last converved with the lowest validation loss was
-        saved).
+        """Save the results of the :class:`.ModelResult`, which is typically
+        called when the validation loss decreases.  Note this does not save the
+        model weights since doing so might clobber with an overtrained model
+        (assuming the last converved with the lowest validation loss was saved).
 
         :param executor: the executor with the model results to save
 
         """
         if logger.isEnabledFor(logging.DEBUG):
             logger.debug(f'updating results: {self.path}')
         checkpoint = self._get_checkpoint(False)
@@ -217,16 +217,16 @@
         if save_weights:
             with time(f'saved model weights to {weight_path}'):
                 torch.save(weights, str(weight_path))
         with time(f'saved model state to {state_path}'):
             torch.save(checkpoint, str(state_path))
 
     def _get_checkpoint(self, load_weights: bool) -> Dict[str, Any]:
-        """The check point from loaded by the PyTorch framework.  This contains the
-        executor, model results, and model weights.
+        """The check point from loaded by the PyTorch framework.  This contains
+        the executor, model results, and model weights.
 
         :param load_weights: if ``True`` load the weights from the weights file
                              and add it to the checkpoint state
 
         """
         state_path, weight_path = self._get_paths(self.path)
         if not load_weights:
```

## zensols/deeplearn/model/module.py

```diff
@@ -1,14 +1,14 @@
 """Base class PyTorch module and utilities.
 
 """
 __author__ = 'Paul Landes'
 
 from types import ModuleType
-from typing import Union, Type
+from typing import Union, Type, ClassVar
 from abc import abstractmethod, ABCMeta
 import logging
 import torch
 from torch import nn
 from torch import Tensor
 from zensols.introspect import ClassImporter
 from zensols.persist import PersistableContainer
@@ -25,29 +25,29 @@
 logger = logging.getLogger(__name__)
 
 
 class DebugModule(nn.Module):
     """A utility base class that makes logging more understandable.
 
     """
-    DEBUG_DEVICE = False
+    DEBUG_DEVICE: ClassVar[bool] = False
     """If ``True``, add tensor devices to log messages."""
 
-    DEBUG_TYPE = False
+    DEBUG_TYPE: ClassVar[bool] = False
     """If ``True``, add tensor shapes to log messages."""
 
-    DEBUG_CLASS = True
+    DEBUG_CLASS: ClassVar[bool] = True
     """If ``True``, add the logging class to log messages."""
 
-    MODULE_NAME = None
-    """The module name used in the logging message.  This is set in each inherited
-    class.
+    MODULE_NAME: ClassVar[str] = None
+    """The module name used in the logging message.  This is set in each
+    inherited class.
 
     """
-    _DEBUG_MESSAGE_MAX_LEN = 100
+    _DEBUG_MESSAGE_MAX_LEN: ClassVar[int] = 100
 
     def __init__(self, sub_logger: logging.Logger = None):
         """Initialize.
 
         :param sub_logger: used to log activity in this module so they logged
                            module comes from some parent model
 
@@ -71,27 +71,27 @@
     def _debug(self, msg: str):
         """Debug a message using the module name in the description.
 
         """
         if self.logger.isEnabledFor(logging.DEBUG):
             if msg is not None:
                 if len(msg) > self._DEBUG_MESSAGE_MAX_LEN:
-                    msg = msg[:self._DEBUG_MESSAGE_MAX_LEN-3] + '...'
+                    msg = msg[:self._DEBUG_MESSAGE_MAX_LEN - 3] + '...'
             mname = self.MODULE_NAME
             cls = self.__class__.__name__
             mname = '' if mname is None else f'[{mname}]'
             if self.DEBUG_CLASS:
                 prefix = f'{cls}{mname}'
             else:
                 prefix = mname if len(mname) > 0 else f'[{cls}]'
             self.logger.debug(f'{prefix} {msg}')
 
     def _shape_debug(self, msg: str, x: Tensor):
-        """Debug a message using the module name in the description and include the
-        shape.
+        """Debug a message using the module name in the description and include
+        the shape.
 
         """
         if self.logger.isEnabledFor(logging.DEBUG):
             if x is None:
                 shape, device, dtype = [None] * 3
             else:
                 shape, device, dtype = x.shape, x.device, x.dtype
@@ -99,25 +99,25 @@
             if self.DEBUG_DEVICE:
                 msg += f', device: {device}'
             if self.DEBUG_TYPE:
                 msg += f', type: {dtype}'
             self._debug(msg)
 
     def _bail(self):
-        """A convenience method to assist in debugging.  This is useful when the output
-        isn't in the correct form for the :class:`.ModelExecutor`.
+        """A convenience method to assist in debugging.  This is useful when the
+        output isn't in the correct form for the :class:`.ModelExecutor`.
 
         """
         self.logger.debug('-' * 60)
         raise EarlyBailError()
 
 
 class BaseNetworkModule(DebugModule, PersistableContainer, metaclass=ABCMeta):
-    """A utility base network module that contains ubiquitous, but optional layers,
-    such as dropout and batch layeres, activation, etc.
+    """A utility base network module that contains ubiquitous, but optional
+    layers, such as dropout and batch layeres, activation, etc.
 
     .. document private functions
     .. automethod:: _forward
 
     """
     def __init__(self, net_settings: NetworkSettings,
                  sub_logger: logging.Logger = None):
@@ -221,27 +221,28 @@
         else:
             if self.logger.isEnabledFor(logging.DEBUG):
                 self._debug(f'activation: {self.activation_function}')
             x = self.activation_function(x)
         return x
 
     def _forward_batch_act_drop(self, x: Tensor) -> Tensor:
-        """Forward convolution, batch normalization, pool, activation and dropout for
-        those layers that are configured.
+        """Forward convolution, batch normalization, pool, activation and
+        dropout for those layers that are configured.
 
-        :see: `Sunghean et al <http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf>`_
-        :see: `Ioffe et al <https://arxiv.org/pdf/1502.03167.pdf>`_
+        :see: `Sunghean et al. <http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf>`_
+
+        :see: `Ioffe et al. <https://arxiv.org/pdf/1502.03167.pdf>`_
 
         """
         x = self._forward_batch_norm(x)
         x = self._forward_activation(x)
         x = self._forward_dropout(x)
         return x
 
     def forward(self, x: Union[Batch, Tensor], *args, **kwargs) -> Tensor:
-        """Main forward takes a batch for top level modules, or a tensor for framework
-        based layers.  Return the transformed tensor.
+        """Main forward takes a batch for top level modules, or a tensor for
+        framework based layers.  Return the transformed tensor.
 
         """
         if self.logger.isEnabledFor(logging.DEBUG) and isinstance(x, Batch):
             self._debug(f'input batch: {x}')
         return self._forward(x, *args, **kwargs)
```

## zensols/deeplearn/model/pred.py

```diff
@@ -1,13 +1,12 @@
-from __future__ import annotations
 """Contains classs for creating predictions from a trained model.
 
 """
+from __future__ import annotations
 __author__ = 'Paul Landes'
-
 from typing import Tuple, List, Any, Type
 from abc import ABCMeta, abstractmethod
 from dataclasses import dataclass, field
 from zensols.persist import PersistableContainer, persisted
 from zensols.deeplearn.batch import DataPoint, Batch, BatchStash
 from zensols.deeplearn.result import ResultsContainer
 from .. import ModelError
@@ -66,17 +65,17 @@
         dps: Tuple[DataPoint] = tuple(
             map(lambda f: self._create_data_point(dpcls, f), features))
         return self.batch_stash.create_batch(dps)
 
     @property
     @persisted('_batches')
     def batches(self) -> List[Batch]:
-        """Create a prediction batch that is detached from any stash resources, except
-        this instance that created it.  This creates a tuple of features, each
-        of which is used to create a :class:`.DataPoint`.
+        """Create a prediction batch that is detached from any stash resources,
+        except this instance that created it.  This creates a tuple of features,
+        each of which is used to create a :class:`.DataPoint`.
 
         """
         return self._create_batches()
 
     def _create_batches(self) -> List[Batch]:
         bcls: Type[Batch] = self.batch_stash.batch_type
         batches = []
@@ -88,16 +87,16 @@
             dec_batch.batch_stash = self.batch_stash
             dec_batch.data_points = batch.data_points
             batches.append(dec_batch)
         return batches
 
     def _create_data_point(self, cls: Type[DataPoint],
                            feature: Any) -> DataPoint:
-        """Create a data point.  This base implementation creates it with the passed
-        parameters.
+        """Create a data point.  This base implementation creates it with the
+        passed parameters.
 
         :param cls: the data point class of which to make an instance
 
         :param stash: to be set as the batch stash on the data point and the
                       caller
 
         :param feature: to be set as the third argument and generate from
```

## zensols/deeplearn/resources/cli-pack.conf

```diff
@@ -1,10 +1,10 @@
 # description: facade application for creating a model distribution zip file
 
 [deeplearn_model_packer]
 class_name = zensols.deeplearn.model.ModelPacker
 executor = instance: executor
-version = 0.0.1
+version = 0.0.0
 
 [deeplearn_fac_package_app]
 class_name = zensols.deeplearn.cli.FacadePackageApplication
 packer = instance: deeplearn_model_packer
```

## zensols/deeplearn/result/domain.py

```diff
@@ -1,15 +1,17 @@
-from __future__ import annotations
 """Contains contain classes for results generated from training and testing a
 model.
 
 """
-__author__ = 'Paul Landes'
 
-from typing import List, Dict, Set, Iterable, Any, Type, Tuple, Callable
+from __future__ import annotations
+__author__ = 'Paul Landes'
+from typing import (
+    List, Dict, Set, Iterable, Any, Type, Tuple, Callable, ClassVar
+)
 from dataclasses import dataclass, field, InitVar
 from enum import Enum
 from abc import ABCMeta, abstractmethod
 import logging
 import sys
 import copy as cp
 from collections import OrderedDict
@@ -831,15 +833,15 @@
 
 @dataclass
 class ModelResult(Dictable):
     """A container class used to capture the training, validation and test
     results.  The data captured is used to report and plot curves.
 
     """
-    RUNS = 1
+    RUNS: ClassVar[int] = 1
 
     config: Configurable = field()
     """Useful for retrieving hyperparameter settings later after unpersisting
     from disk.
 
     """
```

## zensols/deeplearn/result/pred.py

```diff
@@ -1,23 +1,24 @@
 """This creates Pandas dataframes containing predictions.
 
 """
 __author__ = 'Paul Landes'
 
-from typing import Callable, List, Iterable, Any
+from typing import Callable, List, Iterable, Any, ClassVar, Dict, Tuple
 from dataclasses import dataclass, field
 import logging
 import sys
 import itertools as it
 from pathlib import Path
 from frozendict import frozendict
 import numpy as np
 import pandas as pd
 from sklearn.preprocessing import LabelEncoder
 from zensols.persist import persisted
+from zensols.datdesc import DataFrameDescriber
 from zensols.deeplearn.vectorize import (
     CategoryEncodableFeatureVectorizer,
     FeatureVectorizerManagerSet,
 )
 from zensols.deeplearn.batch import Batch, BatchStash, DataPoint
 from . import (
     ModelResultError, ModelResult, EpochResult, ClassificationMetrics
@@ -31,63 +32,99 @@
     """Create a Pandas data frame containing results from a result as output from a
     ``ModelExecutor``.  The data frame contains the feature IDs, labels,
     predictions mapped back to their original value from the feature data item.
 
     Currently only classification models are supported.
 
     """
-    METRIC_DESCRIPTIONS = frozendict(
-        {'wF1': 'weighted F1',
-         'wP': 'weighted precision',
-         'wR': 'weighted recall',
-         'mF1': 'micro F1',
-         'mP': 'micro precision',
-         'mR': 'micro recall',
-         'MF1': 'macro F1',
-         'MP': 'macro precision',
-         'MR': 'macro recall',
-         'correct': 'the number of correct classifications',
-         'count': 'the number of data points in the test set',
-         'acc': 'accuracy',
-         })
+    METRIC_DESCRIPTIONS: ClassVar[Dict[str, str]] = frozendict({
+        'wF1': 'weighted F1',
+        'wP': 'weighted precision',
+        'wR': 'weighted recall',
+        'mF1': 'micro F1',
+        'mP': 'micro precision',
+        'mR': 'micro recall',
+        'MF1': 'macro F1',
+        'MP': 'macro precision',
+        'MR': 'macro recall',
+        'correct': 'the number of correct classifications',
+        'count': 'the number of data points in the test set',
+        'acc': 'accuracy',
+
+        'wF1t': 'weighted F1 on the test set',
+        'wPt': 'weighted precision on the test set',
+        'wRt': 'weighted recall on the test set',
+        'mF1t': 'micro F1 on the test set',
+        'mPt': 'micro precision on the test set',
+        'mRt': 'micro recall on the test set',
+        'MF1t': 'macro F1 on the test set',
+        'MPt': 'macro precision on the test set',
+        'MRt': 'macro recall on the test set',
+        'acct': 'accuracy on the test set',
+
+        'wF1v': 'weighted F1 on the validation set',
+        'wPv': 'weighted precision on the validation set',
+        'wRv': 'weighted recall on the validation set',
+        'mF1v': 'micro F1 on the validation set',
+        'mPv': 'micro precision on the validation set',
+        'mRv': 'micro recall on the validation set',
+        'MF1v': 'macro F1 on the validation set',
+        'MPv': 'macro precision on the validation set',
+        'MRv': 'macro recall on the validation set',
+        'accv': 'accuracy on the validation set',
+
+        'train_occurs': 'the number of data points used to train the model',
+        'test_occurs': 'the number of data points used to test the model',
+        'validation_occurs': 'the number of data points used to validate the model',
+
+        'label': 'the model class',
+        'name': 'the model or result set name',
+        'file': 'the directory name of the results',
+        'start': 'when the test started',
+        'train_duration': 'the time it took to train the model in HH:MM:SS',
+        'converged': 'the last epoch with the lowest loss',
+        'features': 'the features used in the model'})
     """Dictionary of performance metrics column names to human readable
     descriptions.
 
     """
-    ID_COL = 'id'
+    ID_COL: ClassVar[str] = 'id'
     """The data point ID in the generated dataframe in :obj:`dataframe` and
     :obj:`metrics_dataframe`.
 
     """
-    LABEL_COL = 'label'
+    LABEL_COL: ClassVar[str] = 'label'
     """The gold label column in the generated dataframe in :obj:`dataframe` and
     :obj:`metrics_dataframe`.
 
     """
-    PREDICTION_COL = 'pred'
+    PREDICTION_COL: ClassVar[str] = 'pred'
     """The prediction column in the generated dataframe in :obj:`dataframe` and
     :obj:`metrics_dataframe`.
 
     """
-    CORRECT_COL = 'correct'
+    CORRECT_COL: ClassVar[str] = 'correct'
     """The correct/incorrect indication column in the generated dataframe in
     :obj:`dataframe` and :obj:`metrics_dataframe`.
 
     """
-    METRICS_DF_WEIGHTED_COLUMNS = tuple('wF1 wP wR'.split())
+    METRICS_DF_WEIGHTED_COLUMNS: ClassVar[Tuple[str, ...]] = tuple(
+        'wF1 wP wR'.split())
     """Weighed performance metrics columns."""
 
-    METRICS_DF_MICRO_COLUMNS = tuple('mF1 mP mR'.split())
+    METRICS_DF_MICRO_COLUMNS: ClassVar[Tuple[str, ...]] = tuple(
+        'mF1 mP mR'.split())
     """Micro performance metrics columns."""
 
-    METRICS_DF_MACRO_COLUMNS = tuple('MF1 MP MR'.split())
+    METRICS_DF_MACRO_COLUMNS: ClassVar[Tuple[str, ...]] = tuple(
+        'MF1 MP MR'.split())
     """Macro performance metrics columns."""
 
-    METRICS_DF_COLUMNS = tuple(('label wF1 wP wR mF1 mP mR MF1 MP MR ' +
-                                'correct acc count').split())
+    METRICS_DF_COLUMNS: ClassVar[Tuple[str, ...]] = tuple(
+        'label wF1 wP wR mF1 mP mR MF1 MP MR correct acc count'.split())
     """
     :see: :obj:`metrics_dataframe`
     """
     source: Path = field()
     """The source file from where the results were unpickled."""
 
     result: ModelResult = field()
@@ -140,15 +177,14 @@
         return self.result.name
 
     def _transform_dataframe(self, batch: Batch, labs: List[str],
                              preds: List[str]):
         transform: Callable = self.data_point_transform
         rows = []
         for dp, lab, pred in zip(batch.data_points, labs, preds):
-            assert dp.label == lab
             row = [dp.id, lab, pred, lab == pred]
             row.extend(transform(dp))
             rows.append(row)
         cols = [self.ID_COL, self.LABEL_COL, self.PREDICTION_COL,
                 self.CORRECT_COL]
         cols = cols + list(self.column_names)
         return pd.DataFrame(rows, columns=cols)
@@ -267,14 +303,28 @@
         df: pd.DataFrame = self.dataframe
         le = LabelEncoder()
         gold: np.ndarray = le.fit_transform(df[self.ID_COL].to_list())
         max_id: str = df.groupby(self.ID_COL)[self.ID_COL].agg('count').idxmax()
         majlab: np.ndarray = np.repeat(le.transform([max_id])[0], gold.shape[0])
         return ClassificationMetrics(gold, majlab, gold.shape[0])
 
+    @property
+    def metrics_dataframe_describer(self) -> DataFrameDescriber:
+        """Get a dataframe describer of metrics (see :obj:`metrics_dataframe`).
+
+        """
+        df: pd.DataFrame = self.metrics_dataframe
+        meta: Tuple[Tuple[str, str], ...] = \
+            tuple(map(lambda c: (c, self.METRIC_DESCRIPTIONS[c]), df.columns))
+        return DataFrameDescriber(
+            name=self.name,
+            df=df,
+            desc=f'{self.name.capitalize()} Model Results',
+            meta=meta)
+
 
 @dataclass
 class SequencePredictionsDataFrameFactory(PredictionsDataFrameFactory):
     """Like the super class but create predictions for sequence based models.
 
     :see: :class:`~zensols.deeplearn.model.sequence.SequenceNetworkModule`
```

## zensols/deeplearn/result/report.py

```diff
@@ -1,17 +1,19 @@
 """A utility class to summarize all results in a directory.
 
 """
 __author__ = 'Paul Landes'
 
+from typing import Dict, Tuple, ClassVar
 from dataclasses import dataclass, field
 from pathlib import Path
 import logging
 import pandas as pd
 from zensols.util.time import time
+from zensols.datdesc import DataFrameDescriber
 from zensols.deeplearn import DatasetSplitType
 from . import (
     ModelResult, EpochResult, DatasetResult, ModelResultManager, ArchivedResult,
     Metrics, PredictionsDataFrameFactory,
 )
 
 logger = logging.getLogger(__name__)
@@ -22,15 +24,16 @@
     """Summarize all results in a directory from the output of model execution
     from :class:`~zensols.deeplearn.model.ModelExectuor`.
 
     The class iterates through the pickled binary output files from the run and
     summarizes in a Pandas dataframe, which is handy for reporting in papers.
 
     """
-    METRIC_DESCRIPTIONS = PredictionsDataFrameFactory.METRIC_DESCRIPTIONS
+    METRIC_DESCRIPTIONS: ClassVar[Dict[str, str]] = \
+        PredictionsDataFrameFactory.METRIC_DESCRIPTIONS
     """Dictionary of performance metrics column names to human readable
     descriptions.
 
     """
     result_manager: ModelResultManager = field()
     """Contains the results to report on--and specifically the path to directory
     where the results were persisted.
@@ -70,15 +73,16 @@
             else:
                 conv_epoch = None
                 ver: EpochResult = None
             if test is not None:
                 vm: Metrics = ver.metrics
                 tm: Metrics = test.metrics
                 features = ', '.join(res.decoded_attributes)
-                row = [res.name, fname, train.start_time, dur, conv_epoch, features]
+                row = [res.name, fname, train.start_time, dur,
+                       conv_epoch, features]
                 row.extend([
                     tm.weighted.f1, tm.weighted.precision, tm.weighted.recall,
                     tm.micro.f1, tm.micro.precision, tm.micro.recall,
                     tm.macro.f1, tm.macro.precision, tm.macro.recall,
                     tm.accuracy])
                 if self.include_validation:
                     row.extend([
@@ -91,14 +95,30 @@
                     test.statistics[dpt_key]])
                 rows.append(row)
                 if logger.isEnabledFor(logging.INFO):
                     logger.info('result calculation complete for ' +
                                 f'{res.name} ({fname})')
         return pd.DataFrame(rows, columns=cols)
 
+    @property
+    def dataframe_describer(self) -> DataFrameDescriber:
+        """Get a dataframe describer of metrics (see :obj:`metrics_dataframe`).
+
+        """
+        df: pd.DataFrame = self.dataframe
+        meta: Tuple[Tuple[str, str], ...] = \
+            tuple(map(lambda c: (c, self.METRIC_DESCRIPTIONS[c]), df.columns))
+        name: str = (self.result_manager.name.capitalize() +
+                     ' Summarized Model Results')
+        return DataFrameDescriber(
+            name='Summarized Model Results',
+            df=df,
+            desc=name,
+            meta=meta)
+
     def dump(self, path: Path) -> pd.DataFrame:
         """Create the summarized results and write them to the file system.
 
         """
         with time(f'wrote results summary: {path}'):
             df: pd.DataFrame = self.dataframe
             df.to_csv(path)
```

## Comparing `zensols.deeplearn-1.6.0.dist-info/METADATA` & `zensols.deeplearn-1.6.1.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 Metadata-Version: 2.1
 Name: zensols.deeplearn
-Version: 1.6.0
+Version: 1.6.1
 Summary: General deep learing utility library
 Home-page: https://github.com/plandes/deeplearn
-Download-URL: https://github.com/plandes/deeplearn/releases/download/v1.6.0/zensols.deeplearn-1.6.0-py3-none-any.whl
+Download-URL: https://github.com/plandes/deeplearn/releases/download/v1.6.1/zensols.deeplearn-1.6.1-py3-none-any.whl
 Author: Paul Landes
 Author-email: landes@mailc.net
 Keywords: tooling
 Description-Content-Type: text/markdown
 Requires-Dist: numpy (~=1.23.1)
 Requires-Dist: scipy (~=1.8.1)
 Requires-Dist: scikit-learn (~=1.1.2)
 Requires-Dist: pandas (~=1.4.0)
 Requires-Dist: matplotlib (~=3.5.2)
-Requires-Dist: torch (~=1.12.1)
-Requires-Dist: torchvision
+Requires-Dist: torch (~=1.13.1)
+Requires-Dist: torchvision (~=0.14.0)
 Requires-Dist: zensols.install (~=0.2.0)
-Requires-Dist: zensols.util (~=1.12.0)
+Requires-Dist: zensols.datdesc (~=0.0.1)
 
 # DeepZensols Deep Learning Framework
 
 [![PyPI][pypi-badge]][pypi-link]
 [![Python 3.9][python39-badge]][python39-link]
 [![Python 3.10][python310-badge]][python310-link]
 [![Build Status][build-badge]][build-link]
```

## Comparing `zensols.deeplearn-1.6.0.dist-info/RECORD` & `zensols.deeplearn-1.6.1.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -7,67 +7,67 @@
 zensols/dataset/leaveout.py,sha256=mubHPcEwJzUoNycKEET57su0t2gb515ndcw4uZR3f5g,3211
 zensols/dataset/outlier.py,sha256=41dVfILnL0R3n5brr5063jWFkRQfD-IoGL4Jr04MXKo,8343
 zensols/dataset/split.py,sha256=rgMUe1Znv8jbZ42JB9K8ngXDKqq_ZkujCT-LcXBco58,10965
 zensols/dataset/stash.py,sha256=VRUZwyuI79UyFDoLAADeaddFOcDe4aGHfn04wS4hqWY,9725
 zensols/deeplearn/__init__.py,sha256=MJ8nKg1_nGfg2NHVI6_XzXWducfsOV3FZ1-XgS5H72w,202
 zensols/deeplearn/domain.py,sha256=adJW0mOMO6opc632_UYpNd62dS6z_jE4TSLs1quLoDg,16052
 zensols/deeplearn/observer.py,sha256=BNS8tnzvHsEbN9s0BGSeRG5GbycTkKJlSU7PRSGc5RU,8475
-zensols/deeplearn/torchconfig.py,sha256=DmJuAIEnCc9emnv8j_74qmTcinUZGn2BTAtWE6w9i1I,21749
+zensols/deeplearn/torchconfig.py,sha256=Y35MFS-WjIW__ky3qvo_uCBoFGqez4rYhm58BPP3sZw,22070
 zensols/deeplearn/torchtype.py,sha256=DgAgFqarbhn58XmAzllEwsW8x4cbGcJYBt7xVs7oo7g,5141
 zensols/deeplearn/batch/__init__.py,sha256=4Xov58tGi7AARHdQj-XkLQ5q8_4Ad7hwArsmZl5tvw4,208
 zensols/deeplearn/batch/domain.py,sha256=5-6ovqRUoI17pSAQnFMt8qTYLdnRBIKnHxtyxx55dZQ,21605
 zensols/deeplearn/batch/interface.py,sha256=grrAPStPgN9kuBnTQhShdGhinlTyLvys8BB4wXfKs6E,1569
 zensols/deeplearn/batch/mapping.py,sha256=MEdjnoItEDe5Cg2HznGmXphW7qkrVt85h5ENCWi1u0A,7202
 zensols/deeplearn/batch/meta.py,sha256=yQQ2BNItpsuvQTB_zmCN28s-4fSmEpwHUgSoc0lReg8,2904
 zensols/deeplearn/batch/multi.py,sha256=TuHGvz8bsJDaZ6KX2JBzFUZ3xPIfPuJmIEcYdxUqR3M,1738
 zensols/deeplearn/batch/stash.py,sha256=PVDUJlePLoU0a-AsQ-s5fwWOFcL2W-AAcSxfDJVTIUo,15680
 zensols/deeplearn/cli/__init__.py,sha256=K3UdhLC275kO67S3w-Y3kweoAbrk9EegwNaCRpAx7d0,19
-zensols/deeplearn/cli/app.py,sha256=iBSfgh9c8-1oBwf1Iu8Pk39-o084nciYVNIl7jDQyf4,30223
+zensols/deeplearn/cli/app.py,sha256=T3RoiB1NnxmnpZV4NMrR6jhHr11Nuy3bThnT0_1glZY,30885
 zensols/deeplearn/dataframe/__init__.py,sha256=dR6Uauwp-HnR2CGqOWRrUmGyfdsrFCyNNNS13P-oH8g,212
 zensols/deeplearn/dataframe/batch.py,sha256=KbNZJ56y3E3qVwD-wnPVywBS05p7k5YGhTr1M9AlzNo,3720
 zensols/deeplearn/dataframe/util.py,sha256=GfHOrH-OYlIDR5WDw8pDfedfpM5QGZJDHh6ewita6MM,1122
 zensols/deeplearn/dataframe/vectorize.py,sha256=-HI-Ijcld7wm1q9Wg5STBzN8ehs2dWWSaBbDHqWopDU,9426
 zensols/deeplearn/layer/__init__.py,sha256=nORiyKZGQwuvdCGJ3lYLkKihcvpaw4CrP42D2x4xUiM,359
 zensols/deeplearn/layer/conv.py,sha256=ciNMBVh8HJUMpQl5900YxHNuPR2bqsnkMSm9MrBUPFw,9186
 zensols/deeplearn/layer/crf.py,sha256=SrgnCJXZ6Jwtkj_Alg45tjUQyGmTP9ADdqHx9bP2L-U,17314
 zensols/deeplearn/layer/linear.py,sha256=wmfdPBhwL6gjAloDCJQqKDqYmirpvYPCfz0BoUmsXcI,8331
 zensols/deeplearn/layer/recur.py,sha256=G8kSZEndOna1ldZlximg0I40qjiqzhLnEU6a4yFBnw0,4297
 zensols/deeplearn/layer/recurcrf.py,sha256=QSE9VWjnV0j2d48Uwrsx56EyUBK8G-NWqmShYF1OI4s,7346
 zensols/deeplearn/model/__init__.py,sha256=5GntoQtMdTHqgKA-hLQ9cE-EIAZ9nI6BH6YPEdc-YMk,491
 zensols/deeplearn/model/analyze.py,sha256=wjiyWUhVJ0rLaPgEb_uCoWnNM-2zWDaDS0W5RBZxEIQ,4613
 zensols/deeplearn/model/batchiter.py,sha256=F8Hpv_nJRLN0swLYZql1XmlhovNHICzXjKvIFa6chDg,10586
 zensols/deeplearn/model/executor.py,sha256=1EfIjSvJ__U8rcldyQcHhuzPWccJ0eVY_vZi9yjnzws,36975
-zensols/deeplearn/model/facade.py,sha256=TedTwOkG6_J2f0qLMraY1oVo_ssD-zMNU9UQ0QeVYpE,29753
-zensols/deeplearn/model/format.py,sha256=mLtLebM5hWU-loaOAcGEZ8hhAz2evYVMXZyqgoEJzUM,10076
-zensols/deeplearn/model/manager.py,sha256=pduRWPSj_0MarZ9Wg3isI1kv3a_NWpNMoT2x1lNMPX8,10601
+zensols/deeplearn/model/facade.py,sha256=6SbClZ0z-jdsnPn5HJlPwbu2aynkHc89DX8bL4Jmrbk,30926
+zensols/deeplearn/model/format.py,sha256=2u7hyiUx11rStPAh8gZYav339ya0mbGkZ--yCxwuOIg,10075
+zensols/deeplearn/model/manager.py,sha256=a9qQRzw2vXxWU2oXcieJ6zVC-tV8dQFm_7QFF3k25W4,10602
 zensols/deeplearn/model/meta.py,sha256=KjZ_4MWwWtWHY4-RoJ2MX5fMq4SBfO6uq2DbpsKSqQA,958
-zensols/deeplearn/model/module.py,sha256=2PJ28kVRjcvxCj9VRKH92DTw7sD3cteE8N2NsEGYQqE,8413
+zensols/deeplearn/model/module.py,sha256=DTgaGiwCbCgsxT2pXOv6Nu4n7CrIT7Te0UZWqmvOKrQ,8506
 zensols/deeplearn/model/optimizer.py,sha256=wB4liISNb3LeXmxCBadFGRlMOQ5istLGkdAup75oupY,516
 zensols/deeplearn/model/pack.py,sha256=im5iXT5vH7r_qhARlnrekjA8j_uOUUS-2QpJSl-r2vA,3496
-zensols/deeplearn/model/pred.py,sha256=LjcZ60ds2ZED_yUKNWLKpWgjL4zFyKfh6VvY1Hii6w4,3817
+zensols/deeplearn/model/pred.py,sha256=in9PLQMDHCBxb8ml80YP1d8iPACUKZ__2aJnjNy5cQ0,3816
 zensols/deeplearn/model/sequence.py,sha256=LQl_I877uHZ06VxhmxBRHIjDn6FmHiKppnSHj6wAPfY,7204
 zensols/deeplearn/model/trainmng.py,sha256=4_RHmULxq8Tlj-y-iTaAaygTLJq_dpTgGkrXif-9fEo,10544
 zensols/deeplearn/model/wgtexecutor.py,sha256=gn6N9F1fbYZZV07VWdZzUsSgoPID_FkH4I4lH3pqcvA,3710
 zensols/deeplearn/resources/batch.conf,sha256=znXVhkD6CLwRZjOzbj8wV7PG6GxkXjxuPRBLmoXKJ4I,3865
-zensols/deeplearn/resources/cli-pack.conf,sha256=53WA3LRH_ciBzziFadITii1y4QPqgqsOn5SlnDnGnno,329
+zensols/deeplearn/resources/cli-pack.conf,sha256=z9TQR62LQ7XXM2YVLP0MKSqPC4S4ynbjs-gs9QIS8OE,329
 zensols/deeplearn/resources/cli.conf,sha256=6sqtbeKX5EPWn5thCZCXXRdv3H-8pIsbpRcIOVGQX6M,1004
 zensols/deeplearn/resources/default.conf,sha256=HQpALN19aS7SdHXIdU4ghG6SawzI8vDTxJn5PyA18eI,297
 zensols/deeplearn/resources/model.conf,sha256=dy8KTpdC_JjQpWmp_QB8SQsZWhGVaDQbPku4T6CApyM,4391
 zensols/deeplearn/resources/obj.conf,sha256=XeCb43CSnoq2elrNVhhFqEgk9YXGL6Ia9Acrel3Abzo,316
 zensols/deeplearn/resources/observer.conf,sha256=m5ybJmtYWy16e_PJzDPPObaR6brL-qYwdnHXglXfW4k,1015
 zensols/deeplearn/resources/torch.conf,sha256=hgjacnDz3DdqIZJI-XwiqifPaO4G_KHSo3OOII8B5Hg,399
 zensols/deeplearn/result/__init__.py,sha256=MIurqikLNDTvP6ponrF-zC1b2JAXfSBNQXCc7IZ6dkI,269
 zensols/deeplearn/result/compare.py,sha256=O5dToC5a2BA5NU6WopmvXUdyxx6DmbDDg9cov0Cv5_k,1371
-zensols/deeplearn/result/domain.py,sha256=hcWN_yNKnVU4LXnQoMbYYq8UwLqi7EZXX1mtyEsMlrc,34957
+zensols/deeplearn/result/domain.py,sha256=00lX14nWGxiSJzZWvOmYhfAzOk5YzLkAaET-hI7phT8,34990
 zensols/deeplearn/result/manager.py,sha256=MxilsQvMZAl4xxoqBFrgqXZ0VzXVXEZWFBRcn6mtzDM,8940
 zensols/deeplearn/result/plot.py,sha256=VreEbGVNmH9L55kP2QCC-ob5ToG9HDaJmkI_WQAP4Dg,3631
-zensols/deeplearn/result/pred.py,sha256=1EXMGQLz74XNqFuhgJ9Awn_lmz60ic5USs07pH9-q18,11379
-zensols/deeplearn/result/report.py,sha256=9yJ_q2hoJNZ9omwklWek1Pzjnvqc0-QWSq4O7OWbtKA,4395
+zensols/deeplearn/result/pred.py,sha256=WHb1G3ZLuf-IYm-x1-CcvT9UWaP4JbEkOBb8ZbDJeDE,13719
+zensols/deeplearn/result/report.py,sha256=ZFCYdhhRvMIZlEUM17wXA8k9AspIZTlxkFJ4vfsXoHY,5130
 zensols/deeplearn/vectorize/__init__.py,sha256=hKXSHSnZmp_3HeP6rkCg_Pxcu-IJvx1iAIwz86iTiAE,198
 zensols/deeplearn/vectorize/domain.py,sha256=xtJAU-mIUNAuhGda7FIul3TwYQxDcGJBUAe1ik6w2tA,6708
 zensols/deeplearn/vectorize/manager.py,sha256=w3m_O_PvugPAcAawLnTpBVPJ2XYm0L6RWdeLmW1IwL0,13990
 zensols/deeplearn/vectorize/util.py,sha256=KYjRXUsK7G3QZdpP31QN3Ad8O3Omf4Rq4KhVKZeYi-w,2061
 zensols/deeplearn/vectorize/vectorizers.py,sha256=-rHDN33Pj59V_d0ULbV3RcZmNGD2NPCW4Z4jBUfDhOE,14594
-zensols.deeplearn-1.6.0.dist-info/METADATA,sha256=V3lgoFpDwR5qjH9mzt_8hbWdK6eH2OdA3O_Sidt_oR0,10552
-zensols.deeplearn-1.6.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-zensols.deeplearn-1.6.0.dist-info/top_level.txt,sha256=IEecO7gsWiRRRw2vk-fUv1-u_lJJL7oZyNSqqj1LqOI,52
-zensols.deeplearn-1.6.0.dist-info/RECORD,,
+zensols.deeplearn-1.6.1.dist-info/METADATA,sha256=yURAjgQVSSYN1DR0ZIGwP15bMxj2dwJHFNoQ-L_WlJk,10565
+zensols.deeplearn-1.6.1.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+zensols.deeplearn-1.6.1.dist-info/top_level.txt,sha256=IEecO7gsWiRRRw2vk-fUv1-u_lJJL7oZyNSqqj1LqOI,52
+zensols.deeplearn-1.6.1.dist-info/RECORD,,
```

