# Comparing `tmp/mlagility-3.0.2.tar.gz` & `tmp/mlagility-3.1.1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "mlagility-3.0.2.tar", last modified: Fri Apr 28 17:01:28 2023, max compression
+gzip compressed data, was "mlagility-3.1.1.tar", last modified: Thu Jun  8 21:31:56 2023, max compression
```

## Comparing `mlagility-3.0.2.tar` & `mlagility-3.1.1.tar`

### file list

```diff
@@ -1,1932 +1,1947 @@
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.443534 mlagility-3.0.2/
--rw-r--r--   0 runner    (1001) docker     (123)     1066 2023-04-28 17:00:56.000000 mlagility-3.0.2/LICENSE
--rw-r--r--   0 runner    (1001) docker     (123)     5303 2023-04-28 17:01:28.443534 mlagility-3.0.2/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)     4843 2023-04-28 17:00:56.000000 mlagility-3.0.2/README.md
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.027530 mlagility-3.0.2/models/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.027530 mlagility-3.0.2/models/diffusers/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/diffusers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      616 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/diffusers/clip_text_encoder.py
--rw-r--r--   0 runner    (1001) docker     (123)      643 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/diffusers/safety_clipvision.py
--rw-r--r--   0 runner    (1001) docker     (123)      780 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/diffusers/unet_2d_condition.py
--rw-r--r--   0 runner    (1001) docker     (123)      600 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/diffusers/vae_decoder.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.027530 mlagility-3.0.2/models/graph_convolutions/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      868 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/chebconv.py
--rw-r--r--   0 runner    (1001) docker     (123)      922 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/dnaconv.py
--rw-r--r--   0 runner    (1001) docker     (123)      867 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/egconv.py
--rw-r--r--   0 runner    (1001) docker     (123)      749 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/feastconv.py
--rw-r--r--   0 runner    (1001) docker     (123)      820 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/gatedgraphconv.py
--rw-r--r--   0 runner    (1001) docker     (123)      689 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/generalconv.py
--rw-r--r--   0 runner    (1001) docker     (123)      742 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/leconv.py
--rw-r--r--   0 runner    (1001) docker     (123)      871 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/pnaconv.py
--rw-r--r--   0 runner    (1001) docker     (123)      717 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/resgatedgraphconv.py
--rw-r--r--   0 runner    (1001) docker     (123)      685 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/sageconv.py
--rw-r--r--   0 runner    (1001) docker     (123)      715 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/graph_convolutions/tagconv.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.155531 mlagility-3.0.2/models/popular_on_huggingface/
--rw-r--r--   0 runner    (1001) docker     (123)     1615 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/0x7194633_keyt5-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      356 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/AI-Growth-Lab_PatentSBERTa.py
--rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/AmazonScience_qanlu.py
--rw-r--r--   0 runner    (1001) docker     (123)     1002 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/BM-K_KoSimCSE-roberta.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Babelscape_wikineural-multilingual-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)      739 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Bhuvana_t5-base-spellchecker.py
--rw-r--r--   0 runner    (1001) docker     (123)      323 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-ca-pos-egy.py
--rw-r--r--   0 runner    (1001) docker     (123)      309 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-ca.py
--rw-r--r--   0 runner    (1001) docker     (123)      422 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-da-pos-msa.py
--rw-r--r--   0 runner    (1001) docker     (123)      307 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-da.py
--rw-r--r--   0 runner    (1001) docker     (123)      426 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-mix-pos-msa.py
--rw-r--r--   0 runner    (1001) docker     (123)      309 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-mix.py
--rw-r--r--   0 runner    (1001) docker     (123)      309 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-msa.py
--rw-r--r--   0 runner    (1001) docker     (123)      626 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/CompVis_ldm-text2im-large-256.py
--rw-r--r--   0 runner    (1001) docker     (123)      538 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/CompVis_stable-diffusion-v1-4.py
--rw-r--r--   0 runner    (1001) docker     (123)      437 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/DMetaSoul_sbert-chinese-general-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      612 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Davlan_bert-base-multilingual-cased-masakhaner.py
--rw-r--r--   0 runner    (1001) docker     (123)      635 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Davlan_bert-base-multilingual-cased-ner-hrl.py
--rw-r--r--   0 runner    (1001) docker     (123)      651 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Davlan_distilbert-base-multilingual-cased-ner-hrl.py
--rw-r--r--   0 runner    (1001) docker     (123)      597 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Davlan_xlm-roberta-base-ner-hrl.py
--rw-r--r--   0 runner    (1001) docker     (123)      600 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Davlan_xlm-roberta-large-ner-hrl.py
--rw-r--r--   0 runner    (1001) docker     (123)      307 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/DmitryPogrebnoy_MedRuRobertaLarge.py
--rw-r--r--   0 runner    (1001) docker     (123)     1182 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ElKulako_cryptobert.py
--rw-r--r--   0 runner    (1001) docker     (123)      600 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Elron_bleurt-base-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      604 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Elron_bleurt-large-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      605 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Elron_bleurt-tiny-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      660 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/FinanceInc_finbert_fls.py
--rw-r--r--   0 runner    (1001) docker     (123)      879 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/HooshvareLab_bert-fa-zwnj-base-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)      893 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/HooshvareLab_distilbert-fa-zwnj-base-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)     2304 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Huffon_sentence-klue-roberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      564 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-DeBERTa-v2-710M-Chinese.py
--rw-r--r--   0 runner    (1001) docker     (123)      601 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-110M-NLI.py
--rw-r--r--   0 runner    (1001) docker     (123)      583 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-110M-Sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)      581 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-330M-Sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)      622 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-330M-Similarity.py
--rw-r--r--   0 runner    (1001) docker     (123)      542 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/IIC_dpr-spanish-passage_encoder-allqa-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      518 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/IIC_dpr-spanish-question_encoder-allqa-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      884 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/IlyaGusev_rubert_telegram_headlines.py
--rw-r--r--   0 runner    (1001) docker     (123)      730 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/IlyaGusev_rut5_base_sum_gazeta.py
--rw-r--r--   0 runner    (1001) docker     (123)      624 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Intel_dpt-large-ade.py
--rw-r--r--   0 runner    (1001) docker     (123)     1054 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Intel_dpt-large.py
--rw-r--r--   0 runner    (1001) docker     (123)     2315 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Jean-Baptiste_camembert-ner-with-dates.py
--rw-r--r--   0 runner    (1001) docker     (123)      925 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Jean-Baptiste_camembert-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)     1298 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Jean-Baptiste_roberta-large-ner-english.py
--rw-r--r--   0 runner    (1001) docker     (123)      562 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/K024_mt5-zh-ja-en-trimmed.py
--rw-r--r--   0 runner    (1001) docker     (123)      374 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/KBLab_sentence-bert-swedish-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      682 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/KES_T5-TTParser.py
--rw-r--r--   0 runner    (1001) docker     (123)      699 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/KES_TEC-English.py
--rw-r--r--   0 runner    (1001) docker     (123)      526 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Kamuuung_autonlp-lessons_tagging-606217261.py
--rw-r--r--   0 runner    (1001) docker     (123)      629 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/KoichiYasuoka_bert-base-japanese-upos.py
--rw-r--r--   0 runner    (1001) docker     (123)      671 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/KoichiYasuoka_bert-large-japanese-wikipedia-ud-head.py
--rw-r--r--   0 runner    (1001) docker     (123)      668 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/KoichiYasuoka_deberta-base-japanese-aozora-ud-head.py
--rw-r--r--   0 runner    (1001) docker     (123)      611 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/KoichiYasuoka_deberta-base-thai-ud-head.py
--rw-r--r--   0 runner    (1001) docker     (123)      660 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/KoichiYasuoka_roberta-base-thai-spm-upos.py
--rw-r--r--   0 runner    (1001) docker     (123)      756 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MCG-NJU_videomae-base-finetuned-kinetics.py
--rw-r--r--   0 runner    (1001) docker     (123)      856 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MCG-NJU_videomae-base-ssv2.py
--rw-r--r--   0 runner    (1001) docker     (123)      831 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MCG-NJU_videomae-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      912 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MaRiOrOsSi_t5-base-finetuned-question-answering.py
--rw-r--r--   0 runner    (1001) docker     (123)      725 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MarcBrun_ixambert-finetuned-squad-eu-en.py
--rw-r--r--   0 runner    (1001) docker     (123)     2468 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Michau_t5-base-en-generate-headline.py
--rw-r--r--   0 runner    (1001) docker     (123)      326 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MilaNLProc_feel-it-italian-emotion.py
--rw-r--r--   0 runner    (1001) docker     (123)      330 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MilaNLProc_feel-it-italian-sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)      544 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-base-mnli-fever-anli.py
--rw-r--r--   0 runner    (1001) docker     (123)      559 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-base-mnli-fever-docnli-ling-2c.py
--rw-r--r--   0 runner    (1001) docker     (123)      568 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-large-mnli-fever-anli-ling-wanli.py
--rw-r--r--   0 runner    (1001) docker     (123)     1055 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary.py
--rw-r--r--   0 runner    (1001) docker     (123)      546 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_mDeBERTa-v3-base-mnli-xnli.py
--rw-r--r--   0 runner    (1001) docker     (123)      563 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.py
--rw-r--r--   0 runner    (1001) docker     (123)     1432 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_policy-distilbert-7d.py
--rw-r--r--   0 runner    (1001) docker     (123)      614 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Musixmatch_umberto-commoncrawl-cased-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      909 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Narrativa_bsc_roberta2roberta_shared-spanish-finetuned-mlsum-summarization.py
--rw-r--r--   0 runner    (1001) docker     (123)      538 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/NbAiLab_nb-bert-base-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)      779 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/NeuML_bert-small-cord19qa.py
--rw-r--r--   0 runner    (1001) docker     (123)     1103 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/NlpHUST_gpt2-vietnamese.py
--rw-r--r--   0 runner    (1001) docker     (123)     1305 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/NlpHUST_t5-en-vi-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      655 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/NlpHUST_vibert4news-base-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      532 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Preetiha_clause_classification.py
--rw-r--r--   0 runner    (1001) docker     (123)      848 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Recognai_bert-base-spanish-wwm-cased-xnli.py
--rw-r--r--   0 runner    (1001) docker     (123)      838 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Recognai_zeroshot_selectra_medium.py
--rw-r--r--   0 runner    (1001) docker     (123)      449 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Rostlab_prot_bert.py
--rw-r--r--   0 runner    (1001) docker     (123)      460 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Rostlab_prot_bert_bfd.py
--rw-r--r--   0 runner    (1001) docker     (123)      939 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Rostlab_prot_t5_xl_bfd.py
--rw-r--r--   0 runner    (1001) docker     (123)      955 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Rostlab_prot_t5_xl_uniref50.py
--rw-r--r--   0 runner    (1001) docker     (123)      840 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Sahajtomar_German_Zeroshot.py
--rw-r--r--   0 runner    (1001) docker     (123)      555 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-2B-mono.py
--rw-r--r--   0 runner    (1001) docker     (123)      558 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-2B-multi.py
--rw-r--r--   0 runner    (1001) docker     (123)      562 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-350M-mono.py
--rw-r--r--   0 runner    (1001) docker     (123)      565 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-350M-multi.py
--rw-r--r--   0 runner    (1001) docker     (123)      552 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-350M-nl.py
--rw-r--r--   0 runner    (1001) docker     (123)      555 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-6B-mono.py
--rw-r--r--   0 runner    (1001) docker     (123)      558 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-6B-multi.py
--rw-r--r--   0 runner    (1001) docker     (123)      660 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codet5-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      617 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codet5-large-ntp-py.py
--rw-r--r--   0 runner    (1001) docker     (123)      625 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codet5-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      666 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codet5-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      596 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Salesforce_mixqg-base.py
--rw-r--r--   0 runner    (1001) docker     (123)     2413 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Sehong_t5-large-QuestionGeneration.py
--rw-r--r--   0 runner    (1001) docker     (123)     1198 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/SenseTime_deformable-detr.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Sentdex_GPyT.py
--rw-r--r--   0 runner    (1001) docker     (123)      894 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Seznam_small-e-czech.py
--rw-r--r--   0 runner    (1001) docker     (123)      558 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/SkolkovoInstitute_roberta_toxicity_classifier.py
--rw-r--r--   0 runner    (1001) docker     (123)      545 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/SkolkovoInstitute_russian_toxicity_classifier.py
--rw-r--r--   0 runner    (1001) docker     (123)      569 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/SkolkovoInstitute_xlmr_formality_classifier.py
--rw-r--r--   0 runner    (1001) docker     (123)      400 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/StevenLimcorn_indonesian-roberta-base-emotion-classifier.py
--rw-r--r--   0 runner    (1001) docker     (123)      550 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/TristanBehrens_js-fakes-4bars.py
--rw-r--r--   0 runner    (1001) docker     (123)      375 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/TurkuNLP_sbert-cased-finnish-paraphrase.py
--rw-r--r--   0 runner    (1001) docker     (123)     1559 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/UBC-NLP_AraT5-base-title-generation.py
--rw-r--r--   0 runner    (1001) docker     (123)      853 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Unbabel_gec-t5_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      425 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/VMware_vbert-2021-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      784 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Visual-Attention-Network_van-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      784 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Visual-Attention-Network_van-tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      765 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Wikidepia_IndoT5-base-paraphrase.py
--rw-r--r--   0 runner    (1001) docker     (123)      447 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/Xuhui_ToxDect-roberta-large.py
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      547 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/abhishek_autonlp-bbc-news-classification-37229289.py
--rw-r--r--   0 runner    (1001) docker     (123)     1149 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ahmedrachid_FinancialBERT-Sentiment-Analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)     4284 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ai4bharat_IndicBART.py
--rw-r--r--   0 runner    (1001) docker     (123)     3998 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ai4bharat_IndicBARTSS.py
--rw-r--r--   0 runner    (1001) docker     (123)      368 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/aiknowyou_aiky-sentence-bertino.py
--rw-r--r--   0 runner    (1001) docker     (123)      255 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/albert-base-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      258 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/albert-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      254 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/albert-large-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      260 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/albert-large-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      256 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/albert-xlarge-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      258 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/albert-xlarge-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      260 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/albert-xxlarge-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      261 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/albert-xxlarge-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      808 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/allegro_herbert-base-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      465 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/allegro_herbert-klej-cased-tokenizer-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      455 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/allegro_herbert-klej-cased-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      810 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/allegro_herbert-large-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      974 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/allenai_t5-small-next-word-generator-qoogle.py
--rw-r--r--   0 runner    (1001) docker     (123)     1029 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/allenai_t5-small-squad2-question-generation.py
--rw-r--r--   0 runner    (1001) docker     (123)     2095 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/aneuraz_awesome-align-with-co.py
--rw-r--r--   0 runner    (1001) docker     (123)      376 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ans_vaccinating-covid-tweets.py
--rw-r--r--   0 runner    (1001) docker     (123)      728 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/apple_deeplabv3-mobilevit-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      737 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/apple_deeplabv3-mobilevit-xx-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      823 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/apple_mobilevit-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      830 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/apple_mobilevit-xx-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      774 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/asi_gpt-fr-cased-base.py
--rw-r--r--   0 runner    (1001) docker     (123)     1025 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/assemblyai_bert-large-uncased-sst2.py
--rw-r--r--   0 runner    (1001) docker     (123)      803 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/aubmindlab_araelectra-base-discriminator.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/aujer_ni_model_8_19.py
--rw-r--r--   0 runner    (1001) docker     (123)      468 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/avichr_heBERT.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/avichr_heBERT_sentiment_analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)      901 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/aware-ai_bart-squadv2.py
--rw-r--r--   0 runner    (1001) docker     (123)     1905 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/azwierzc_herbert-large-poquad.py
--rw-r--r--   0 runner    (1001) docker     (123)     2101 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/azwierzc_plt5-base-poquad.py
--rw-r--r--   0 runner    (1001) docker     (123)     2104 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/azwierzc_plt5-large-poquad.py
--rw-r--r--   0 runner    (1001) docker     (123)      740 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/batterydata_batterybert-cased-squad-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      261 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bert-base-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      287 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bert-base-multilingual-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      289 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bert-base-multilingual-uncased.py
--rw-r--r--   0 runner    (1001) docker     (123)      263 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bert-base-uncased.py
--rw-r--r--   0 runner    (1001) docker     (123)      296 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bert-large-cased-whole-word-masking.py
--rw-r--r--   0 runner    (1001) docker     (123)      260 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bert-large-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      301 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bert-large-uncased-whole-word-masking.py
--rw-r--r--   0 runner    (1001) docker     (123)      266 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bert-large-uncased.py
--rw-r--r--   0 runner    (1001) docker     (123)     3166 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bespin-global_klue-bert-base-aihub-mrc.py
--rw-r--r--   0 runner    (1001) docker     (123)     1319 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bespin-global_klue-bert-base-mrc.py
--rw-r--r--   0 runner    (1001) docker     (123)      404 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bespin-global_klue-sentence-roberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      416 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bespin-global_klue-sroberta-base-continue-learning-by-mnr.py
--rw-r--r--   0 runner    (1001) docker     (123)      773 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bhadresh-savani_bert-base-uncased-emotion.py
--rw-r--r--   0 runner    (1001) docker     (123)      787 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bhadresh-savani_distilbert-base-uncased-emotion.py
--rw-r--r--   0 runner    (1001) docker     (123)      761 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bhadresh-savani_electra-base-emotion.py
--rw-r--r--   0 runner    (1001) docker     (123)      758 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bhadresh-savani_roberta-base-emotion.py
--rw-r--r--   0 runner    (1001) docker     (123)      530 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bigscience_T0.py
--rw-r--r--   0 runner    (1001) docker     (123)      528 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/bigscience_T0p.py
--rw-r--r--   0 runner    (1001) docker     (123)     1898 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/blinoff_roberta-base-russian-v0.py
--rw-r--r--   0 runner    (1001) docker     (123)      285 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cahya_bert-base-indonesian-522M.py
--rw-r--r--   0 runner    (1001) docker     (123)      293 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cahya_distilbert-base-indonesian.py
--rw-r--r--   0 runner    (1001) docker     (123)      288 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cahya_roberta-base-indonesian-522M.py
--rw-r--r--   0 runner    (1001) docker     (123)     1217 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_tweet-topic-21-multi.py
--rw-r--r--   0 runner    (1001) docker     (123)     1191 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_tweet-topic-21-single.py
--rw-r--r--   0 runner    (1001) docker     (123)     2090 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-emoji.py
--rw-r--r--   0 runner    (1001) docker     (123)     2061 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-emotion.py
--rw-r--r--   0 runner    (1001) docker     (123)     2036 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-hate.py
--rw-r--r--   0 runner    (1001) docker     (123)     2078 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-irony.py
--rw-r--r--   0 runner    (1001) docker     (123)     2047 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-offensive.py
--rw-r--r--   0 runner    (1001) docker     (123)     2054 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)      346 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-xlm-roberta-base-sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)      642 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/chkla_parlbert-topic-german.py
--rw-r--r--   0 runner    (1001) docker     (123)      735 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/clips_mfaq.py
--rw-r--r--   0 runner    (1001) docker     (123)     1934 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cmarkea_distilcamembert-base-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)     1123 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cmarkea_distilcamembert-base-nli.py
--rw-r--r--   0 runner    (1001) docker     (123)     1340 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cmarkea_distilcamembert-base-qa.py
--rw-r--r--   0 runner    (1001) docker     (123)      735 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cmarkea_distilcamembert-base-sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)      431 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/codeparrot_codeparrot-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      391 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/codeparrot_codeparrot.py
--rw-r--r--   0 runner    (1001) docker     (123)      639 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cointegrated_LaBSE-en-ru.py
--rw-r--r--   0 runner    (1001) docker     (123)      970 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rubert-base-cased-nli-threeway.py
--rw-r--r--   0 runner    (1001) docker     (123)     1428 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rubert-tiny-sentiment-balanced.py
--rw-r--r--   0 runner    (1001) docker     (123)     1573 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rubert-tiny-toxicity.py
--rw-r--r--   0 runner    (1001) docker     (123)      869 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rubert-tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      871 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rubert-tiny2.py
--rw-r--r--   0 runner    (1001) docker     (123)      899 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rut5-small-chitchat.py
--rw-r--r--   0 runner    (1001) docker     (123)      804 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rut5-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      589 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-MiniLM2-L6-H768.py
--rw-r--r--   0 runner    (1001) docker     (123)      583 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-deberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      591 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      591 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      591 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      595 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-xsmall.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-distilroberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      585 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-roberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)     2363 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/csebuetnlp_mT5_m2m_crossSum.py
--rw-r--r--   0 runner    (1001) docker     (123)     2107 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/csebuetnlp_mT5_m2o_arabic_crossSum.py
--rw-r--r--   0 runner    (1001) docker     (123)     2131 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/csebuetnlp_mT5_m2o_chinese_simplified_crossSum.py
--rw-r--r--   0 runner    (1001) docker     (123)     2109 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/csebuetnlp_mT5_multilingual_XLSum.py
--rw-r--r--   0 runner    (1001) docker     (123)      578 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ctrl.py
--rw-r--r--   0 runner    (1001) docker     (123)      621 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/d4data_biomedical-ner-all.py
--rw-r--r--   0 runner    (1001) docker     (123)     1002 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dandelin_vilt-b32-finetuned-nlvr2.py
--rw-r--r--   0 runner    (1001) docker     (123)      817 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dandelin_vilt-b32-finetuned-vqa.py
--rw-r--r--   0 runner    (1001) docker     (123)     1679 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dandelin_vilt-b32-mlm.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dangvantuan_sentence-camembert-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      603 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dangvantuan_sentence-camembert-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/daveni_twitter-xlm-roberta-emotion-es.py
--rw-r--r--   0 runner    (1001) docker     (123)      366 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deepset_all-mpnet-base-v2-table.py
--rw-r--r--   0 runner    (1001) docker     (123)      748 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deepset_deberta-v3-base-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)      754 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deepset_deberta-v3-large-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)      747 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deepset_electra-base-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)      760 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deepset_roberta-base-squad2-covid.py
--rw-r--r--   0 runner    (1001) docker     (123)      749 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deepset_roberta-base-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)      744 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deepset_tinyroberta-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)      767 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deepset_xlm-roberta-base-squad2-distilled.py
--rw-r--r--   0 runner    (1001) docker     (123)      756 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deepset_xlm-roberta-large-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)      283 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dennlinger_bert-wiki-paragraphs.py
--rw-r--r--   0 runner    (1001) docker     (123)      281 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dennlinger_roberta-cls-consec.py
--rw-r--r--   0 runner    (1001) docker     (123)     1292 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deutsche-telekom_bert-multi-english-german-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)     1398 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/deutsche-telekom_electra-base-de-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)      615 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/digitalepidemiologylab_covid-twitter-bert-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      620 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/digitalepidemiologylab_covid-twitter-bert.py
--rw-r--r--   0 runner    (1001) docker     (123)      271 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/distilbert-base-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      299 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/distilbert-base-multilingual-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      640 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/distilbert-base-uncased-finetuned-sst-2-english.py
--rw-r--r--   0 runner    (1001) docker     (123)      277 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/distilbert-base-uncased.py
--rw-r--r--   0 runner    (1001) docker     (123)      310 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/distilroberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)     1086 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dkleczek_bert-base-polish-cased-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)     1093 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dkleczek_bert-base-polish-uncased-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)     1095 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/doc2query_all-t5-base-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)     1170 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/doc2query_all-with_prefix-t5-base-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)     1103 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/doc2query_msmarco-t5-base-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dslim_bert-base-NER.py
--rw-r--r--   0 runner    (1001) docker     (123)      532 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dslim_bert-large-NER.py
--rw-r--r--   0 runner    (1001) docker     (123)      706 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/dumitrescustefan_bert-base-romanian-cased-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      665 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/edumunozsala_beto_sentiment_analysis_es.py
--rw-r--r--   0 runner    (1001) docker     (123)      672 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/edumunozsala_vit_base-224-in21k-ft-cifar100.py
--rw-r--r--   0 runner    (1001) docker     (123)      315 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/efederici_cross-encoder-umberto-stsb.py
--rw-r--r--   0 runner    (1001) docker     (123)      364 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/efederici_sentence-bert-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      526 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ehdwns1516_klue-roberta-base-kornli.py
--rw-r--r--   0 runner    (1001) docker     (123)      410 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/embedding-data_distilroberta-base-sentence-transformer.py
--rw-r--r--   0 runner    (1001) docker     (123)      567 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/esiebomajeremiah_autonlp-email-classification-657119381.py
--rw-r--r--   0 runner    (1001) docker     (123)      539 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/etalab-ia_camembert-base-squadFR-fquad-piaf.py
--rw-r--r--   0 runner    (1001) docker     (123)      548 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/etalab-ia_dpr-ctx_encoder-fr_qa-camembert.py
--rw-r--r--   0 runner    (1001) docker     (123)      574 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/etalab-ia_dpr-question_encoder-fr_qa-camembert.py
--rw-r--r--   0 runner    (1001) docker     (123)     1226 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/fabiochiu_t5-base-tag-generation.py
--rw-r--r--   0 runner    (1001) docker     (123)      446 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_bart-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      447 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_bart-large.py
--rw-r--r--   0 runner    (1001) docker     (123)     1058 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_contriever-msmarco.py
--rw-r--r--   0 runner    (1001) docker     (123)     1022 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_contriever.py
--rw-r--r--   0 runner    (1001) docker     (123)      789 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-base-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      787 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-base-384.py
--rw-r--r--   0 runner    (1001) docker     (123)      809 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-large-224-22k-1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      792 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-small-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      789 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-tiny-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      804 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-xlarge-224-22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      816 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-xlarge-384-22k-1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      860 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_data2vec-vision-base-ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      902 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-base-distilled-patch16-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      882 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-base-distilled-patch16-384.py
--rw-r--r--   0 runner    (1001) docker     (123)      828 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-base-patch16-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      826 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-base-patch16-384.py
--rw-r--r--   0 runner    (1001) docker     (123)      885 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-small-distilled-patch16-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      831 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-small-patch16-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      880 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-tiny-distilled-patch16-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      828 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-tiny-patch16-224.py
--rw-r--r--   0 runner    (1001) docker     (123)     1297 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_detr-resnet-50-panoptic.py
--rw-r--r--   0 runner    (1001) docker     (123)     1175 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_detr-resnet-50.py
--rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_dino-vitb16.py
--rw-r--r--   0 runner    (1001) docker     (123)      613 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_dino-vitb8.py
--rw-r--r--   0 runner    (1001) docker     (123)      616 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_dino-vits16.py
--rw-r--r--   0 runner    (1001) docker     (123)      613 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_dino-vits8.py
--rw-r--r--   0 runner    (1001) docker     (123)     1696 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_flava-full.py
--rw-r--r--   0 runner    (1001) docker     (123)      826 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_levit-128S.py
--rw-r--r--   0 runner    (1001) docker     (123)     1196 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_maskformer-swin-base-ade.py
--rw-r--r--   0 runner    (1001) docker     (123)     1199 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_maskformer-swin-base-coco.py
--rw-r--r--   0 runner    (1001) docker     (123)     1191 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_maskformer-swin-large-ade.py
--rw-r--r--   0 runner    (1001) docker     (123)     1198 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_maskformer-swin-small-coco.py
--rw-r--r--   0 runner    (1001) docker     (123)     1196 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_maskformer-swin-tiny-ade.py
--rw-r--r--   0 runner    (1001) docker     (123)      764 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_mbart-large-50.py
--rw-r--r--   0 runner    (1001) docker     (123)      268 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_opt-125m.py
--rw-r--r--   0 runner    (1001) docker     (123)      268 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_opt-350m.py
--rw-r--r--   0 runner    (1001) docker     (123)      760 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_regnet-y-040.py
--rw-r--r--   0 runner    (1001) docker     (123)      665 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_vit-mae-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      667 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_vit-mae-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      262 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/facebook_xlm-roberta-xl.py
--rw-r--r--   0 runner    (1001) docker     (123)      393 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/fhswf_bert_de_ner.py
--rw-r--r--   0 runner    (1001) docker     (123)      964 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/flax-community_clip-rsicd-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      308 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/flax-community_roberta-hindi.py
--rw-r--r--   0 runner    (1001) docker     (123)      926 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/flax-community_t5-large-wikisplit.py
--rw-r--r--   0 runner    (1001) docker     (123)      412 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/flax-sentence-embeddings_all_datasets_v3_mpnet-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      539 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/flax-sentence-embeddings_all_datasets_v3_roberta-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/flax-sentence-embeddings_all_datasets_v4_MiniLM-L6.py
--rw-r--r--   0 runner    (1001) docker     (123)     1290 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/flax-sentence-embeddings_st-codesearch-distilroberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      544 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/flax-sentence-embeddings_stackoverflow_mpnet-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      736 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/flexudy_t5-base-multi-sentence-doctor.py
--rw-r--r--   0 runner    (1001) docker     (123)     1062 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/flexudy_t5-small-wav2vec2-grammar-fixer.py
--rw-r--r--   0 runner    (1001) docker     (123)      911 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/fran-martinez_scibert_scivocab_cased_ner_jnlpba.py
--rw-r--r--   0 runner    (1001) docker     (123)      471 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/funnel-transformer_large-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      474 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/funnel-transformer_xlarge-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      848 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/gerulata_slovakbert.py
--rw-r--r--   0 runner    (1001) docker     (123)      644 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/gilf_french-camembert-postag-model.py
--rw-r--r--   0 runner    (1001) docker     (123)      614 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/gilf_french-postag-model.py
--rw-r--r--   0 runner    (1001) docker     (123)      721 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_bert2bert_L-24_wmt_de_en.py
--rw-r--r--   0 runner    (1001) docker     (123)      569 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_byt5-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      569 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_byt5-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      572 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_byt5-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      599 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_canine-c.py
--rw-r--r--   0 runner    (1001) docker     (123)      600 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_canine-s.py
--rw-r--r--   0 runner    (1001) docker     (123)      582 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_ddpm-celebahq-256.py
--rw-r--r--   0 runner    (1001) docker     (123)      578 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_ddpm-cifar10-32.py
--rw-r--r--   0 runner    (1001) docker     (123)      895 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_electra-base-discriminator.py
--rw-r--r--   0 runner    (1001) docker     (123)      430 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_electra-base-generator.py
--rw-r--r--   0 runner    (1001) docker     (123)      897 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_electra-large-discriminator.py
--rw-r--r--   0 runner    (1001) docker     (123)      908 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_electra-small-discriminator.py
--rw-r--r--   0 runner    (1001) docker     (123)      415 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_fnet-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      463 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_long-t5-local-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      470 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_long-t5-tglobal-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      472 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_long-t5-tglobal-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      461 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_long-t5-tglobal-xl.py
--rw-r--r--   0 runner    (1001) docker     (123)      416 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_mobilebert-uncased.py
--rw-r--r--   0 runner    (1001) docker     (123)     1441 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_owlvit-base-patch16.py
--rw-r--r--   0 runner    (1001) docker     (123)     1442 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_owlvit-base-patch32.py
--rw-r--r--   0 runner    (1001) docker     (123)     1444 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_owlvit-large-patch14.py
--rw-r--r--   0 runner    (1001) docker     (123)     1705 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_roberta2roberta_L-24_bbc.py
--rw-r--r--   0 runner    (1001) docker     (123)     2610 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_roberta2roberta_L-24_cnn_daily_mail.py
--rw-r--r--   0 runner    (1001) docker     (123)      808 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_roberta2roberta_L-24_discofuse.py
--rw-r--r--   0 runner    (1001) docker     (123)      542 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_t5-small-ssm-nq.py
--rw-r--r--   0 runner    (1001) docker     (123)      660 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-base-patch16-224-in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      824 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-base-patch16-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      817 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-base-patch16-384.py
--rw-r--r--   0 runner    (1001) docker     (123)      654 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-base-patch32-224-in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      817 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-base-patch32-384.py
--rw-r--r--   0 runner    (1001) docker     (123)      653 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-huge-patch14-224-in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      655 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-large-patch16-224-in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      818 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-large-patch16-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      818 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-large-patch16-384.py
--rw-r--r--   0 runner    (1001) docker     (123)      653 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-large-patch32-224-in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      820 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/google_vit-large-patch32-384.py
--rw-r--r--   0 runner    (1001) docker     (123)      703 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/hakurei_lit-6B.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/henryk_bert-base-multilingual-cased-finetuned-dutch-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)      564 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/henryk_bert-base-multilingual-cased-finetuned-polish-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)     1582 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/hetpandya_t5-base-tapaco.py
--rw-r--r--   0 runner    (1001) docker     (123)     1583 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/hetpandya_t5-small-tapaco.py
--rw-r--r--   0 runner    (1001) docker     (123)      372 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/hiiamsid_sentence_similarity_hindi.py
--rw-r--r--   0 runner    (1001) docker     (123)      382 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/hiiamsid_sentence_similarity_spanish_es.py
--rw-r--r--   0 runner    (1001) docker     (123)      705 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/hustvl_yolos-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      708 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/hustvl_yolos-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      706 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/hustvl_yolos-tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      552 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/imranraad_idiom-xlm-roberta.py
--rw-r--r--   0 runner    (1001) docker     (123)     1236 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/inkoziev_rugpt_chitchat.py
--rw-r--r--   0 runner    (1001) docker     (123)     1545 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/intfloat_simlm-msmarco-reranker.py
--rw-r--r--   0 runner    (1001) docker     (123)      320 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/j-hartmann_emotion-english-distilroberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      328 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/j-hartmann_purchase-intention-english-roberta-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      336 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/j-hartmann_sentiment-roberta-large-english-3-classes.py
--rw-r--r--   0 runner    (1001) docker     (123)     1559 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/jaehyeong_koelectra-base-v3-generalized-sentiment-analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)      373 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/jhgan_ko-sbert-multitask.py
--rw-r--r--   0 runner    (1001) docker     (123)      381 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/jhgan_ko-sroberta-multitask.py
--rw-r--r--   0 runner    (1001) docker     (123)      367 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/jhgan_ko-sroberta-sts.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/joeddav_bart-large-mnli-yahoo-answers.py
--rw-r--r--   0 runner    (1001) docker     (123)      619 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/johngiorgi_declutr-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      623 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/johngiorgi_declutr-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      966 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/jsylee_scibert_scivocab_uncased-finetuned-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)     1010 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_chinese_base.py
--rw-r--r--   0 runner    (1001) docker     (123)     2539 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_chinese_sim_char_base.py
--rw-r--r--   0 runner    (1001) docker     (123)     2542 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_chinese_sim_char_ft_base.py
--rw-r--r--   0 runner    (1001) docker     (123)     2258 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_base.py
--rw-r--r--   0 runner    (1001) docker     (123)     2260 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_large.py
--rw-r--r--   0 runner    (1001) docker     (123)     2259 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      914 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed-pmc-lt.py
--rw-r--r--   0 runner    (1001) docker     (123)      911 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed-pmc.py
--rw-r--r--   0 runner    (1001) docker     (123)      909 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed.py
--rw-r--r--   0 runner    (1001) docker     (123)      364 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/keepitreal_vietnamese-sbert.py
--rw-r--r--   0 runner    (1001) docker     (123)     1077 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ken11_albert-base-japanese-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/kiheh85202_yolo.py
--rw-r--r--   0 runner    (1001) docker     (123)      413 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/kiri-ai_distiluse-base-multilingual-cased-et.py
--rw-r--r--   0 runner    (1001) docker     (123)      651 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/laituan245_molt5-large-smiles2caption.py
--rw-r--r--   0 runner    (1001) docker     (123)      447 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/law-ai_InLegalBERT.py
--rw-r--r--   0 runner    (1001) docker     (123)     2121 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/lcw99_t5-base-korean-chit-chat.py
--rw-r--r--   0 runner    (1001) docker     (123)     1085 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/liandarizkia_SA01-IndoBert.py
--rw-r--r--   0 runner    (1001) docker     (123)      550 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/madhurjindal_autonlp-Gibberish-Detector-492513457.py
--rw-r--r--   0 runner    (1001) docker     (123)      997 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/malteos_scincl.py
--rw-r--r--   0 runner    (1001) docker     (123)     3811 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/marefa-nlp_marefa-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)      366 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/matthewburke_korean_sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)      403 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/maxpe_twitter-roberta-base-jun2022_sem_eval_2018_task_1.py
--rw-r--r--   0 runner    (1001) docker     (123)     1037 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mdhugol_indonesia-bert-sentiment-classification.py
--rw-r--r--   0 runner    (1001) docker     (123)     1077 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/melll-uff_bertweetbr.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/michiyasunaga_BioLinkBERT-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      492 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/michiyasunaga_BioLinkBERT-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      459 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/michiyasunaga_LinkBERT-base.py
--rw-r--r--   0 runner    (1001) docker     (123)     1324 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_BiomedVLP-CXR-BERT-specialized.py
--rw-r--r--   0 runner    (1001) docker     (123)      876 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-base-patch16-224-pt22k-ft22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      687 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-base-patch16-224-pt22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      833 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-base-patch16-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      833 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-base-patch16-384.py
--rw-r--r--   0 runner    (1001) docker     (123)      876 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-large-patch16-224-pt22k-ft22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      688 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-large-patch16-224-pt22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      834 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-large-patch16-384.py
--rw-r--r--   0 runner    (1001) docker     (123)      836 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-large-patch16-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      504 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_codebert-base-mlm.py
--rw-r--r--   0 runner    (1001) docker     (123)     1233 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_conditional-detr-resnet-50.py
--rw-r--r--   0 runner    (1001) docker     (123)      789 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_cvt-13.py
--rw-r--r--   0 runner    (1001) docker     (123)      834 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_prophetnet-large-uncased.py
--rw-r--r--   0 runner    (1001) docker     (123)      756 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_resnet-101.py
--rw-r--r--   0 runner    (1001) docker     (123)      756 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_resnet-152.py
--rw-r--r--   0 runner    (1001) docker     (123)      754 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_resnet-18.py
--rw-r--r--   0 runner    (1001) docker     (123)      753 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_resnet-34.py
--rw-r--r--   0 runner    (1001) docker     (123)      757 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_resnet-50.py
--rw-r--r--   0 runner    (1001) docker     (123)      878 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-base-patch4-window12-384-in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      858 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-base-patch4-window12-384.py
--rw-r--r--   0 runner    (1001) docker     (123)      875 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-base-patch4-window7-224-in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      857 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-base-patch4-window7-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      882 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-large-patch4-window12-384-in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      876 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-large-patch4-window7-224-in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      860 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-large-patch4-window7-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      858 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-small-patch4-window7-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      857 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-tiny-patch4-window7-224.py
--rw-r--r--   0 runner    (1001) docker     (123)      863 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_swinv2-tiny-patch4-window8-256.py
--rw-r--r--   0 runner    (1001) docker     (123)      911 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_tapex-large-finetuned-tabfact.py
--rw-r--r--   0 runner    (1001) docker     (123)      758 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-base-handwritten.py
--rw-r--r--   0 runner    (1001) docker     (123)      805 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-base-printed.py
--rw-r--r--   0 runner    (1001) docker     (123)      761 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-large-handwritten.py
--rw-r--r--   0 runner    (1001) docker     (123)      807 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-large-printed.py
--rw-r--r--   0 runner    (1001) docker     (123)      723 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-large-str.py
--rw-r--r--   0 runner    (1001) docker     (123)      761 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-small-handwritten.py
--rw-r--r--   0 runner    (1001) docker     (123)      810 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-small-stage1.py
--rw-r--r--   0 runner    (1001) docker     (123)      865 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/microsoft_xprophetnet-large-wiki100-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      639 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ml4pubmed_BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext_pub_section.py
--rw-r--r--   0 runner    (1001) docker     (123)      566 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ml6team_bert-base-uncased-city-country-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)      581 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ml6team_distilbert-base-german-cased-toxic-comments.py
--rw-r--r--   0 runner    (1001) docker     (123)      579 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/model-attribution-challenge_codegen-350M-multi.py
--rw-r--r--   0 runner    (1001) docker     (123)      277 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/model-attribution-challenge_opt-350m.py
--rw-r--r--   0 runner    (1001) docker     (123)      452 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/model-attribution-challenge_xlnet-base-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      758 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/monilouise_ner_news_portuguese.py
--rw-r--r--   0 runner    (1001) docker     (123)     1101 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_TinyBERT-spanish-uncased-finetuned-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)      353 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-base-german-finetuned-ler.py
--rw-r--r--   0 runner    (1001) docker     (123)      712 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-italian-finedtuned-squadv1-it-alfa.py
--rw-r--r--   0 runner    (1001) docker     (123)      530 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-medium-finetuned-squadv2.py
--rw-r--r--   0 runner    (1001) docker     (123)     1536 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-multi-cased-finetuned-xquadv1.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-small-finetuned-squadv2.py
--rw-r--r--   0 runner    (1001) docker     (123)     1041 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-small2bert-small-finetuned-cnn_daily_mail-summarization.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-spanish-cased-finetuned-ner.py
--rw-r--r--   0 runner    (1001) docker     (123)      518 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-tiny-5-finetuned-squadv2.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-tiny-finetuned-squadv2.py
--rw-r--r--   0 runner    (1001) docker     (123)      864 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert2bert_shared-german-finetuned-summarization.py
--rw-r--r--   0 runner    (1001) docker     (123)      869 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert2bert_shared-spanish-finetuned-summarization.py
--rw-r--r--   0 runner    (1001) docker     (123)      847 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert2bert_shared-turkish-summarization.py
--rw-r--r--   0 runner    (1001) docker     (123)      742 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_codebert-base-finetuned-detect-insecure-code.py
--rw-r--r--   0 runner    (1001) docker     (123)     1023 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es.py
--rw-r--r--   0 runner    (1001) docker     (123)      564 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_electra-small-finetuned-squadv2.py
--rw-r--r--   0 runner    (1001) docker     (123)     1160 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_electricidad-base-discriminator.py
--rw-r--r--   0 runner    (1001) docker     (123)      575 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_roberta-base-1B-1-finetuned-squadv1.py
--rw-r--r--   0 runner    (1001) docker     (123)      603 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_spanbert-finetuned-squadv2.py
--rw-r--r--   0 runner    (1001) docker     (123)      576 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_spanbert-large-finetuned-squadv2.py
--rw-r--r--   0 runner    (1001) docker     (123)      809 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-common_gen.py
--rw-r--r--   0 runner    (1001) docker     (123)      810 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-e2m-intent.py
--rw-r--r--   0 runner    (1001) docker     (123)      688 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-imdb-sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)     1021 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-quartz.py
--rw-r--r--   0 runner    (1001) docker     (123)     1001 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-question-generation-ap.py
--rw-r--r--   0 runner    (1001) docker     (123)     1057 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-span-sentiment-extraction.py
--rw-r--r--   0 runner    (1001) docker     (123)      866 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-squadv2.py
--rw-r--r--   0 runner    (1001) docker     (123)      802 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-wikiSQL.py
--rw-r--r--   0 runner    (1001) docker     (123)     1327 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-small-finetuned-quora-for-paraphrasing.py
--rw-r--r--   0 runner    (1001) docker     (123)      892 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nateraw_vit-age-classifier.py
--rw-r--r--   0 runner    (1001) docker     (123)      813 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nateraw_vit-base-patch16-224-cifar10.py
--rw-r--r--   0 runner    (1001) docker     (123)      898 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/navteca_bart-large-mnli.py
--rw-r--r--   0 runner    (1001) docker     (123)      585 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/navteca_nli-deberta-v3-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      799 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/navteca_roberta-base-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)      804 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/navteca_roberta-large-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)     1010 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nbroad_mt5-base-qgen.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/neuralspace-reverie_indic-transformers-bn-distilbert.py
--rw-r--r--   0 runner    (1001) docker     (123)     1212 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/neuraly_bert-base-italian-cased-sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)      620 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/neuropark_sahajBERT.py
--rw-r--r--   0 runner    (1001) docker     (123)      804 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nickmuchi_yolos-small-rego-plates-detection.py
--rw-r--r--   0 runner    (1001) docker     (123)      336 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nickprock_xlm-roberta-base-banking77-classification.py
--rw-r--r--   0 runner    (1001) docker     (123)     1070 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nkoh01_MSRoberta.py
--rw-r--r--   0 runner    (1001) docker     (123)      785 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_groupvit-gcc-yfcc.py
--rw-r--r--   0 runner    (1001) docker     (123)      791 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_mit-b1.py
--rw-r--r--   0 runner    (1001) docker     (123)      792 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_mit-b2.py
--rw-r--r--   0 runner    (1001) docker     (123)      791 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_mit-b3.py
--rw-r--r--   0 runner    (1001) docker     (123)      791 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_mit-b4.py
--rw-r--r--   0 runner    (1001) docker     (123)      791 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_mit-b5.py
--rw-r--r--   0 runner    (1001) docker     (123)      762 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-ade-512-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      788 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-1024-1024.py
--rw-r--r--   0 runner    (1001) docker     (123)      783 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-512-1024.py
--rw-r--r--   0 runner    (1001) docker     (123)      782 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-768-768.py
--rw-r--r--   0 runner    (1001) docker     (123)      761 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b1-finetuned-ade-512-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      786 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b2-finetuned-cityscapes-1024-1024.py
--rw-r--r--   0 runner    (1001) docker     (123)      759 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b3-finetuned-ade-512-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      788 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b3-finetuned-cityscapes-1024-1024.py
--rw-r--r--   0 runner    (1001) docker     (123)      761 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b4-finetuned-ade-512-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      786 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b4-finetuned-cityscapes-1024-1024.py
--rw-r--r--   0 runner    (1001) docker     (123)      788 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b5-finetuned-cityscapes-1024-1024.py
--rw-r--r--   0 runner    (1001) docker     (123)      399 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/nytimesrd_paraphrase-MiniLM-L6-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      369 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/obrizum_all-MiniLM-L6-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      371 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/obrizum_all-mpnet-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      804 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/openai_clip-vit-base-patch16.py
--rw-r--r--   0 runner    (1001) docker     (123)      812 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/openai_clip-vit-base-patch32.py
--rw-r--r--   0 runner    (1001) docker     (123)      816 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/openai_clip-vit-large-patch14.py
--rw-r--r--   0 runner    (1001) docker     (123)      384 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/optimum_all-MiniLM-L6-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)    11236 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/patrickvonplaten_longformer2roberta-cnn_dailymail-fp16.py
--rw-r--r--   0 runner    (1001) docker     (123)      573 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/paust_pko-t5-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      576 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/paust_pko-t5-large.py
--rw-r--r--   0 runner    (1001) docker     (123)     1397 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/persiannlp_mt5-large-parsinlu-arc-comqa-obqa-multiple-choice.py
--rw-r--r--   0 runner    (1001) docker     (123)      491 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/philschmid_BERT-Banking77.py
--rw-r--r--   0 runner    (1001) docker     (123)      594 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/philschmid_distilroberta-base-ner-conll2003.py
--rw-r--r--   0 runner    (1001) docker     (123)      642 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/philschmid_distilroberta-base-ner-wikiann-conll2003-3-class.py
--rw-r--r--   0 runner    (1001) docker     (123)      642 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/philschmid_distilroberta-base-ner-wikiann-conll2003-4-class.py
--rw-r--r--   0 runner    (1001) docker     (123)      588 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/philschmid_distilroberta-base-ner-wikiann.py
--rw-r--r--   0 runner    (1001) docker     (123)      787 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/phiyodr_bart-large-finetuned-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)      787 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/phiyodr_bert-base-finetuned-squad2.py
--rw-r--r--   0 runner    (1001) docker     (123)     2525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/phpaiola_ptt5-base-summ-cstnews.py
--rw-r--r--   0 runner    (1001) docker     (123)     1162 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/pierreguillou_ner-bert-large-cased-pt-lenerbr.py
--rw-r--r--   0 runner    (1001) docker     (123)      556 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/pin_senda.py
--rw-r--r--   0 runner    (1001) docker     (123)      380 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/pritamdeka_S-BioBert-snli-multinli-stsb.py
--rw-r--r--   0 runner    (1001) docker     (123)      396 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/pritamdeka_S-Biomed-Roberta-snli-multinli-stsb.py
--rw-r--r--   0 runner    (1001) docker     (123)      382 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/pritamdeka_S-Bluebert-snli-multinli-stsb.py
--rw-r--r--   0 runner    (1001) docker     (123)      366 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/pritamdeka_S-PubMedBert-MS-MARCO.py
--rw-r--r--   0 runner    (1001) docker     (123)      571 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/projecte-aina_roberta-base-ca-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      382 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/pszemraj_grammar-synthesis-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      385 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/pszemraj_grammar-synthesis-large.py
--rw-r--r--   0 runner    (1001) docker     (123)     1207 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/pvl_labse_bert.py
--rw-r--r--   0 runner    (1001) docker     (123)      591 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/racai_distilbert-base-romanian-uncased.py
--rw-r--r--   0 runner    (1001) docker     (123)     1273 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ramsrigouthamg_t5-large-paraphraser-diverse-high-quality.py
--rw-r--r--   0 runner    (1001) docker     (123)     1882 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ramsrigouthamg_t5_paraphraser.py
--rw-r--r--   0 runner    (1001) docker     (123)      352 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/raynardj_ner-gene-dna-rna-jnlpba-pubmed.py
--rw-r--r--   0 runner    (1001) docker     (123)      443 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/razent_spbert-mlm-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      455 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/razent_spbert-mlm-wso-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      689 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/readerbench_RoBERT-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      694 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/readerbench_RoBERT-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      885 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/readerbench_RoGPT2-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      890 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/readerbench_RoGPT2-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      697 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/readerbench_jurBERT-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      348 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/recobo_agriculture-bert-uncased.py
--rw-r--r--   0 runner    (1001) docker     (123)      249 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/roberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      250 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/roberta-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      412 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/saattrupdan_nbailab-base-ner-scandi.py
--rw-r--r--   0 runner    (1001) docker     (123)      526 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-lid-lince.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-ner-lince.py
--rw-r--r--   0 runner    (1001) docker     (123)      526 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-pos-lince.py
--rw-r--r--   0 runner    (1001) docker     (123)      661 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sagorsarker_codeswitch-spaeng-sentiment-analysis-lince.py
--rw-r--r--   0 runner    (1001) docker     (123)      813 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sail_poolformer_s12.py
--rw-r--r--   0 runner    (1001) docker     (123)     1005 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/salesken_natural_rephrase.py
--rw-r--r--   0 runner    (1001) docker     (123)     1900 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/salesken_paraphrase_diversity_ranker.py
--rw-r--r--   0 runner    (1001) docker     (123)     1245 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/salesken_paraphrase_generation.py
--rw-r--r--   0 runner    (1001) docker     (123)     1004 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/salesken_text_generate.py
--rw-r--r--   0 runner    (1001) docker     (123)      749 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sampathkethineedi_industry-classification.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/savasy_bert-base-turkish-ner-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      787 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/savasy_bert-base-turkish-sentiment-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)     1392 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sberbank-ai_sbert_large_mt_nlu_ru.py
--rw-r--r--   0 runner    (1001) docker     (123)     1392 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sberbank-ai_sbert_large_nlu_ru.py
--rw-r--r--   0 runner    (1001) docker     (123)      380 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_LaBSE.py
--rw-r--r--   0 runner    (1001) docker     (123)      402 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_all-MiniLM-L12-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      404 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_all-MiniLM-L12-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      400 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_all-MiniLM-L6-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      404 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_all-MiniLM-L6-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      409 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_all-distilroberta-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      402 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_all-mpnet-base-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      404 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_all-mpnet-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      409 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_all-roberta-large-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      398 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_allenai-specter.py
--rw-r--r--   0 runner    (1001) docker     (123)      414 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_bert-base-nli-cls-token.py
--rw-r--r--   0 runner    (1001) docker     (123)      414 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_bert-base-nli-max-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      420 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_bert-base-nli-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      429 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_bert-base-nli-stsb-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      448 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_bert-base-wikipedia-sections-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      418 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_bert-large-nli-max-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      420 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_bert-large-nli-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      428 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_bert-large-nli-stsb-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)     1965 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_clip-ViT-B-32-multilingual-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      430 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_distilbert-base-nli-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      442 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_distilbert-base-nli-stsb-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      442 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_distilbert-base-nli-stsb-quora-ranking.py
--rw-r--r--   0 runner    (1001) docker     (123)      426 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_distilroberta-base-msmarco-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      432 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_distilroberta-base-paraphrase-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      441 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_distiluse-base-multilingual-cased-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      444 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_distiluse-base-multilingual-cased-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      442 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_facebook-dpr-ctx_encoder-multiset-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      444 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_facebook-dpr-ctx_encoder-single-nq-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      452 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_facebook-dpr-question_encoder-multiset-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      454 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_facebook-dpr-question_encoder-single-nq-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      388 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_gtr-t5-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      392 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_gtr-t5-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      386 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_gtr-t5-xl.py
--rw-r--r--   0 runner    (1001) docker     (123)      412 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-MiniLM-L-12-v3.py
--rw-r--r--   0 runner    (1001) docker     (123)      410 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-MiniLM-L-6-v3.py
--rw-r--r--   0 runner    (1001) docker     (123)      893 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-MiniLM-L6-cos-v5.py
--rw-r--r--   0 runner    (1001) docker     (123)      919 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-bert-base-dot-v5.py
--rw-r--r--   0 runner    (1001) docker     (123)      438 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-dot-prod-v3.py
--rw-r--r--   0 runner    (1001) docker     (123)      926 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-tas-b.py
--rw-r--r--   0 runner    (1001) docker     (123)      420 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      420 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-v3.py
--rw-r--r--   0 runner    (1001) docker     (123)      421 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-v4.py
--rw-r--r--   0 runner    (1001) docker     (123)      897 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-cos-v5.py
--rw-r--r--   0 runner    (1001) docker     (123)      940 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-dot-v5.py
--rw-r--r--   0 runner    (1001) docker     (123)      478 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-multilingual-en-de-v2-tmp-lng-aligned.py
--rw-r--r--   0 runner    (1001) docker     (123)      488 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-multilingual-en-de-v2-tmp-trained-scratch.py
--rw-r--r--   0 runner    (1001) docker     (123)      426 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilroberta-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      430 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-roberta-base-ance-firstp.py
--rw-r--r--   0 runner    (1001) docker     (123)      416 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-roberta-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      414 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-roberta-base-v3.py
--rw-r--r--   0 runner    (1001) docker     (123)      899 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_multi-qa-MiniLM-L6-cos-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      898 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_multi-qa-MiniLM-L6-dot-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      899 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_multi-qa-distilbert-cos-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      900 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_multi-qa-mpnet-base-cos-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      901 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_multi-qa-mpnet-base-dot-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      392 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_nli-bert-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      416 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_nli-distilroberta-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      403 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_nli-mpnet-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      404 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_nli-roberta-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      400 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_nli-roberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      400 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_nli-roberta-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      410 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_nq-distilbert-base-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      418 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-MiniLM-L12-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      416 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-MiniLM-L3-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      418 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-MiniLM-L6-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      419 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-TinyBERT-L6-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      421 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-albert-small-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      433 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-distilroberta-base-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      433 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-distilroberta-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      418 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-mpnet-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      444 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-multilingual-MiniLM-L12-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      444 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-multilingual-mpnet-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      434 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_paraphrase-xlm-r-multilingual-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      408 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_quora-distilbert-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      427 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_quora-distilbert-multilingual.py
--rw-r--r--   0 runner    (1001) docker     (123)      424 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_roberta-base-nli-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      434 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_roberta-base-nli-stsb-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      424 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_roberta-large-nli-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      436 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_roberta-large-nli-stsb-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      400 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_sentence-t5-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      400 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_sentence-t5-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      394 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_sentence-t5-xl.py
--rw-r--r--   0 runner    (1001) docker     (123)      396 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_sentence-t5-xxl.py
--rw-r--r--   0 runner    (1001) docker     (123)      396 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_stsb-bert-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      396 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_stsb-bert-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      409 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_stsb-distilbert-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      420 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_stsb-distilroberta-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      405 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_stsb-mpnet-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      410 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_stsb-roberta-base-v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      404 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_stsb-roberta-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      415 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_stsb-xlm-r-multilingual.py
--rw-r--r--   0 runner    (1001) docker     (123)      408 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_use-cmlm-multilingual.py
--rw-r--r--   0 runner    (1001) docker     (123)      459 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_xlm-r-100langs-bert-base-nli-stsb-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      438 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_xlm-r-bert-base-nli-stsb-mean-tokens.py
--rw-r--r--   0 runner    (1001) docker     (123)      444 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_xlm-r-distilroberta-base-paraphrase-v1.py
--rw-r--r--   0 runner    (1001) docker     (123)      600 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/setu4993_LaBSE.py
--rw-r--r--   0 runner    (1001) docker     (123)      624 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/setu4993_smaller-LaBSE.py
--rw-r--r--   0 runner    (1001) docker     (123)      305 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/siebert_sentiment-roberta-large-english.py
--rw-r--r--   0 runner    (1001) docker     (123)      408 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sijunhe_nezha-cn-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      414 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/sijunhe_nezha-large-wwm.py
--rw-r--r--   0 runner    (1001) docker     (123)      374 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/snunlp_KR-SBERT-V40K-klueNLI-augSTS.py
--rw-r--r--   0 runner    (1001) docker     (123)      496 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/soheeyang_rdr-ctx_encoder-single-nq-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      549 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/soheeyang_rdr-question_encoder-single-nq-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      455 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/soleimanian_financial-roberta-large-sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)      602 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/squirro_albert-base-v2-squad_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)     1175 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/strombergnlp_dant5-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      608 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/svalabs_gbert-large-zeroshot-nli.py
--rw-r--r--   0 runner    (1001) docker     (123)      636 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/t5-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      637 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/t5-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      639 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/t5-small.py
--rw-r--r--   0 runner    (1001) docker     (123)      712 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/taeminlee_kogpt2.py
--rw-r--r--   0 runner    (1001) docker     (123)      672 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/tartuNLP_EstBERT_NER.py
--rw-r--r--   0 runner    (1001) docker     (123)      524 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/tdobrxl_ClinicBERT.py
--rw-r--r--   0 runner    (1001) docker     (123)      302 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/tennessejoyce_titlewave-t5-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      346 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/teven_all_bs160_allneg.py
--rw-r--r--   0 runner    (1001) docker     (123)      348 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/teven_all_bs192_hardneg.py
--rw-r--r--   0 runner    (1001) docker     (123)      348 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/teven_all_bs320_vanilla.py
--rw-r--r--   0 runner    (1001) docker     (123)      669 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/thanathorn_mt5-cpe-kmutt-thai-sentence-sum.py
--rw-r--r--   0 runner    (1001) docker     (123)      421 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/thunlp_Lawformer.py
--rw-r--r--   0 runner    (1001) docker     (123)      453 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/transfo-xl-wt103.py
--rw-r--r--   0 runner    (1001) docker     (123)     1661 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/tugstugi_bert-large-mongolian-uncased.py
--rw-r--r--   0 runner    (1001) docker     (123)      491 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/tuhailong_SimCSE-bert-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      458 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_albert-base-chinese-cluecorpussmall.py
--rw-r--r--   0 runner    (1001) docker     (123)      256 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_chinese_roberta_L-12_H-128.py
--rw-r--r--   0 runner    (1001) docker     (123)      258 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_chinese_roberta_L-12_H-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      257 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_chinese_roberta_L-2_H-128.py
--rw-r--r--   0 runner    (1001) docker     (123)      257 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_chinese_roberta_L-4_H-256.py
--rw-r--r--   0 runner    (1001) docker     (123)      257 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_chinese_roberta_L-4_H-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      255 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_chinese_roberta_L-6_H-128.py
--rw-r--r--   0 runner    (1001) docker     (123)      255 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_chinese_roberta_L-6_H-768.py
--rw-r--r--   0 runner    (1001) docker     (123)      255 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_chinese_roberta_L-8_H-256.py
--rw-r--r--   0 runner    (1001) docker     (123)      257 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_chinese_roberta_L-8_H-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      984 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-chinese-extractive-qa.py
--rw-r--r--   0 runner    (1001) docker     (123)      554 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-finetuned-chinanews-chinese.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-finetuned-cluener2020-chinese.py
--rw-r--r--   0 runner    (1001) docker     (123)      553 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-finetuned-dianping-chinese.py
--rw-r--r--   0 runner    (1001) docker     (123)      552 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-finetuned-jd-binary-chinese.py
--rw-r--r--   0 runner    (1001) docker     (123)      550 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-finetuned-jd-full-chinese.py
--rw-r--r--   0 runner    (1001) docker     (123)      286 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-word-chinese-cluecorpussmall.py
--rw-r--r--   0 runner    (1001) docker     (123)      545 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_t5-base-chinese-cluecorpussmall.py
--rw-r--r--   0 runner    (1001) docker     (123)      550 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_t5-small-chinese-cluecorpussmall.py
--rw-r--r--   0 runner    (1001) docker     (123)      564 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_t5-v1_1-base-chinese-cluecorpussmall.py
--rw-r--r--   0 runner    (1001) docker     (123)      563 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uer_t5-v1_1-small-chinese-cluecorpussmall.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/unicamp-dl_translation-pt-en-t5.py
--rw-r--r--   0 runner    (1001) docker     (123)      679 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/unitary_multilingual-toxic-xlm-roberta.py
--rw-r--r--   0 runner    (1001) docker     (123)      665 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/unitary_toxic-bert.py
--rw-r--r--   0 runner    (1001) docker     (123)      671 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/unitary_unbiased-toxic-roberta.py
--rw-r--r--   0 runner    (1001) docker     (123)      861 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ushikado_yuyuyui-chatbot.py
--rw-r--r--   0 runner    (1001) docker     (123)      254 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/uw-madison_nystromformer-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      955 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/valhalla_bart-large-finetuned-squadv1.py
--rw-r--r--   0 runner    (1001) docker     (123)      893 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/valhalla_t5-base-squad.py
--rw-r--r--   0 runner    (1001) docker     (123)      575 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/vblagoje_dpr-ctx_encoder-single-lfqa-wiki.py
--rw-r--r--   0 runner    (1001) docker     (123)     1071 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/vinvino02_glpn-kitti.py
--rw-r--r--   0 runner    (1001) docker     (123)     1065 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/vinvino02_glpn-nyu.py
--rw-r--r--   0 runner    (1001) docker     (123)      936 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/voidful_albert_chinese_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      938 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/voidful_albert_chinese_large.py
--rw-r--r--   0 runner    (1001) docker     (123)      940 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/voidful_albert_chinese_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      938 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/voidful_albert_chinese_tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/voidful_dpr-ctx_encoder-bert-base-multilingual.py
--rw-r--r--   0 runner    (1001) docker     (123)      547 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/voidful_dpr-question_encoder-bert-base-multilingual.py
--rw-r--r--   0 runner    (1001) docker     (123)      809 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/wanyu_IteraTeR-ROBERTA-Intention-Classifier.py
--rw-r--r--   0 runner    (1001) docker     (123)      369 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/whaleloops_phrase-bert.py
--rw-r--r--   0 runner    (1001) docker     (123)      863 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/wonrax_phobert-base-vietnamese-sentiment.py
--rw-r--r--   0 runner    (1001) docker     (123)      728 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/xlm-clm-ende-1024.py
--rw-r--r--   0 runner    (1001) docker     (123)      725 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/xlm-clm-enfr-1024.py
--rw-r--r--   0 runner    (1001) docker     (123)      441 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/xlm-mlm-en-2048.py
--rw-r--r--   0 runner    (1001) docker     (123)      257 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/xlm-roberta-base.py
--rw-r--r--   0 runner    (1001) docker     (123)      621 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/xlm-roberta-large-finetuned-conll03-german.py
--rw-r--r--   0 runner    (1001) docker     (123)      258 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/xlm-roberta-large.py
--rw-r--r--   0 runner    (1001) docker     (123)      438 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/xlnet-base-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)      440 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/xlnet-large-cased.py
--rw-r--r--   0 runner    (1001) docker     (123)     1413 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ybelkada_japanese-roberta-question-answering.py
--rw-r--r--   0 runner    (1001) docker     (123)     1288 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ydshieh_roberta-large-ner-english.py
--rw-r--r--   0 runner    (1001) docker     (123)     1137 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/ydshieh_vit-gpt2-coco-en.py
--rw-r--r--   0 runner    (1001) docker     (123)      645 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/yiyanghkust_finbert-esg.py
--rw-r--r--   0 runner    (1001) docker     (123)      663 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/yiyanghkust_finbert-fls.py
--rw-r--r--   0 runner    (1001) docker     (123)      767 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/popular_on_huggingface/yiyanghkust_finbert-tone.py
--rw-r--r--   0 runner    (1001) docker     (123)     9259 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/readme.md
--rw-r--r--   0 runner    (1001) docker     (123)      300 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/requirements.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.155531 mlagility-3.0.2/models/selftest/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/selftest/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      595 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/selftest/linear.py
--rw-r--r--   0 runner    (1001) docker     (123)      699 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/selftest/twolayer.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.371533 mlagility-3.0.2/models/timm/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/adv_inception_v3.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/bat_resnext26ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/beit_base_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/beit_base_patch16_224_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/beit_base_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/beit_large_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/beit_large_patch16_224_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/beit_large_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/beit_large_patch16_512.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/botnet26t_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/botnet50ts_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cait_m36_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cait_m48_448.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cait_s24_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cait_s24_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cait_s36_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cait_xs24_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cait_xxs24_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cait_xxs24_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cait_xxs36_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cait_xxs36_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/coat_lite_mini.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/coat_lite_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/coat_lite_tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/coat_mini.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/coat_tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convit_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convit_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convit_tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convmixer_1024_20_ks9_p14.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convmixer_1536_20.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convmixer_768_32.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_base_384_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_base_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_base_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_large.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_large_384_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_large_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_large_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_nano.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_nano_hnf.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_nano_ols.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_small_384_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_small_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_small_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_tiny_384_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_tiny_hnf.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_tiny_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_tiny_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_xlarge_384_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_xlarge_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/convnext_xlarge_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_15_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_15_dagger_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_15_dagger_408.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_18_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_18_dagger_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_18_dagger_408.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_9_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_9_dagger_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_base_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_small_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/crossvit_tiny_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3darknet_focus_l.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3darknet_focus_m.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3darknet_focus_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3darknet_focus_x.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3darknet_l.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3darknet_m.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3darknet_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3darknet_x.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3edgenet_x.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3se_edgenet_x.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3sedarknet_l.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3sedarknet_x.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cs3sedarknet_xdw.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cspdarknet53.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cspresnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cspresnet50d.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cspresnet50w.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/cspresnext50.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/darknet17.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/darknet21.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/darknet53.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/darknetaa53.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_base_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      541 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_base_patch16_224_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_base_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      541 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_base_patch16_384_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_huge_patch14_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      541 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_huge_patch14_224_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_large_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_large_patch16_224_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_large_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_large_patch16_384_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_small_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_small_patch16_224_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_small_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit3_small_patch16_384_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      541 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit_base_distilled_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      541 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit_base_distilled_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit_base_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit_base_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit_small_distilled_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit_small_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      541 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit_tiny_distilled_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/deit_tiny_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/densenet121.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/densenet121d.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/densenet161.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/densenet169.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/densenet201.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/densenet264.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/densenetblur121d.py
--rw-r--r--   0 runner    (1001) docker     (123)      491 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla102.py
--rw-r--r--   0 runner    (1001) docker     (123)      493 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla102x.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla102x2.py
--rw-r--r--   0 runner    (1001) docker     (123)      491 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla169.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla34.py
--rw-r--r--   0 runner    (1001) docker     (123)      493 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla46_c.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla46x_c.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla60.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla60_res2net.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla60_res2next.py
--rw-r--r--   0 runner    (1001) docker     (123)      491 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla60x.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dla60x_c.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dm_nfnet_f0.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dm_nfnet_f1.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dm_nfnet_f2.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dm_nfnet_f3.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dm_nfnet_f4.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dm_nfnet_f5.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dm_nfnet_f6.py
--rw-r--r--   0 runner    (1001) docker     (123)      491 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dpn107.py
--rw-r--r--   0 runner    (1001) docker     (123)      491 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dpn131.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dpn68.py
--rw-r--r--   0 runner    (1001) docker     (123)      491 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dpn68b.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dpn92.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/dpn98.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/eca_botnext26ts_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/eca_halonext26ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/eca_nfnet_l0.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/eca_nfnet_l1.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/eca_nfnet_l2.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/eca_nfnet_l3.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/eca_resnet33ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/eca_resnext26ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/eca_vovnet39b.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ecaresnet101d.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ecaresnet200d.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ecaresnet269d.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ecaresnet26t.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ecaresnet50d.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ecaresnet50t.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ecaresnetlight.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ecaresnext26t_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ecaresnext50t_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/edgenext_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/edgenext_small_rw.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/edgenext_x_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/edgenext_xx_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b0.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b0_g16_evos.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b0_g8_gn.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b0_gn.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b1.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b2.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b2a.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b3.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b3_g8_gn.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b3_gn.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b3a.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b4.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b5.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b6.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b7.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_b8.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_cc_b0_4e.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_cc_b0_8e.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_cc_b1_8e.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_el.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_el_pruned.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_em.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_es.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_es_pruned.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_l2.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_lite0.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_lite1.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_lite2.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_lite3.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnet_lite4.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnetv2_l.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnetv2_m.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnetv2_rw_m.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnetv2_rw_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnetv2_rw_t.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnetv2_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/efficientnetv2_xl.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ens_adv_inception_resnet_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ese_vovnet19b_dw.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ese_vovnet19b_slim.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ese_vovnet19b_slim_dw.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ese_vovnet39b.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ese_vovnet39b_evos.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ese_vovnet57b.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ese_vovnet99b.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/fbnetc_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/fbnetv3_b.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/fbnetv3_d.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/fbnetv3_g.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gc_efficientnetv2_rw_t.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gcresnet33ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gcresnet50t.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gcresnext26ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gcresnext50ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gernet_l.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gernet_m.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gernet_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ghostnet_050.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ghostnet_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ghostnet_130.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_inception_v3.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet101_v1b.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet101_v1c.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet101_v1d.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet101_v1s.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet152_v1b.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet152_v1c.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet152_v1d.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet152_v1s.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet18_v1b.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet34_v1b.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet50_v1b.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet50_v1c.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet50_v1d.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnet50_v1s.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnext101_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnext101_64x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_resnext50_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_senet154.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_seresnext101_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_seresnext101_64x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_seresnext50_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gluon_xception65.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gmixer_12_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gmixer_24_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gmlp_b16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gmlp_s16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/gmlp_ti16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/halo2botnet50ts_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/halonet26t.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/halonet50ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/halonet_h1.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/haloregnetz_b.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hardcorenas_a.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hardcorenas_b.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hardcorenas_c.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hardcorenas_d.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hardcorenas_e.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hardcorenas_f.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hrnet_w18.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hrnet_w18_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hrnet_w18_small_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hrnet_w30.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hrnet_w32.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hrnet_w40.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hrnet_w44.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hrnet_w48.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/hrnet_w64.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ig_resnext101_32x16d.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ig_resnext101_32x32d.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ig_resnext101_32x48d.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ig_resnext101_32x8d.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/inception_resnet_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/inception_v3.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/inception_v4.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/jx_nest_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/jx_nest_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/jx_nest_tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/lambda_resnet26rpt_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/lambda_resnet26t.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/lambda_resnet50ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/lamhalobotnet50ts_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/lcnet_035.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/lcnet_050.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/lcnet_075.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/lcnet_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/lcnet_150.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/legacy_senet154.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/legacy_seresnet101.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/legacy_seresnet152.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/legacy_seresnet18.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/legacy_seresnet34.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/legacy_seresnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/legacy_seresnext101_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/legacy_seresnext26_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/legacy_seresnext50_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/levit_128.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/levit_128s.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/levit_192.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/levit_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/levit_256d.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/levit_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixer_b16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixer_b16_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixer_b16_224_miil.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixer_b16_224_miil_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixer_b32_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixer_l16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixer_l16_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixer_l32_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixer_s16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixer_s32_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixnet_l.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixnet_m.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixnet_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixnet_xl.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mixnet_xxl.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mnasnet_050.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mnasnet_075.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mnasnet_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mnasnet_140.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mnasnet_a1.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mnasnet_b1.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mnasnet_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv2_035.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv2_050.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv2_075.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv2_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv2_110d.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv2_120d.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv2_140.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv3_large_075.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv3_large_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv3_large_100_miil.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv3_large_100_miil_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv3_rw.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv3_small_050.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv3_small_075.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilenetv3_small_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevit_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevit_xs.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevit_xxs.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_050.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_075.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_125.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_150.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_150_384_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_150_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_175.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_175_384_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_175_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_200.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_200_384_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/mobilevitv2_200_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nasnetalarge.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nest_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nest_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nest_tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_ecaresnet101.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_ecaresnet26.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_ecaresnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_regnet_b0.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_regnet_b1.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_regnet_b2.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_regnet_b3.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_regnet_b4.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_regnet_b5.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_resnet101.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_resnet26.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_resnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_seresnet101.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_seresnet26.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nf_seresnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nfnet_f0.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nfnet_f1.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nfnet_f2.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nfnet_f3.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nfnet_f4.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nfnet_f5.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nfnet_f6.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nfnet_f7.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/nfnet_l0.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/pit_b_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/pit_b_distilled_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/pit_s_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/pit_s_distilled_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/pit_ti_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/pit_ti_distilled_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/pit_xs_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/pit_xs_distilled_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/pnasnet5large.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/poolformer_m36.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/poolformer_m48.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/poolformer_s12.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/poolformer_s24.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/poolformer_s36.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetv_040.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetv_064.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_002.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_004.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_006.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_008.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_016.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_032.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_040.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_064.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_080.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_120.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_160.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetx_320.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_002.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_004.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_006.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_008.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_016.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_032.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_040.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_040s_gn.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_064.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_080.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_120.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_160.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnety_320.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_005.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_040.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_040h.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_b16.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_b16_evos.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_c16.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_c16_evos.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_d32.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_d8.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_d8_evos.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/regnetz_e8.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/repvgg_a2.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/repvgg_b0.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/repvgg_b1.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/repvgg_b1g4.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/repvgg_b2.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/repvgg_b2g4.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/repvgg_b3.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/repvgg_b3g4.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/res2net101_26w_4s.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/res2net50_14w_8s.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/res2net50_26w_4s.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/res2net50_26w_6s.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/res2net50_26w_8s.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/res2net50_48w_2s.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/res2next50.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_12_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_12_224_dino.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_12_distilled_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_24_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_24_224_dino.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_24_distilled_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_36_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_36_distilled_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_big_24_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_big_24_224_in22ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resmlp_big_24_distilled_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnest101e.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnest14d.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnest200e.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnest269e.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnest26d.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnest50d.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnest50d_1s4x24d.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnest50d_4s2x40d.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet101.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet101d.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet10t.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet14t.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet152.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet152d.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet18.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet18d.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet200.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet200d.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet26.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet26d.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet26t.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet32ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet33ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet34.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet34d.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet50_gn.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet50d.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet50t.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet51q.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnet61q.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetaa101d.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetaa50.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetaa50d.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetblur101d.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetblur18.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetblur50.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetblur50d.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetrs101.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetrs152.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetrs200.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetrs270.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetrs350.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetrs420.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetrs50.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_101.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_101d.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_101x1_bitm.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_101x1_bitm_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_101x3_bitm.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_101x3_bitm_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_152.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_152d.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_152x2_bit_teacher.py
--rw-r--r--   0 runner    (1001) docker     (123)      539 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_152x2_bit_teacher_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_152x2_bitm.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_152x2_bitm_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_152x4_bitm.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_152x4_bitm_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50d.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50d_evob.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50d_evos.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50d_frn.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50d_gn.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50t.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50x1_bit_distilled.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50x1_bitm.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50x1_bitm_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50x3_bitm.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnetv2_50x3_bitm_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnext101_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnext101_32x8d.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnext101_64x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnext26ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnext50_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/resnext50d_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/rexnet_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/rexnet_130.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/rexnet_150.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/rexnet_200.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/rexnetr_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/rexnetr_130.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/rexnetr_150.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/rexnetr_200.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/sebotnet33ts_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/sedarknet21.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/sehalonet33ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/selecsls42.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/selecsls42b.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/selecsls60.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/selecsls60b.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/selecsls84.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/semnasnet_050.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/semnasnet_075.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/semnasnet_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/semnasnet_140.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/semobilevit_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/senet154.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/sequencer2d_l.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/sequencer2d_m.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/sequencer2d_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnet101.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnet152.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnet152d.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnet18.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnet200d.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnet269d.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnet33ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnet34.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnet50t.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnetaa50d.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnext101_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnext101_32x8d.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnext101d_32x8d.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnext26d_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnext26t_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnext26tn_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnext26ts.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnext50_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/seresnextaa101d_32x8d.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/skresnet18.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/skresnet34.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/skresnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/skresnet50d.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/skresnext50_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/spnasnet_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ssl_resnet18.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ssl_resnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ssl_resnext101_32x16d.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ssl_resnext101_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ssl_resnext101_32x8d.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/ssl_resnext50_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      537 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_base_patch4_window12_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      549 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_base_patch4_window12_384_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_base_patch4_window7_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      547 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_base_patch4_window7_224_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      539 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_large_patch4_window12_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      551 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_large_patch4_window12_384_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      537 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_large_patch4_window7_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      549 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_large_patch4_window7_224_in22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_s3_base_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_s3_small_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_s3_tiny_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      537 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_small_patch4_window7_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swin_tiny_patch4_window7_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_base_window12_192_22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      561 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_base_window12to16_192to256_22kft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      561 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_base_window12to24_192to384_22kft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_base_window16_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_base_window8_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_base_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_base_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_base_ns_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_giant_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_giant_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_huge_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_huge_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_large_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_large_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_small_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_small_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_small_ns_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_tiny_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_tiny_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_cr_tiny_ns_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      537 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_large_window12_192_22k.py
--rw-r--r--   0 runner    (1001) docker     (123)      563 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_large_window12to16_192to256_22kft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      563 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_large_window12to24_192to384_22kft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_small_window16_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_small_window8_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_tiny_window16_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swinv2_tiny_window8_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swsl_resnet18.py
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swsl_resnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swsl_resnext101_32x16d.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swsl_resnext101_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swsl_resnext101_32x8d.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/swsl_resnext50_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b0.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b0_ap.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b0_ns.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b1.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b1_ap.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b1_ns.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b2.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b2_ap.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b2_ns.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b3.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b3_ap.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b3_ns.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b4.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b4_ap.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b4_ns.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b5.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b5_ap.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b5_ns.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b6.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b6_ap.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b6_ns.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b7.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b7_ap.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b7_ns.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b8.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_b8_ap.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_cc_b0_4e.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_cc_b0_8e.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_cc_b1_8e.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_el.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_em.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_es.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_l2_ns.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_l2_ns_475.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_lite0.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_lite1.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_lite2.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_lite3.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnet_lite4.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_b0.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_b1.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_b2.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_b3.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_l.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_l_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_l_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_m.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_m_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_m_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_s_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_s_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      537 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_xl_in21ft1k.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_efficientnetv2_xl_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_inception_v3.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_mixnet_l.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_mixnet_m.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_mixnet_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_mobilenetv3_large_075.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_mobilenetv3_large_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_mobilenetv3_large_minimal_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_mobilenetv3_small_075.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_mobilenetv3_small_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tf_mobilenetv3_small_minimal_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tinynet_a.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tinynet_b.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tinynet_c.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tinynet_d.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tinynet_e.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tnt_b_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tnt_s_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tv_densenet121.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tv_resnet101.py
--rw-r--r--   0 runner    (1001) docker     (123)      503 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tv_resnet152.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tv_resnet34.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tv_resnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      515 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/tv_resnext50_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/twins_pcpvt_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/twins_pcpvt_large.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/twins_pcpvt_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/twins_svt_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/twins_svt_large.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/twins_svt_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vgg11.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vgg11_bn.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vgg13.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vgg13_bn.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vgg16.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vgg16_bn.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vgg19.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vgg19_bn.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/visformer_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      507 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/visformer_tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch16_18x2_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch16_224_dino.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch16_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch16_224_miil.py
--rw-r--r--   0 runner    (1001) docker     (123)      541 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch16_224_miil_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch16_224_sam.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch16_plus_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch16_rpn_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch32_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch32_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch32_224_sam.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch32_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch32_plus_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch8_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch8_224_dino.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_patch8_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_r26_s32_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_r50_s16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_r50_s16_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_r50_s16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_resnet26d_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_resnet50_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_resnet50_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_base_resnet50d_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_giant_patch14_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_gigantic_patch14_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_huge_patch14_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_huge_patch14_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_large_patch14_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_large_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_large_patch16_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_large_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_large_patch32_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_large_patch32_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_large_patch32_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_large_r50_s32_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_large_r50_s32_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_large_r50_s32_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_base_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      541 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_base_patch16_cls_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      547 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_base_patch16_clsgap_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_base_patch16_plus_240.py
--rw-r--r--   0 runner    (1001) docker     (123)      541 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_base_patch16_rpn_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      551 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_base_patch32_plus_rpn_256.py
--rw-r--r--   0 runner    (1001) docker     (123)      537 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_medium_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      545 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_medium_patch16_cls_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      545 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_medium_patch16_rpn_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_small_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_relpos_small_patch16_rpn_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_patch16_18x2_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_patch16_224_dino.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_patch16_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_patch16_36x1_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_patch32_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_patch32_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_patch32_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_patch8_224_dino.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_r26_s32_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_r26_s32_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_r26_s32_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_resnet26d_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_small_resnet50d_s16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      539 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_srelpos_medium_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      537 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_srelpos_small_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_tiny_patch16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_tiny_patch16_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_tiny_patch16_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_tiny_r_s16_p8_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_tiny_r_s16_p8_224_in21k.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vit_tiny_r_s16_p8_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d1_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d1_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d2_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d2_384.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d3_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d3_448.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d4_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d4_448.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d5_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d5_448.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/volo_d5_512.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vovnet39a.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/vovnet57a.py
--rw-r--r--   0 runner    (1001) docker     (123)      511 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/wide_resnet101_2.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/wide_resnet50_2.py
--rw-r--r--   0 runner    (1001) docker     (123)      495 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xception.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xception41.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xception41p.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xception65.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xception65p.py
--rw-r--r--   0 runner    (1001) docker     (123)      499 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xception71.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_large_24_p16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_large_24_p16_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_large_24_p16_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_large_24_p8_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_large_24_p8_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_large_24_p8_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_medium_24_p16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_medium_24_p16_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_medium_24_p16_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_medium_24_p8_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_medium_24_p8_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_medium_24_p8_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_nano_12_p16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_nano_12_p16_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_nano_12_p16_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_nano_12_p8_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_nano_12_p8_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_nano_12_p8_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_12_p16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_12_p16_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_12_p16_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_12_p8_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_12_p8_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_12_p8_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_24_p16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_24_p16_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_24_p16_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_24_p8_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_24_p8_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_small_24_p8_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_12_p16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_12_p16_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_12_p16_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_12_p8_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_12_p8_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_12_p8_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_24_p16_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_24_p16_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_24_p16_384_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_24_p8_224.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_24_p8_224_dist.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/timm/xcit_tiny_24_p8_384_dist.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.403533 mlagility-3.0.2/models/torch_hub/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      589 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/alexnet.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/convnext_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/convnext_large.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/convnext_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/convnext_tiny.py
--rw-r--r--   0 runner    (1001) docker     (123)      492 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/dcgan.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/densenet121.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/densenet161.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/densenet169.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/densenet201.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_b0.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_b1.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_b2.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_b3.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_b4.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_b5.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_b6.py
--rw-r--r--   0 runner    (1001) docker     (123)      527 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_b7.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_v2_l.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_v2_m.py
--rw-r--r--   0 runner    (1001) docker     (123)      531 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/efficientnet_v2_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      590 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/ghostnet.py
--rw-r--r--   0 runner    (1001) docker     (123)      596 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/ghostnet_1x.py
--rw-r--r--   0 runner    (1001) docker     (123)      595 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/googlenet.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/hardnet39ds.py
--rw-r--r--   0 runner    (1001) docker     (123)      594 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/hardnet68.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/hardnet68ds.py
--rw-r--r--   0 runner    (1001) docker     (123)      594 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/hardnet85.py
--rw-r--r--   0 runner    (1001) docker     (123)      604 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/inception_v3.py
--rw-r--r--   0 runner    (1001) docker     (123)      615 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mealv1_resnest50.py
--rw-r--r--   0 runner    (1001) docker     (123)      627 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mealv2_efficientnet_b0.py
--rw-r--r--   0 runner    (1001) docker     (123)      641 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mealv2_mobilenet_v3_large_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      639 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mealv2_mobilenetv3_small_075.py
--rw-r--r--   0 runner    (1001) docker     (123)      639 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mealv2_mobilenetv3_small_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      615 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mealv2_resnest50.py
--rw-r--r--   0 runner    (1001) docker     (123)      631 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mealv2_resnest50_380x380.py
--rw-r--r--   0 runner    (1001) docker     (123)      629 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mealv2_resnest50_cutmix.py
--rw-r--r--   0 runner    (1001) docker     (123)      542 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/midas_v2.1_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      540 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/midas_v3_hybrid.py
--rw-r--r--   0 runner    (1001) docker     (123)      538 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/midas_v3_large.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mnasnet0_5.py
--rw-r--r--   0 runner    (1001) docker     (123)      519 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mnasnet0_75.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mnasnet1_0.py
--rw-r--r--   0 runner    (1001) docker     (123)      517 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mnasnet1_3.py
--rw-r--r--   0 runner    (1001) docker     (123)      604 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mobilenet_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mobilenet_v3_large.py
--rw-r--r--   0 runner    (1001) docker     (123)      533 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/mobilenet_v3_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      608 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/proxyless_cpu.py
--rw-r--r--   0 runner    (1001) docker     (123)      608 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/proxyless_gpu.py
--rw-r--r--   0 runner    (1001) docker     (123)      614 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/proxyless_mobile.py
--rw-r--r--   0 runner    (1001) docker     (123)      620 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/proxyless_mobile_14.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_x_16gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_x_1_6gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_x_32gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_x_3_2gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_x_400mf.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_x_800mf.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_x_8gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_y_128gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_y_16gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_y_1_6gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_y_32gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_y_3_2gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_y_400mf.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_y_800mf.py
--rw-r--r--   0 runner    (1001) docker     (123)      521 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/regnet_y_8gf.py
--rw-r--r--   0 runner    (1001) docker     (123)      594 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest101.py
--rw-r--r--   0 runner    (1001) docker     (123)      594 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest200.py
--rw-r--r--   0 runner    (1001) docker     (123)      594 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest269.py
--rw-r--r--   0 runner    (1001) docker     (123)      592 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest50.py
--rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest50_fast_1s1x64d.py
--rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest50_fast_1s2x40d.py
--rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest50_fast_1s4x24d.py
--rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest50_fast_2s1x64d.py
--rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest50_fast_2s2x40d.py
--rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest50_fast_4s1x64d.py
--rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnest50_fast_4s2x40d.py
--rw-r--r--   0 runner    (1001) docker     (123)      592 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet101.py
--rw-r--r--   0 runner    (1001) docker     (123)      600 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet101_ibn_a.py
--rw-r--r--   0 runner    (1001) docker     (123)      600 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet101_ibn_b.py
--rw-r--r--   0 runner    (1001) docker     (123)      592 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet152.py
--rw-r--r--   0 runner    (1001) docker     (123)      590 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet18.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet18_ibn_a.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet18_ibn_b.py
--rw-r--r--   0 runner    (1001) docker     (123)      590 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet34.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet34_ibn_a.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet34_ibn_b.py
--rw-r--r--   0 runner    (1001) docker     (123)      590 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet50.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet50_ibn_a.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnet50_ibn_b.py
--rw-r--r--   0 runner    (1001) docker     (123)      607 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnext101_32x8d.py
--rw-r--r--   0 runner    (1001) docker     (123)      602 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnext101_ibn_a.py
--rw-r--r--   0 runner    (1001) docker     (123)      605 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/resnext50_32x4d.py
--rw-r--r--   0 runner    (1001) docker     (123)      606 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/se_resnet101_ibn_a.py
--rw-r--r--   0 runner    (1001) docker     (123)      617 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/shufflenet_v2_x0_5.py
--rw-r--r--   0 runner    (1001) docker     (123)      617 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/shufflenet_v2_x1_0.py
--rw-r--r--   0 runner    (1001) docker     (123)      617 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/shufflenet_v2_x1_5.py
--rw-r--r--   0 runner    (1001) docker     (123)      617 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/shufflenet_v2_x2_0.py
--rw-r--r--   0 runner    (1001) docker     (123)      604 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/squeezenet1_0.py
--rw-r--r--   0 runner    (1001) docker     (123)      604 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/squeezenet1_1.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/swin_b.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/swin_s.py
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/swin_t.py
--rw-r--r--   0 runner    (1001) docker     (123)      643 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/unet.py
--rw-r--r--   0 runner    (1001) docker     (123)      581 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vgg11.py
--rw-r--r--   0 runner    (1001) docker     (123)      587 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vgg11_bn.py
--rw-r--r--   0 runner    (1001) docker     (123)      581 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vgg13.py
--rw-r--r--   0 runner    (1001) docker     (123)      587 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vgg13_bn.py
--rw-r--r--   0 runner    (1001) docker     (123)      581 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vgg16.py
--rw-r--r--   0 runner    (1001) docker     (123)      587 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vgg16_bn.py
--rw-r--r--   0 runner    (1001) docker     (123)      581 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vgg19.py
--rw-r--r--   0 runner    (1001) docker     (123)      587 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vgg19_bn.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vit_b_16.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vit_b_32.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vit_h_14.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vit_l_16.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/vit_l_32.py
--rw-r--r--   0 runner    (1001) docker     (123)      611 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/wide_resnet101_2.py
--rw-r--r--   0 runner    (1001) docker     (123)      609 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torch_hub/wide_resnet50_2.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.407534 mlagility-3.0.2/models/torchvision/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      654 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/fasterrcnn_mobilenet_v3_large_320_fpn.py
--rw-r--r--   0 runner    (1001) docker     (123)      642 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/fasterrcnn_mobilenet_v3_large_fpn.py
--rw-r--r--   0 runner    (1001) docker     (123)      612 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/fasterrcnn_resnet50_fpn.py
--rw-r--r--   0 runner    (1001) docker     (123)      621 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/fasterrcnn_resnet50_fpn_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      587 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/fcos_resnet50_fpn.py
--rw-r--r--   0 runner    (1001) docker     (123)      620 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/keypointrcnn_resnet50_fpn.py
--rw-r--r--   0 runner    (1001) docker     (123)      604 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/maskrcnn_resnet50_fpn.py
--rw-r--r--   0 runner    (1001) docker     (123)      613 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/maskrcnn_resnet50_fpn_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      607 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/retinanet_resnet50_fpn.py
--rw-r--r--   0 runner    (1001) docker     (123)      616 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/retinanet_resnet50_fpn_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)      571 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/ssd300_vgg16.py
--rw-r--r--   0 runner    (1001) docker     (123)      626 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/torchvision/ssdlite320_mobilenet_v3_large.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.427533 mlagility-3.0.2/models/transformers/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      566 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/bart.py
--rw-r--r--   0 runner    (1001) docker     (123)      552 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/beit.py
--rw-r--r--   0 runner    (1001) docker     (123)      650 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/bert.py
--rw-r--r--   0 runner    (1001) docker     (123)      804 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/bert_for_question_answering.py
--rw-r--r--   0 runner    (1001) docker     (123)      875 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/bert_generation.py
--rw-r--r--   0 runner    (1001) docker     (123)      745 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/bert_tiny_for_sequence_classification.py
--rw-r--r--   0 runner    (1001) docker     (123)      597 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/bigbird_pegasus.py
--rw-r--r--   0 runner    (1001) docker     (123)      711 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/biggan.py
--rw-r--r--   0 runner    (1001) docker     (123)      602 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/blenderbot_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      581 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/camembert.py
--rw-r--r--   0 runner    (1001) docker     (123)      578 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/convbert.py
--rw-r--r--   0 runner    (1001) docker     (123)      564 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/convnext.py
--rw-r--r--   0 runner    (1001) docker     (123)      545 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/data2vecaudio.py
--rw-r--r--   0 runner    (1001) docker     (123)      668 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/data2vectext.py
--rw-r--r--   0 runner    (1001) docker     (123)      575 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/deberta.py
--rw-r--r--   0 runner    (1001) docker     (123)      552 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/deit.py
--rw-r--r--   0 runner    (1001) docker     (123)      649 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/deit_base_for_image_classification.py
--rw-r--r--   0 runner    (1001) docker     (123)      649 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/deit_tiny_for_image_classification.py
--rw-r--r--   0 runner    (1001) docker     (123)      552 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/detr.py
--rw-r--r--   0 runner    (1001) docker     (123)      744 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/detr_for_object_detection.py
--rw-r--r--   0 runner    (1001) docker     (123)      693 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/distil_wav2vec2_for_audio_classification.py
--rw-r--r--   0 runner    (1001) docker     (123)      600 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/distilbert.py
--rw-r--r--   0 runner    (1001) docker     (123)      728 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/distilbert_for_question_answering.py
--rw-r--r--   0 runner    (1001) docker     (123)      674 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/distilhubert_for_audio_classification.py
--rw-r--r--   0 runner    (1001) docker     (123)      575 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/electra.py
--rw-r--r--   0 runner    (1001) docker     (123)      718 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/electra_for_sequence_classification.py
--rw-r--r--   0 runner    (1001) docker     (123)      686 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/encoder_decoder.py
--rw-r--r--   0 runner    (1001) docker     (123)      578 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/flaubert.py
--rw-r--r--   0 runner    (1001) docker     (123)      572 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/funnel.py
--rw-r--r--   0 runner    (1001) docker     (123)      581 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/funnel_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      576 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/gpt1.py
--rw-r--r--   0 runner    (1001) docker     (123)      566 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/gpt2.py
--rw-r--r--   0 runner    (1001) docker     (123)      588 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/gpt2_doublehead.py
--rw-r--r--   0 runner    (1001) docker     (123)      524 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/hubert.py
--rw-r--r--   0 runner    (1001) docker     (123)      569 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/ibert.py
--rw-r--r--   0 runner    (1001) docker     (123)      578 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/imagegpt.py
--rw-r--r--   0 runner    (1001) docker     (123)      705 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/layoutlm.py
--rw-r--r--   0 runner    (1001) docker     (123)      566 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/luke.py
--rw-r--r--   0 runner    (1001) docker     (123)      575 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/m2m_100.py
--rw-r--r--   0 runner    (1001) docker     (123)      553 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/marian.py
--rw-r--r--   0 runner    (1001) docker     (123)      557 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/marianmt.py
--rw-r--r--   0 runner    (1001) docker     (123)      591 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/megatron_bert.py
--rw-r--r--   0 runner    (1001) docker     (123)      783 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/minilmv2.py
--rw-r--r--   0 runner    (1001) docker     (123)      584 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/mobilebert.py
--rw-r--r--   0 runner    (1001) docker     (123)      727 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/mobilebert_for_sequence_classification.py
--rw-r--r--   0 runner    (1001) docker     (123)      635 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/mobilevit.py
--rw-r--r--   0 runner    (1001) docker     (123)      656 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/mobilevit_small_for_semantic_segmentation.py
--rw-r--r--   0 runner    (1001) docker     (123)      672 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/mobilevit_x_small_for_semantic_segmentation.py
--rw-r--r--   0 runner    (1001) docker     (123)      665 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/mobilevit_xx_small_for_semantic_segmentation.py
--rw-r--r--   0 runner    (1001) docker     (123)      569 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/mpnet.py
--rw-r--r--   0 runner    (1001) docker     (123)      541 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/mt5_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/mt5_encoder.py
--rw-r--r--   0 runner    (1001) docker     (123)      543 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/mt5_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      600 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/openai_doublehead.py
--rw-r--r--   0 runner    (1001) docker     (123)      577 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/pegasus.py
--rw-r--r--   0 runner    (1001) docker     (123)      523 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/perceiver.py
--rw-r--r--   0 runner    (1001) docker     (123)      570 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/poolformer.py
--rw-r--r--   0 runner    (1001) docker     (123)      785 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/rag.py
--rw-r--r--   0 runner    (1001) docker     (123)      579 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/realm.py
--rw-r--r--   0 runner    (1001) docker     (123)      582 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/rembert.py
--rw-r--r--   0 runner    (1001) docker     (123)      797 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/retribert.py
--rw-r--r--   0 runner    (1001) docker     (123)      582 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/roberta.py
--rw-r--r--   0 runner    (1001) docker     (123)      585 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/roformer.py
--rw-r--r--   0 runner    (1001) docker     (123)      574 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/segformer.py
--rw-r--r--   0 runner    (1001) docker     (123)      450 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/sew.py
--rw-r--r--   0 runner    (1001) docker     (123)      454 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/sew_d.py
--rw-r--r--   0 runner    (1001) docker     (123)      711 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/speech_encoder_decoder.py
--rw-r--r--   0 runner    (1001) docker     (123)      810 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/speech_encoder_decoder_pretrained.py
--rw-r--r--   0 runner    (1001) docker     (123)      624 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/speech_to_text.py
--rw-r--r--   0 runner    (1001) docker     (123)      585 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/splinter.py
--rw-r--r--   0 runner    (1001) docker     (123)      594 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/squeezebert.py
--rw-r--r--   0 runner    (1001) docker     (123)      557 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/t5_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      501 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/t5_encoder.py
--rw-r--r--   0 runner    (1001) docker     (123)      559 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/t5_large.py
--rw-r--r--   0 runner    (1001) docker     (123)      559 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/t5_small.py
--rw-r--r--   0 runner    (1001) docker     (123)      585 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/unispeech.py
--rw-r--r--   0 runner    (1001) docker     (123)      595 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/unispeech_sat.py
--rw-r--r--   0 runner    (1001) docker     (123)      781 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/vision_encoder_decoder.py
--rw-r--r--   0 runner    (1001) docker     (123)      556 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/vit.py
--rw-r--r--   0 runner    (1001) docker     (123)      465 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/wav2vec2.py
--rw-r--r--   0 runner    (1001) docker     (123)      573 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/xglm.py
--rw-r--r--   0 runner    (1001) docker     (123)      570 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/xlm.py
--rw-r--r--   0 runner    (1001) docker     (123)      592 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/xlm_roberta.py
--rw-r--r--   0 runner    (1001) docker     (123)      524 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/xlnet-512.py
--rw-r--r--   0 runner    (1001) docker     (123)      576 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/xlnet.py
--rw-r--r--   0 runner    (1001) docker     (123)      621 2023-04-28 17:00:56.000000 mlagility-3.0.2/models/transformers/yolos_tiny_for_object_detection.py
--rw-r--r--   0 runner    (1001) docker     (123)       86 2023-04-28 17:00:56.000000 mlagility-3.0.2/pyproject.toml
--rw-r--r--   0 runner    (1001) docker     (123)       38 2023-04-28 17:01:28.443534 mlagility-3.0.2/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (123)     2181 2023-04-28 17:00:56.000000 mlagility-3.0.2/setup.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.023530 mlagility-3.0.2/src/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.431534 mlagility-3.0.2/src/mlagility/
--rw-r--r--   0 runner    (1001) docker     (123)      171 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.431534 mlagility-3.0.2/src/mlagility/analysis/
--rw-r--r--   0 runner    (1001) docker     (123)    18571 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/analysis/analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)     4493 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/analysis/status.py
--rw-r--r--   0 runner    (1001) docker     (123)     1213 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/analysis/tf_helpers.py
--rw-r--r--   0 runner    (1001) docker     (123)     3983 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/analysis/util.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.435534 mlagility-3.0.2/src/mlagility/api/
--rw-r--r--   0 runner    (1001) docker     (123)      251 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/api/Dockerfile
--rw-r--r--   0 runner    (1001) docker     (123)    22712 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/api/devices.py
--rw-r--r--   0 runner    (1001) docker     (123)     5325 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/api/execute_trt.py
--rw-r--r--   0 runner    (1001) docker     (123)     9817 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/api/model_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     2973 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/api/ortmodel.py
--rw-r--r--   0 runner    (1001) docker     (123)      732 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/api/performance.py
--rw-r--r--   0 runner    (1001) docker     (123)     3020 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/api/run_ort_model.py
--rw-r--r--   0 runner    (1001) docker     (123)    12751 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/api/script_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     8029 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/api/setup_ort.py
--rw-r--r--   0 runner    (1001) docker     (123)     3045 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/api/trtmodel.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.435534 mlagility-3.0.2/src/mlagility/cli/
--rwxr-xr-x   0 runner    (1001) docker     (123)    16226 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/cli/cli.py
--rw-r--r--   0 runner    (1001) docker     (123)      583 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/cli/login.py
--rw-r--r--   0 runner    (1001) docker     (123)    10164 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/cli/report.py
--rw-r--r--   0 runner    (1001) docker     (123)     4497 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/cli/slurm.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.435534 mlagility-3.0.2/src/mlagility/common/
--rw-r--r--   0 runner    (1001) docker     (123)    10924 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/common/filesystem.py
--rw-r--r--   0 runner    (1001) docker     (123)     3299 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/common/labels.py
--rw-r--r--   0 runner    (1001) docker     (123)     3495 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/parser.py
--rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/mlagility/version.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.431534 mlagility-3.0.2/src/mlagility.egg-info/
--rw-r--r--   0 runner    (1001) docker     (123)     5303 2023-04-28 17:01:27.000000 mlagility-3.0.2/src/mlagility.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)    89406 2023-04-28 17:01:28.000000 mlagility-3.0.2/src/mlagility.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-28 17:01:27.000000 mlagility-3.0.2/src/mlagility.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (123)       49 2023-04-28 17:01:27.000000 mlagility-3.0.2/src/mlagility.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (123)      300 2023-04-28 17:01:27.000000 mlagility-3.0.2/src/mlagility.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (123)       36 2023-04-28 17:01:27.000000 mlagility-3.0.2/src/mlagility.egg-info/top_level.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.439534 mlagility-3.0.2/src/onnxflow/
--rw-r--r--   0 runner    (1001) docker     (123)      150 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.439534 mlagility-3.0.2/src/onnxflow/common/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/common/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    15253 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/common/build.py
--rw-r--r--   0 runner    (1001) docker     (123)     1052 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/common/cache.py
--rw-r--r--   0 runner    (1001) docker     (123)     1614 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/common/exceptions.py
--rw-r--r--   0 runner    (1001) docker     (123)     4631 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/common/onnx_helpers.py
--rw-r--r--   0 runner    (1001) docker     (123)     3063 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/common/printing.py
--rw-r--r--   0 runner    (1001) docker     (123)     2342 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/common/quantization_helpers.py
--rw-r--r--   0 runner    (1001) docker     (123)     2440 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/common/tensor_helpers.py
--rw-r--r--   0 runner    (1001) docker     (123)     1196 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/common/tf_helpers.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.443534 mlagility-3.0.2/src/onnxflow/justbuildit/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/justbuildit/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (123)     5110 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/justbuildit/buildit.py
--rw-r--r--   0 runner    (1001) docker     (123)    22145 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/justbuildit/export.py
--rw-r--r--   0 runner    (1001) docker     (123)     6970 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/justbuildit/hummingbird.py
--rw-r--r--   0 runner    (1001) docker     (123)    21952 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/justbuildit/ignition.py
--rw-r--r--   0 runner    (1001) docker     (123)    11511 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/justbuildit/stage.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-28 17:01:28.443534 mlagility-3.0.2/src/onnxflow/model/
--rw-r--r--   0 runner    (1001) docker     (123)       53 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     5919 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/model/model.py
--rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-28 17:00:56.000000 mlagility-3.0.2/src/onnxflow/version.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.901213 mlagility-3.1.1/
+-rw-r--r--   0 runner    (1001) docker     (123)     1066 2023-06-08 21:31:08.000000 mlagility-3.1.1/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (123)     5486 2023-06-08 21:31:56.901213 mlagility-3.1.1/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     5026 2023-06-08 21:31:08.000000 mlagility-3.1.1/README.md
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.673214 mlagility-3.1.1/models/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.673214 mlagility-3.1.1/models/diffusers/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/diffusers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      567 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/diffusers/clip_text_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (123)      804 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/diffusers/safety_clipvision.py
+-rw-r--r--   0 runner    (1001) docker     (123)      736 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/diffusers/unet_2d_condition.py
+-rw-r--r--   0 runner    (1001) docker     (123)      554 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/diffusers/vae_decoder.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.673214 mlagility-3.1.1/models/graph_convolutions/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      897 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/chebconv.py
+-rw-r--r--   0 runner    (1001) docker     (123)      951 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/dnaconv.py
+-rw-r--r--   0 runner    (1001) docker     (123)      896 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/egconv.py
+-rw-r--r--   0 runner    (1001) docker     (123)      778 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/feastconv.py
+-rw-r--r--   0 runner    (1001) docker     (123)      849 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/gatedgraphconv.py
+-rw-r--r--   0 runner    (1001) docker     (123)      718 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/generalconv.py
+-rw-r--r--   0 runner    (1001) docker     (123)      771 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/leconv.py
+-rw-r--r--   0 runner    (1001) docker     (123)      900 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/pnaconv.py
+-rw-r--r--   0 runner    (1001) docker     (123)      746 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/resgatedgraphconv.py
+-rw-r--r--   0 runner    (1001) docker     (123)      714 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/sageconv.py
+-rw-r--r--   0 runner    (1001) docker     (123)      744 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/graph_convolutions/tagconv.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.673214 mlagility-3.1.1/models/llm/
+-rw-r--r--   0 runner    (1001) docker     (123)      718 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm/gpt_neo.py
+-rw-r--r--   0 runner    (1001) docker     (123)      721 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm/gpt_neox.py
+-rw-r--r--   0 runner    (1001) docker     (123)      659 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm/gptj.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.673214 mlagility-3.1.1/models/llm_layer/
+-rw-r--r--   0 runner    (1001) docker     (123)      768 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/gpt_neo_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      761 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/gpt_neox_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      726 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/gptj_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      205 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/llama_13b_cache_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      200 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/llama_13b_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      205 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/llama_33b_cache_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      200 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/llama_33b_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      205 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/llama_65b_cache_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      200 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/llama_65b_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      203 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/llama_7b_cache_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      198 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/llama_7b_layer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3266 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/llm_layer/llama_layer_prototype.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.749214 mlagility-3.1.1/models/popular_on_huggingface/
+-rw-r--r--   0 runner    (1001) docker     (123)     1653 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/0x7194633_keyt5-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      394 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/AI-Growth-Lab_PatentSBERTa.py
+-rw-r--r--   0 runner    (1001) docker     (123)      656 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/AmazonScience_qanlu.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1023 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/BM-K_KoSimCSE-roberta.py
+-rw-r--r--   0 runner    (1001) docker     (123)      636 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Babelscape_wikineural-multilingual-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)      777 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Bhuvana_t5-base-spellchecker.py
+-rw-r--r--   0 runner    (1001) docker     (123)      361 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-ca-pos-egy.py
+-rw-r--r--   0 runner    (1001) docker     (123)      347 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-ca.py
+-rw-r--r--   0 runner    (1001) docker     (123)      460 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-da-pos-msa.py
+-rw-r--r--   0 runner    (1001) docker     (123)      345 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-da.py
+-rw-r--r--   0 runner    (1001) docker     (123)      464 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-mix-pos-msa.py
+-rw-r--r--   0 runner    (1001) docker     (123)      347 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-mix.py
+-rw-r--r--   0 runner    (1001) docker     (123)      347 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-msa.py
+-rw-r--r--   0 runner    (1001) docker     (123)      647 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/CompVis_ldm-text2im-large-256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      559 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/CompVis_stable-diffusion-v1-4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      475 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/DMetaSoul_sbert-chinese-general-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      650 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Davlan_bert-base-multilingual-cased-masakhaner.py
+-rw-r--r--   0 runner    (1001) docker     (123)      673 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Davlan_bert-base-multilingual-cased-ner-hrl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      689 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Davlan_distilbert-base-multilingual-cased-ner-hrl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      635 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Davlan_xlm-roberta-base-ner-hrl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      638 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Davlan_xlm-roberta-large-ner-hrl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      345 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/DmitryPogrebnoy_MedRuRobertaLarge.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1220 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ElKulako_cryptobert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      638 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Elron_bleurt-base-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      642 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Elron_bleurt-large-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      643 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Elron_bleurt-tiny-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      698 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/FinanceInc_finbert_fls.py
+-rw-r--r--   0 runner    (1001) docker     (123)      917 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/HooshvareLab_bert-fa-zwnj-base-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)      931 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/HooshvareLab_distilbert-fa-zwnj-base-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2324 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Huffon_sentence-klue-roberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      602 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-DeBERTa-v2-710M-Chinese.py
+-rw-r--r--   0 runner    (1001) docker     (123)      639 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-110M-NLI.py
+-rw-r--r--   0 runner    (1001) docker     (123)      621 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-110M-Sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)      619 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-330M-Sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)      660 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-330M-Similarity.py
+-rw-r--r--   0 runner    (1001) docker     (123)      580 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/IIC_dpr-spanish-passage_encoder-allqa-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      556 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/IIC_dpr-spanish-question_encoder-allqa-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      922 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/IlyaGusev_rubert_telegram_headlines.py
+-rw-r--r--   0 runner    (1001) docker     (123)      768 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/IlyaGusev_rut5_base_sum_gazeta.py
+-rw-r--r--   0 runner    (1001) docker     (123)      650 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Intel_dpt-large-ade.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1062 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Intel_dpt-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2353 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Jean-Baptiste_camembert-ner-with-dates.py
+-rw-r--r--   0 runner    (1001) docker     (123)      963 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Jean-Baptiste_camembert-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1336 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Jean-Baptiste_roberta-large-ner-english.py
+-rw-r--r--   0 runner    (1001) docker     (123)      600 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/K024_mt5-zh-ja-en-trimmed.py
+-rw-r--r--   0 runner    (1001) docker     (123)      412 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/KBLab_sentence-bert-swedish-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      720 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/KES_T5-TTParser.py
+-rw-r--r--   0 runner    (1001) docker     (123)      737 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/KES_TEC-English.py
+-rw-r--r--   0 runner    (1001) docker     (123)      564 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Kamuuung_autonlp-lessons_tagging-606217261.py
+-rw-r--r--   0 runner    (1001) docker     (123)      667 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/KoichiYasuoka_bert-base-japanese-upos.py
+-rw-r--r--   0 runner    (1001) docker     (123)      709 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/KoichiYasuoka_bert-large-japanese-wikipedia-ud-head.py
+-rw-r--r--   0 runner    (1001) docker     (123)      706 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/KoichiYasuoka_deberta-base-japanese-aozora-ud-head.py
+-rw-r--r--   0 runner    (1001) docker     (123)      649 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/KoichiYasuoka_deberta-base-thai-ud-head.py
+-rw-r--r--   0 runner    (1001) docker     (123)      698 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/KoichiYasuoka_roberta-base-thai-spm-upos.py
+-rw-r--r--   0 runner    (1001) docker     (123)      764 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MCG-NJU_videomae-base-finetuned-kinetics.py
+-rw-r--r--   0 runner    (1001) docker     (123)      864 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MCG-NJU_videomae-base-ssv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      839 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MCG-NJU_videomae-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      950 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MaRiOrOsSi_t5-base-finetuned-question-answering.py
+-rw-r--r--   0 runner    (1001) docker     (123)      763 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MarcBrun_ixambert-finetuned-squad-eu-en.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2506 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Michau_t5-base-en-generate-headline.py
+-rw-r--r--   0 runner    (1001) docker     (123)      364 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MilaNLProc_feel-it-italian-emotion.py
+-rw-r--r--   0 runner    (1001) docker     (123)      368 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MilaNLProc_feel-it-italian-sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)      582 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-base-mnli-fever-anli.py
+-rw-r--r--   0 runner    (1001) docker     (123)      597 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-base-mnli-fever-docnli-ling-2c.py
+-rw-r--r--   0 runner    (1001) docker     (123)      606 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-large-mnli-fever-anli-ling-wanli.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1093 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary.py
+-rw-r--r--   0 runner    (1001) docker     (123)      584 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_mDeBERTa-v3-base-mnli-xnli.py
+-rw-r--r--   0 runner    (1001) docker     (123)      601 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1470 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_policy-distilbert-7d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      652 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Musixmatch_umberto-commoncrawl-cased-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      947 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Narrativa_bsc_roberta2roberta_shared-spanish-finetuned-mlsum-summarization.py
+-rw-r--r--   0 runner    (1001) docker     (123)      576 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/NbAiLab_nb-bert-base-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)      817 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/NeuML_bert-small-cord19qa.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1141 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/NlpHUST_gpt2-vietnamese.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1343 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/NlpHUST_t5-en-vi-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      693 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/NlpHUST_vibert4news-base-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      570 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Preetiha_clause_classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)      886 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Recognai_bert-base-spanish-wwm-cased-xnli.py
+-rw-r--r--   0 runner    (1001) docker     (123)      876 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Recognai_zeroshot_selectra_medium.py
+-rw-r--r--   0 runner    (1001) docker     (123)      487 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Rostlab_prot_bert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      498 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Rostlab_prot_bert_bfd.py
+-rw-r--r--   0 runner    (1001) docker     (123)      977 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Rostlab_prot_t5_xl_bfd.py
+-rw-r--r--   0 runner    (1001) docker     (123)      993 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Rostlab_prot_t5_xl_uniref50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      878 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Sahajtomar_German_Zeroshot.py
+-rw-r--r--   0 runner    (1001) docker     (123)      593 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-2B-mono.py
+-rw-r--r--   0 runner    (1001) docker     (123)      596 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-2B-multi.py
+-rw-r--r--   0 runner    (1001) docker     (123)      600 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-350M-mono.py
+-rw-r--r--   0 runner    (1001) docker     (123)      603 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-350M-multi.py
+-rw-r--r--   0 runner    (1001) docker     (123)      590 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-350M-nl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      593 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-6B-mono.py
+-rw-r--r--   0 runner    (1001) docker     (123)      596 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-6B-multi.py
+-rw-r--r--   0 runner    (1001) docker     (123)      698 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codet5-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      655 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codet5-large-ntp-py.py
+-rw-r--r--   0 runner    (1001) docker     (123)      663 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codet5-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      704 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codet5-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      634 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Salesforce_mixqg-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2451 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Sehong_t5-large-QuestionGeneration.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1224 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/SenseTime_deformable-detr.py
+-rw-r--r--   0 runner    (1001) docker     (123)      636 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Sentdex_GPyT.py
+-rw-r--r--   0 runner    (1001) docker     (123)      914 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Seznam_small-e-czech.py
+-rw-r--r--   0 runner    (1001) docker     (123)      596 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/SkolkovoInstitute_roberta_toxicity_classifier.py
+-rw-r--r--   0 runner    (1001) docker     (123)      583 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/SkolkovoInstitute_russian_toxicity_classifier.py
+-rw-r--r--   0 runner    (1001) docker     (123)      607 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/SkolkovoInstitute_xlmr_formality_classifier.py
+-rw-r--r--   0 runner    (1001) docker     (123)      438 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/StevenLimcorn_indonesian-roberta-base-emotion-classifier.py
+-rw-r--r--   0 runner    (1001) docker     (123)      588 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/TristanBehrens_js-fakes-4bars.py
+-rw-r--r--   0 runner    (1001) docker     (123)      413 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/TurkuNLP_sbert-cased-finnish-paraphrase.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1597 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/UBC-NLP_AraT5-base-title-generation.py
+-rw-r--r--   0 runner    (1001) docker     (123)      891 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Unbabel_gec-t5_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      463 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/VMware_vbert-2021-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      810 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Visual-Attention-Network_van-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      810 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Visual-Attention-Network_van-tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      803 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Wikidepia_IndoT5-base-paraphrase.py
+-rw-r--r--   0 runner    (1001) docker     (123)      485 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/Xuhui_ToxDect-roberta-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      585 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/abhishek_autonlp-bbc-news-classification-37229289.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1187 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ahmedrachid_FinancialBERT-Sentiment-Analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4322 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ai4bharat_IndicBART.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4036 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ai4bharat_IndicBARTSS.py
+-rw-r--r--   0 runner    (1001) docker     (123)      406 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/aiknowyou_aiky-sentence-bertino.py
+-rw-r--r--   0 runner    (1001) docker     (123)      293 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/albert-base-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      296 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/albert-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      292 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/albert-large-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      298 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/albert-large-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      294 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/albert-xlarge-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      296 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/albert-xlarge-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      298 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/albert-xxlarge-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      299 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/albert-xxlarge-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      829 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/allegro_herbert-base-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      485 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/allegro_herbert-klej-cased-tokenizer-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      475 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/allegro_herbert-klej-cased-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      831 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/allegro_herbert-large-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1012 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/allenai_t5-small-next-word-generator-qoogle.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1067 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/allenai_t5-small-squad2-question-generation.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2133 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/aneuraz_awesome-align-with-co.py
+-rw-r--r--   0 runner    (1001) docker     (123)      414 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ans_vaccinating-covid-tweets.py
+-rw-r--r--   0 runner    (1001) docker     (123)      754 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/apple_deeplabv3-mobilevit-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      763 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/apple_deeplabv3-mobilevit-xx-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      849 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/apple_mobilevit-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      856 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/apple_mobilevit-xx-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      812 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/asi_gpt-fr-cased-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1063 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/assemblyai_bert-large-uncased-sst2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      823 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/aubmindlab_araelectra-base-discriminator.py
+-rw-r--r--   0 runner    (1001) docker     (123)      551 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/aujer_ni_model_8_19.py
+-rw-r--r--   0 runner    (1001) docker     (123)      506 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/avichr_heBERT.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/avichr_heBERT_sentiment_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)      939 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/aware-ai_bart-squadv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1943 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/azwierzc_herbert-large-poquad.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2139 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/azwierzc_plt5-base-poquad.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2142 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/azwierzc_plt5-large-poquad.py
+-rw-r--r--   0 runner    (1001) docker     (123)      778 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/batterydata_batterybert-cased-squad-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      299 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bert-base-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      325 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bert-base-multilingual-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      327 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bert-base-multilingual-uncased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      301 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bert-base-uncased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      334 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bert-large-cased-whole-word-masking.py
+-rw-r--r--   0 runner    (1001) docker     (123)      298 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bert-large-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      339 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bert-large-uncased-whole-word-masking.py
+-rw-r--r--   0 runner    (1001) docker     (123)      304 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bert-large-uncased.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3204 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bespin-global_klue-bert-base-aihub-mrc.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1357 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bespin-global_klue-bert-base-mrc.py
+-rw-r--r--   0 runner    (1001) docker     (123)      442 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bespin-global_klue-sentence-roberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      454 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bespin-global_klue-sroberta-base-continue-learning-by-mnr.py
+-rw-r--r--   0 runner    (1001) docker     (123)      811 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bhadresh-savani_bert-base-uncased-emotion.py
+-rw-r--r--   0 runner    (1001) docker     (123)      825 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bhadresh-savani_distilbert-base-uncased-emotion.py
+-rw-r--r--   0 runner    (1001) docker     (123)      799 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bhadresh-savani_electra-base-emotion.py
+-rw-r--r--   0 runner    (1001) docker     (123)      796 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bhadresh-savani_roberta-base-emotion.py
+-rw-r--r--   0 runner    (1001) docker     (123)      568 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bigscience_T0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      566 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/bigscience_T0p.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1936 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/blinoff_roberta-base-russian-v0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      323 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cahya_bert-base-indonesian-522M.py
+-rw-r--r--   0 runner    (1001) docker     (123)      331 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cahya_distilbert-base-indonesian.py
+-rw-r--r--   0 runner    (1001) docker     (123)      326 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cahya_roberta-base-indonesian-522M.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1255 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_tweet-topic-21-multi.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1229 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_tweet-topic-21-single.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2128 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-emoji.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2099 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-emotion.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2074 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-hate.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2116 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-irony.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2085 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-offensive.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2092 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)      384 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-xlm-roberta-base-sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)      680 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/chkla_parlbert-topic-german.py
+-rw-r--r--   0 runner    (1001) docker     (123)      773 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/clips_mfaq.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1972 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cmarkea_distilcamembert-base-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1161 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cmarkea_distilcamembert-base-nli.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1378 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cmarkea_distilcamembert-base-qa.py
+-rw-r--r--   0 runner    (1001) docker     (123)      773 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cmarkea_distilcamembert-base-sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)      469 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/codeparrot_codeparrot-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      429 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/codeparrot_codeparrot.py
+-rw-r--r--   0 runner    (1001) docker     (123)      660 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cointegrated_LaBSE-en-ru.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1008 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rubert-base-cased-nli-threeway.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1466 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rubert-tiny-sentiment-balanced.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1611 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rubert-tiny-toxicity.py
+-rw-r--r--   0 runner    (1001) docker     (123)      890 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rubert-tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      892 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rubert-tiny2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      937 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rut5-small-chitchat.py
+-rw-r--r--   0 runner    (1001) docker     (123)      842 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rut5-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      627 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-MiniLM2-L6-H768.py
+-rw-r--r--   0 runner    (1001) docker     (123)      621 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-deberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      629 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      629 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      629 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      633 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-xsmall.py
+-rw-r--r--   0 runner    (1001) docker     (123)      636 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-distilroberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      623 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-roberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2401 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/csebuetnlp_mT5_m2m_crossSum.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2145 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/csebuetnlp_mT5_m2o_arabic_crossSum.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2169 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/csebuetnlp_mT5_m2o_chinese_simplified_crossSum.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2147 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/csebuetnlp_mT5_multilingual_XLSum.py
+-rw-r--r--   0 runner    (1001) docker     (123)      602 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ctrl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      659 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/d4data_biomedical-ner-all.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1005 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dandelin_vilt-b32-finetuned-nlvr2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      838 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dandelin_vilt-b32-finetuned-vqa.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1717 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dandelin_vilt-b32-mlm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      636 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dangvantuan_sentence-camembert-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      641 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dangvantuan_sentence-camembert-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/daveni_twitter-xlm-roberta-emotion-es.py
+-rw-r--r--   0 runner    (1001) docker     (123)      404 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deepset_all-mpnet-base-v2-table.py
+-rw-r--r--   0 runner    (1001) docker     (123)      786 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deepset_deberta-v3-base-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      792 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deepset_deberta-v3-large-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      785 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deepset_electra-base-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      798 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deepset_roberta-base-squad2-covid.py
+-rw-r--r--   0 runner    (1001) docker     (123)      787 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deepset_roberta-base-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      782 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deepset_tinyroberta-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      805 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deepset_xlm-roberta-base-squad2-distilled.py
+-rw-r--r--   0 runner    (1001) docker     (123)      794 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deepset_xlm-roberta-large-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      321 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dennlinger_bert-wiki-paragraphs.py
+-rw-r--r--   0 runner    (1001) docker     (123)      319 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dennlinger_roberta-cls-consec.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1330 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deutsche-telekom_bert-multi-english-german-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1436 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/deutsche-telekom_electra-base-de-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      635 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/digitalepidemiologylab_covid-twitter-bert-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/digitalepidemiologylab_covid-twitter-bert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      291 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/distilbert-base-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      337 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/distilbert-base-multilingual-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      678 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/distilbert-base-uncased-finetuned-sst-2-english.py
+-rw-r--r--   0 runner    (1001) docker     (123)      315 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/distilbert-base-uncased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      348 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/distilroberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1106 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dkleczek_bert-base-polish-cased-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1131 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dkleczek_bert-base-polish-uncased-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1133 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/doc2query_all-t5-base-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1208 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/doc2query_all-with_prefix-t5-base-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1141 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/doc2query_msmarco-t5-base-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      569 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dslim_bert-base-NER.py
+-rw-r--r--   0 runner    (1001) docker     (123)      570 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dslim_bert-large-NER.py
+-rw-r--r--   0 runner    (1001) docker     (123)      744 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/dumitrescustefan_bert-base-romanian-cased-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      703 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/edumunozsala_beto_sentiment_analysis_es.py
+-rw-r--r--   0 runner    (1001) docker     (123)      698 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/edumunozsala_vit_base-224-in21k-ft-cifar100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      353 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/efederici_cross-encoder-umberto-stsb.py
+-rw-r--r--   0 runner    (1001) docker     (123)      402 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/efederici_sentence-bert-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      564 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ehdwns1516_klue-roberta-base-kornli.py
+-rw-r--r--   0 runner    (1001) docker     (123)      448 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/embedding-data_distilroberta-base-sentence-transformer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      605 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/esiebomajeremiah_autonlp-email-classification-657119381.py
+-rw-r--r--   0 runner    (1001) docker     (123)      577 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/etalab-ia_camembert-base-squadFR-fquad-piaf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      568 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/etalab-ia_dpr-ctx_encoder-fr_qa-camembert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      595 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/etalab-ia_dpr-question_encoder-fr_qa-camembert.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1264 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/fabiochiu_t5-base-tag-generation.py
+-rw-r--r--   0 runner    (1001) docker     (123)      467 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_bart-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      468 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_bart-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1079 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_contriever-msmarco.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1042 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_contriever.py
+-rw-r--r--   0 runner    (1001) docker     (123)      815 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-base-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      813 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-base-384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      835 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-large-224-22k-1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      818 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-small-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      815 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-tiny-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      830 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-xlarge-224-22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      842 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-xlarge-384-22k-1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      886 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_data2vec-vision-base-ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      928 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-base-distilled-patch16-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      908 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-base-distilled-patch16-384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      854 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-base-patch16-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      852 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-base-patch16-384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      911 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-small-distilled-patch16-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      857 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-small-patch16-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      906 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-tiny-distilled-patch16-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      854 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-tiny-patch16-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1323 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_detr-resnet-50-panoptic.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1201 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_detr-resnet-50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      639 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_dino-vitb16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      634 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_dino-vitb8.py
+-rw-r--r--   0 runner    (1001) docker     (123)      637 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_dino-vits16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      634 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_dino-vits8.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1699 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_flava-full.py
+-rw-r--r--   0 runner    (1001) docker     (123)      852 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_levit-128S.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1222 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_maskformer-swin-base-ade.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1225 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_maskformer-swin-base-coco.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1217 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_maskformer-swin-large-ade.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1224 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_maskformer-swin-small-coco.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1222 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_maskformer-swin-tiny-ade.py
+-rw-r--r--   0 runner    (1001) docker     (123)      802 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_mbart-large-50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      306 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_opt-125m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      306 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_opt-350m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      786 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_regnet-y-040.py
+-rw-r--r--   0 runner    (1001) docker     (123)      673 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_vit-mae-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      675 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_vit-mae-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      300 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/facebook_xlm-roberta-xl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      431 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/fhswf_bert_de_ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)      990 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/flax-community_clip-rsicd-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      346 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/flax-community_roberta-hindi.py
+-rw-r--r--   0 runner    (1001) docker     (123)      964 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/flax-community_t5-large-wikisplit.py
+-rw-r--r--   0 runner    (1001) docker     (123)      450 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/flax-sentence-embeddings_all_datasets_v3_mpnet-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      577 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/flax-sentence-embeddings_all_datasets_v3_roberta-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      571 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/flax-sentence-embeddings_all_datasets_v4_MiniLM-L6.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1328 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/flax-sentence-embeddings_st-codesearch-distilroberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      582 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/flax-sentence-embeddings_stackoverflow_mpnet-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      774 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/flexudy_t5-base-multi-sentence-doctor.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1082 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/flexudy_t5-small-wav2vec2-grammar-fixer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      949 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/fran-martinez_scibert_scivocab_cased_ner_jnlpba.py
+-rw-r--r--   0 runner    (1001) docker     (123)      492 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/funnel-transformer_large-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/funnel-transformer_xlarge-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      886 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/gerulata_slovakbert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      682 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/gilf_french-camembert-postag-model.py
+-rw-r--r--   0 runner    (1001) docker     (123)      652 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/gilf_french-postag-model.py
+-rw-r--r--   0 runner    (1001) docker     (123)      759 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_bert2bert_L-24_wmt_de_en.py
+-rw-r--r--   0 runner    (1001) docker     (123)      607 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_byt5-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      607 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_byt5-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      610 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_byt5-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_canine-c.py
+-rw-r--r--   0 runner    (1001) docker     (123)      621 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_canine-s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      608 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_ddpm-celebahq-256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      604 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_ddpm-cifar10-32.py
+-rw-r--r--   0 runner    (1001) docker     (123)      915 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_electra-base-discriminator.py
+-rw-r--r--   0 runner    (1001) docker     (123)      468 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_electra-base-generator.py
+-rw-r--r--   0 runner    (1001) docker     (123)      917 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_electra-large-discriminator.py
+-rw-r--r--   0 runner    (1001) docker     (123)      928 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_electra-small-discriminator.py
+-rw-r--r--   0 runner    (1001) docker     (123)      435 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_fnet-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_long-t5-local-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      508 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_long-t5-tglobal-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      510 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_long-t5-tglobal-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_long-t5-tglobal-xl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      436 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_mobilebert-uncased.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1467 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_owlvit-base-patch16.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1468 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_owlvit-base-patch32.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1470 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_owlvit-large-patch14.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1743 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_roberta2roberta_L-24_bbc.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2648 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_roberta2roberta_L-24_cnn_daily_mail.py
+-rw-r--r--   0 runner    (1001) docker     (123)      846 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_roberta2roberta_L-24_discofuse.py
+-rw-r--r--   0 runner    (1001) docker     (123)      580 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_t5-small-ssm-nq.py
+-rw-r--r--   0 runner    (1001) docker     (123)      681 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-base-patch16-224-in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      850 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-base-patch16-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      843 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-base-patch16-384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      675 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-base-patch32-224-in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      843 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-base-patch32-384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      674 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-huge-patch14-224-in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      676 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-large-patch16-224-in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      844 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-large-patch16-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      844 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-large-patch16-384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      674 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-large-patch32-224-in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      846 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/google_vit-large-patch32-384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      741 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/hakurei_lit-6B.py
+-rw-r--r--   0 runner    (1001) docker     (123)      571 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/henryk_bert-base-multilingual-cased-finetuned-dutch-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      602 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/henryk_bert-base-multilingual-cased-finetuned-polish-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/hetpandya_t5-base-tapaco.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1621 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/hetpandya_t5-small-tapaco.py
+-rw-r--r--   0 runner    (1001) docker     (123)      410 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/hiiamsid_sentence_similarity_hindi.py
+-rw-r--r--   0 runner    (1001) docker     (123)      420 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/hiiamsid_sentence_similarity_spanish_es.py
+-rw-r--r--   0 runner    (1001) docker     (123)      731 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/hustvl_yolos-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      734 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/hustvl_yolos-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      732 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/hustvl_yolos-tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      590 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/imranraad_idiom-xlm-roberta.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1274 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/inkoziev_rugpt_chitchat.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1583 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/intfloat_simlm-msmarco-reranker.py
+-rw-r--r--   0 runner    (1001) docker     (123)      358 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/j-hartmann_emotion-english-distilroberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      366 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/j-hartmann_purchase-intention-english-roberta-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      374 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/j-hartmann_sentiment-roberta-large-english-3-classes.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1597 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/jaehyeong_koelectra-base-v3-generalized-sentiment-analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)      411 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/jhgan_ko-sbert-multitask.py
+-rw-r--r--   0 runner    (1001) docker     (123)      419 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/jhgan_ko-sroberta-multitask.py
+-rw-r--r--   0 runner    (1001) docker     (123)      405 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/jhgan_ko-sroberta-sts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      573 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/joeddav_bart-large-mnli-yahoo-answers.py
+-rw-r--r--   0 runner    (1001) docker     (123)      657 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/johngiorgi_declutr-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      661 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/johngiorgi_declutr-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1004 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/jsylee_scibert_scivocab_uncased-finetuned-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1048 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_chinese_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2577 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_chinese_sim_char_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2580 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_chinese_sim_char_ft_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2296 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2298 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_large.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2297 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      934 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed-pmc-lt.py
+-rw-r--r--   0 runner    (1001) docker     (123)      930 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed-pmc.py
+-rw-r--r--   0 runner    (1001) docker     (123)      929 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed.py
+-rw-r--r--   0 runner    (1001) docker     (123)      402 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/keepitreal_vietnamese-sbert.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1115 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ken11_albert-base-japanese-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      644 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/kiheh85202_yolo.py
+-rw-r--r--   0 runner    (1001) docker     (123)      434 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/kiri-ai_distiluse-base-multilingual-cased-et.py
+-rw-r--r--   0 runner    (1001) docker     (123)      689 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/laituan245_molt5-large-smiles2caption.py
+-rw-r--r--   0 runner    (1001) docker     (123)      485 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/law-ai_InLegalBERT.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2159 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/lcw99_t5-base-korean-chit-chat.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1123 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/liandarizkia_SA01-IndoBert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      588 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/madhurjindal_autonlp-Gibberish-Detector-492513457.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1018 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/malteos_scincl.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3849 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/marefa-nlp_marefa-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)      404 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/matthewburke_korean_sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)      441 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/maxpe_twitter-roberta-base-jun2022_sem_eval_2018_task_1.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1075 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mdhugol_indonesia-bert-sentiment-classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1115 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/melll-uff_bertweetbr.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/michiyasunaga_BioLinkBERT-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      530 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/michiyasunaga_BioLinkBERT-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/michiyasunaga_LinkBERT-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1362 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_BiomedVLP-CXR-BERT-specialized.py
+-rw-r--r--   0 runner    (1001) docker     (123)      902 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-base-patch16-224-pt22k-ft22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      713 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-base-patch16-224-pt22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      859 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-base-patch16-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      859 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-base-patch16-384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      902 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-large-patch16-224-pt22k-ft22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      714 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-large-patch16-224-pt22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      860 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-large-patch16-384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      862 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-large-patch16-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      542 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_codebert-base-mlm.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1259 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_conditional-detr-resnet-50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      815 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_cvt-13.py
+-rw-r--r--   0 runner    (1001) docker     (123)      872 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_prophetnet-large-uncased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      782 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_resnet-101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      782 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_resnet-152.py
+-rw-r--r--   0 runner    (1001) docker     (123)      780 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_resnet-18.py
+-rw-r--r--   0 runner    (1001) docker     (123)      779 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_resnet-34.py
+-rw-r--r--   0 runner    (1001) docker     (123)      783 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_resnet-50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      904 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-base-patch4-window12-384-in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      884 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-base-patch4-window12-384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      901 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-base-patch4-window7-224-in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      883 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-base-patch4-window7-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      908 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-large-patch4-window12-384-in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      902 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-large-patch4-window7-224-in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      886 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-large-patch4-window7-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      884 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-small-patch4-window7-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      883 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-tiny-patch4-window7-224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      889 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_swinv2-tiny-patch4-window8-256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      949 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_tapex-large-finetuned-tabfact.py
+-rw-r--r--   0 runner    (1001) docker     (123)      761 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-base-handwritten.py
+-rw-r--r--   0 runner    (1001) docker     (123)      808 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-base-printed.py
+-rw-r--r--   0 runner    (1001) docker     (123)      764 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-large-handwritten.py
+-rw-r--r--   0 runner    (1001) docker     (123)      810 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-large-printed.py
+-rw-r--r--   0 runner    (1001) docker     (123)      726 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-large-str.py
+-rw-r--r--   0 runner    (1001) docker     (123)      764 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-small-handwritten.py
+-rw-r--r--   0 runner    (1001) docker     (123)      813 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-small-stage1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      903 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/microsoft_xprophetnet-large-wiki100-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      677 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ml4pubmed_BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext_pub_section.py
+-rw-r--r--   0 runner    (1001) docker     (123)      604 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ml6team_bert-base-uncased-city-country-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)      619 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ml6team_distilbert-base-german-cased-toxic-comments.py
+-rw-r--r--   0 runner    (1001) docker     (123)      617 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/model-attribution-challenge_codegen-350M-multi.py
+-rw-r--r--   0 runner    (1001) docker     (123)      315 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/model-attribution-challenge_opt-350m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      490 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/model-attribution-challenge_xlnet-base-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      796 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/monilouise_ner_news_portuguese.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1139 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_TinyBERT-spanish-uncased-finetuned-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)      391 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-base-german-finetuned-ler.py
+-rw-r--r--   0 runner    (1001) docker     (123)      750 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-italian-finedtuned-squadv1-it-alfa.py
+-rw-r--r--   0 runner    (1001) docker     (123)      568 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-medium-finetuned-squadv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1574 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-multi-cased-finetuned-xquadv1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      567 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-small-finetuned-squadv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1079 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-small2bert-small-finetuned-cnn_daily_mail-summarization.py
+-rw-r--r--   0 runner    (1001) docker     (123)      551 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-spanish-cased-finetuned-ner.py
+-rw-r--r--   0 runner    (1001) docker     (123)      556 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-tiny-5-finetuned-squadv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      563 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-tiny-finetuned-squadv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      902 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert2bert_shared-german-finetuned-summarization.py
+-rw-r--r--   0 runner    (1001) docker     (123)      907 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert2bert_shared-spanish-finetuned-summarization.py
+-rw-r--r--   0 runner    (1001) docker     (123)      885 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert2bert_shared-turkish-summarization.py
+-rw-r--r--   0 runner    (1001) docker     (123)      780 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_codebert-base-finetuned-detect-insecure-code.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1061 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es.py
+-rw-r--r--   0 runner    (1001) docker     (123)      602 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_electra-small-finetuned-squadv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1180 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_electricidad-base-discriminator.py
+-rw-r--r--   0 runner    (1001) docker     (123)      613 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_roberta-base-1B-1-finetuned-squadv1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      641 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_spanbert-finetuned-squadv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      596 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_spanbert-large-finetuned-squadv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      847 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-common_gen.py
+-rw-r--r--   0 runner    (1001) docker     (123)      848 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-e2m-intent.py
+-rw-r--r--   0 runner    (1001) docker     (123)      726 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-imdb-sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1059 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-quartz.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1039 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-question-generation-ap.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1095 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-span-sentiment-extraction.py
+-rw-r--r--   0 runner    (1001) docker     (123)      904 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-squadv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      840 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-wikiSQL.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1365 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-small-finetuned-quora-for-paraphrasing.py
+-rw-r--r--   0 runner    (1001) docker     (123)      918 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nateraw_vit-age-classifier.py
+-rw-r--r--   0 runner    (1001) docker     (123)      839 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nateraw_vit-base-patch16-224-cifar10.py
+-rw-r--r--   0 runner    (1001) docker     (123)      936 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/navteca_bart-large-mnli.py
+-rw-r--r--   0 runner    (1001) docker     (123)      623 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/navteca_nli-deberta-v3-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      837 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/navteca_roberta-base-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      842 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/navteca_roberta-large-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1048 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nbroad_mt5-base-qgen.py
+-rw-r--r--   0 runner    (1001) docker     (123)      581 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/neuralspace-reverie_indic-transformers-bn-distilbert.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1250 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/neuraly_bert-base-italian-cased-sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)      658 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/neuropark_sahajBERT.py
+-rw-r--r--   0 runner    (1001) docker     (123)      830 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nickmuchi_yolos-small-rego-plates-detection.py
+-rw-r--r--   0 runner    (1001) docker     (123)      374 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nickprock_xlm-roberta-base-banking77-classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1108 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nkoh01_MSRoberta.py
+-rw-r--r--   0 runner    (1001) docker     (123)      806 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_groupvit-gcc-yfcc.py
+-rw-r--r--   0 runner    (1001) docker     (123)      817 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_mit-b1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      818 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_mit-b2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      817 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_mit-b3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      817 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_mit-b4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      817 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_mit-b5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      788 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-ade-512-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      814 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-1024-1024.py
+-rw-r--r--   0 runner    (1001) docker     (123)      809 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-512-1024.py
+-rw-r--r--   0 runner    (1001) docker     (123)      808 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-768-768.py
+-rw-r--r--   0 runner    (1001) docker     (123)      787 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b1-finetuned-ade-512-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      812 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b2-finetuned-cityscapes-1024-1024.py
+-rw-r--r--   0 runner    (1001) docker     (123)      785 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b3-finetuned-ade-512-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      814 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b3-finetuned-cityscapes-1024-1024.py
+-rw-r--r--   0 runner    (1001) docker     (123)      787 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b4-finetuned-ade-512-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      812 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b4-finetuned-cityscapes-1024-1024.py
+-rw-r--r--   0 runner    (1001) docker     (123)      814 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b5-finetuned-cityscapes-1024-1024.py
+-rw-r--r--   0 runner    (1001) docker     (123)      420 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/nytimesrd_paraphrase-MiniLM-L6-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      390 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/obrizum_all-MiniLM-L6-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      392 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/obrizum_all-mpnet-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      830 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/openai_clip-vit-base-patch16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      838 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/openai_clip-vit-base-patch32.py
+-rw-r--r--   0 runner    (1001) docker     (123)      842 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/openai_clip-vit-large-patch14.py
+-rw-r--r--   0 runner    (1001) docker     (123)      422 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/optimum_all-MiniLM-L6-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11274 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/patrickvonplaten_longformer2roberta-cnn_dailymail-fp16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      611 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/paust_pko-t5-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      614 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/paust_pko-t5-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1435 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/persiannlp_mt5-large-parsinlu-arc-comqa-obqa-multiple-choice.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/philschmid_BERT-Banking77.py
+-rw-r--r--   0 runner    (1001) docker     (123)      632 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/philschmid_distilroberta-base-ner-conll2003.py
+-rw-r--r--   0 runner    (1001) docker     (123)      680 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/philschmid_distilroberta-base-ner-wikiann-conll2003-3-class.py
+-rw-r--r--   0 runner    (1001) docker     (123)      680 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/philschmid_distilroberta-base-ner-wikiann-conll2003-4-class.py
+-rw-r--r--   0 runner    (1001) docker     (123)      626 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/philschmid_distilroberta-base-ner-wikiann.py
+-rw-r--r--   0 runner    (1001) docker     (123)      825 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/phiyodr_bart-large-finetuned-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      825 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/phiyodr_bert-base-finetuned-squad2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2563 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/phpaiola_ptt5-base-summ-cstnews.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1200 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/pierreguillou_ner-bert-large-cased-pt-lenerbr.py
+-rw-r--r--   0 runner    (1001) docker     (123)      594 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/pin_senda.py
+-rw-r--r--   0 runner    (1001) docker     (123)      418 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/pritamdeka_S-BioBert-snli-multinli-stsb.py
+-rw-r--r--   0 runner    (1001) docker     (123)      434 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/pritamdeka_S-Biomed-Roberta-snli-multinli-stsb.py
+-rw-r--r--   0 runner    (1001) docker     (123)      420 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/pritamdeka_S-Bluebert-snli-multinli-stsb.py
+-rw-r--r--   0 runner    (1001) docker     (123)      404 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/pritamdeka_S-PubMedBert-MS-MARCO.py
+-rw-r--r--   0 runner    (1001) docker     (123)      609 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/projecte-aina_roberta-base-ca-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      420 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/pszemraj_grammar-synthesis-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      423 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/pszemraj_grammar-synthesis-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1227 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/pvl_labse_bert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      611 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/racai_distilbert-base-romanian-uncased.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1311 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ramsrigouthamg_t5-large-paraphraser-diverse-high-quality.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1920 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ramsrigouthamg_t5_paraphraser.py
+-rw-r--r--   0 runner    (1001) docker     (123)      390 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/raynardj_ner-gene-dna-rna-jnlpba-pubmed.py
+-rw-r--r--   0 runner    (1001) docker     (123)      481 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/razent_spbert-mlm-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      493 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/razent_spbert-mlm-wso-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      709 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/readerbench_RoBERT-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      714 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/readerbench_RoBERT-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      923 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/readerbench_RoGPT2-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      928 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/readerbench_RoGPT2-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      717 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/readerbench_jurBERT-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      386 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/recobo_agriculture-bert-uncased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      287 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/roberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      288 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/roberta-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      450 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/saattrupdan_nbailab-base-ner-scandi.py
+-rw-r--r--   0 runner    (1001) docker     (123)      564 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-lid-lince.py
+-rw-r--r--   0 runner    (1001) docker     (123)      567 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-ner-lince.py
+-rw-r--r--   0 runner    (1001) docker     (123)      564 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-pos-lince.py
+-rw-r--r--   0 runner    (1001) docker     (123)      699 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sagorsarker_codeswitch-spaeng-sentiment-analysis-lince.py
+-rw-r--r--   0 runner    (1001) docker     (123)      839 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sail_poolformer_s12.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1043 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/salesken_natural_rephrase.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1938 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/salesken_paraphrase_diversity_ranker.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1283 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/salesken_paraphrase_generation.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1042 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/salesken_text_generate.py
+-rw-r--r--   0 runner    (1001) docker     (123)      787 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sampathkethineedi_industry-classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/savasy_bert-base-turkish-ner-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      825 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/savasy_bert-base-turkish-sentiment-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1413 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sberbank-ai_sbert_large_mt_nlu_ru.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1413 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sberbank-ai_sbert_large_nlu_ru.py
+-rw-r--r--   0 runner    (1001) docker     (123)      418 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_LaBSE.py
+-rw-r--r--   0 runner    (1001) docker     (123)      440 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_all-MiniLM-L12-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      442 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_all-MiniLM-L12-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      438 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_all-MiniLM-L6-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      442 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_all-MiniLM-L6-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      447 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_all-distilroberta-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      440 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_all-mpnet-base-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      442 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_all-mpnet-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      447 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_all-roberta-large-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      436 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_allenai-specter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      452 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_bert-base-nli-cls-token.py
+-rw-r--r--   0 runner    (1001) docker     (123)      452 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_bert-base-nli-max-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      458 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_bert-base-nli-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      467 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_bert-base-nli-stsb-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      486 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_bert-base-wikipedia-sections-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      456 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_bert-large-nli-max-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      458 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_bert-large-nli-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      466 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_bert-large-nli-stsb-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2003 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_clip-ViT-B-32-multilingual-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      451 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_distilbert-base-nli-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      480 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_distilbert-base-nli-stsb-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      480 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_distilbert-base-nli-stsb-quora-ranking.py
+-rw-r--r--   0 runner    (1001) docker     (123)      464 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_distilroberta-base-msmarco-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      470 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_distilroberta-base-paraphrase-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      479 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_distiluse-base-multilingual-cased-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      482 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_distiluse-base-multilingual-cased-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      480 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_facebook-dpr-ctx_encoder-multiset-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      482 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_facebook-dpr-ctx_encoder-single-nq-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      490 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_facebook-dpr-question_encoder-multiset-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      492 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_facebook-dpr-question_encoder-single-nq-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      426 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_gtr-t5-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      430 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_gtr-t5-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      424 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_gtr-t5-xl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      450 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-MiniLM-L-12-v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      448 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-MiniLM-L-6-v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      931 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-MiniLM-L6-cos-v5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      957 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-bert-base-dot-v5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      476 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-dot-prod-v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      964 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-tas-b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      458 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      458 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      459 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-v4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      935 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-cos-v5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      978 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-dot-v5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      516 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-multilingual-en-de-v2-tmp-lng-aligned.py
+-rw-r--r--   0 runner    (1001) docker     (123)      526 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-multilingual-en-de-v2-tmp-trained-scratch.py
+-rw-r--r--   0 runner    (1001) docker     (123)      464 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilroberta-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      468 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-roberta-base-ance-firstp.py
+-rw-r--r--   0 runner    (1001) docker     (123)      454 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-roberta-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      452 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-roberta-base-v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      937 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_multi-qa-MiniLM-L6-cos-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      936 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_multi-qa-MiniLM-L6-dot-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      937 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_multi-qa-distilbert-cos-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      938 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_multi-qa-mpnet-base-cos-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      939 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_multi-qa-mpnet-base-dot-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      430 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_nli-bert-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      454 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_nli-distilroberta-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      441 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_nli-mpnet-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      442 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_nli-roberta-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      438 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_nli-roberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      438 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_nli-roberta-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      448 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_nq-distilbert-base-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      456 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-MiniLM-L12-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      454 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-MiniLM-L3-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      456 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-MiniLM-L6-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      457 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-TinyBERT-L6-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      459 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-albert-small-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      471 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-distilroberta-base-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      471 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-distilroberta-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      456 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-mpnet-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      482 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-multilingual-MiniLM-L12-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      482 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-multilingual-mpnet-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      472 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_paraphrase-xlm-r-multilingual-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      446 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_quora-distilbert-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      465 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_quora-distilbert-multilingual.py
+-rw-r--r--   0 runner    (1001) docker     (123)      462 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_roberta-base-nli-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      472 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_roberta-base-nli-stsb-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      462 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_roberta-large-nli-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      474 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_roberta-large-nli-stsb-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      438 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_sentence-t5-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      438 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_sentence-t5-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      432 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_sentence-t5-xl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      434 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_sentence-t5-xxl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      434 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_stsb-bert-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      434 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_stsb-bert-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      447 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_stsb-distilbert-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      458 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_stsb-distilroberta-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      443 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_stsb-mpnet-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      448 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_stsb-roberta-base-v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      442 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_stsb-roberta-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      453 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_stsb-xlm-r-multilingual.py
+-rw-r--r--   0 runner    (1001) docker     (123)      446 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_use-cmlm-multilingual.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_xlm-r-100langs-bert-base-nli-stsb-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      476 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_xlm-r-bert-base-nli-stsb-mean-tokens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      482 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_xlm-r-distilroberta-base-paraphrase-v1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      621 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/setu4993_LaBSE.py
+-rw-r--r--   0 runner    (1001) docker     (123)      645 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/setu4993_smaller-LaBSE.py
+-rw-r--r--   0 runner    (1001) docker     (123)      343 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/siebert_sentiment-roberta-large-english.py
+-rw-r--r--   0 runner    (1001) docker     (123)      446 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sijunhe_nezha-cn-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      452 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/sijunhe_nezha-large-wwm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      412 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/snunlp_KR-SBERT-V40K-klueNLI-augSTS.py
+-rw-r--r--   0 runner    (1001) docker     (123)      516 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/soheeyang_rdr-ctx_encoder-single-nq-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      570 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/soheeyang_rdr-question_encoder-single-nq-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      493 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/soleimanian_financial-roberta-large-sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/squirro_albert-base-v2-squad_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1213 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/strombergnlp_dant5-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      646 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/svalabs_gbert-large-zeroshot-nli.py
+-rw-r--r--   0 runner    (1001) docker     (123)      674 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/t5-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      675 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/t5-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      677 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/t5-small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      750 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/taeminlee_kogpt2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      710 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/tartuNLP_EstBERT_NER.py
+-rw-r--r--   0 runner    (1001) docker     (123)      562 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/tdobrxl_ClinicBERT.py
+-rw-r--r--   0 runner    (1001) docker     (123)      340 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/tennessejoyce_titlewave-t5-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      384 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/teven_all_bs160_allneg.py
+-rw-r--r--   0 runner    (1001) docker     (123)      386 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/teven_all_bs192_hardneg.py
+-rw-r--r--   0 runner    (1001) docker     (123)      386 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/teven_all_bs320_vanilla.py
+-rw-r--r--   0 runner    (1001) docker     (123)      707 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/thanathorn_mt5-cpe-kmutt-thai-sentence-sum.py
+-rw-r--r--   0 runner    (1001) docker     (123)      459 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/thunlp_Lawformer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      491 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/transfo-xl-wt103.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1699 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/tugstugi_bert-large-mongolian-uncased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/tuhailong_SimCSE-bert-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      496 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_albert-base-chinese-cluecorpussmall.py
+-rw-r--r--   0 runner    (1001) docker     (123)      294 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_chinese_roberta_L-12_H-128.py
+-rw-r--r--   0 runner    (1001) docker     (123)      296 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_chinese_roberta_L-12_H-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      295 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_chinese_roberta_L-2_H-128.py
+-rw-r--r--   0 runner    (1001) docker     (123)      295 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_chinese_roberta_L-4_H-256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      295 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_chinese_roberta_L-4_H-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      293 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_chinese_roberta_L-6_H-128.py
+-rw-r--r--   0 runner    (1001) docker     (123)      293 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_chinese_roberta_L-6_H-768.py
+-rw-r--r--   0 runner    (1001) docker     (123)      293 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_chinese_roberta_L-8_H-256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      295 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_chinese_roberta_L-8_H-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1022 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-chinese-extractive-qa.py
+-rw-r--r--   0 runner    (1001) docker     (123)      592 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-finetuned-chinanews-chinese.py
+-rw-r--r--   0 runner    (1001) docker     (123)      555 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-finetuned-cluener2020-chinese.py
+-rw-r--r--   0 runner    (1001) docker     (123)      591 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-finetuned-dianping-chinese.py
+-rw-r--r--   0 runner    (1001) docker     (123)      590 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-finetuned-jd-binary-chinese.py
+-rw-r--r--   0 runner    (1001) docker     (123)      588 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-finetuned-jd-full-chinese.py
+-rw-r--r--   0 runner    (1001) docker     (123)      324 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-word-chinese-cluecorpussmall.py
+-rw-r--r--   0 runner    (1001) docker     (123)      583 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_t5-base-chinese-cluecorpussmall.py
+-rw-r--r--   0 runner    (1001) docker     (123)      588 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_t5-small-chinese-cluecorpussmall.py
+-rw-r--r--   0 runner    (1001) docker     (123)      602 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_t5-v1_1-base-chinese-cluecorpussmall.py
+-rw-r--r--   0 runner    (1001) docker     (123)      601 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uer_t5-v1_1-small-chinese-cluecorpussmall.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/unicamp-dl_translation-pt-en-t5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      899 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ushikado_yuyuyui-chatbot.py
+-rw-r--r--   0 runner    (1001) docker     (123)      292 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/uw-madison_nystromformer-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      993 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/valhalla_bart-large-finetuned-squadv1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      931 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/valhalla_t5-base-squad.py
+-rw-r--r--   0 runner    (1001) docker     (123)      595 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/vblagoje_dpr-ctx_encoder-single-lfqa-wiki.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1079 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/vinvino02_glpn-kitti.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1073 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/vinvino02_glpn-nyu.py
+-rw-r--r--   0 runner    (1001) docker     (123)      974 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/voidful_albert_chinese_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      976 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/voidful_albert_chinese_large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      978 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/voidful_albert_chinese_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      976 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/voidful_albert_chinese_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      537 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/voidful_dpr-ctx_encoder-bert-base-multilingual.py
+-rw-r--r--   0 runner    (1001) docker     (123)      568 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/voidful_dpr-question_encoder-bert-base-multilingual.py
+-rw-r--r--   0 runner    (1001) docker     (123)      847 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/wanyu_IteraTeR-ROBERTA-Intention-Classifier.py
+-rw-r--r--   0 runner    (1001) docker     (123)      407 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/whaleloops_phrase-bert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      901 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/wonrax_phobert-base-vietnamese-sentiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)      766 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/xlm-clm-ende-1024.py
+-rw-r--r--   0 runner    (1001) docker     (123)      763 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/xlm-clm-enfr-1024.py
+-rw-r--r--   0 runner    (1001) docker     (123)      479 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/xlm-mlm-en-2048.py
+-rw-r--r--   0 runner    (1001) docker     (123)      295 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/xlm-roberta-base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      659 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/xlm-roberta-large-finetuned-conll03-german.py
+-rw-r--r--   0 runner    (1001) docker     (123)      296 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/xlm-roberta-large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      476 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/xlnet-base-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)      478 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/xlnet-large-cased.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1433 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ybelkada_japanese-roberta-question-answering.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1326 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ydshieh_roberta-large-ner-english.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1145 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/ydshieh_vit-gpt2-coco-en.py
+-rw-r--r--   0 runner    (1001) docker     (123)      683 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/yiyanghkust_finbert-esg.py
+-rw-r--r--   0 runner    (1001) docker     (123)      701 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/yiyanghkust_finbert-fls.py
+-rw-r--r--   0 runner    (1001) docker     (123)      805 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/popular_on_huggingface/yiyanghkust_finbert-tone.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9259 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/readme.md
+-rw-r--r--   0 runner    (1001) docker     (123)      300 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/requirements.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.749214 mlagility-3.1.1/models/selftest/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/selftest/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      595 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/selftest/linear.py
+-rw-r--r--   0 runner    (1001) docker     (123)      699 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/selftest/twolayer.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.861213 mlagility-3.1.1/models/timm/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/adv_inception_v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/bat_resnext26ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/beit_base_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/beit_base_patch16_224_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/beit_base_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/beit_large_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/beit_large_patch16_224_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/beit_large_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/beit_large_patch16_512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/botnet26t_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/botnet50ts_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cait_m36_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cait_m48_448.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cait_s24_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cait_s24_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cait_s36_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cait_xs24_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cait_xxs24_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cait_xxs24_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cait_xxs36_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cait_xxs36_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/coat_lite_mini.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/coat_lite_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/coat_lite_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/coat_mini.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/coat_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convit_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convit_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convit_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convmixer_1024_20_ks9_p14.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convmixer_1536_20.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convmixer_768_32.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_base_384_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_base_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_base_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_large_384_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_large_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_large_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_nano.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_nano_hnf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_nano_ols.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_small_384_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_small_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_small_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_tiny_384_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_tiny_hnf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_tiny_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_tiny_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_xlarge_384_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_xlarge_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/convnext_xlarge_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_15_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_15_dagger_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_15_dagger_408.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_18_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_18_dagger_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_18_dagger_408.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_9_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_9_dagger_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_base_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_small_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/crossvit_tiny_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3darknet_focus_l.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3darknet_focus_m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3darknet_focus_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3darknet_focus_x.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3darknet_l.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3darknet_m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3darknet_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3darknet_x.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3edgenet_x.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3se_edgenet_x.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3sedarknet_l.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3sedarknet_x.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cs3sedarknet_xdw.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cspdarknet53.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cspresnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cspresnet50d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cspresnet50w.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/cspresnext50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/darknet17.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/darknet21.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/darknet53.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/darknetaa53.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_base_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_base_patch16_224_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_base_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_base_patch16_384_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_huge_patch14_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_huge_patch14_224_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_large_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_large_patch16_224_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_large_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_large_patch16_384_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_small_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_small_patch16_224_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_small_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit3_small_patch16_384_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit_base_distilled_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit_base_distilled_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit_base_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit_base_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit_small_distilled_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit_small_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit_tiny_distilled_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/deit_tiny_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/densenet121.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/densenet121d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/densenet161.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/densenet169.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/densenet201.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/densenet264.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/densenetblur121d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      491 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla102.py
+-rw-r--r--   0 runner    (1001) docker     (123)      493 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla102x.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla102x2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      491 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla169.py
+-rw-r--r--   0 runner    (1001) docker     (123)      489 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla34.py
+-rw-r--r--   0 runner    (1001) docker     (123)      493 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla46_c.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla46x_c.py
+-rw-r--r--   0 runner    (1001) docker     (123)      489 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla60.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla60_res2net.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla60_res2next.py
+-rw-r--r--   0 runner    (1001) docker     (123)      491 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla60x.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dla60x_c.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dm_nfnet_f0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dm_nfnet_f1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dm_nfnet_f2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dm_nfnet_f3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dm_nfnet_f4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dm_nfnet_f5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dm_nfnet_f6.py
+-rw-r--r--   0 runner    (1001) docker     (123)      491 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dpn107.py
+-rw-r--r--   0 runner    (1001) docker     (123)      491 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dpn131.py
+-rw-r--r--   0 runner    (1001) docker     (123)      489 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dpn68.py
+-rw-r--r--   0 runner    (1001) docker     (123)      491 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dpn68b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      489 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dpn92.py
+-rw-r--r--   0 runner    (1001) docker     (123)      489 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/dpn98.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/eca_botnext26ts_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/eca_halonext26ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/eca_nfnet_l0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/eca_nfnet_l1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/eca_nfnet_l2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/eca_nfnet_l3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/eca_resnet33ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/eca_resnext26ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/eca_vovnet39b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ecaresnet101d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ecaresnet200d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ecaresnet269d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ecaresnet26t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ecaresnet50d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ecaresnet50t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ecaresnetlight.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ecaresnext26t_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ecaresnext50t_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/edgenext_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/edgenext_small_rw.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/edgenext_x_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/edgenext_xx_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b0_g16_evos.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b0_g8_gn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b0_gn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b2a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b3_g8_gn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b3_gn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b3a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b6.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b7.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_b8.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_cc_b0_4e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_cc_b0_8e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_cc_b1_8e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_el.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_el_pruned.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_em.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_es.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_es_pruned.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_l2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_lite0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_lite1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_lite2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_lite3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnet_lite4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnetv2_l.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnetv2_m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnetv2_rw_m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnetv2_rw_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnetv2_rw_t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnetv2_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/efficientnetv2_xl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ens_adv_inception_resnet_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ese_vovnet19b_dw.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ese_vovnet19b_slim.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ese_vovnet19b_slim_dw.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ese_vovnet39b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ese_vovnet39b_evos.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ese_vovnet57b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ese_vovnet99b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/fbnetc_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/fbnetv3_b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/fbnetv3_d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/fbnetv3_g.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gc_efficientnetv2_rw_t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gcresnet33ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gcresnet50t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gcresnext26ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gcresnext50ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gernet_l.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gernet_m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gernet_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ghostnet_050.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ghostnet_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ghostnet_130.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_inception_v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet101_v1b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet101_v1c.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet101_v1d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet101_v1s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet152_v1b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet152_v1c.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet152_v1d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet152_v1s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet18_v1b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet34_v1b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet50_v1b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet50_v1c.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet50_v1d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnet50_v1s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnext101_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnext101_64x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_resnext50_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_senet154.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_seresnext101_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_seresnext101_64x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_seresnext50_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gluon_xception65.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gmixer_12_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gmixer_24_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gmlp_b16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gmlp_s16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/gmlp_ti16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/halo2botnet50ts_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/halonet26t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/halonet50ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/halonet_h1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/haloregnetz_b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hardcorenas_a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hardcorenas_b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hardcorenas_c.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hardcorenas_d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hardcorenas_e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hardcorenas_f.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hrnet_w18.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hrnet_w18_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hrnet_w18_small_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hrnet_w30.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hrnet_w32.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hrnet_w40.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hrnet_w44.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hrnet_w48.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/hrnet_w64.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ig_resnext101_32x16d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ig_resnext101_32x32d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ig_resnext101_32x48d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ig_resnext101_32x8d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/inception_resnet_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/inception_v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/inception_v4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/jx_nest_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/jx_nest_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/jx_nest_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/lambda_resnet26rpt_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/lambda_resnet26t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/lambda_resnet50ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/lamhalobotnet50ts_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/lcnet_035.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/lcnet_050.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/lcnet_075.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/lcnet_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/lcnet_150.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/legacy_senet154.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/legacy_seresnet101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/legacy_seresnet152.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/legacy_seresnet18.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/legacy_seresnet34.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/legacy_seresnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/legacy_seresnext101_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/legacy_seresnext26_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/legacy_seresnext50_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/levit_128.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/levit_128s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/levit_192.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/levit_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/levit_256d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/levit_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixer_b16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixer_b16_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixer_b16_224_miil.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixer_b16_224_miil_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixer_b32_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixer_l16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixer_l16_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixer_l32_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixer_s16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixer_s32_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixnet_l.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixnet_m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixnet_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixnet_xl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mixnet_xxl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mnasnet_050.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mnasnet_075.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mnasnet_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mnasnet_140.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mnasnet_a1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mnasnet_b1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mnasnet_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv2_035.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv2_050.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv2_075.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv2_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv2_110d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv2_120d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv2_140.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv3_large_075.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv3_large_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv3_large_100_miil.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv3_large_100_miil_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv3_rw.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv3_small_050.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv3_small_075.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilenetv3_small_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevit_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevit_xs.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevit_xxs.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_050.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_075.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_125.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_150.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_150_384_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_150_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_175.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_175_384_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_175_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_200.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_200_384_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/mobilevitv2_200_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nasnetalarge.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nest_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nest_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nest_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_ecaresnet101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_ecaresnet26.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_ecaresnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_regnet_b0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_regnet_b1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_regnet_b2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_regnet_b3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_regnet_b4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_regnet_b5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_resnet101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_resnet26.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_resnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_seresnet101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_seresnet26.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nf_seresnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nfnet_f0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nfnet_f1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nfnet_f2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nfnet_f3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nfnet_f4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nfnet_f5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nfnet_f6.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nfnet_f7.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/nfnet_l0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/pit_b_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/pit_b_distilled_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/pit_s_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/pit_s_distilled_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/pit_ti_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/pit_ti_distilled_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/pit_xs_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/pit_xs_distilled_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/pnasnet5large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/poolformer_m36.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/poolformer_m48.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/poolformer_s12.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/poolformer_s24.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/poolformer_s36.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetv_040.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetv_064.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_002.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_004.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_006.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_008.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_016.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_032.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_040.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_064.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_080.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_120.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_160.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetx_320.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_002.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_004.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_006.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_008.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_016.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_032.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_040.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_040s_gn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_064.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_080.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_120.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_160.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnety_320.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_005.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_040.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_040h.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_b16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_b16_evos.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_c16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_c16_evos.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_d32.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_d8.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_d8_evos.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/regnetz_e8.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/repvgg_a2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/repvgg_b0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/repvgg_b1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/repvgg_b1g4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/repvgg_b2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/repvgg_b2g4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/repvgg_b3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/repvgg_b3g4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/res2net101_26w_4s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/res2net50_14w_8s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/res2net50_26w_4s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/res2net50_26w_6s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/res2net50_26w_8s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/res2net50_48w_2s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/res2next50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_12_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_12_224_dino.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_12_distilled_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_24_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_24_224_dino.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_24_distilled_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_36_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_36_distilled_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_big_24_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_big_24_224_in22ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resmlp_big_24_distilled_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnest101e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnest14d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnest200e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnest269e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnest26d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnest50d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnest50d_1s4x24d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnest50d_4s2x40d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet101d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet10t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet14t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet152.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet152d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet18.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet18d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet200.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet200d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet26.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet26d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet26t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet32ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet33ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet34.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet34d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet50_gn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet50d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet50t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet51q.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnet61q.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetaa101d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetaa50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetaa50d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetblur101d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetblur18.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetblur50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetblur50d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetrs101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetrs152.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetrs200.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetrs270.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetrs350.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetrs420.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetrs50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_101d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_101x1_bitm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_101x1_bitm_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_101x3_bitm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_101x3_bitm_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_152.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_152d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_152x2_bit_teacher.py
+-rw-r--r--   0 runner    (1001) docker     (123)      539 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_152x2_bit_teacher_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_152x2_bitm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_152x2_bitm_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_152x4_bitm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_152x4_bitm_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50d_evob.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50d_evos.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50d_frn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50d_gn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50x1_bit_distilled.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50x1_bitm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50x1_bitm_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50x3_bitm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnetv2_50x3_bitm_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnext101_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnext101_32x8d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnext101_64x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnext26ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnext50_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/resnext50d_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/rexnet_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/rexnet_130.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/rexnet_150.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/rexnet_200.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/rexnetr_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/rexnetr_130.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/rexnetr_150.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/rexnetr_200.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/sebotnet33ts_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/sedarknet21.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/sehalonet33ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/selecsls42.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/selecsls42b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/selecsls60.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/selecsls60b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/selecsls84.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/semnasnet_050.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/semnasnet_075.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/semnasnet_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/semnasnet_140.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/semobilevit_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/senet154.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/sequencer2d_l.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/sequencer2d_m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/sequencer2d_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnet101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnet152.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnet152d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnet18.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnet200d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnet269d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnet33ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnet34.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnet50t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnetaa50d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnext101_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnext101_32x8d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnext101d_32x8d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnext26d_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnext26t_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnext26tn_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnext26ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnext50_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/seresnextaa101d_32x8d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/skresnet18.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/skresnet34.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/skresnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/skresnet50d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/skresnext50_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/spnasnet_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ssl_resnet18.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ssl_resnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ssl_resnext101_32x16d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ssl_resnext101_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ssl_resnext101_32x8d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/ssl_resnext50_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      537 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_base_patch4_window12_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_base_patch4_window12_384_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_base_patch4_window7_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_base_patch4_window7_224_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      539 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_large_patch4_window12_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      551 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_large_patch4_window12_384_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      537 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_large_patch4_window7_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_large_patch4_window7_224_in22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_s3_base_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_s3_small_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_s3_tiny_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      537 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_small_patch4_window7_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swin_tiny_patch4_window7_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_base_window12_192_22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      561 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_base_window12to16_192to256_22kft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      561 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_base_window12to24_192to384_22kft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_base_window16_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_base_window8_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_base_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_base_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_base_ns_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_giant_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_giant_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_huge_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_huge_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_large_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_large_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_small_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_small_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_small_ns_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_tiny_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_tiny_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_cr_tiny_ns_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      537 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_large_window12_192_22k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      563 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_large_window12to16_192to256_22kft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      563 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_large_window12to24_192to384_22kft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_small_window16_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_small_window8_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_tiny_window16_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swinv2_tiny_window8_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swsl_resnet18.py
+-rw-r--r--   0 runner    (1001) docker     (123)      505 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swsl_resnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swsl_resnext101_32x16d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swsl_resnext101_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swsl_resnext101_32x8d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/swsl_resnext50_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b0_ap.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b0_ns.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b1_ap.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b1_ns.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b2_ap.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b2_ns.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b3_ap.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b3_ns.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b4_ap.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b4_ns.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b5_ap.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b5_ns.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b6.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b6_ap.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b6_ns.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b7.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b7_ap.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b7_ns.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b8.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_b8_ap.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_cc_b0_4e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_cc_b0_8e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_cc_b1_8e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_el.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_em.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_es.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_l2_ns.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_l2_ns_475.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_lite0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_lite1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_lite2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_lite3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnet_lite4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_b0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_b1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_b2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_b3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_l.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_l_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_l_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_m_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_m_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_s_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_s_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      537 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_xl_in21ft1k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_efficientnetv2_xl_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_inception_v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_mixnet_l.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_mixnet_m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_mixnet_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_mobilenetv3_large_075.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_mobilenetv3_large_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_mobilenetv3_large_minimal_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_mobilenetv3_small_075.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_mobilenetv3_small_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tf_mobilenetv3_small_minimal_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tinynet_a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tinynet_b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tinynet_c.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tinynet_d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tinynet_e.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tnt_b_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tnt_s_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tv_densenet121.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tv_resnet101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      503 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tv_resnet152.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tv_resnet34.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tv_resnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      515 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/tv_resnext50_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/twins_pcpvt_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/twins_pcpvt_large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/twins_pcpvt_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/twins_svt_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/twins_svt_large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/twins_svt_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      489 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vgg11.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vgg11_bn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      489 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vgg13.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vgg13_bn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      489 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vgg16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vgg16_bn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      489 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vgg19.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vgg19_bn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/visformer_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      507 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/visformer_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch16_18x2_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch16_224_dino.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch16_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch16_224_miil.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch16_224_miil_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch16_224_sam.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch16_plus_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch16_rpn_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch32_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch32_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch32_224_sam.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch32_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch32_plus_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch8_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch8_224_dino.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_patch8_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_r26_s32_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_r50_s16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_r50_s16_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_r50_s16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_resnet26d_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_resnet50_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_resnet50_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_base_resnet50d_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_giant_patch14_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_gigantic_patch14_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_huge_patch14_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_huge_patch14_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_large_patch14_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_large_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_large_patch16_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_large_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_large_patch32_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_large_patch32_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_large_patch32_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_large_r50_s32_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_large_r50_s32_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_large_r50_s32_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_base_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_base_patch16_cls_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_base_patch16_clsgap_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_base_patch16_plus_240.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_base_patch16_rpn_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      551 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_base_patch32_plus_rpn_256.py
+-rw-r--r--   0 runner    (1001) docker     (123)      537 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_medium_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      545 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_medium_patch16_cls_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      545 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_medium_patch16_rpn_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_small_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_relpos_small_patch16_rpn_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_patch16_18x2_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_patch16_224_dino.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_patch16_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_patch16_36x1_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_patch32_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_patch32_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_patch32_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_patch8_224_dino.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_r26_s32_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_r26_s32_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_r26_s32_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_resnet26d_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_small_resnet50d_s16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      539 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_srelpos_medium_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      537 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_srelpos_small_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_tiny_patch16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_tiny_patch16_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_tiny_patch16_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_tiny_r_s16_p8_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_tiny_r_s16_p8_224_in21k.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vit_tiny_r_s16_p8_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d1_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d1_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d2_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d2_384.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d3_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d3_448.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d4_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d4_448.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d5_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d5_448.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/volo_d5_512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vovnet39a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/vovnet57a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      511 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/wide_resnet101_2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/wide_resnet50_2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      495 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xception.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xception41.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xception41p.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xception65.py
+-rw-r--r--   0 runner    (1001) docker     (123)      501 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xception65p.py
+-rw-r--r--   0 runner    (1001) docker     (123)      499 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xception71.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_large_24_p16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_large_24_p16_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_large_24_p16_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_large_24_p8_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_large_24_p8_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_large_24_p8_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      523 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_medium_24_p16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_medium_24_p16_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      533 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_medium_24_p16_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_medium_24_p8_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_medium_24_p8_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_medium_24_p8_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_nano_12_p16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_nano_12_p16_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_nano_12_p16_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_nano_12_p8_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_nano_12_p8_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_nano_12_p8_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_12_p16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_12_p16_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_12_p16_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_12_p8_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_12_p8_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_12_p8_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      521 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_24_p16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_24_p16_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_24_p16_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_24_p8_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_24_p8_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_small_24_p8_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_12_p16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_12_p16_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_12_p16_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_12_p8_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_12_p8_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_12_p8_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      519 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_24_p16_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_24_p16_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_24_p16_384_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      517 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_24_p8_224.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_24_p8_224_dist.py
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/timm/xcit_tiny_24_p8_384_dist.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.873213 mlagility-3.1.1/models/torch_hub/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      611 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/alexnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)      545 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/convnext_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/convnext_large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/convnext_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      545 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/convnext_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (123)      512 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/dcgan.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/densenet121.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/densenet161.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/densenet169.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/densenet201.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_b0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_b1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_b2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_b3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_b4.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_b5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_b6.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_b7.py
+-rw-r--r--   0 runner    (1001) docker     (123)      553 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_v2_l.py
+-rw-r--r--   0 runner    (1001) docker     (123)      553 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_v2_m.py
+-rw-r--r--   0 runner    (1001) docker     (123)      553 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/efficientnet_v2_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      612 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/ghostnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)      618 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/ghostnet_1x.py
+-rw-r--r--   0 runner    (1001) docker     (123)      617 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/googlenet.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/hardnet39ds.py
+-rw-r--r--   0 runner    (1001) docker     (123)      616 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/hardnet68.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/hardnet68ds.py
+-rw-r--r--   0 runner    (1001) docker     (123)      616 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/hardnet85.py
+-rw-r--r--   0 runner    (1001) docker     (123)      626 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/inception_v3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      637 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mealv1_resnest50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      649 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mealv2_efficientnet_b0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      663 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mealv2_mobilenet_v3_large_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      661 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mealv2_mobilenetv3_small_075.py
+-rw-r--r--   0 runner    (1001) docker     (123)      661 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mealv2_mobilenetv3_small_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      637 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mealv2_resnest50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      653 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mealv2_resnest50_380x380.py
+-rw-r--r--   0 runner    (1001) docker     (123)      651 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mealv2_resnest50_cutmix.py
+-rw-r--r--   0 runner    (1001) docker     (123)      564 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/midas_v2.1_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      562 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/midas_v3_hybrid.py
+-rw-r--r--   0 runner    (1001) docker     (123)      560 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/midas_v3_large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      539 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mnasnet0_5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      541 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mnasnet0_75.py
+-rw-r--r--   0 runner    (1001) docker     (123)      539 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mnasnet1_0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      539 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mnasnet1_3.py
+-rw-r--r--   0 runner    (1001) docker     (123)      626 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mobilenet_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      555 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mobilenet_v3_large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      555 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/mobilenet_v3_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      630 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/proxyless_cpu.py
+-rw-r--r--   0 runner    (1001) docker     (123)      630 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/proxyless_gpu.py
+-rw-r--r--   0 runner    (1001) docker     (123)      636 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/proxyless_mobile.py
+-rw-r--r--   0 runner    (1001) docker     (123)      642 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/proxyless_mobile_14.py
+-rw-r--r--   0 runner    (1001) docker     (123)      545 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_x_16gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_x_1_6gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      545 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_x_32gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_x_3_2gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_x_400mf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_x_800mf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_x_8gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_y_128gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      545 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_y_16gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_y_1_6gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      545 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_y_32gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_y_3_2gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_y_400mf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      547 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_y_800mf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      543 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/regnet_y_8gf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      616 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      616 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest200.py
+-rw-r--r--   0 runner    (1001) docker     (123)      616 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest269.py
+-rw-r--r--   0 runner    (1001) docker     (123)      614 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest50_fast_1s1x64d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest50_fast_1s2x40d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest50_fast_1s4x24d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest50_fast_2s1x64d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest50_fast_2s2x40d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest50_fast_4s1x64d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnest50_fast_4s2x40d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      614 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet101.py
+-rw-r--r--   0 runner    (1001) docker     (123)      622 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet101_ibn_a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      622 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet101_ibn_b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      614 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet152.py
+-rw-r--r--   0 runner    (1001) docker     (123)      612 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet18.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet18_ibn_a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet18_ibn_b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      612 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet34.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet34_ibn_a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet34_ibn_b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      612 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet50.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet50_ibn_a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnet50_ibn_b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      629 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnext101_32x8d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      624 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnext101_ibn_a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      627 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/resnext50_32x4d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      628 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/se_resnet101_ibn_a.py
+-rw-r--r--   0 runner    (1001) docker     (123)      639 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/shufflenet_v2_x0_5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      639 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/shufflenet_v2_x1_0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      639 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/shufflenet_v2_x1_5.py
+-rw-r--r--   0 runner    (1001) docker     (123)      639 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/shufflenet_v2_x2_0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      626 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/squeezenet1_0.py
+-rw-r--r--   0 runner    (1001) docker     (123)      626 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/squeezenet1_1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/swin_b.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/swin_s.py
+-rw-r--r--   0 runner    (1001) docker     (123)      531 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/swin_t.py
+-rw-r--r--   0 runner    (1001) docker     (123)      665 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/unet.py
+-rw-r--r--   0 runner    (1001) docker     (123)      603 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vgg11.py
+-rw-r--r--   0 runner    (1001) docker     (123)      609 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vgg11_bn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      603 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vgg13.py
+-rw-r--r--   0 runner    (1001) docker     (123)      609 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vgg13_bn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      603 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vgg16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      609 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vgg16_bn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      603 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vgg19.py
+-rw-r--r--   0 runner    (1001) docker     (123)      609 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vgg19_bn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vit_b_16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vit_b_32.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vit_h_14.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vit_l_16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/vit_l_32.py
+-rw-r--r--   0 runner    (1001) docker     (123)      633 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/wide_resnet101_2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      631 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torch_hub/wide_resnet50_2.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.877213 mlagility-3.1.1/models/torchvision/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      676 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/fasterrcnn_mobilenet_v3_large_320_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      664 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/fasterrcnn_mobilenet_v3_large_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      634 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/fasterrcnn_resnet50_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      643 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/fasterrcnn_resnet50_fpn_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      609 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/fcos_resnet50_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      642 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/keypointrcnn_resnet50_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      626 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/maskrcnn_resnet50_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      635 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/maskrcnn_resnet50_fpn_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      629 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/retinanet_resnet50_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (123)      638 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/retinanet_resnet50_fpn_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      593 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/ssd300_vgg16.py
+-rw-r--r--   0 runner    (1001) docker     (123)      648 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/torchvision/ssdlite320_mobilenet_v3_large.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.893213 mlagility-3.1.1/models/transformers/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      600 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/bart.py
+-rw-r--r--   0 runner    (1001) docker     (123)      574 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/beit.py
+-rw-r--r--   0 runner    (1001) docker     (123)      684 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/bert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      838 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/bert_for_question_answering.py
+-rw-r--r--   0 runner    (1001) docker     (123)      909 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/bert_generation.py
+-rw-r--r--   0 runner    (1001) docker     (123)      779 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/bert_tiny_for_sequence_classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)      631 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/bigbird_pegasus.py
+-rw-r--r--   0 runner    (1001) docker     (123)      731 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/biggan.py
+-rw-r--r--   0 runner    (1001) docker     (123)      636 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/blenderbot_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      615 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/camembert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      612 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/convbert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      586 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (123)      557 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/data2vecaudio.py
+-rw-r--r--   0 runner    (1001) docker     (123)      702 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/data2vectext.py
+-rw-r--r--   0 runner    (1001) docker     (123)      609 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/deberta.py
+-rw-r--r--   0 runner    (1001) docker     (123)      574 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/deit.py
+-rw-r--r--   0 runner    (1001) docker     (123)      671 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/deit_base_for_image_classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)      671 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/deit_tiny_for_image_classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)      574 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/detr.py
+-rw-r--r--   0 runner    (1001) docker     (123)      766 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/detr_for_object_detection.py
+-rw-r--r--   0 runner    (1001) docker     (123)      705 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/distil_wav2vec2_for_audio_classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)      634 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/distilbert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      762 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/distilbert_for_question_answering.py
+-rw-r--r--   0 runner    (1001) docker     (123)      686 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/distilhubert_for_audio_classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)      609 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/electra.py
+-rw-r--r--   0 runner    (1001) docker     (123)      752 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/electra_for_sequence_classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)      703 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/encoder_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (123)      612 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/flaubert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      606 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/funnel.py
+-rw-r--r--   0 runner    (1001) docker     (123)      615 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/funnel_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      596 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/gpt1.py
+-rw-r--r--   0 runner    (1001) docker     (123)      586 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/gpt2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      608 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/gpt2_doublehead.py
+-rw-r--r--   0 runner    (1001) docker     (123)      536 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/hubert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      603 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/ibert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      598 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/imagegpt.py
+-rw-r--r--   0 runner    (1001) docker     (123)      739 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/layoutlm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      600 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/luke.py
+-rw-r--r--   0 runner    (1001) docker     (123)      609 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/m2m_100.py
+-rw-r--r--   0 runner    (1001) docker     (123)      587 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/marian.py
+-rw-r--r--   0 runner    (1001) docker     (123)      591 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/marianmt.py
+-rw-r--r--   0 runner    (1001) docker     (123)      625 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/megatron_bert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      817 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/minilmv2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      618 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/mobilebert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      761 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/mobilebert_for_sequence_classification.py
+-rw-r--r--   0 runner    (1001) docker     (123)      657 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/mobilevit.py
+-rw-r--r--   0 runner    (1001) docker     (123)      678 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/mobilevit_small_for_semantic_segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (123)      694 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/mobilevit_x_small_for_semantic_segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (123)      687 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/mobilevit_xx_small_for_semantic_segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (123)      603 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/mpnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)      558 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/mt5_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      514 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/mt5_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (123)      560 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/mt5_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      620 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/openai_doublehead.py
+-rw-r--r--   0 runner    (1001) docker     (123)      611 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/pegasus.py
+-rw-r--r--   0 runner    (1001) docker     (123)      540 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/perceiver.py
+-rw-r--r--   0 runner    (1001) docker     (123)      604 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/poolformer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      802 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/rag.py
+-rw-r--r--   0 runner    (1001) docker     (123)      613 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/realm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      616 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/rembert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      831 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/retribert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      616 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/roberta.py
+-rw-r--r--   0 runner    (1001) docker     (123)      619 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/roformer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      596 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/segformer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      484 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/sew.py
+-rw-r--r--   0 runner    (1001) docker     (123)      488 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/sew_d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      723 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/speech_encoder_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (123)      822 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/speech_encoder_decoder_pretrained.py
+-rw-r--r--   0 runner    (1001) docker     (123)      636 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/speech_to_text.py
+-rw-r--r--   0 runner    (1001) docker     (123)      619 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/splinter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      628 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/squeezebert.py
+-rw-r--r--   0 runner    (1001) docker     (123)      591 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/t5_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/t5_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (123)      593 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/t5_large.py
+-rw-r--r--   0 runner    (1001) docker     (123)      593 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/t5_small.py
+-rw-r--r--   0 runner    (1001) docker     (123)      597 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/unispeech.py
+-rw-r--r--   0 runner    (1001) docker     (123)      607 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/unispeech_sat.py
+-rw-r--r--   0 runner    (1001) docker     (123)      803 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/vision_encoder_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (123)      578 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/vit.py
+-rw-r--r--   0 runner    (1001) docker     (123)      477 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/wav2vec2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      602 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/xglm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      604 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/xlm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      626 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/xlm_roberta.py
+-rw-r--r--   0 runner    (1001) docker     (123)      558 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/xlnet-512.py
+-rw-r--r--   0 runner    (1001) docker     (123)      610 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/xlnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)      643 2023-06-08 21:31:08.000000 mlagility-3.1.1/models/transformers/yolos_tiny_for_object_detection.py
+-rw-r--r--   0 runner    (1001) docker     (123)       86 2023-06-08 21:31:08.000000 mlagility-3.1.1/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (123)       38 2023-06-08 21:31:56.901213 mlagility-3.1.1/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (123)     2290 2023-06-08 21:31:08.000000 mlagility-3.1.1/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.669214 mlagility-3.1.1/src/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.893213 mlagility-3.1.1/src/mlagility/
+-rw-r--r--   0 runner    (1001) docker     (123)      171 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.897213 mlagility-3.1.1/src/mlagility/analysis/
+-rw-r--r--   0 runner    (1001) docker     (123)    20362 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/analysis/analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4493 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/analysis/status.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1213 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/analysis/tf_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4267 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/analysis/util.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.897213 mlagility-3.1.1/src/mlagility/api/
+-rw-r--r--   0 runner    (1001) docker     (123)      251 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/Dockerfile
+-rw-r--r--   0 runner    (1001) docker     (123)    22712 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/devices.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9256 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/execute_trt.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9930 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/model_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2973 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/ortmodel.py
+-rw-r--r--   0 runner    (1001) docker     (123)      732 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/performance.py
+-rw-r--r--   0 runner    (1001) docker     (123)      722 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3020 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/run_ort_model.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14123 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/script_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8029 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/setup_ort.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3045 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/api/trtmodel.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.897213 mlagility-3.1.1/src/mlagility/cli/
+-rwxr-xr-x   0 runner    (1001) docker     (123)    18139 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/cli/cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)      583 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/cli/login.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10164 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/cli/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6714 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/cli/spawn.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.897213 mlagility-3.1.1/src/mlagility/common/
+-rw-r--r--   0 runner    (1001) docker     (123)    10936 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/common/filesystem.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3299 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/common/labels.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3495 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)       22 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/mlagility/version.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.893213 mlagility-3.1.1/src/mlagility.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)     5486 2023-06-08 21:31:56.000000 mlagility-3.1.1/src/mlagility.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    89762 2023-06-08 21:31:56.000000 mlagility-3.1.1/src/mlagility.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-06-08 21:31:56.000000 mlagility-3.1.1/src/mlagility.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       49 2023-06-08 21:31:56.000000 mlagility-3.1.1/src/mlagility.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      328 2023-06-08 21:31:56.000000 mlagility-3.1.1/src/mlagility.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       36 2023-06-08 21:31:56.000000 mlagility-3.1.1/src/mlagility.egg-info/top_level.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.897213 mlagility-3.1.1/src/onnxflow/
+-rw-r--r--   0 runner    (1001) docker     (123)      150 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.901213 mlagility-3.1.1/src/onnxflow/common/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/common/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15476 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/common/build.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1052 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/common/cache.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1614 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/common/exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4631 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/common/onnx_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3063 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/common/printing.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2342 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/common/quantization_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2440 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/common/tensor_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1196 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/common/tf_helpers.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.901213 mlagility-3.1.1/src/onnxflow/justbuildit/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/justbuildit/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     5295 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/justbuildit/buildit.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22145 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/justbuildit/export.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6970 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/justbuildit/hummingbird.py
+-rw-r--r--   0 runner    (1001) docker     (123)    23186 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/justbuildit/ignition.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11511 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/justbuildit/stage.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-08 21:31:56.901213 mlagility-3.1.1/src/onnxflow/model/
+-rw-r--r--   0 runner    (1001) docker     (123)       53 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5919 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/model/model.py
+-rw-r--r--   0 runner    (1001) docker     (123)       22 2023-06-08 21:31:08.000000 mlagility-3.1.1/src/onnxflow/version.py
```

### Comparing `mlagility-3.0.2/LICENSE` & `mlagility-3.1.1/LICENSE`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/PKG-INFO` & `mlagility-3.1.1/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mlagility
-Version: 3.0.2
+Version: 3.1.1
 Summary: MLAgility Benchmark and Tools
 Home-page: https://github.com/groq/mlagility
 Author: Jeremy Fowers, Daniel Holanda, Ramakrishnan Sivakumar, Victoria Godsoe
 Author-email: jfowers@groq.com, dhnoronha@groq.com, rsivakumar@groq.com, vgodsoe@groq.com
 License: MIT
 Requires-Python: >=3.8, <3.11
 Description-Content-Type: text/markdown
@@ -12,14 +12,15 @@
 Provides-Extra: groq
 License-File: LICENSE
 
 # The MLAgility Project
 
 [![MLAgility tests](https://github.com/groq/mlagility/actions/workflows/test_mlagility.yml/badge.svg)](https://github.com/groq/mlagility/tree/main/test "Check out our tests")
 [![onnxflow tests](https://github.com/groq/mlagility/actions/workflows/test_onnxflow.yml/badge.svg)](https://github.com/groq/mlagility/tree/main/test "Check out our tests")
+[![MLAgility GPU tests](https://github.com/groq/mlagility/actions/workflows/test_gpu_mlagility.yml/badge.svg)](https://github.com/groq/mlagility/tree/main/test "Check out our tests")
 [![OS - Linux](https://img.shields.io/badge/OS-Linux-blue?logo=linux&logoColor=white)](https://github.com/groq/mlagility/blob/main/docs/install.md "Check out our instructions")
 [![Made with Python](https://img.shields.io/badge/Python-3.8,3.10-blue?logo=python&logoColor=white)](https://github.com/groq/mlagility/blob/main/docs/install.md "Check out our instructions")
 [![License](https://img.shields.io/badge/License-MIT-blue)](https://github.com/groq/mlagility/blob/main/LICENSE "Check out our license")
 
 
 MLAgility offers a complementary approach to MLPerf by examining the capability of vendors to provide turnkey solutions to a corpus of hundreds of off-the-shelf models. All of the model scripts and benchmarking code are published as open source software. The performance data is available at our [Huggingface Space](https://huggingface.co/spaces/Groq/mlagility).
```

### Comparing `mlagility-3.0.2/README.md` & `mlagility-3.1.1/README.md`

 * *Files 8% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 # The MLAgility Project
 
 [![MLAgility tests](https://github.com/groq/mlagility/actions/workflows/test_mlagility.yml/badge.svg)](https://github.com/groq/mlagility/tree/main/test "Check out our tests")
 [![onnxflow tests](https://github.com/groq/mlagility/actions/workflows/test_onnxflow.yml/badge.svg)](https://github.com/groq/mlagility/tree/main/test "Check out our tests")
+[![MLAgility GPU tests](https://github.com/groq/mlagility/actions/workflows/test_gpu_mlagility.yml/badge.svg)](https://github.com/groq/mlagility/tree/main/test "Check out our tests")
 [![OS - Linux](https://img.shields.io/badge/OS-Linux-blue?logo=linux&logoColor=white)](https://github.com/groq/mlagility/blob/main/docs/install.md "Check out our instructions")
 [![Made with Python](https://img.shields.io/badge/Python-3.8,3.10-blue?logo=python&logoColor=white)](https://github.com/groq/mlagility/blob/main/docs/install.md "Check out our instructions")
 [![License](https://img.shields.io/badge/License-MIT-blue)](https://github.com/groq/mlagility/blob/main/LICENSE "Check out our license")
 
 
 MLAgility offers a complementary approach to MLPerf by examining the capability of vendors to provide turnkey solutions to a corpus of hundreds of off-the-shelf models. All of the model scripts and benchmarking code are published as open source software. The performance data is available at our [Huggingface Space](https://huggingface.co/spaces/Groq/mlagility).
```

### Comparing `mlagility-3.0.2/models/diffusers/clip_text_encoder.py` & `mlagility-3.1.1/models/diffusers/clip_text_encoder.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,19 +1,14 @@
-# labels: test_group::mlagility name::clip_text_encoder author::diffusers
+# labels: test_group::mlagility name::clip_text_encoder author::diffusers task::MultiModal
 # https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py
 # Use Stable Diffusion to instantiate the CLIP text embedding model, then return the model
 
 from diffusers import StableDiffusionPipeline
 import torch
 
-
-pipe = StableDiffusionPipeline.from_pretrained(
-    "CompVis/stable-diffusion-v1-4",
-    use_auth_token="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",
-)
+pipe = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2-1")
 
 model = pipe.text_encoder
 inputs = {"input_ids": torch.ones([1, 77], dtype=torch.int)}
 
-
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/diffusers/safety_clipvision.py` & `mlagility-3.1.1/models/diffusers/safety_clipvision.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,19 +1,20 @@
-# labels: test_group::mlagility name::safety_clipvision author::diffusers
+# labels: test_group::mlagility name::safety_clipvision author::diffusers task::Generative_AI
 # https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py
 # Use Stable Diffusion to instantiate the Safety ClipVision model, then return the model
 
-from diffusers import StableDiffusionPipeline
 import torch
-
+from diffusers import StableDiffusionPipeline
+from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker
 
 pipe = StableDiffusionPipeline.from_pretrained(
-    "CompVis/stable-diffusion-v1-4",
-    use_auth_token="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",
+    "stabilityai/stable-diffusion-2-1",
+    safety_checker=StableDiffusionSafetyChecker.from_pretrained(
+        "CompVis/stable-diffusion-safety-checker"
+    ),
 )
 
 model = pipe.safety_checker.vision_model
 inputs = {"pixel_values": torch.ones([1, 3, 224, 224], dtype=torch.float)}
 
-
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/diffusers/unet_2d_condition.py` & `mlagility-3.1.1/models/diffusers/unet_2d_condition.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,27 +1,21 @@
-# labels: test_group::mlagility name::unet_2d_condition author::diffusers
+# labels: test_group::mlagility name::unet_2d_condition author::diffusers task::Computer_Vision
 # https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py
 # Use Stable Diffusion to instantiate the unet, then return the unet
 
 from diffusers import StableDiffusionPipeline
 import torch
 
-
-pipe = StableDiffusionPipeline.from_pretrained(
-    "CompVis/stable-diffusion-v1-4",
-    use_auth_token="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",
-)
-
+pipe = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2-1")
 model = pipe.unet
 
-latent_model_shape = [2, 4, 64, 64]
-text_embeddings_shape = [2, 77, 768]
+latent_model_shape = [2, 4, 94, 94]
+text_embeddings_shape = [2, 77, 1024]
 
 inputs = {
     "sample": torch.ones(latent_model_shape, dtype=torch.float),
     "timestep": 1,
     "encoder_hidden_states": torch.ones(text_embeddings_shape, dtype=torch.float),
 }
 
-
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/diffusers/vae_decoder.py` & `mlagility-3.1.1/models/diffusers/vae_decoder.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,14 @@
-# labels: test_group::mlagility name::vae_decoder author::diffusers
+# labels: test_group::mlagility name::vae_decoder author::diffusers task::Generative_AI
 # https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py
 # Use Stable Diffusion to instantiate the VAE decoder model, then return the VAE
 
 from diffusers import StableDiffusionPipeline
 import torch
 
-
-pipe = StableDiffusionPipeline.from_pretrained(
-    "CompVis/stable-diffusion-v1-4",
-    use_auth_token="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",
-)
+pipe = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2-1")
 
 model = pipe.vae.decoder
 inputs = {"z": torch.ones([1, 4, 64, 64], dtype=torch.float)}
 
-
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/graph_convolutions/chebconv.py` & `mlagility-3.1.1/models/graph_convolutions/chebconv.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::chebconv author::graph_convolutions
+# labels: test_group::mlagility name::chebconv author::graph_convolutions task::Graph_Machine_Learning
 """
 The chebyshev spectral graph convolutional operator from the `"Convolutional
 Neural Networks on Graphs with Fast Localized Spectral Filtering"
 <https://arxiv.org/abs/1606.09375>`_ paper
 """
 from mlagility.parser import parse
 import torch
```

### Comparing `mlagility-3.0.2/models/graph_convolutions/dnaconv.py` & `mlagility-3.1.1/models/graph_convolutions/dnaconv.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::dnaconv author::graph_convolutions
+# labels: test_group::mlagility name::dnaconv author::graph_convolutions task::Graph_Machine_Learning
 """
 The dynamic neighborhood aggregation operator from the
 `"Just Jump: Towards Dynamic Neighborhood Aggregation in Graph Neural Networks"
 <https://arxiv.org/abs/1904.04849>`_ paper
 """
 
 from mlagility.parser import parse
```

### Comparing `mlagility-3.0.2/models/graph_convolutions/egconv.py` & `mlagility-3.1.1/models/graph_convolutions/gatedgraphconv.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,30 +1,27 @@
-# labels: test_group::mlagility name::egconv author::graph_convolutions
+# labels: test_group::mlagility name::gatedgraphconv author::graph_convolutions task::Graph_Machine_Learning
 """
-Efficient Graph Convolution from the `"Adaptive Filters and
-Aggregator Fusion for Efficient Graph Convolutions"
-<https://arxiv.org/abs/2104.01481>`_ paper.
+The gated graph convolution operator from the `"Gated Graph Sequence Neural Networks"
+<https://arxiv.org/abs/1511.05493>`_ paper
 """
-
 from mlagility.parser import parse
 import torch
 
 from torch_geometric.datasets import Planetoid
-from torch_geometric.nn import EGConv
+from torch_geometric.nn import GatedGraphConv
 
 dataset = Planetoid(root=".", name="Cora")
 data = dataset[0]
 edge_index_rows = 2
 
 # Parsing command-line arguments
-out_channels = parse(["out_channels"])[0]
+num_layers, out_channels = parse(["num_layers", "out_channels"])
 
 
-model = EGConv(dataset.num_features, out_channels)
-# out_channels must be divisible by the number of heads
+model = GatedGraphConv(out_channels, num_layers)
 x = torch.ones(data.num_nodes, data.num_features, dtype=torch.float)
 edge_index = torch.ones(edge_index_rows, data.num_nodes, dtype=torch.long)
 inputs = {
     "x": x,
     "edge_index": edge_index,
 }
```

### Comparing `mlagility-3.0.2/models/graph_convolutions/feastconv.py` & `mlagility-3.1.1/models/graph_convolutions/sageconv.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# labels: test_group::mlagility name::feastconv author::graph_convolutions
+# labels: test_group::mlagility name::sageconv author::graph_convolutions task::Graph_Machine_Learning
 """
-The (translation-invariant) feature-steered convolutional operator from the
-`"FeaStNet: Feature-Steered Graph Convolutions for 3D Shape Analysis"
-<https://arxiv.org/abs/1706.05206>`_ paper
+The GraphSAGE operator from the `"Inductive Representation Learning on Large Graphs"
+<https://arxiv.org/abs/1706.02216>`_ paper
 """
 
 import torch
 
 from torch_geometric.datasets import Planetoid
-from torch_geometric.nn import FeaStConv
+from torch_geometric.nn import SAGEConv
 
 dataset = Planetoid(root=".", name="Cora")
 data = dataset[0]
 edge_index_rows = 2
 
 
-model = FeaStConv(dataset.num_features, dataset.num_classes)
+model = SAGEConv(dataset.num_features, dataset.num_classes)
 x = torch.ones(data.num_nodes, data.num_features, dtype=torch.float)
 edge_index = torch.ones(edge_index_rows, data.num_nodes, dtype=torch.long)
 inputs = {
     "x": x,
     "edge_index": edge_index,
 }
```

### Comparing `mlagility-3.0.2/models/graph_convolutions/gatedgraphconv.py` & `mlagility-3.1.1/models/graph_convolutions/pnaconv.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,27 +1,26 @@
-# labels: test_group::mlagility name::gatedgraphconv author::graph_convolutions
+# labels: test_group::mlagility name::pnaconv author::graph_convolutions task::Graph_Machine_Learning
 """
-The gated graph convolution operator from the `"Gated Graph Sequence Neural Networks"
-<https://arxiv.org/abs/1511.05493>`_ paper
+The Principal Neighbourhood Aggregation graph convolution operator from the
+`"Principal Neighbourhood Aggregation for Graph Nets"
+<https://arxiv.org/abs/2004.05718>`_ paper
 """
-from mlagility.parser import parse
 import torch
 
 from torch_geometric.datasets import Planetoid
-from torch_geometric.nn import GatedGraphConv
+from torch_geometric.nn import PNAConv
 
 dataset = Planetoid(root=".", name="Cora")
 data = dataset[0]
 edge_index_rows = 2
+deg = torch.ones(1, data.num_nodes, dtype=torch.int)
 
-# Parsing command-line arguments
-num_layers, out_channels = parse(["num_layers", "out_channels"])
 
-
-model = GatedGraphConv(out_channels, num_layers)
+# PNAConv(in_channels, out_channels, aggregators, scalers, deg)
+model = PNAConv(dataset.num_features, dataset.num_classes, ["sum"], ["identity"], deg)
 x = torch.ones(data.num_nodes, data.num_features, dtype=torch.float)
 edge_index = torch.ones(edge_index_rows, data.num_nodes, dtype=torch.long)
 inputs = {
     "x": x,
     "edge_index": edge_index,
 }
```

### Comparing `mlagility-3.0.2/models/graph_convolutions/generalconv.py` & `mlagility-3.1.1/models/graph_convolutions/feastconv.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,24 +1,25 @@
-# labels: test_group::mlagility name::generalconv author::graph_convolutions
+# labels: test_group::mlagility name::feastconv author::graph_convolutions task::Graph_Machine_Learning
 """
-A general GNN layer adapted from the `"Design Space for Graph Neural Networks"
-<https://arxiv.org/abs/2011.08843>`_ paper.
+The (translation-invariant) feature-steered convolutional operator from the
+`"FeaStNet: Feature-Steered Graph Convolutions for 3D Shape Analysis"
+<https://arxiv.org/abs/1706.05206>`_ paper
 """
 
 import torch
 
 from torch_geometric.datasets import Planetoid
-from torch_geometric.nn import GeneralConv
+from torch_geometric.nn import FeaStConv
 
 dataset = Planetoid(root=".", name="Cora")
 data = dataset[0]
 edge_index_rows = 2
 
 
-model = GeneralConv(dataset.num_features, dataset.num_classes)
+model = FeaStConv(dataset.num_features, dataset.num_classes)
 x = torch.ones(data.num_nodes, data.num_features, dtype=torch.float)
 edge_index = torch.ones(edge_index_rows, data.num_nodes, dtype=torch.long)
 inputs = {
     "x": x,
     "edge_index": edge_index,
 }
```

### Comparing `mlagility-3.0.2/models/graph_convolutions/leconv.py` & `mlagility-3.1.1/models/graph_convolutions/leconv.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::leconv author::graph_convolutions
+# labels: test_group::mlagility name::leconv author::graph_convolutions task::Graph_Machine_Learning
 """
 The local extremum graph neural network operator from the
 `"ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations"
 <https://arxiv.org/abs/1911.07979>`_ paper
 """
 
 import torch
```

### Comparing `mlagility-3.0.2/models/graph_convolutions/pnaconv.py` & `mlagility-3.1.1/models/graph_convolutions/generalconv.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-# labels: test_group::mlagility name::pnaconv author::graph_convolutions
+# labels: test_group::mlagility name::generalconv author::graph_convolutions task::Graph_Machine_Learning
 """
-The Principal Neighbourhood Aggregation graph convolution operator from the
-`"Principal Neighbourhood Aggregation for Graph Nets"
-<https://arxiv.org/abs/2004.05718>`_ paper
+A general GNN layer adapted from the `"Design Space for Graph Neural Networks"
+<https://arxiv.org/abs/2011.08843>`_ paper.
 """
+
 import torch
 
 from torch_geometric.datasets import Planetoid
-from torch_geometric.nn import PNAConv
+from torch_geometric.nn import GeneralConv
 
 dataset = Planetoid(root=".", name="Cora")
 data = dataset[0]
 edge_index_rows = 2
-deg = torch.ones(1, data.num_nodes, dtype=torch.int)
 
 
-# PNAConv(in_channels, out_channels, aggregators, scalers, deg)
-model = PNAConv(dataset.num_features, dataset.num_classes, ["sum"], ["identity"], deg)
+model = GeneralConv(dataset.num_features, dataset.num_classes)
 x = torch.ones(data.num_nodes, data.num_features, dtype=torch.float)
 edge_index = torch.ones(edge_index_rows, data.num_nodes, dtype=torch.long)
 inputs = {
     "x": x,
     "edge_index": edge_index,
 }
```

### Comparing `mlagility-3.0.2/models/graph_convolutions/resgatedgraphconv.py` & `mlagility-3.1.1/models/graph_convolutions/resgatedgraphconv.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::resgatedgraphconv author::graph_convolutions
+# labels: test_group::mlagility name::resgatedgraphconv author::graph_convolutions task::Graph_Machine_Learning
 """
 The residual gated graph convolutional operator from the `"Residual Gated Graph ConvNets"
 <https://arxiv.org/abs/1711.07553>`_ paper
 """
 
 import torch
```

### Comparing `mlagility-3.0.2/models/graph_convolutions/sageconv.py` & `mlagility-3.1.1/models/graph_convolutions/tagconv.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,24 +1,24 @@
-# labels: test_group::mlagility name::sageconv author::graph_convolutions
+# labels: test_group::mlagility name::tagconv author::graph_convolutions task::Graph_Machine_Learning
 """
-The GraphSAGE operator from the `"Inductive Representation Learning on Large Graphs"
-<https://arxiv.org/abs/1706.02216>`_ paper
+The topology adaptive graph convolutional networks operator from the
+`"Topology Adaptive Graph Convolutional Networks"
+<https://arxiv.org/abs/1710.10370>`_ paper
 """
-
 import torch
 
 from torch_geometric.datasets import Planetoid
-from torch_geometric.nn import SAGEConv
+from torch_geometric.nn import TAGConv
 
 dataset = Planetoid(root=".", name="Cora")
 data = dataset[0]
 edge_index_rows = 2
 
 
-model = SAGEConv(dataset.num_features, dataset.num_classes)
+model = TAGConv(dataset.num_features, dataset.num_classes)
 x = torch.ones(data.num_nodes, data.num_features, dtype=torch.float)
 edge_index = torch.ones(edge_index_rows, data.num_nodes, dtype=torch.long)
 inputs = {
     "x": x,
     "edge_index": edge_index,
 }
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/0x7194633_keyt5-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/0x7194633_keyt5-large.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::0x7194633 name::keyt5-large downloads::432 license::mit task::Text2Text_Generation
+# labels: test_group::monthly author::0x7194633 name::keyt5-large downloads::432 license::mit task::Natural_Language_Processing sub_task::Text2Text_Generation
 from itertools import groupby
 import torch
 from transformers import T5ForConditionalGeneration, T5Tokenizer
 model_name = "0x7194633/keyt5-large" # or 0x7194633/keyt5-base
 tokenizer = T5Tokenizer.from_pretrained(model_name)
 model = T5ForConditionalGeneration.from_pretrained(model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/AmazonScience_qanlu.py` & `mlagility-3.1.1/models/popular_on_huggingface/AmazonScience_qanlu.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::AmazonScience name::qanlu downloads::374 license::cc-by-4.0 task::Question_Answering
+# labels: test_group::monthly author::AmazonScience name::qanlu downloads::374 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline
   
 tokenizer = AutoTokenizer.from_pretrained("AmazonScience/qanlu", use_auth_token=True)
 
 model = AutoModelForQuestionAnswering.from_pretrained("AmazonScience/qanlu", use_auth_token=True)
 
 qa_pipeline = pipeline('question-answering', model=model, tokenizer=tokenizer)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/BM-K_KoSimCSE-roberta.py` & `mlagility-3.1.1/models/popular_on_huggingface/BM-K_KoSimCSE-roberta.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::BM-K name::KoSimCSE-roberta downloads::634 task::Feature_Extraction
+# labels: test_group::monthly author::BM-K name::KoSimCSE-roberta downloads::634 task::Multimodal sub_task::Feature_Extraction
 import torch
 from transformers import AutoModel, AutoTokenizer
 
 def cal_score(a, b):
     if len(a.shape) == 1: a = a.unsqueeze(0)
     if len(b.shape) == 1: b = b.unsqueeze(0)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Babelscape_wikineural-multilingual-ner.py` & `mlagility-3.1.1/models/popular_on_huggingface/philschmid_distilroberta-base-ner-wikiann.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,12 +1,11 @@
-# labels: test_group::monthly author::Babelscape name::wikineural-multilingual-ner downloads::2,798 license::cc-by-nc-sa-4.0 task::Token_Classification
+# labels: test_group::monthly author::philschmid name::distilroberta-base-ner-wikiann downloads::233 license::apache-2.0 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
 
-tokenizer = AutoTokenizer.from_pretrained("Babelscape/wikineural-multilingual-ner")
-model = AutoModelForTokenClassification.from_pretrained("Babelscape/wikineural-multilingual-ner")
+tokenizer = AutoTokenizer.from_pretrained("philschmid/distilroberta-base-ner-wikiann")
+model = AutoModelForTokenClassification.from_pretrained("philschmid/distilroberta-base-ner-wikiann")
 
-nlp = pipeline("ner", model=model, tokenizer=tokenizer)
-example = "My name is Wolfgang and I live in Berlin"
+nlp = pipeline("ner", model=model, tokenizer=tokenizer, grouped_entities=True)
+example = "My name is Philipp and live in Germany"
 
-ner_results = nlp(example)
-print(ner_results)
+nlp(example)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Bhuvana_t5-base-spellchecker.py` & `mlagility-3.1.1/models/popular_on_huggingface/Bhuvana_t5-base-spellchecker.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Bhuvana name::t5-base-spellchecker downloads::215 task::Text2Text_Generation
+# labels: test_group::monthly author::Bhuvana name::t5-base-spellchecker downloads::215 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 tokenizer = AutoTokenizer.from_pretrained("Bhuvana/t5-base-spellchecker")
 
 model = AutoModelForSeq2SeqLM.from_pretrained("Bhuvana/t5-base-spellchecker")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/CompVis_ldm-text2im-large-256.py` & `mlagility-3.1.1/models/popular_on_huggingface/CompVis_ldm-text2im-large-256.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::CompVis name::ldm-text2im-large-256 downloads::2,736 license::apache-2.0 task::Text-to-Image
+# labels: test_group::monthly,daily author::CompVis name::ldm-text2im-large-256 downloads::2,736 license::apache-2.0 task::Multimodal sub_task::Text-to-Image
 # !pip install diffusers transformers
 from diffusers import DiffusionPipeline
 
 model_id = "CompVis/ldm-text2im-large-256"
 
 # load model and scheduler
 ldm = DiffusionPipeline.from_pretrained(model_id)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/CompVis_stable-diffusion-v1-4.py` & `mlagility-3.1.1/models/popular_on_huggingface/CompVis_stable-diffusion-v1-4.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::hot_at_groq,monthly,daily author::CompVis name::stable-diffusion-v1-4 downloads::933,179 license::creativeml-openrail-m task::Text-to-Image
+# labels: test_group::hot_at_groq,monthly,daily author::CompVis name::stable-diffusion-v1-4 downloads::933,179 license::creativeml-openrail-m task::Multimodal sub_task::Text-to-Image
 import torch
 from torch import autocast
 from diffusers import StableDiffusionPipeline
 
 model_id = "CompVis/stable-diffusion-v1-4"
 device = "cpu"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Davlan_bert-base-multilingual-cased-masakhaner.py` & `mlagility-3.1.1/models/popular_on_huggingface/Davlan_bert-base-multilingual-cased-masakhaner.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Davlan name::bert-base-multilingual-cased-masakhaner downloads::396 task::Token_Classification
+# labels: test_group::monthly author::Davlan name::bert-base-multilingual-cased-masakhaner downloads::396 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
 tokenizer = AutoTokenizer.from_pretrained("Davlan/bert-base-multilingual-cased-masakhaner")
 model = AutoModelForTokenClassification.from_pretrained("Davlan/bert-base-multilingual-cased-masakhaner")
 nlp = pipeline("ner", model=model, tokenizer=tokenizer)
 example = "Emir of Kano turban Zhang wey don spend 18 years for Nigeria"
 ner_results = nlp(example)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Davlan_bert-base-multilingual-cased-ner-hrl.py` & `mlagility-3.1.1/models/popular_on_huggingface/Davlan_distilbert-base-multilingual-cased-ner-hrl.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-# labels: test_group::monthly author::Davlan name::bert-base-multilingual-cased-ner-hrl downloads::202,600 task::Token_Classification
+# labels: test_group::monthly author::Davlan name::distilbert-base-multilingual-cased-ner-hrl downloads::1,544 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
-tokenizer = AutoTokenizer.from_pretrained("Davlan/bert-base-multilingual-cased-ner-hrl")
-model = AutoModelForTokenClassification.from_pretrained("Davlan/bert-base-multilingual-cased-ner-hrl")
+tokenizer = AutoTokenizer.from_pretrained("Davlan/distilbert-base-multilingual-cased-ner-hrl")
+model = AutoModelForTokenClassification.from_pretrained("Davlan/distilbert-base-multilingual-cased-ner-hrl")
 nlp = pipeline("ner", model=model, tokenizer=tokenizer)
 example = "Nader Jokhadar had given Syria the lead with a well-struck header in the seventh minute."
 ner_results = nlp(example)
 print(ner_results)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Davlan_distilbert-base-multilingual-cased-ner-hrl.py` & `mlagility-3.1.1/models/popular_on_huggingface/Davlan_bert-base-multilingual-cased-ner-hrl.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-# labels: test_group::monthly author::Davlan name::distilbert-base-multilingual-cased-ner-hrl downloads::1,544 task::Token_Classification
+# labels: test_group::monthly author::Davlan name::bert-base-multilingual-cased-ner-hrl downloads::202,600 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
-tokenizer = AutoTokenizer.from_pretrained("Davlan/distilbert-base-multilingual-cased-ner-hrl")
-model = AutoModelForTokenClassification.from_pretrained("Davlan/distilbert-base-multilingual-cased-ner-hrl")
+tokenizer = AutoTokenizer.from_pretrained("Davlan/bert-base-multilingual-cased-ner-hrl")
+model = AutoModelForTokenClassification.from_pretrained("Davlan/bert-base-multilingual-cased-ner-hrl")
 nlp = pipeline("ner", model=model, tokenizer=tokenizer)
 example = "Nader Jokhadar had given Syria the lead with a well-struck header in the seventh minute."
 ner_results = nlp(example)
 print(ner_results)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Davlan_xlm-roberta-base-ner-hrl.py` & `mlagility-3.1.1/models/popular_on_huggingface/Davlan_xlm-roberta-base-ner-hrl.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Davlan name::xlm-roberta-base-ner-hrl downloads::5,604 task::Token_Classification
+# labels: test_group::monthly author::Davlan name::xlm-roberta-base-ner-hrl downloads::5,604 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
 tokenizer = AutoTokenizer.from_pretrained("Davlan/xlm-roberta-base-ner-hrl")
 model = AutoModelForTokenClassification.from_pretrained("Davlan/xlm-roberta-base-ner-hrl")
 nlp = pipeline("ner", model=model, tokenizer=tokenizer)
 example = "Nader Jokhadar had given Syria the lead with a well-struck header in the seventh minute."
 ner_results = nlp(example)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Davlan_xlm-roberta-large-ner-hrl.py` & `mlagility-3.1.1/models/popular_on_huggingface/Davlan_xlm-roberta-large-ner-hrl.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Davlan name::xlm-roberta-large-ner-hrl downloads::1,442 task::Token_Classification
+# labels: test_group::monthly author::Davlan name::xlm-roberta-large-ner-hrl downloads::1,442 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
 tokenizer = AutoTokenizer.from_pretrained("Davlan/xlm-roberta-large-ner-hrl")
 model = AutoModelForTokenClassification.from_pretrained("Davlan/xlm-roberta-large-ner-hrl")
 nlp = pipeline("ner", model=model, tokenizer=tokenizer)
 example = "Nader Jokhadar had given Syria the lead with a well-struck header in the seventh minute."
 ner_results = nlp(example)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ElKulako_cryptobert.py` & `mlagility-3.1.1/models/popular_on_huggingface/ElKulako_cryptobert.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ElKulako name::cryptobert downloads::740 task::Text_Classification
+# labels: test_group::monthly author::ElKulako name::cryptobert downloads::740 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import TextClassificationPipeline, AutoModelForSequenceClassification, AutoTokenizer
 model_name = "ElKulako/cryptobert"
 tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)
 model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 3)
 pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, max_length=64, truncation=True, padding = 'max_length')
 # post_1 & post_3 = bullish, post_2 = bearish
 post_1 = " see y'all tomorrow and can't wait to see ada in the morning, i wonder what price it is going to be at. , bitcoin is looking good go for it and flash by that 45k. "
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Elron_bleurt-base-512.py` & `mlagility-3.1.1/models/popular_on_huggingface/Elron_bleurt-large-512.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-# labels: test_group::monthly author::Elron name::bleurt-base-512 downloads::243 task::Text_Classification
+# labels: test_group::monthly author::Elron name::bleurt-large-512 downloads::3,298 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification, AutoTokenizer
 import torch
 
-tokenizer = AutoTokenizer.from_pretrained("Elron/bleurt-base-512")
-model = AutoModelForSequenceClassification.from_pretrained("Elron/bleurt-base-512")
+tokenizer = AutoTokenizer.from_pretrained("Elron/bleurt-large-512")
+model = AutoModelForSequenceClassification.from_pretrained("Elron/bleurt-large-512")
 model.eval()
 
 references = ["hello world", "hello world"]
 candidates = ["hi universe", "bye world"]
 
 with torch.no_grad():
   scores = model(**tokenizer(references, candidates, return_tensors='pt'))[0].squeeze()
-
-print(scores) # tensor([1.0327, 0.2055])
+print(scores) # tensor([0.9877, 0.0475])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Elron_bleurt-large-512.py` & `mlagility-3.1.1/models/popular_on_huggingface/Elron_bleurt-tiny-512.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,14 +1,15 @@
-# labels: test_group::monthly author::Elron name::bleurt-large-512 downloads::3,298 task::Text_Classification
+# labels: test_group::monthly author::Elron name::bleurt-tiny-512 downloads::34,866 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification, AutoTokenizer
 import torch
 
-tokenizer = AutoTokenizer.from_pretrained("Elron/bleurt-large-512")
-model = AutoModelForSequenceClassification.from_pretrained("Elron/bleurt-large-512")
+tokenizer = AutoTokenizer.from_pretrained("Elron/bleurt-tiny-512")
+model = AutoModelForSequenceClassification.from_pretrained("Elron/bleurt-tiny-512")
 model.eval()
 
 references = ["hello world", "hello world"]
 candidates = ["hi universe", "bye world"]
 
 with torch.no_grad():
   scores = model(**tokenizer(references, candidates, return_tensors='pt'))[0].squeeze()
-print(scores) # tensor([0.9877, 0.0475])
+
+print(scores) # tensor([-0.9414, -0.5678])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/FinanceInc_finbert_fls.py` & `mlagility-3.1.1/models/popular_on_huggingface/FinanceInc_finbert_fls.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::FinanceInc name::finbert_fls downloads::230 task::Text_Classification
+# labels: test_group::monthly author::FinanceInc name::finbert_fls downloads::230 task::Natural_Language_Processing sub_task::Text_Classification
 # tested in transformers==4.18.0 
 from transformers import BertTokenizer, BertForSequenceClassification, pipeline
 
 finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-fls',num_labels=3)
 tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-fls')
 nlp = pipeline("text-classification", model=finbert, tokenizer=tokenizer)
 results = nlp('We expect the age of our fleet to enhance availability and reliability due to reduced downtime for repairs.')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/HooshvareLab_bert-fa-zwnj-base-ner.py` & `mlagility-3.1.1/models/popular_on_huggingface/HooshvareLab_bert-fa-zwnj-base-ner.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::HooshvareLab name::bert-fa-zwnj-base-ner downloads::187 task::Token_Classification
+# labels: test_group::monthly author::HooshvareLab name::bert-fa-zwnj-base-ner downloads::187 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer
 from transformers import AutoModelForTokenClassification  # for pytorch
 from transformers import TFAutoModelForTokenClassification  # for tensorflow
 from transformers import pipeline
 
 
 model_name_or_path = "HooshvareLab/bert-fa-zwnj-base-ner"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/HooshvareLab_distilbert-fa-zwnj-base-ner.py` & `mlagility-3.1.1/models/popular_on_huggingface/HooshvareLab_distilbert-fa-zwnj-base-ner.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::HooshvareLab name::distilbert-fa-zwnj-base-ner downloads::5,185 task::Token_Classification
+# labels: test_group::monthly author::HooshvareLab name::distilbert-fa-zwnj-base-ner downloads::5,185 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer
 from transformers import AutoModelForTokenClassification  # for pytorch
 from transformers import TFAutoModelForTokenClassification  # for tensorflow
 from transformers import pipeline
 
 
 model_name_or_path = "HooshvareLab/distilbert-fa-zwnj-base-ner"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Huffon_sentence-klue-roberta-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/Huffon_sentence-klue-roberta-base.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Huffon name::sentence-klue-roberta-base task::unknown downloads::810
+# labels: test_group::monthly author::Huffon name::sentence-klue-roberta-base task::Natural_Language_Processing downloads::810
 import torch
 from sentence_transformers import SentenceTransformer, util
 
 model = SentenceTransformer("Huffon/sentence-klue-roberta-base")
 
 docs = [
     "1992 7 8            .",
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-110M-NLI.py` & `mlagility-3.1.1/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-110M-NLI.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::IDEA-CCNL name::Erlangshen-Roberta-110M-NLI downloads::890 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::IDEA-CCNL name::Erlangshen-Roberta-110M-NLI downloads::890 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import BertForSequenceClassification
 from transformers import BertTokenizer
 import torch
 
 tokenizer=BertTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-110M-NLI')
 model=BertForSequenceClassification.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-110M-NLI')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-110M-Sentiment.py` & `mlagility-3.1.1/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-110M-Sentiment.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::IDEA-CCNL name::Erlangshen-Roberta-110M-Sentiment downloads::2,437 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::IDEA-CCNL name::Erlangshen-Roberta-110M-Sentiment downloads::2,437 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import BertForSequenceClassification
 from transformers import BertTokenizer
 import torch
 
 tokenizer=BertTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment')
 model=BertForSequenceClassification.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-330M-Sentiment.py` & `mlagility-3.1.1/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-330M-Sentiment.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::IDEA-CCNL name::Erlangshen-Roberta-330M-Sentiment downloads::289 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::IDEA-CCNL name::Erlangshen-Roberta-330M-Sentiment downloads::289 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import BertForSequenceClassification
 from transformers import BertTokenizer
 import torch
 
 tokenizer=BertTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-330M-Sentiment')
 model=BertForSequenceClassification.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-330M-Sentiment')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-330M-Similarity.py` & `mlagility-3.1.1/models/popular_on_huggingface/IDEA-CCNL_Erlangshen-Roberta-330M-Similarity.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::IDEA-CCNL name::Erlangshen-Roberta-330M-Similarity downloads::349 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::IDEA-CCNL name::Erlangshen-Roberta-330M-Similarity downloads::349 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import BertForSequenceClassification
 from transformers import BertTokenizer
 import torch
 
 tokenizer=BertTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-330M-Similarity')
 model=BertForSequenceClassification.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-330M-Similarity')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/IIC_dpr-spanish-passage_encoder-allqa-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/IIC_dpr-spanish-passage_encoder-allqa-base.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::IIC name::dpr-spanish-passage_encoder-allqa-base downloads::388 task::Fill-Mask
+# labels: test_group::monthly author::IIC name::dpr-spanish-passage_encoder-allqa-base downloads::388 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import DPRContextEncoder, DPRContextEncoderTokenizer
 
 model_str = "IIC/dpr-spanish-passage_encoder-allqa-base"
 tokenizer = DPRContextEncoderTokenizer.from_pretrained(model_str)
 model = DPRContextEncoder.from_pretrained(model_str)
 
 input_ids = tokenizer("Usain Bolt gan varias medallas de oro en las Olimpiadas del ao 2012", return_tensors="pt")["input_ids"]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/IIC_dpr-spanish-question_encoder-allqa-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/IIC_dpr-spanish-question_encoder-allqa-base.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::IIC name::dpr-spanish-question_encoder-allqa-base downloads::391 task::Fill-Mask
+# labels: test_group::monthly author::IIC name::dpr-spanish-question_encoder-allqa-base downloads::391 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer
 
 model_str = "IIC/dpr-spanish-question_encoder-allqa-base"
 tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(model_str)
 model = DPRQuestionEncoder.from_pretrained(model_str)
 
 input_ids = tokenizer("Qu medallas gan Usain Bolt en 2012?", return_tensors="pt")["input_ids"]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/IlyaGusev_rubert_telegram_headlines.py` & `mlagility-3.1.1/models/popular_on_huggingface/IlyaGusev_rut5_base_sum_gazeta.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# labels: test_group::monthly author::IlyaGusev name::rubert_telegram_headlines downloads::227 license::apache-2.0 task::Summarization
-from transformers import AutoTokenizer, EncoderDecoderModel
+# labels: test_group::monthly author::IlyaGusev name::rut5_base_sum_gazeta downloads::469 license::apache-2.0 task::Natural_Language_Processing sub_task::Summarization
+from transformers import AutoTokenizer, T5ForConditionalGeneration
 
-model_name = "IlyaGusev/rubert_telegram_headlines"
-tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False, do_basic_tokenize=False, strip_accents=False)
-model = EncoderDecoderModel.from_pretrained(model_name)
+model_name = "IlyaGusev/rut5_base_sum_gazeta"
+tokenizer = AutoTokenizer.from_pretrained(model_name)
+model = T5ForConditionalGeneration.from_pretrained(model_name)
 
 article_text = "..."
 
 input_ids = tokenizer(
     [article_text],
+    max_length=600,
     add_special_tokens=True,
-    max_length=256,
     padding="max_length",
     truncation=True,
-    return_tensors="pt",
+    return_tensors="pt"
 )["input_ids"]
 
 output_ids = model.generate(
     input_ids=input_ids,
-    max_length=64,
-    no_repeat_ngram_size=3,
-    num_beams=10,
-    top_p=0.95
+    no_repeat_ngram_size=4
 )[0]
 
-headline = tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)
-print(headline)
+summary = tokenizer.decode(output_ids, skip_special_tokens=True)
+print(summary)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Intel_dpt-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/Intel_dpt-large.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Intel name::dpt-large task::unknown downloads::1,735 license::apache-2.0
+# labels: test_group::monthly author::Intel name::dpt-large task::Computer_Vision downloads::1,735 license::apache-2.0
 from transformers import DPTFeatureExtractor, DPTForDepthEstimation
 import torch
 import numpy as np
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Jean-Baptiste_camembert-ner-with-dates.py` & `mlagility-3.1.1/models/popular_on_huggingface/Jean-Baptiste_camembert-ner-with-dates.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Jean-Baptiste name::camembert-ner-with-dates downloads::23,765 task::Token_Classification
+# labels: test_group::monthly author::Jean-Baptiste name::camembert-ner-with-dates downloads::23,765 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 
 tokenizer = AutoTokenizer.from_pretrained("Jean-Baptiste/camembert-ner-with-dates")
 model = AutoModelForTokenClassification.from_pretrained("Jean-Baptiste/camembert-ner-with-dates")
 
 
 ##### Process text sample (from wikipedia)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Jean-Baptiste_camembert-ner.py` & `mlagility-3.1.1/models/popular_on_huggingface/Jean-Baptiste_camembert-ner.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Jean-Baptiste name::camembert-ner downloads::11,200,580 task::Token_Classification
+# labels: test_group::monthly author::Jean-Baptiste name::camembert-ner downloads::11,200,580 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 
 tokenizer = AutoTokenizer.from_pretrained("Jean-Baptiste/camembert-ner")
 model = AutoModelForTokenClassification.from_pretrained("Jean-Baptiste/camembert-ner")
 
 
 ##### Process text sample (from wikipedia)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Jean-Baptiste_roberta-large-ner-english.py` & `mlagility-3.1.1/models/popular_on_huggingface/Jean-Baptiste_roberta-large-ner-english.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Jean-Baptiste name::roberta-large-ner-english downloads::142,964 task::Token_Classification
+# labels: test_group::monthly author::Jean-Baptiste name::roberta-large-ner-english downloads::142,964 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 
 tokenizer = AutoTokenizer.from_pretrained("Jean-Baptiste/roberta-large-ner-english")
 model = AutoModelForTokenClassification.from_pretrained("Jean-Baptiste/roberta-large-ner-english")
 
 
 ##### Process text sample (from wikipedia)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/KES_T5-TTParser.py` & `mlagility-3.1.1/models/popular_on_huggingface/KES_T5-TTParser.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::KES name::T5-TTParser downloads::1,381 license::cc-by-nc-sa-4.0 task::Text2Text_Generation
+# labels: test_group::monthly author::KES name::T5-TTParser downloads::1,381 license::cc-by-nc-sa-4.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 tokenizer = AutoTokenizer.from_pretrained("KES/T5-TTParser")
 
 model = AutoModelForSeq2SeqLM.from_pretrained("KES/T5-TTParser")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/KES_TEC-English.py` & `mlagility-3.1.1/models/popular_on_huggingface/KES_TEC-English.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::KES name::TEC-English downloads::7,358 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::KES name::TEC-English downloads::7,358 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 tokenizer = AutoTokenizer.from_pretrained("KES/TEC-English")
 
 model = AutoModelForSeq2SeqLM.from_pretrained("KES/TEC-English")
 text = "Dem men doh kno wat dey doing wid d money"
 inputs = tokenizer("tec:"+text, truncation=True, return_tensors='pt')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Kamuuung_autonlp-lessons_tagging-606217261.py` & `mlagility-3.1.1/models/popular_on_huggingface/Kamuuung_autonlp-lessons_tagging-606217261.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Kamuuung name::autonlp-lessons_tagging-606217261 downloads::292 task::Text_Classification
+# labels: test_group::monthly author::Kamuuung name::autonlp-lessons_tagging-606217261 downloads::292 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification, AutoTokenizer
 
 model = AutoModelForSequenceClassification.from_pretrained("Kamuuung/autonlp-lessons_tagging-606217261", use_auth_token=True)
 
 tokenizer = AutoTokenizer.from_pretrained("Kamuuung/autonlp-lessons_tagging-606217261", use_auth_token=True)
 
 inputs = tokenizer("I love AutoNLP", return_tensors="pt")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/KoichiYasuoka_bert-base-japanese-upos.py` & `mlagility-3.1.1/models/popular_on_huggingface/KoichiYasuoka_bert-base-japanese-upos.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::KoichiYasuoka name::bert-base-japanese-upos downloads::284 license::cc-by-sa-4.0 task::Token_Classification
+# labels: test_group::monthly author::KoichiYasuoka name::bert-base-japanese-upos downloads::284 license::cc-by-sa-4.0 task::Natural_Language_Processing sub_task::Token_Classification
 import torch
 from transformers import AutoTokenizer,AutoModelForTokenClassification
 tokenizer=AutoTokenizer.from_pretrained("KoichiYasuoka/bert-base-japanese-upos")
 model=AutoModelForTokenClassification.from_pretrained("KoichiYasuoka/bert-base-japanese-upos")
 s=""
 p=[model.config.id2label[q] for q in torch.argmax(model(tokenizer.encode(s,return_tensors="pt"))["logits"],dim=2)[0].tolist()[1:-1]]
 print(list(zip(s,p)))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/KoichiYasuoka_bert-large-japanese-wikipedia-ud-head.py` & `mlagility-3.1.1/models/popular_on_huggingface/KoichiYasuoka_bert-large-japanese-wikipedia-ud-head.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,6 +1,6 @@
-# labels: test_group::monthly author::KoichiYasuoka name::bert-large-japanese-wikipedia-ud-head downloads::187 license::cc-by-sa-4.0 task::Question_Answering
+# labels: test_group::monthly author::KoichiYasuoka name::bert-large-japanese-wikipedia-ud-head downloads::187 license::cc-by-sa-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoTokenizer,AutoModelForQuestionAnswering,QuestionAnsweringPipeline
 tokenizer=AutoTokenizer.from_pretrained("KoichiYasuoka/bert-large-japanese-wikipedia-ud-head")
 model=AutoModelForQuestionAnswering.from_pretrained("KoichiYasuoka/bert-large-japanese-wikipedia-ud-head")
 qap=QuestionAnsweringPipeline(tokenizer=tokenizer,model=model,align_to_words=False)
 print(qap(question="",context=">"))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/KoichiYasuoka_deberta-base-japanese-aozora-ud-head.py` & `mlagility-3.1.1/models/popular_on_huggingface/KoichiYasuoka_deberta-base-japanese-aozora-ud-head.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,6 +1,6 @@
-# labels: test_group::monthly author::KoichiYasuoka name::deberta-base-japanese-aozora-ud-head downloads::358 license::cc-by-sa-4.0 task::Question_Answering
+# labels: test_group::monthly author::KoichiYasuoka name::deberta-base-japanese-aozora-ud-head downloads::358 license::cc-by-sa-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoTokenizer,AutoModelForQuestionAnswering,QuestionAnsweringPipeline
 tokenizer=AutoTokenizer.from_pretrained("KoichiYasuoka/deberta-base-japanese-aozora-ud-head")
 model=AutoModelForQuestionAnswering.from_pretrained("KoichiYasuoka/deberta-base-japanese-aozora-ud-head")
 qap=QuestionAnsweringPipeline(tokenizer=tokenizer,model=model,align_to_words=False)
 print(qap(question="",context=">"))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/KoichiYasuoka_deberta-base-thai-ud-head.py` & `mlagility-3.1.1/models/popular_on_huggingface/KoichiYasuoka_deberta-base-thai-ud-head.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,6 +1,6 @@
-# labels: test_group::monthly author::KoichiYasuoka name::deberta-base-thai-ud-head downloads::418 license::apache-2.0 task::Question_Answering
+# labels: test_group::monthly author::KoichiYasuoka name::deberta-base-thai-ud-head downloads::418 license::apache-2.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoTokenizer,AutoModelForQuestionAnswering,QuestionAnsweringPipeline
 tokenizer=AutoTokenizer.from_pretrained("KoichiYasuoka/deberta-base-thai-ud-head")
 model=AutoModelForQuestionAnswering.from_pretrained("KoichiYasuoka/deberta-base-thai-ud-head")
 qap=QuestionAnsweringPipeline(tokenizer=tokenizer,model=model,align_to_words=False)
 print(qap(question="",context=""))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/KoichiYasuoka_roberta-base-thai-spm-upos.py` & `mlagility-3.1.1/models/popular_on_huggingface/KoichiYasuoka_roberta-base-thai-spm-upos.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::KoichiYasuoka name::roberta-base-thai-spm-upos downloads::728 license::apache-2.0 task::Token_Classification
+# labels: test_group::monthly author::KoichiYasuoka name::roberta-base-thai-spm-upos downloads::728 license::apache-2.0 task::Natural_Language_Processing sub_task::Token_Classification
 import torch
 from transformers import AutoTokenizer,AutoModelForTokenClassification
 tokenizer=AutoTokenizer.from_pretrained("KoichiYasuoka/roberta-base-thai-spm-upos")
 model=AutoModelForTokenClassification.from_pretrained("KoichiYasuoka/roberta-base-thai-spm-upos")
 s=""
 t=tokenizer.tokenize(s)
 p=[model.config.id2label[q] for q in torch.argmax(model(tokenizer.encode(s,return_tensors="pt"))["logits"],dim=2)[0].tolist()[1:-1]]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MCG-NJU_videomae-base-finetuned-kinetics.py` & `mlagility-3.1.1/models/popular_on_huggingface/MCG-NJU_videomae-base-finetuned-kinetics.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::MCG-NJU name::videomae-base-finetuned-kinetics task::unknown downloads::1,449 license::cc-by-nc-4.0
+# labels: test_group::monthly author::MCG-NJU name::videomae-base-finetuned-kinetics task::Computer_Vision downloads::1,449 license::cc-by-nc-4.0
 from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification
 import numpy as np
 import torch
 
 video = list(np.random.randn(16, 3, 224, 224))
 
 feature_extractor = VideoMAEFeatureExtractor.from_pretrained("MCG-NJU/videomae-base-finetuned-kinetics")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MCG-NJU_videomae-base-ssv2.py` & `mlagility-3.1.1/models/popular_on_huggingface/MCG-NJU_videomae-base-ssv2.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::MCG-NJU name::videomae-base-ssv2 task::unknown downloads::249 license::cc-by-nc-4.0
+# labels: test_group::monthly author::MCG-NJU name::videomae-base-ssv2 task::Computer_Vision downloads::249 license::cc-by-nc-4.0
 from transformers import VideoMAEFeatureExtractor, VideoMAEForPreTraining
 import numpy as np
 import torch
 
 num_frames = 16
 video = list(np.random.randn(16, 3, 224, 224))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MCG-NJU_videomae-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/MCG-NJU_videomae-base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::MCG-NJU name::videomae-base task::unknown downloads::6,013 license::cc-by-nc-4.0
+# labels: test_group::monthly author::MCG-NJU name::videomae-base task::Computer_Vision downloads::6,013 license::cc-by-nc-4.0
 from transformers import VideoMAEFeatureExtractor, VideoMAEForPreTraining
 import numpy as np
 import torch
 
 num_frames = 16
 video = list(np.random.randn(16, 3, 224, 224))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MaRiOrOsSi_t5-base-finetuned-question-answering.py` & `mlagility-3.1.1/models/popular_on_huggingface/MaRiOrOsSi_t5-base-finetuned-question-answering.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::MaRiOrOsSi name::t5-base-finetuned-question-answering downloads::845 task::Text2Text_Generation
+# labels: test_group::monthly author::MaRiOrOsSi name::t5-base-finetuned-question-answering downloads::845 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from  transformers  import  AutoTokenizer, AutoModelWithLMHead, pipeline
 
 model_name = "MaRiOrOsSi/t5-base-finetuned-question-answering"
 tokenizer = AutoTokenizer.from_pretrained(model_name)
 model = AutoModelWithLMHead.from_pretrained(model_name)
 question = "What is 42?"
 context = "42 is the answer to life, the universe and everything"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MarcBrun_ixambert-finetuned-squad-eu-en.py` & `mlagility-3.1.1/models/popular_on_huggingface/MarcBrun_ixambert-finetuned-squad-eu-en.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::MarcBrun name::ixambert-finetuned-squad-eu-en downloads::886 task::Question_Answering
+# labels: test_group::monthly author::MarcBrun name::ixambert-finetuned-squad-eu-en downloads::886 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
 
 model_name = "MarcBrun/ixambert-finetuned-squad-eu-en"
 
 # To get predictions
 context = "Florence Nightingale, known for being the founder of modern nursing, was born in Florence, Italy, in 1820"
 question = "When was Florence Nightingale born?"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Michau_t5-base-en-generate-headline.py` & `mlagility-3.1.1/models/popular_on_huggingface/Michau_t5-base-en-generate-headline.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Michau name::t5-base-en-generate-headline downloads::34,355 task::Text2Text_Generation
+# labels: test_group::monthly author::Michau name::t5-base-en-generate-headline downloads::34,355 task::Natural_Language_Processing sub_task::Text2Text_Generation
 import torch
 from transformers import T5ForConditionalGeneration,T5Tokenizer
 
 device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
 
 model = T5ForConditionalGeneration.from_pretrained("Michau/t5-base-en-generate-headline")
 tokenizer = T5Tokenizer.from_pretrained("Michau/t5-base-en-generate-headline")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-base-mnli-fever-anli.py` & `mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-base-mnli-fever-anli.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::MoritzLaurer name::DeBERTa-v3-base-mnli-fever-anli downloads::4,615 license::mit task::Zero-Shot_Classification
+# labels: test_group::monthly author::MoritzLaurer name::DeBERTa-v3-base-mnli-fever-anli downloads::4,615 license::mit task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import pipeline
 classifier = pipeline("zero-shot-classification", model="MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli")
 sequence_to_classify = "Angela Merkel is a politician in Germany and leader of the CDU"
 candidate_labels = ["politics", "economy", "entertainment", "environment"]
 output = classifier(sequence_to_classify, candidate_labels, multi_label=False)
 print(output)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-base-mnli-fever-docnli-ling-2c.py` & `mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-base-mnli-fever-docnli-ling-2c.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::MoritzLaurer name::DeBERTa-v3-base-mnli-fever-docnli-ling-2c downloads::2,891 license::mit task::Text_Classification
+# labels: test_group::monthly author::MoritzLaurer name::DeBERTa-v3-base-mnli-fever-docnli-ling-2c downloads::2,891 license::mit task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 classifier = pipeline("zero-shot-classification", model="MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c")
 sequence_to_classify = "Angela Merkel is a politician in Germany and leader of the CDU"
 candidate_labels = ["politics", "economy", "entertainment", "environment"]
 output = classifier(sequence_to_classify, candidate_labels, multi_label=False)
 print(output)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-large-mnli-fever-anli-ling-wanli.py` & `mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-large-mnli-fever-anli-ling-wanli.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::MoritzLaurer name::DeBERTa-v3-large-mnli-fever-anli-ling-wanli downloads::5,584 license::mit task::Zero-Shot_Classification
+# labels: test_group::monthly author::MoritzLaurer name::DeBERTa-v3-large-mnli-fever-anli-ling-wanli downloads::5,584 license::mit task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import pipeline
 classifier = pipeline("zero-shot-classification", model="MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli")
 sequence_to_classify = "Angela Merkel is a politician in Germany and leader of the CDU"
 candidate_labels = ["politics", "economy", "entertainment", "environment"]
 output = classifier(sequence_to_classify, candidate_labels, multi_label=False)
 print(output)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary.py` & `mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::MoritzLaurer name::DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary downloads::2,595 license::mit task::Zero-Shot_Classification
+# labels: test_group::monthly author::MoritzLaurer name::DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary downloads::2,595 license::mit task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 import torch
 device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
 
 model_name = "MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary"
 tokenizer = AutoTokenizer.from_pretrained(model_name)
 model = AutoModelForSequenceClassification.from_pretrained(model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_mDeBERTa-v3-base-mnli-xnli.py` & `mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_mDeBERTa-v3-base-mnli-xnli.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::MoritzLaurer name::mDeBERTa-v3-base-mnli-xnli downloads::9,503 license::mit task::Zero-Shot_Classification
+# labels: test_group::monthly author::MoritzLaurer name::mDeBERTa-v3-base-mnli-xnli downloads::9,503 license::mit task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import pipeline
 classifier = pipeline("zero-shot-classification", model="MoritzLaurer/mDeBERTa-v3-base-mnli-xnli")
 
 sequence_to_classify = "Angela Merkel ist eine Politikerin in Deutschland und Vorsitzende der CDU"
 candidate_labels = ["politics", "economy", "entertainment", "environment"]
 output = classifier(sequence_to_classify, candidate_labels, multi_label=False)
 print(output)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.py` & `mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::MoritzLaurer name::mDeBERTa-v3-base-xnli-multilingual-nli-2mil7 downloads::2,386 license::mit task::Zero-Shot_Classification
+# labels: test_group::monthly author::MoritzLaurer name::mDeBERTa-v3-base-xnli-multilingual-nli-2mil7 downloads::2,386 license::mit task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import pipeline
 classifier = pipeline("zero-shot-classification", model="MoritzLaurer/mDeBERTa-v3-base-mnli-xnli")
 sequence_to_classify = "Angela Merkel ist eine Politikerin in Deutschland und Vorsitzende der CDU"
 candidate_labels = ["politics", "economy", "entertainment", "environment"]
 output = classifier(sequence_to_classify, candidate_labels, multi_label=False)
 print(output)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/MoritzLaurer_policy-distilbert-7d.py` & `mlagility-3.1.1/models/popular_on_huggingface/MoritzLaurer_policy-distilbert-7d.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::MoritzLaurer name::policy-distilbert-7d downloads::188 task::Text_Classification
+# labels: test_group::monthly author::MoritzLaurer name::policy-distilbert-7d downloads::188 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 import torch
 
 model_name = "MoritzLaurer/policy-distilbert-7d"
 tokenizer = AutoTokenizer.from_pretrained(model_name)
 model = AutoModelForSequenceClassification.from_pretrained(model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Narrativa_bsc_roberta2roberta_shared-spanish-finetuned-mlsum-summarization.py` & `mlagility-3.1.1/models/popular_on_huggingface/Narrativa_bsc_roberta2roberta_shared-spanish-finetuned-mlsum-summarization.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Narrativa name::bsc_roberta2roberta_shared-spanish-finetuned-mlsum-summarization downloads::313 task::Summarization
+# labels: test_group::monthly author::Narrativa name::bsc_roberta2roberta_shared-spanish-finetuned-mlsum-summarization downloads::313 task::Natural_Language_Processing sub_task::Summarization
 import torch
 from transformers import RobertaTokenizerFast, EncoderDecoderModel
 device = 'cuda' if torch.cuda.is_available() else 'cpu'
 ckpt = 'Narrativa/bsc_roberta2roberta_shared-spanish-finetuned-mlsum-summarization'
 tokenizer = RobertaTokenizerFast.from_pretrained(ckpt)
 model = EncoderDecoderModel.from_pretrained(ckpt).to(device)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/NbAiLab_nb-bert-base-ner.py` & `mlagility-3.1.1/models/popular_on_huggingface/NbAiLab_nb-bert-base-ner.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::NbAiLab name::nb-bert-base-ner downloads::188 license::cc-by-4.0 task::Token_Classification
+# labels: test_group::monthly author::NbAiLab name::nb-bert-base-ner downloads::188 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
 
 tokenizer = AutoTokenizer.from_pretrained("NbAiLab/nb-bert-base-ner")
 model = AutoModelForTokenClassification.from_pretrained("NbAiLab/nb-bert-base-ner")
 
 nlp = pipeline("ner", model=model, tokenizer=tokenizer)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/NeuML_bert-small-cord19qa.py` & `mlagility-3.1.1/models/popular_on_huggingface/NeuML_bert-small-cord19qa.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::NeuML name::bert-small-cord19qa downloads::491 task::Question_Answering
+# labels: test_group::monthly author::NeuML name::bert-small-cord19qa downloads::491 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 qa = pipeline(
     "question-answering",
     model="NeuML/bert-small-cord19qa",
     tokenizer="NeuML/bert-small-cord19qa"
 )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/NlpHUST_gpt2-vietnamese.py` & `mlagility-3.1.1/models/popular_on_huggingface/NlpHUST_gpt2-vietnamese.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::NlpHUST name::gpt2-vietnamese downloads::775 task::Text_Generation
+# labels: test_group::monthly author::NlpHUST name::gpt2-vietnamese downloads::775 task::Natural_Language_Processing sub_task::Text_Generation
 import torch
 from transformers import GPT2Tokenizer, GPT2LMHeadModel
 
 tokenizer = GPT2Tokenizer.from_pretrained('NlpHUST/gpt2-vietnamese')
 model = GPT2LMHeadModel.from_pretrained('NlpHUST/gpt2-vietnamese')
 
 text = "Vit Nam l quc gia c"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/NlpHUST_t5-en-vi-small.py` & `mlagility-3.1.1/models/popular_on_huggingface/NlpHUST_t5-en-vi-small.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::NlpHUST name::t5-en-vi-small downloads::874 task::Text2Text_Generation
+# labels: test_group::monthly author::NlpHUST name::t5-en-vi-small downloads::874 task::Natural_Language_Processing sub_task::Text2Text_Generation
 import torch
 
 from transformers import T5ForConditionalGeneration, T5Tokenizer
 import torch
 if torch.cuda.is_available():       
     device = torch.device("cuda")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Preetiha_clause_classification.py` & `mlagility-3.1.1/models/popular_on_huggingface/Preetiha_clause_classification.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Preetiha name::clause_classification downloads::264 task::Text_Classification
+# labels: test_group::monthly author::Preetiha name::clause_classification downloads::264 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification, AutoTokenizer
 
 model = AutoModelForSequenceClassification.from_pretrained("Preetiha/autotrain-clause-classification-812025458", use_auth_token=True)
 
 tokenizer = AutoTokenizer.from_pretrained("Preetiha/autotrain-clause-classification-812025458", use_auth_token=True)
 
 inputs = tokenizer("I love AutoTrain", return_tensors="pt")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Recognai_bert-base-spanish-wwm-cased-xnli.py` & `mlagility-3.1.1/models/popular_on_huggingface/Recognai_bert-base-spanish-wwm-cased-xnli.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Recognai name::bert-base-spanish-wwm-cased-xnli downloads::9,931 license::mit task::Zero-Shot_Classification
+# labels: test_group::monthly author::Recognai name::bert-base-spanish-wwm-cased-xnli downloads::9,931 license::mit task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import pipeline
 classifier = pipeline("zero-shot-classification", 
                        model="Recognai/bert-base-spanish-wwm-cased-xnli")
 
 classifier(
     "El autor se perfila, a los 50 aos de su muerte, como uno de los grandes de su siglo",
     candidate_labels=["cultura", "sociedad", "economia", "salud", "deportes"],
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Recognai_zeroshot_selectra_medium.py` & `mlagility-3.1.1/models/popular_on_huggingface/Recognai_zeroshot_selectra_medium.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Recognai name::zeroshot_selectra_medium downloads::716 license::apache-2.0 task::Zero-Shot_Classification
+# labels: test_group::monthly author::Recognai name::zeroshot_selectra_medium downloads::716 license::apache-2.0 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import pipeline
 classifier = pipeline("zero-shot-classification", 
                        model="Recognai/zeroshot_selectra_medium")
 
 classifier(
     "El autor se perfila, a los 50 aos de su muerte, como uno de los grandes de su siglo",
     candidate_labels=["cultura", "sociedad", "economia", "salud", "deportes"],
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Rostlab_prot_t5_xl_bfd.py` & `mlagility-3.1.1/models/popular_on_huggingface/Rostlab_prot_t5_xl_bfd.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Rostlab name::prot_t5_xl_bfd downloads::7,057 task::Text2Text_Generation
+# labels: test_group::monthly author::Rostlab name::prot_t5_xl_bfd downloads::7,057 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5Tokenizer, T5Model
 import re
 import torch
 
 tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_bfd', do_lower_case=False)
 
 model = T5Model.from_pretrained("Rostlab/prot_t5_xl_bfd")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Rostlab_prot_t5_xl_uniref50.py` & `mlagility-3.1.1/models/popular_on_huggingface/Rostlab_prot_t5_xl_uniref50.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Rostlab name::prot_t5_xl_uniref50 downloads::26,060 task::Text2Text_Generation
+# labels: test_group::monthly author::Rostlab name::prot_t5_xl_uniref50 downloads::26,060 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5Tokenizer, T5Model
 import re
 import torch
 
 tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_uniref50', do_lower_case=False)
 
 model = T5Model.from_pretrained("Rostlab/prot_t5_xl_uniref50")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Sahajtomar_German_Zeroshot.py` & `mlagility-3.1.1/models/popular_on_huggingface/Sahajtomar_German_Zeroshot.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Sahajtomar name::German_Zeroshot downloads::20,169 task::Zero-Shot_Classification
+# labels: test_group::monthly author::Sahajtomar name::German_Zeroshot downloads::20,169 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import pipeline
 classifier = pipeline("zero-shot-classification",
                       model="Sahajtomar/German_Zeroshot")
 sequence = "Letzte Woche gab es einen Selbstmord in einer nahe gelegenen kolonie"
 candidate_labels = ["Verbrechen","Tragdie","Stehlen"]
 hypothesis_template = "In deisem geht es um {}."    ## Since monolingual model,its sensitive to hypothesis template. This can be experimented
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-2B-mono.py` & `mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-2B-multi.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::monthly author::Salesforce name::codegen-2B-mono downloads::8,941 license::bsd-3-clause task::Text_Generation
+# labels: test_group::monthly author::Salesforce name::codegen-2B-multi downloads::5,712 license::bsd-3-clause task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelForCausalLM
-tokenizer = AutoTokenizer.from_pretrained("Salesforce/codegen-2B-mono")
-model = AutoModelForCausalLM.from_pretrained("Salesforce/codegen-2B-mono")
+tokenizer = AutoTokenizer.from_pretrained("Salesforce/codegen-2B-multi")
+model = AutoModelForCausalLM.from_pretrained("Salesforce/codegen-2B-multi")
 
 text = "def hello_world():"
 input_ids = tokenizer(text, return_tensors="pt").input_ids
 
 generated_ids = model.generate(input_ids, max_length=128)
 print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-2B-multi.py` & `mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-6B-multi.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::monthly author::Salesforce name::codegen-2B-multi downloads::5,712 license::bsd-3-clause task::Text_Generation
+# labels: test_group::monthly author::Salesforce name::codegen-6B-multi downloads::7,048 license::bsd-3-clause task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelForCausalLM
-tokenizer = AutoTokenizer.from_pretrained("Salesforce/codegen-2B-multi")
-model = AutoModelForCausalLM.from_pretrained("Salesforce/codegen-2B-multi")
+tokenizer = AutoTokenizer.from_pretrained("Salesforce/codegen-6B-multi")
+model = AutoModelForCausalLM.from_pretrained("Salesforce/codegen-6B-multi")
 
 text = "def hello_world():"
 input_ids = tokenizer(text, return_tensors="pt").input_ids
 
 generated_ids = model.generate(input_ids, max_length=128)
 print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-350M-mono.py` & `mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-350M-multi.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::monthly author::Salesforce name::codegen-350M-mono downloads::20,252 license::bsd-3-clause task::Text_Generation
+# labels: test_group::monthly author::Salesforce name::codegen-350M-multi downloads::13,205 license::bsd-3-clause task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelForCausalLM
-tokenizer = AutoTokenizer.from_pretrained("Salesforce/codegen-350M-mono")
-model = AutoModelForCausalLM.from_pretrained("Salesforce/codegen-350M-mono")
+tokenizer = AutoTokenizer.from_pretrained("Salesforce/codegen-350M-multi")
+model = AutoModelForCausalLM.from_pretrained("Salesforce/codegen-350M-multi")
 
 text = "def hello_world():"
 input_ids = tokenizer(text, return_tensors="pt").input_ids
 
 generated_ids = model.generate(input_ids, max_length=128)
 print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-350M-multi.py` & `mlagility-3.1.1/models/popular_on_huggingface/model-attribution-challenge_codegen-350M-multi.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Salesforce name::codegen-350M-multi downloads::13,205 license::bsd-3-clause task::Text_Generation
+# labels: test_group::monthly author::model-attribution-challenge name::codegen-350M-multi downloads::500 license::bsd-3-clause task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelForCausalLM
 tokenizer = AutoTokenizer.from_pretrained("Salesforce/codegen-350M-multi")
 model = AutoModelForCausalLM.from_pretrained("Salesforce/codegen-350M-multi")
 
 text = "def hello_world():"
 input_ids = tokenizer(text, return_tensors="pt").input_ids
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-350M-nl.py` & `mlagility-3.1.1/models/popular_on_huggingface/TristanBehrens_js-fakes-4bars.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,12 @@
-# labels: test_group::monthly author::Salesforce name::codegen-350M-nl downloads::364 license::bsd-3-clause task::Text_Generation
+# labels: test_group::monthly author::TristanBehrens name::js-fakes-4bars downloads::199 task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelForCausalLM
-tokenizer = AutoTokenizer.from_pretrained("Salesforce/codegen-350M-nl")
-model = AutoModelForCausalLM.from_pretrained("Salesforce/codegen-350M-nl")
 
-text = "def hello_world():"
-input_ids = tokenizer(text, return_tensors="pt").input_ids
-generated_ids = model.generate(input_ids, max_length=128)
-print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))
+tokenizer = AutoTokenizer.from_pretrained("TristanBehrens/js-fakes-4bars")
+model = AutoModelForCausalLM.from_pretrained("TristanBehrens/js-fakes-4bars")
+
+input_ids = tokenizer.encode("PIECE_START", return_tensors="pt")
+print(input_ids)
+
+generated_ids = model.generate(input_ids, max_length=500)
+generated_sequence = tokenizer.decode(generated_ids[0])
+print(generated_sequence)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codegen-6B-multi.py` & `mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codegen-6B-mono.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::monthly author::Salesforce name::codegen-6B-multi downloads::7,048 license::bsd-3-clause task::Text_Generation
+# labels: test_group::monthly author::Salesforce name::codegen-6B-mono downloads::7,274 license::bsd-3-clause task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelForCausalLM
-tokenizer = AutoTokenizer.from_pretrained("Salesforce/codegen-6B-multi")
-model = AutoModelForCausalLM.from_pretrained("Salesforce/codegen-6B-multi")
+tokenizer = AutoTokenizer.from_pretrained("Salesforce/codegen-6B-mono")
+model = AutoModelForCausalLM.from_pretrained("Salesforce/codegen-6B-mono")
 
 text = "def hello_world():"
 input_ids = tokenizer(text, return_tensors="pt").input_ids
 
 generated_ids = model.generate(input_ids, max_length=128)
 print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codet5-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codet5-base.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Salesforce name::codet5-base downloads::14,381 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::Salesforce name::codet5-base downloads::14,381 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import RobertaTokenizer, T5ForConditionalGeneration
 
 tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')
 model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base')
 
 text = "def greet(user): print(f'hello <extra_id_0>!')"
 input_ids = tokenizer(text, return_tensors="pt").input_ids
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codet5-large-ntp-py.py` & `mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codet5-large.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::monthly author::Salesforce name::codet5-large-ntp-py downloads::462 license::bsd-3-clause task::Text2Text_Generation
+# labels: test_group::monthly author::Salesforce name::codet5-large downloads::18,952 license::bsd-3-clause task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, T5ForConditionalGeneration
-tokenizer = AutoTokenizer.from_pretrained("Salesforce/codet5-large-ntp-py")
-model = T5ForConditionalGeneration.from_pretrained("Salesforce/codet5-large-ntp-py")
-text = "def hello_world():"
+tokenizer = AutoTokenizer.from_pretrained("Salesforce/codet5-large")
+model = T5ForConditionalGeneration.from_pretrained("Salesforce/codet5-large")
+text = "def greet(user): print(f'hello <extra_id_0>!')"
 input_ids = tokenizer(text, return_tensors="pt").input_ids
 
 # simply generate a single sequence
-generated_ids = model.generate(input_ids, max_length=128)
+generated_ids = model.generate(input_ids, max_length=8)
 print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codet5-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codet5-large-ntp-py.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::monthly author::Salesforce name::codet5-large downloads::18,952 license::bsd-3-clause task::Text2Text_Generation
+# labels: test_group::monthly author::Salesforce name::codet5-large-ntp-py downloads::462 license::bsd-3-clause task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, T5ForConditionalGeneration
-tokenizer = AutoTokenizer.from_pretrained("Salesforce/codet5-large")
-model = T5ForConditionalGeneration.from_pretrained("Salesforce/codet5-large")
-text = "def greet(user): print(f'hello <extra_id_0>!')"
+tokenizer = AutoTokenizer.from_pretrained("Salesforce/codet5-large-ntp-py")
+model = T5ForConditionalGeneration.from_pretrained("Salesforce/codet5-large-ntp-py")
+text = "def hello_world():"
 input_ids = tokenizer(text, return_tensors="pt").input_ids
 
 # simply generate a single sequence
-generated_ids = model.generate(input_ids, max_length=8)
+generated_ids = model.generate(input_ids, max_length=128)
 print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_codet5-small.py` & `mlagility-3.1.1/models/popular_on_huggingface/Salesforce_codet5-small.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Salesforce name::codet5-small downloads::19,456 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::Salesforce name::codet5-small downloads::19,456 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import RobertaTokenizer, T5ForConditionalGeneration
 
 tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')
 model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-small')
 
 text = "def greet(user): print(f'hello <extra_id_0>!')"
 input_ids = tokenizer(text, return_tensors="pt").input_ids
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Salesforce_mixqg-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/Salesforce_mixqg-base.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Salesforce name::mixqg-base downloads::920 task::Text2Text_Generation
+# labels: test_group::monthly author::Salesforce name::mixqg-base downloads::920 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import pipeline
 
 nlp = pipeline("text2text-generation", model='Salesforce/mixqg-base', tokenizer='Salesforce/mixqg-base')
     
 CONTEXT = "In the late 17th century, Robert Boyle proved that air is necessary for combustion."
 ANSWER = "Robert Boyle"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Sehong_t5-large-QuestionGeneration.py` & `mlagility-3.1.1/models/popular_on_huggingface/Sehong_t5-large-QuestionGeneration.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Sehong name::t5-large-QuestionGeneration downloads::405 license::mit task::Text2Text_Generation
+# labels: test_group::monthly author::Sehong name::t5-large-QuestionGeneration downloads::405 license::mit task::Natural_Language_Processing sub_task::Text2Text_Generation
 import torch
 from transformers import PreTrainedTokenizerFast
 from transformers import T5ForConditionalGeneration
 
 tokenizer = PreTrainedTokenizerFast.from_pretrained('Sehong/t5-large-QuestionGeneration')
 model = T5ForConditionalGeneration.from_pretrained('Sehong/t5-large-QuestionGeneration')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/SenseTime_deformable-detr.py` & `mlagility-3.1.1/models/popular_on_huggingface/SenseTime_deformable-detr.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::SenseTime name::deformable-detr downloads::719 license::apache-2.0 task::Object_Detection
+# labels: test_group::monthly author::SenseTime name::deformable-detr downloads::719 license::apache-2.0 task::Computer_Vision sub_task::Object_Detection
 from transformers import AutoFeatureExtractor, DeformableDetrForObjectDetection
 import torch
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Sentdex_GPyT.py` & `mlagility-3.1.1/models/popular_on_huggingface/Sentdex_GPyT.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Sentdex name::GPyT downloads::249 license::mit task::Text_Generation
+# labels: test_group::monthly author::Sentdex name::GPyT downloads::249 license::mit task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelWithLMHead
 
 tokenizer = AutoTokenizer.from_pretrained("Sentdex/GPyT")
 model = AutoModelWithLMHead.from_pretrained("Sentdex/GPyT")
 
 # copy and paste some code in here
 inp = """import"""
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Seznam_small-e-czech.py` & `mlagility-3.1.1/models/popular_on_huggingface/Seznam_small-e-czech.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Seznam name::small-e-czech task::unknown downloads::8,270 license::cc-by-4.0
+# labels: test_group::monthly author::Seznam name::small-e-czech task::Natural_Language_Processing downloads::8,270 license::cc-by-4.0
 from transformers import ElectraForPreTraining, ElectraTokenizerFast
 import torch
 
 discriminator = ElectraForPreTraining.from_pretrained("Seznam/small-e-czech")
 tokenizer = ElectraTokenizerFast.from_pretrained("Seznam/small-e-czech")
 
 sentence = "Za hory, za doly, m zlat parohy"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/SkolkovoInstitute_roberta_toxicity_classifier.py` & `mlagility-3.1.1/models/popular_on_huggingface/SkolkovoInstitute_roberta_toxicity_classifier.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::SkolkovoInstitute name::roberta_toxicity_classifier downloads::15,220 task::Text_Classification
+# labels: test_group::monthly author::SkolkovoInstitute name::roberta_toxicity_classifier downloads::15,220 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import RobertaTokenizer, RobertaForSequenceClassification
 
 # load tokenizer and model weights
 tokenizer = RobertaTokenizer.from_pretrained('SkolkovoInstitute/roberta_toxicity_classifier')
 model = RobertaForSequenceClassification.from_pretrained('SkolkovoInstitute/roberta_toxicity_classifier')
 
 # prepare the input
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/SkolkovoInstitute_russian_toxicity_classifier.py` & `mlagility-3.1.1/models/popular_on_huggingface/SkolkovoInstitute_russian_toxicity_classifier.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::SkolkovoInstitute name::russian_toxicity_classifier downloads::4,336 task::Text_Classification
+# labels: test_group::monthly author::SkolkovoInstitute name::russian_toxicity_classifier downloads::4,336 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import BertTokenizer, BertForSequenceClassification
 
 # load tokenizer and model weights
 tokenizer = BertTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')
 model = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')
 
 # prepare the input
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/UBC-NLP_AraT5-base-title-generation.py` & `mlagility-3.1.1/models/popular_on_huggingface/UBC-NLP_AraT5-base-title-generation.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::UBC-NLP name::AraT5-base-title-generation downloads::387 task::Text2Text_Generation
+# labels: test_group::monthly author::UBC-NLP name::AraT5-base-title-generation downloads::387 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 tokenizer = AutoTokenizer.from_pretrained("UBC-NLP/AraT5-base-title-generation")  
 model = AutoModelForSeq2SeqLM.from_pretrained("UBC-NLP/AraT5-base-title-generation")
 
 Document = "                              2019   6   .                     ."
 
 encoding = tokenizer.encode_plus(Document,pad_to_max_length=True, return_tensors="pt")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Unbabel_gec-t5_small.py` & `mlagility-3.1.1/models/popular_on_huggingface/Unbabel_gec-t5_small.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Unbabel name::gec-t5_small downloads::389 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::Unbabel name::gec-t5_small downloads::389 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5ForConditionalGeneration, T5Tokenizer
 
 model = T5ForConditionalGeneration.from_pretrained("Unbabel/gec-t5_small")
 tokenizer = T5Tokenizer.from_pretrained('t5-small')
 
 sentence = "I like to swimming"
 tokenized_sentence = tokenizer('gec: ' + sentence, max_length=128, truncation=True, padding='max_length', return_tensors='pt')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Visual-Attention-Network_van-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/Visual-Attention-Network_van-base.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Visual-Attention-Network name::van-base downloads::621 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly author::Visual-Attention-Network name::van-base downloads::621 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, VanForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Visual-Attention-Network_van-tiny.py` & `mlagility-3.1.1/models/popular_on_huggingface/Visual-Attention-Network_van-tiny.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Visual-Attention-Network name::van-tiny downloads::305 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly author::Visual-Attention-Network name::van-tiny downloads::305 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, VanForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/Wikidepia_IndoT5-base-paraphrase.py` & `mlagility-3.1.1/models/popular_on_huggingface/Wikidepia_IndoT5-base-paraphrase.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::Wikidepia name::IndoT5-base-paraphrase downloads::2,254 task::Text2Text_Generation
+# labels: test_group::monthly author::Wikidepia name::IndoT5-base-paraphrase downloads::2,254 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 tokenizer = AutoTokenizer.from_pretrained("Wikidepia/IndoT5-base-paraphrase")  
 model = AutoModelForSeq2SeqLM.from_pretrained("Wikidepia/IndoT5-base-paraphrase")
 
 sentence = "Anak anak melakukan piket kelas agar kebersihan kelas terjaga"
 text =  "paraphrase: " + sentence + " </s>"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/abhishek_autonlp-bbc-news-classification-37229289.py` & `mlagility-3.1.1/models/popular_on_huggingface/madhurjindal_autonlp-Gibberish-Detector-492513457.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::monthly author::abhishek name::autonlp-bbc-news-classification-37229289 downloads::524 task::Text_Classification
+# labels: test_group::monthly author::madhurjindal name::autonlp-Gibberish-Detector-492513457 downloads::11,891 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification, AutoTokenizer
 
-model = AutoModelForSequenceClassification.from_pretrained("abhishek/autonlp-bbc-news-classification-37229289", use_auth_token=True)
+model = AutoModelForSequenceClassification.from_pretrained("madhurjindal/autonlp-Gibberish-Detector-492513457", use_auth_token=True)
 
-tokenizer = AutoTokenizer.from_pretrained("abhishek/autonlp-bbc-news-classification-37229289", use_auth_token=True)
+tokenizer = AutoTokenizer.from_pretrained("madhurjindal/autonlp-Gibberish-Detector-492513457", use_auth_token=True)
 
 inputs = tokenizer("I love AutoNLP", return_tensors="pt")
 
 outputs = model(**inputs)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ahmedrachid_FinancialBERT-Sentiment-Analysis.py` & `mlagility-3.1.1/models/popular_on_huggingface/ahmedrachid_FinancialBERT-Sentiment-Analysis.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ahmedrachid name::FinancialBERT-Sentiment-Analysis downloads::3,689 task::Text_Classification
+# labels: test_group::monthly author::ahmedrachid name::FinancialBERT-Sentiment-Analysis downloads::3,689 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import BertTokenizer, BertForSequenceClassification
 from transformers import pipeline
 
 model = BertForSequenceClassification.from_pretrained("ahmedrachid/FinancialBERT-Sentiment-Analysis",num_labels=3)
 tokenizer = BertTokenizer.from_pretrained("ahmedrachid/FinancialBERT-Sentiment-Analysis")
 
 nlp = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ai4bharat_IndicBART.py` & `mlagility-3.1.1/models/popular_on_huggingface/ai4bharat_IndicBART.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ai4bharat name::IndicBART downloads::6,777 task::Text2Text_Generation
+# labels: test_group::monthly author::ai4bharat name::IndicBART downloads::6,777 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import MBartForConditionalGeneration, AutoModelForSeq2SeqLM
 from transformers import AlbertTokenizer, AutoTokenizer
 
 tokenizer = AutoTokenizer.from_pretrained("ai4bharat/IndicBART", do_lower_case=False, use_fast=False, keep_accents=True)
 
 # Or use tokenizer = AlbertTokenizer.from_pretrained("ai4bharat/IndicBART", do_lower_case=False, use_fast=False, keep_accents=True)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ai4bharat_IndicBARTSS.py` & `mlagility-3.1.1/models/popular_on_huggingface/ai4bharat_IndicBARTSS.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ai4bharat name::IndicBARTSS downloads::3,651 task::Text2Text_Generation
+# labels: test_group::monthly author::ai4bharat name::IndicBARTSS downloads::3,651 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import MBartForConditionalGeneration, AutoModelForSeq2SeqLM
 from transformers import AlbertTokenizer, AutoTokenizer
 
 tokenizer = AutoTokenizer.from_pretrained("ai4bharat/IndicBARTSS", do_lower_case=False, use_fast=False, keep_accents=True)
 
 # Or use tokenizer = AlbertTokenizer.from_pretrained("ai4bharat/IndicBARTSS", do_lower_case=False, use_fast=False, keep_accents=True)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/allegro_herbert-base-cased.py` & `mlagility-3.1.1/models/popular_on_huggingface/allegro_herbert-base-cased.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::allegro name::herbert-base-cased downloads::16,580 license::cc-by-4.0 task::Feature_Extraction
+# labels: test_group::monthly author::allegro name::herbert-base-cased downloads::16,580 license::cc-by-4.0 task::Multimodal sub_task::Feature_Extraction
 from transformers import AutoTokenizer, AutoModel
 
 tokenizer = AutoTokenizer.from_pretrained("allegro/herbert-base-cased")
 model = AutoModel.from_pretrained("allegro/herbert-base-cased")
 
 output = model(
     **tokenizer.batch_encode_plus(
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/allegro_herbert-large-cased.py` & `mlagility-3.1.1/models/popular_on_huggingface/allegro_herbert-large-cased.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::allegro name::herbert-large-cased downloads::2,004 license::cc-by-4.0 task::Feature_Extraction
+# labels: test_group::monthly author::allegro name::herbert-large-cased downloads::2,004 license::cc-by-4.0 task::Multimodal sub_task::Feature_Extraction
 from transformers import AutoTokenizer, AutoModel
 
 tokenizer = AutoTokenizer.from_pretrained("allegro/herbert-large-cased")
 model = AutoModel.from_pretrained("allegro/herbert-large-cased")
 
 output = model(
     **tokenizer.batch_encode_plus(
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/allenai_t5-small-next-word-generator-qoogle.py` & `mlagility-3.1.1/models/popular_on_huggingface/allenai_t5-small-next-word-generator-qoogle.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::allenai name::t5-small-next-word-generator-qoogle downloads::216 task::Text2Text_Generation
+# labels: test_group::monthly author::allenai name::t5-small-next-word-generator-qoogle downloads::216 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5Config, T5ForConditionalGeneration, T5Tokenizer
 
 model_name = "allenai/t5-small-next-word-generator-qoogle"
 tokenizer = T5Tokenizer.from_pretrained(model_name)
 model = T5ForConditionalGeneration.from_pretrained(model_name)
 
 def run_model(input_string, **generator_args):
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/allenai_t5-small-squad2-question-generation.py` & `mlagility-3.1.1/models/popular_on_huggingface/allenai_t5-small-squad2-question-generation.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::allenai name::t5-small-squad2-question-generation downloads::1,532 task::Text2Text_Generation
+# labels: test_group::monthly author::allenai name::t5-small-squad2-question-generation downloads::1,532 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5Config, T5ForConditionalGeneration, T5Tokenizer
 
 model_name = "allenai/t5-small-squad2-question-generation"
 tokenizer = T5Tokenizer.from_pretrained(model_name)
 model = T5ForConditionalGeneration.from_pretrained(model_name)
 
 def run_model(input_string, **generator_args):
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/aneuraz_awesome-align-with-co.py` & `mlagility-3.1.1/models/popular_on_huggingface/aneuraz_awesome-align-with-co.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::aneuraz name::awesome-align-with-co downloads::290 license::bsd-3-clause task::Fill-Mask
+# labels: test_group::monthly author::aneuraz name::awesome-align-with-co downloads::290 license::bsd-3-clause task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import AutoModel, AutoTokenizer
 import itertools
 import torch
 
 # load model
 model = AutoModel.from_pretrained("aneuraz/awesome-align-with-co")
 tokenizer = AutoTokenizer.from_pretrained("aneuraz/awesome-align-with-co")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/apple_deeplabv3-mobilevit-small.py` & `mlagility-3.1.1/models/popular_on_huggingface/apple_deeplabv3-mobilevit-small.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::apple name::deeplabv3-mobilevit-small downloads::623 license::other task::Image_Segmentation
+# labels: test_group::monthly,daily author::apple name::deeplabv3-mobilevit-small downloads::623 license::other task::Computer_Vision sub_task::Image_Segmentation
 from transformers import MobileViTFeatureExtractor, MobileViTForSemanticSegmentation
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/apple_deeplabv3-mobilevit-xx-small.py` & `mlagility-3.1.1/models/popular_on_huggingface/apple_deeplabv3-mobilevit-xx-small.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::apple name::deeplabv3-mobilevit-xx-small downloads::296 license::other task::Image_Segmentation
+# labels: test_group::monthly,daily author::apple name::deeplabv3-mobilevit-xx-small downloads::296 license::other task::Computer_Vision sub_task::Image_Segmentation
 from transformers import MobileViTFeatureExtractor, MobileViTForSemanticSegmentation
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/apple_mobilevit-small.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_mit-b2.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# labels: test_group::monthly,daily author::apple name::mobilevit-small downloads::2,156 license::other task::Image_Classification
-from transformers import MobileViTFeatureExtractor, MobileViTForImageClassification
+# labels: test_group::monthly author::nvidia name::mit-b2 downloads::50,931 license::other task::Computer_Vision sub_task::Image_Classification
+from transformers import SegformerFeatureExtractor, SegformerForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = MobileViTFeatureExtractor.from_pretrained("apple/mobilevit-small")
-model = MobileViTForImageClassification.from_pretrained("apple/mobilevit-small")
+feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/mit-b2")
+model = SegformerForImageClassification.from_pretrained("nvidia/mit-b2")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
-
 outputs = model(**inputs)
 logits = outputs.logits
-
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/apple_mobilevit-xx-small.py` & `mlagility-3.1.1/models/popular_on_huggingface/apple_mobilevit-small.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: test_group::monthly,daily author::apple name::mobilevit-xx-small downloads::347 license::other task::Image_Classification
+# labels: test_group::monthly,daily author::apple name::mobilevit-small downloads::2,156 license::other task::Computer_Vision sub_task::Image_Classification
 from transformers import MobileViTFeatureExtractor, MobileViTForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = MobileViTFeatureExtractor.from_pretrained("apple/mobilevit-xx-small")
-model = MobileViTForImageClassification.from_pretrained("apple/mobilevit-xx-small")
+feature_extractor = MobileViTFeatureExtractor.from_pretrained("apple/mobilevit-small")
+model = MobileViTForImageClassification.from_pretrained("apple/mobilevit-small")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 
 outputs = model(**inputs)
 logits = outputs.logits
 
 # model predicts one of the 1000 ImageNet classes
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/asi_gpt-fr-cased-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/asi_gpt-fr-cased-base.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::asi name::gpt-fr-cased-base downloads::638 license::apache-2.0 task::Text_Generation
+# labels: test_group::monthly author::asi name::gpt-fr-cased-base downloads::638 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import GPT2Tokenizer, GPT2LMHeadModel
 
 # Load pretrained model and tokenizer
 model = GPT2LMHeadModel.from_pretrained("asi/gpt-fr-cased-base")
 tokenizer = GPT2Tokenizer.from_pretrained("asi/gpt-fr-cased-base")
 
 # Generate a sample of text
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/assemblyai_bert-large-uncased-sst2.py` & `mlagility-3.1.1/models/popular_on_huggingface/assemblyai_bert-large-uncased-sst2.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::assemblyai name::bert-large-uncased-sst2 downloads::820 task::Text_Classification
+# labels: test_group::monthly author::assemblyai name::bert-large-uncased-sst2 downloads::820 task::Natural_Language_Processing sub_task::Text_Classification
 import torch.nn.functional as F 
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 tokenizer = AutoTokenizer.from_pretrained("assemblyai/bert-large-uncased-sst2") 
 model = AutoModelForSequenceClassification.from_pretrained("assemblyai/bert-large-uncased-sst2")
 
 tokenized_segments = tokenizer(["AssemblyAI is the best speech-to-text API for modern developers with performance being second to none!"], return_tensors="pt", padding=True, truncation=True)
 tokenized_segments_input_ids, tokenized_segments_attention_mask = tokenized_segments.input_ids, tokenized_segments.attention_mask
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/aubmindlab_araelectra-base-discriminator.py` & `mlagility-3.1.1/models/popular_on_huggingface/aubmindlab_araelectra-base-discriminator.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::aubmindlab name::araelectra-base-discriminator task::unknown downloads::1,266
+# labels: test_group::monthly author::aubmindlab name::araelectra-base-discriminator task::Natural_Language_Processing downloads::1,266
 from transformers import ElectraForPreTraining, ElectraTokenizerFast
 import torch
 
 discriminator = ElectraForPreTraining.from_pretrained("aubmindlab/araelectra-base-discriminator")
 tokenizer = ElectraTokenizerFast.from_pretrained("aubmindlab/araelectra-base-discriminator")
 
 sentence = ""
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/aware-ai_bart-squadv2.py` & `mlagility-3.1.1/models/popular_on_huggingface/aware-ai_bart-squadv2.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::aware-ai name::bart-squadv2 downloads::306 task::Question_Answering
+# labels: test_group::monthly author::aware-ai name::bart-squadv2 downloads::306 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import BartTokenizer, BartForQuestionAnswering
 import torch
 
 tokenizer = BartTokenizer.from_pretrained('a-ware/bart-squadv2')
 model = BartForQuestionAnswering.from_pretrained('a-ware/bart-squadv2')
 
 question, text = "Who was Jim Henson?", "Jim Henson was a nice puppet"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/azwierzc_herbert-large-poquad.py` & `mlagility-3.1.1/models/popular_on_huggingface/azwierzc_herbert-large-poquad.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::azwierzc name::herbert-large-poquad downloads::283 license::gpl-3.0 task::Question_Answering
+# labels: test_group::monthly author::azwierzc name::herbert-large-poquad downloads::283 license::gpl-3.0 task::Natural_Language_Processing sub_task::Question_Answering
 import transformers
 from transformers import pipeline
 
 question_answerer = pipeline("question-answering", model='azwierzc/herbert-large-poquad', handle_impossible_answer=True)
 
 context = "Pod koniec ycia Carducci, cho nadal budzi kontrowersje, by szanowanym autorytetem literackim i naukowym. Z okazji 35-lecia pracy profesorskiej zosta obdarowany gazk wawrzynu z drzewa rosncego przy grobie Dantego w Rawennie oraz ksig pamitkow zawierajc nazwiska wszystkich jego studentw. Kiedy ze wzgldu na hemiplegi musia w roku 1904 zaniecha prowadzenia wykadw, parlament przyzna mu  podobnie jak kiedy Alessandrowi Manzoniemu  doywotni emerytur. Katedr obj po nim Giovanni Pascoli. W roku 1906 Giosu Carducci zosta wyrniony Nagrod Nobla w dziedzinie literatury. Komitet Noblowski czu si w obowizku podkreli, e pogaskie motywy w jego wierszach wcale nie oznaczay odrzucenia chrzecijastwa, a jedynie krytyk bdnych posuni Kocioa. Schorowany Carducci nie zdoa pojecha do Sztokholmu, eby osobicie odebra nagrod, goci natomiast u siebie ambasadora Szwecji. Zmar na marsko wtroby dwa miesice pniej, 16 lutego 1907 roku. Jego mier upamitni wierszem Per la tomba di G. Carducci (Na grb G. Carducciego) Gabriele DAnnunzio, gwny przedstawiciel woskiego dekadentyzmu. Utwory Carducciego czsto inspiroway kompozytorw, ktrzy wykorzystywali je jako teksty swoich pieni (Alfredo Casella  Notte de maggio, Guido Alberto Fano  Vere novo, Stanislao Gastaldon  Viva il Re)."
 question = "Jakie wyrnienie otrzyma Carducci?"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/azwierzc_plt5-base-poquad.py` & `mlagility-3.1.1/models/popular_on_huggingface/azwierzc_plt5-base-poquad.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::azwierzc name::plt5-base-poquad downloads::283 license::gpl-3.0 task::Text2Text_Generation
+# labels: test_group::monthly author::azwierzc name::plt5-base-poquad downloads::283 license::gpl-3.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 import torch
 from transformers import AutoTokenizer, T5ForConditionalGeneration
 
 tokenizer = AutoTokenizer.from_pretrained("azwierzc/plt5-base-poquad")
 model = T5ForConditionalGeneration.from_pretrained("azwierzc/plt5-base-poquad")
 
 context = "Pod koniec ycia Carducci, cho nadal budzi kontrowersje, by szanowanym autorytetem literackim i naukowym. Z okazji 35-lecia pracy profesorskiej zosta obdarowany gazk wawrzynu z drzewa rosncego przy grobie Dantego w Rawennie oraz ksig pamitkow zawierajc nazwiska wszystkich jego studentw. Kiedy ze wzgldu na hemiplegi musia w roku 1904 zaniecha prowadzenia wykadw, parlament przyzna mu  podobnie jak kiedy Alessandrowi Manzoniemu  doywotni emerytur. Katedr obj po nim Giovanni Pascoli. W roku 1906 Giosu Carducci zosta wyrniony Nagrod Nobla w dziedzinie literatury. Komitet Noblowski czu si w obowizku podkreli, e pogaskie motywy w jego wierszach wcale nie oznaczay odrzucenia chrzecijastwa, a jedynie krytyk bdnych posuni Kocioa. Schorowany Carducci nie zdoa pojecha do Sztokholmu, eby osobicie odebra nagrod, goci natomiast u siebie ambasadora Szwecji. Zmar na marsko wtroby dwa miesice pniej, 16 lutego 1907 roku. Jego mier upamitni wierszem Per la tomba di G. Carducci (Na grb G. Carducciego) Gabriele DAnnunzio, gwny przedstawiciel woskiego dekadentyzmu. Utwory Carducciego czsto inspiroway kompozytorw, ktrzy wykorzystywali je jako teksty swoich pieni (Alfredo Casella  Notte de maggio, Guido Alberto Fano  Vere novo, Stanislao Gastaldon  Viva il Re)."
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/azwierzc_plt5-large-poquad.py` & `mlagility-3.1.1/models/popular_on_huggingface/azwierzc_plt5-large-poquad.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::azwierzc name::plt5-large-poquad downloads::207 license::gpl-3.0 task::Text2Text_Generation
+# labels: test_group::monthly author::azwierzc name::plt5-large-poquad downloads::207 license::gpl-3.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 import torch
 from transformers import AutoTokenizer, T5ForConditionalGeneration
 
 tokenizer = AutoTokenizer.from_pretrained("azwierzc/plt5-large-poquad")
 model = T5ForConditionalGeneration.from_pretrained("azwierzc/plt5-large-poquad")
 
 context = "Pod koniec ycia Carducci, cho nadal budzi kontrowersje, by szanowanym autorytetem literackim i naukowym. Z okazji 35-lecia pracy profesorskiej zosta obdarowany gazk wawrzynu z drzewa rosncego przy grobie Dantego w Rawennie oraz ksig pamitkow zawierajc nazwiska wszystkich jego studentw. Kiedy ze wzgldu na hemiplegi musia w roku 1904 zaniecha prowadzenia wykadw, parlament przyzna mu  podobnie jak kiedy Alessandrowi Manzoniemu  doywotni emerytur. Katedr obj po nim Giovanni Pascoli. W roku 1906 Giosu Carducci zosta wyrniony Nagrod Nobla w dziedzinie literatury. Komitet Noblowski czu si w obowizku podkreli, e pogaskie motywy w jego wierszach wcale nie oznaczay odrzucenia chrzecijastwa, a jedynie krytyk bdnych posuni Kocioa. Schorowany Carducci nie zdoa pojecha do Sztokholmu, eby osobicie odebra nagrod, goci natomiast u siebie ambasadora Szwecji. Zmar na marsko wtroby dwa miesice pniej, 16 lutego 1907 roku. Jego mier upamitni wierszem Per la tomba di G. Carducci (Na grb G. Carducciego) Gabriele DAnnunzio, gwny przedstawiciel woskiego dekadentyzmu. Utwory Carducciego czsto inspiroway kompozytorw, ktrzy wykorzystywali je jako teksty swoich pieni (Alfredo Casella  Notte de maggio, Guido Alberto Fano  Vere novo, Stanislao Gastaldon  Viva il Re)."
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/batterydata_batterybert-cased-squad-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/batterydata_batterybert-cased-squad-v1.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::batterydata name::batterybert-cased-squad-v1 downloads::202 license::apache-2.0 task::Question_Answering
+# labels: test_group::monthly author::batterydata name::batterybert-cased-squad-v1 downloads::202 license::apache-2.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
 
 model_name = "batterydata/batterybert-cased-squad-v1"
 # a) Get predictions
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 QA_input = {
     'question': 'What is the electrolyte?',
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/bespin-global_klue-bert-base-aihub-mrc.py` & `mlagility-3.1.1/models/popular_on_huggingface/bespin-global_klue-bert-base-aihub-mrc.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::bespin-global name::klue-bert-base-aihub-mrc downloads::981 license::cc-by-nc-4.0 task::Question_Answering
+# labels: test_group::monthly author::bespin-global name::klue-bert-base-aihub-mrc downloads::981 license::cc-by-nc-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 ## Load Transformers library
 import torch
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer
 
 device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
 
 def predict_answer(qa_text_pair):
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/bespin-global_klue-bert-base-mrc.py` & `mlagility-3.1.1/models/popular_on_huggingface/bespin-global_klue-bert-base-mrc.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::bespin-global name::klue-bert-base-mrc downloads::1,844 license::cc-by-nc-4.0 task::Question_Answering
+# labels: test_group::monthly author::bespin-global name::klue-bert-base-mrc downloads::1,844 license::cc-by-nc-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 # Load Transformers library
 import torch
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer
 
 context = "your context"
 question = "your question"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/bhadresh-savani_bert-base-uncased-emotion.py` & `mlagility-3.1.1/models/popular_on_huggingface/bhadresh-savani_bert-base-uncased-emotion.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::bhadresh-savani name::bert-base-uncased-emotion downloads::3,209 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::bhadresh-savani name::bert-base-uncased-emotion downloads::3,209 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 classifier = pipeline("text-classification",model='bhadresh-savani/bert-base-uncased-emotion', return_all_scores=True)
 prediction = classifier("I love using transformers. The best part is wide range of support and its easy to use", )
 print(prediction)
 
 """
 output:
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/bhadresh-savani_distilbert-base-uncased-emotion.py` & `mlagility-3.1.1/models/popular_on_huggingface/bhadresh-savani_distilbert-base-uncased-emotion.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::bhadresh-savani name::distilbert-base-uncased-emotion downloads::104,063 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::bhadresh-savani name::distilbert-base-uncased-emotion downloads::104,063 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 classifier = pipeline("text-classification",model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True)
 prediction = classifier("I love using transformers. The best part is wide range of support and its easy to use", )
 print(prediction)
 
 """
 Output:
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/bhadresh-savani_electra-base-emotion.py` & `mlagility-3.1.1/models/popular_on_huggingface/bhadresh-savani_electra-base-emotion.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::bhadresh-savani name::electra-base-emotion downloads::348 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::bhadresh-savani name::electra-base-emotion downloads::348 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 classifier = pipeline("text-classification",model='bhadresh-savani/electra-base-emotion', return_all_scores=True)
 prediction = classifier("I love using transformers. The best part is wide range of support and its easy to use", )
 print(prediction)
 
 """
 Output:
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/bhadresh-savani_roberta-base-emotion.py` & `mlagility-3.1.1/models/popular_on_huggingface/bhadresh-savani_roberta-base-emotion.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::bhadresh-savani name::roberta-base-emotion downloads::480 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::bhadresh-savani name::roberta-base-emotion downloads::480 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 classifier = pipeline("text-classification",model='bhadresh-savani/roberta-base-emotion', return_all_scores=True)
 prediction = classifier("I love using transformers. The best part is wide range of support and its easy to use", )
 print(prediction)
 
 """
 Output:
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/bigscience_T0.py` & `mlagility-3.1.1/models/popular_on_huggingface/bigscience_T0.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::bigscience name::T0 downloads::26,582 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::bigscience name::T0 downloads::26,582 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 tokenizer = AutoTokenizer.from_pretrained("bigscience/T0pp")
 model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0pp")
 
 inputs = tokenizer.encode("Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy", return_tensors="pt")
 outputs = model.generate(inputs)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/bigscience_T0p.py` & `mlagility-3.1.1/models/popular_on_huggingface/bigscience_T0p.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::bigscience name::T0p downloads::211 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::bigscience name::T0p downloads::211 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 tokenizer = AutoTokenizer.from_pretrained("bigscience/T0pp")
 model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0pp")
 
 inputs = tokenizer.encode("Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy", return_tensors="pt")
 outputs = model.generate(inputs)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/blinoff_roberta-base-russian-v0.py` & `mlagility-3.1.1/models/popular_on_huggingface/blinoff_roberta-base-russian-v0.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::blinoff name::roberta-base-russian-v0 downloads::330 task::Fill-Mask
+# labels: test_group::monthly author::blinoff name::roberta-base-russian-v0 downloads::330 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import pipeline
 from transformers import RobertaTokenizerFast
 
 tokenizer = RobertaTokenizerFast.from_pretrained('blinoff/roberta-base-russian-v0', max_len=512)
 
 fill_mask = pipeline(
     "fill-mask",
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_tweet-topic-21-multi.py` & `mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_tweet-topic-21-multi.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cardiffnlp name::tweet-topic-21-multi downloads::1,102 task::Text_Classification
+# labels: test_group::monthly author::cardiffnlp name::tweet-topic-21-multi downloads::1,102 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification
 from transformers import AutoTokenizer
 import numpy as np
 from scipy.special import expit
 
     
 MODEL = f"cardiffnlp/tweet-topic-21-single"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_tweet-topic-21-single.py` & `mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_tweet-topic-21-single.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cardiffnlp name::tweet-topic-21-single downloads::853 task::Text_Classification
+# labels: test_group::monthly author::cardiffnlp name::tweet-topic-21-single downloads::853 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification
 from transformers import AutoTokenizer
 import numpy as np
 from scipy.special import softmax
 
     
 MODEL = f"cardiffnlp/tweet-topic-21-single"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-emoji.py` & `mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-emoji.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-emoji downloads::1,452 task::Text_Classification
+# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-emoji downloads::1,452 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification
 from transformers import TFAutoModelForSequenceClassification
 from transformers import AutoTokenizer
 import numpy as np
 from scipy.special import softmax
 import csv
 import urllib.request
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-emotion.py` & `mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-emotion.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-emotion downloads::40,849 task::Text_Classification
+# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-emotion downloads::40,849 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification
 from transformers import TFAutoModelForSequenceClassification
 from transformers import AutoTokenizer
 import numpy as np
 from scipy.special import softmax
 import csv
 import urllib.request
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-hate.py` & `mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-hate.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-hate downloads::1,635 task::Text_Classification
+# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-hate downloads::1,635 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification
 from transformers import TFAutoModelForSequenceClassification
 from transformers import AutoTokenizer
 import numpy as np
 from scipy.special import softmax
 import csv
 import urllib.request
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-irony.py` & `mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-irony.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-irony downloads::59,396 task::Text_Classification
+# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-irony downloads::59,396 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification
 from transformers import TFAutoModelForSequenceClassification
 from transformers import AutoTokenizer
 import numpy as np
 from scipy.special import softmax
 import csv
 import urllib.request
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-offensive.py` & `mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-offensive.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-offensive downloads::11,494 task::Text_Classification
+# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-offensive downloads::11,494 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification
 from transformers import TFAutoModelForSequenceClassification
 from transformers import AutoTokenizer
 import numpy as np
 from scipy.special import softmax
 import csv
 import urllib.request
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-sentiment.py` & `mlagility-3.1.1/models/popular_on_huggingface/cardiffnlp_twitter-roberta-base-sentiment.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-sentiment downloads::1,483,976 task::Text_Classification
+# labels: test_group::monthly author::cardiffnlp name::twitter-roberta-base-sentiment downloads::1,483,976 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification
 from transformers import TFAutoModelForSequenceClassification
 from transformers import AutoTokenizer
 import numpy as np
 from scipy.special import softmax
 import csv
 import urllib.request
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/chkla_parlbert-topic-german.py` & `mlagility-3.1.1/models/popular_on_huggingface/chkla_parlbert-topic-german.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::chkla name::parlbert-topic-german downloads::35,916 task::Text_Classification
+# labels: test_group::monthly author::chkla name::parlbert-topic-german downloads::35,916 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 
 pipeline_classification_topics = pipeline("text-classification", model="chkla/parlbert-topic-german", tokenizer="bert-base-german-cased", return_all_scores=False)
 
 text = "Sachgebiet Ausschlieliche Gesetzgebungskompetenz des Bundes ber die Zusammenarbeit des Bundes und der Lnder zum Schutze der freiheitlichen demokratischen Grundordnung, des Bestandes und der Sicherheit des Bundes oder eines Landes Wir fragen die Bundesregierung"
 
 pipeline_classification_topics(text) # Government
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/clips_mfaq.py` & `mlagility-3.1.1/models/popular_on_huggingface/clips_mfaq.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::clips name::mfaq downloads::428,140 license::apache-2.0 task::Sentence_Similarity
+# labels: test_group::monthly author::clips name::mfaq downloads::428,140 license::apache-2.0 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer
 
 question = "<Q>How many models can I host on HuggingFace?"
 answer_1 = "<A>All plans come with unlimited private models and datasets."
 answer_2 = "<A>AutoNLP is an automatic way to train and deploy state-of-the-art NLP models, seamlessly integrated with the Hugging Face ecosystem."
 answer_3 = "<A>Based on how much training data and model variants are created, we send you a compute cost and payment link - as low as $10 per job."
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cmarkea_distilcamembert-base-ner.py` & `mlagility-3.1.1/models/popular_on_huggingface/cmarkea_distilcamembert-base-ner.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cmarkea name::distilcamembert-base-ner downloads::6,491 license::mit task::Token_Classification
+# labels: test_group::monthly author::cmarkea name::distilcamembert-base-ner downloads::6,491 license::mit task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import pipeline
 
 ner = pipeline(
     task='ner',
     model="cmarkea/distilcamembert-base-ner",
     tokenizer="cmarkea/distilcamembert-base-ner",
     aggregation_strategy="simple"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cmarkea_distilcamembert-base-nli.py` & `mlagility-3.1.1/models/popular_on_huggingface/cmarkea_distilcamembert-base-nli.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cmarkea name::distilcamembert-base-nli downloads::425 license::mit task::Zero-Shot_Classification
+# labels: test_group::monthly author::cmarkea name::distilcamembert-base-nli downloads::425 license::mit task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import pipeline
 
 classifier = pipeline(
     task='zero-shot-classification',
     model="cmarkea/distilcamembert-base-nli",
     tokenizer="cmarkea/distilcamembert-base-nli"
 )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cmarkea_distilcamembert-base-qa.py` & `mlagility-3.1.1/models/popular_on_huggingface/cmarkea_distilcamembert-base-qa.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cmarkea name::distilcamembert-base-qa downloads::2,400 license::cc-by-nc-sa-3.0 task::Question_Answering
+# labels: test_group::monthly author::cmarkea name::distilcamembert-base-qa downloads::2,400 license::cc-by-nc-sa-3.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 qa_engine = pipeline(
     "question-answering",
     model="cmarkea/distilcamembert-base-qa",
     tokenizer="cmarkea/distilcamembert-base-qa"
 )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cmarkea_distilcamembert-base-sentiment.py` & `mlagility-3.1.1/models/popular_on_huggingface/cmarkea_distilcamembert-base-sentiment.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cmarkea name::distilcamembert-base-sentiment downloads::2,818 license::mit task::Text_Classification
+# labels: test_group::monthly author::cmarkea name::distilcamembert-base-sentiment downloads::2,818 license::mit task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 
 analyzer = pipeline(
     task='text-classification',
     model="cmarkea/distilcamembert-base-sentiment",
     tokenizer="cmarkea/distilcamembert-base-sentiment"
 )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rubert-base-cased-nli-threeway.py` & `mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rubert-base-cased-nli-threeway.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cointegrated name::rubert-base-cased-nli-threeway downloads::2,865 task::Zero-Shot_Classification
+# labels: test_group::monthly author::cointegrated name::rubert-base-cased-nli-threeway downloads::2,865 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 # !pip install transformers sentencepiece --quiet
 import torch
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 
 model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'
 tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
 model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rubert-tiny-sentiment-balanced.py` & `mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rubert-tiny-sentiment-balanced.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cointegrated name::rubert-tiny-sentiment-balanced downloads::2,202 task::Text_Classification
+# labels: test_group::monthly author::cointegrated name::rubert-tiny-sentiment-balanced downloads::2,202 task::Natural_Language_Processing sub_task::Text_Classification
 # !pip install transformers sentencepiece --quiet
 import torch
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 
 model_checkpoint = 'cointegrated/rubert-tiny-sentiment-balanced'
 tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
 model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rubert-tiny-toxicity.py` & `mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rubert-tiny-toxicity.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cointegrated name::rubert-tiny-toxicity downloads::5,614 task::Text_Classification
+# labels: test_group::monthly author::cointegrated name::rubert-tiny-toxicity downloads::5,614 task::Natural_Language_Processing sub_task::Text_Classification
 # !pip install transformers sentencepiece --quiet
 import torch
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 
 model_checkpoint = 'cointegrated/rubert-tiny-toxicity'
 tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
 model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rubert-tiny.py` & `mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rubert-tiny.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cointegrated name::rubert-tiny downloads::32,164 license::mit task::Feature_Extraction
+# labels: test_group::monthly author::cointegrated name::rubert-tiny downloads::32,164 license::mit task::Multimodal sub_task::Feature_Extraction
 # pip install transformers sentencepiece
 import torch
 from transformers import AutoTokenizer, AutoModel
 tokenizer = AutoTokenizer.from_pretrained("cointegrated/rubert-tiny")
 model = AutoModel.from_pretrained("cointegrated/rubert-tiny")
 # model.cuda()  # uncomment it if you have a GPU
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rubert-tiny2.py` & `mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rubert-tiny2.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cointegrated name::rubert-tiny2 downloads::8,646 license::mit task::Feature_Extraction
+# labels: test_group::monthly author::cointegrated name::rubert-tiny2 downloads::8,646 license::mit task::Multimodal sub_task::Feature_Extraction
 # pip install transformers sentencepiece
 import torch
 from transformers import AutoTokenizer, AutoModel
 tokenizer = AutoTokenizer.from_pretrained("cointegrated/rubert-tiny2")
 model = AutoModel.from_pretrained("cointegrated/rubert-tiny2")
 # model.cuda()  # uncomment it if you have a GPU
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cointegrated_rut5-small-chitchat.py` & `mlagility-3.1.1/models/popular_on_huggingface/cointegrated_rut5-small.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,23 +1,19 @@
-# labels: test_group::monthly author::cointegrated name::rut5-small-chitchat downloads::188 license::mit task::Text2Text_Generation
+# labels: test_group::monthly author::cointegrated name::rut5-small downloads::444 license::mit task::Natural_Language_Processing sub_task::Text2Text_Generation
 # !pip install transformers sentencepiece
 import torch
 from transformers import T5ForConditionalGeneration, T5Tokenizer
 
-tokenizer = T5Tokenizer.from_pretrained("cointegrated/rut5-small-chitchat")
-model = T5ForConditionalGeneration.from_pretrained("cointegrated/rut5-small-chitchat")
+tokenizer = T5Tokenizer.from_pretrained("cointegrated/rut5-small")
+model = T5ForConditionalGeneration.from_pretrained("cointegrated/rut5-small")
 
-text = '! ,   ?'
+text = '   ,     . '
 inputs = tokenizer(text, return_tensors='pt')
 with torch.no_grad():
     hypotheses = model.generate(
         **inputs, 
-        do_sample=True, top_p=0.5, num_return_sequences=3, 
+        do_sample=True, top_p=0.95, num_return_sequences=10, 
         repetition_penalty=2.5,
         max_length=32,
     )
 for h in hypotheses:
     print(tokenizer.decode(h, skip_special_tokens=True))
-#  .
-#  -  .
-# .
-# Wall time: 363 ms
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-MiniLM2-L6-H768.py` & `mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-MiniLM2-L6-H768.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cross-encoder name::nli-MiniLM2-L6-H768 downloads::595 license::apache-2.0 task::Zero-Shot_Classification
+# labels: test_group::monthly author::cross-encoder name::nli-MiniLM2-L6-H768 downloads::595 license::apache-2.0 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from sentence_transformers import CrossEncoder
 model = CrossEncoder('cross-encoder/nli-MiniLM2-L6-H768')
 scores = model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])
 
 #Convert scores to labels
 label_mapping = ['contradiction', 'entailment', 'neutral']
 labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-deberta-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-deberta-base.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cross-encoder name::nli-deberta-base downloads::545 license::apache-2.0 task::Zero-Shot_Classification
+# labels: test_group::monthly author::cross-encoder name::nli-deberta-base downloads::545 license::apache-2.0 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from sentence_transformers import CrossEncoder
 model = CrossEncoder('cross-encoder/nli-deberta-base')
 scores = model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])
 
 #Convert scores to labels
 label_mapping = ['contradiction', 'entailment', 'neutral']
 labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-base.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cross-encoder name::nli-deberta-v3-base downloads::5,572 license::apache-2.0 task::Zero-Shot_Classification
+# labels: test_group::monthly author::cross-encoder name::nli-deberta-v3-base downloads::5,572 license::apache-2.0 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from sentence_transformers import CrossEncoder
 model = CrossEncoder('cross-encoder/nli-deberta-v3-base')
 scores = model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])
 
 #Convert scores to labels
 label_mapping = ['contradiction', 'entailment', 'neutral']
 labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-large.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cross-encoder name::nli-deberta-v3-large downloads::426 license::apache-2.0 task::Zero-Shot_Classification
+# labels: test_group::monthly author::cross-encoder name::nli-deberta-v3-large downloads::426 license::apache-2.0 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from sentence_transformers import CrossEncoder
 model = CrossEncoder('cross-encoder/nli-deberta-v3-large')
 scores = model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])
 
 #Convert scores to labels
 label_mapping = ['contradiction', 'entailment', 'neutral']
 labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-small.py` & `mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-small.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cross-encoder name::nli-deberta-v3-small downloads::309 license::apache-2.0 task::Zero-Shot_Classification
+# labels: test_group::monthly author::cross-encoder name::nli-deberta-v3-small downloads::309 license::apache-2.0 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from sentence_transformers import CrossEncoder
 model = CrossEncoder('cross-encoder/nli-deberta-v3-small')
 scores = model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])
 
 #Convert scores to labels
 label_mapping = ['contradiction', 'entailment', 'neutral']
 labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-xsmall.py` & `mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-deberta-v3-xsmall.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cross-encoder name::nli-deberta-v3-xsmall downloads::8,825 license::apache-2.0 task::Zero-Shot_Classification
+# labels: test_group::monthly author::cross-encoder name::nli-deberta-v3-xsmall downloads::8,825 license::apache-2.0 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from sentence_transformers import CrossEncoder
 model = CrossEncoder('cross-encoder/nli-deberta-v3-xsmall')
 scores = model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])
 
 #Convert scores to labels
 label_mapping = ['contradiction', 'entailment', 'neutral']
 labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-distilroberta-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-distilroberta-base.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cross-encoder name::nli-distilroberta-base downloads::35,444 license::apache-2.0 task::Zero-Shot_Classification
+# labels: test_group::monthly author::cross-encoder name::nli-distilroberta-base downloads::35,444 license::apache-2.0 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from sentence_transformers import CrossEncoder
 model = CrossEncoder('cross-encoder/nli-distilroberta-base')
 scores = model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])
 
 #Convert scores to labels
 label_mapping = ['contradiction', 'entailment', 'neutral']
 labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/cross-encoder_nli-roberta-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/cross-encoder_nli-roberta-base.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::cross-encoder name::nli-roberta-base downloads::2,754 license::apache-2.0 task::Zero-Shot_Classification
+# labels: test_group::monthly author::cross-encoder name::nli-roberta-base downloads::2,754 license::apache-2.0 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from sentence_transformers import CrossEncoder
 model = CrossEncoder('cross-encoder/nli-roberta-base')
 scores = model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])
 
 #Convert scores to labels
 label_mapping = ['contradiction', 'entailment', 'neutral']
 labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/csebuetnlp_mT5_m2m_crossSum.py` & `mlagility-3.1.1/models/popular_on_huggingface/csebuetnlp_mT5_m2m_crossSum.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::csebuetnlp name::mT5_m2m_crossSum downloads::623 task::Summarization
+# labels: test_group::monthly author::csebuetnlp name::mT5_m2m_crossSum downloads::623 task::Natural_Language_Processing sub_task::Summarization
 import re
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 WHITESPACE_HANDLER = lambda k: re.sub('\s+', ' ', re.sub('\n+', ' ', k.strip()))
 
 article_text = """Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said.  The policy includes the termination of accounts of anti-vaccine influencers.  Tech giants have been criticised for not doing more to counter false health information on their sites.  In July, US President Joe Biden said social media platforms were largely responsible for people's scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue.  YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines.  In a blog post, the company said it had seen false claims about Covid jabs "spill over into misinformation about vaccines in general". The new policy covers long-approved vaccines, such as those against measles or hepatitis B.  "We're expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO," the post said, referring to the World Health Organization."""
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/csebuetnlp_mT5_m2o_arabic_crossSum.py` & `mlagility-3.1.1/models/popular_on_huggingface/csebuetnlp_mT5_multilingual_XLSum.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# labels: test_group::monthly author::csebuetnlp name::mT5_m2o_arabic_crossSum downloads::196 task::Summarization
+# labels: test_group::monthly author::csebuetnlp name::mT5_multilingual_XLSum downloads::150,407 task::Natural_Language_Processing sub_task::Summarization
 import re
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 WHITESPACE_HANDLER = lambda k: re.sub('\s+', ' ', re.sub('\n+', ' ', k.strip()))
 
 article_text = """Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said.  The policy includes the termination of accounts of anti-vaccine influencers.  Tech giants have been criticised for not doing more to counter false health information on their sites.  In July, US President Joe Biden said social media platforms were largely responsible for people's scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue.  YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines.  In a blog post, the company said it had seen false claims about Covid jabs "spill over into misinformation about vaccines in general". The new policy covers long-approved vaccines, such as those against measles or hepatitis B.  "We're expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO," the post said, referring to the World Health Organization."""
 
-model_name = "csebuetnlp/mT5_m2o_arabic_crossSum"
+model_name = "csebuetnlp/mT5_multilingual_XLSum"
 tokenizer = AutoTokenizer.from_pretrained(model_name)
 model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
 
 input_ids = tokenizer(
     [WHITESPACE_HANDLER(article_text)],
     return_tensors="pt",
     padding="max_length",
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/csebuetnlp_mT5_m2o_chinese_simplified_crossSum.py` & `mlagility-3.1.1/models/popular_on_huggingface/csebuetnlp_mT5_m2o_chinese_simplified_crossSum.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::csebuetnlp name::mT5_m2o_chinese_simplified_crossSum downloads::489 task::Summarization
+# labels: test_group::monthly author::csebuetnlp name::mT5_m2o_chinese_simplified_crossSum downloads::489 task::Natural_Language_Processing sub_task::Summarization
 import re
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 WHITESPACE_HANDLER = lambda k: re.sub('\s+', ' ', re.sub('\n+', ' ', k.strip()))
 
 article_text = """Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said.  The policy includes the termination of accounts of anti-vaccine influencers.  Tech giants have been criticised for not doing more to counter false health information on their sites.  In July, US President Joe Biden said social media platforms were largely responsible for people's scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue.  YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines.  In a blog post, the company said it had seen false claims about Covid jabs "spill over into misinformation about vaccines in general". The new policy covers long-approved vaccines, such as those against measles or hepatitis B.  "We're expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO," the post said, referring to the World Health Organization."""
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/csebuetnlp_mT5_multilingual_XLSum.py` & `mlagility-3.1.1/models/popular_on_huggingface/csebuetnlp_mT5_m2o_arabic_crossSum.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# labels: test_group::monthly author::csebuetnlp name::mT5_multilingual_XLSum downloads::150,407 task::Summarization
+# labels: test_group::monthly author::csebuetnlp name::mT5_m2o_arabic_crossSum downloads::196 task::Natural_Language_Processing sub_task::Summarization
 import re
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 WHITESPACE_HANDLER = lambda k: re.sub('\s+', ' ', re.sub('\n+', ' ', k.strip()))
 
 article_text = """Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said.  The policy includes the termination of accounts of anti-vaccine influencers.  Tech giants have been criticised for not doing more to counter false health information on their sites.  In July, US President Joe Biden said social media platforms were largely responsible for people's scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue.  YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines.  In a blog post, the company said it had seen false claims about Covid jabs "spill over into misinformation about vaccines in general". The new policy covers long-approved vaccines, such as those against measles or hepatitis B.  "We're expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO," the post said, referring to the World Health Organization."""
 
-model_name = "csebuetnlp/mT5_multilingual_XLSum"
+model_name = "csebuetnlp/mT5_m2o_arabic_crossSum"
 tokenizer = AutoTokenizer.from_pretrained(model_name)
 model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
 
 input_ids = tokenizer(
     [WHITESPACE_HANDLER(article_text)],
     return_tensors="pt",
     padding="max_length",
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ctrl.py` & `mlagility-3.1.1/models/popular_on_huggingface/ctrl.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::huggingface name::ctrl task::unknown downloads::11,873 license::bsd-3-clause
+    # labels: test_group::monthly author::huggingface name::ctrl task::Natural_Language_Processing downloads::11,873 license::bsd-3-clause
 from transformers import CTRLTokenizer, CTRLModel
 import torch
 
 tokenizer = CTRLTokenizer.from_pretrained("ctrl")
 model = CTRLModel.from_pretrained("ctrl")
 
 # CTRL was trained with control codes as the first token
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/d4data_biomedical-ner-all.py` & `mlagility-3.1.1/models/popular_on_huggingface/d4data_biomedical-ner-all.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::d4data name::biomedical-ner-all downloads::14,428 license::apache-2.0 task::Token_Classification
+# labels: test_group::monthly author::d4data name::biomedical-ner-all downloads::14,428 license::apache-2.0 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import pipeline
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 
 tokenizer = AutoTokenizer.from_pretrained("d4data/biomedical-ner-all")
 model = AutoModelForTokenClassification.from_pretrained("d4data/biomedical-ner-all")
 
 pipe = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple") # pass device=0 if using gpu
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/dandelin_vilt-b32-finetuned-nlvr2.py` & `mlagility-3.1.1/models/popular_on_huggingface/dandelin_vilt-b32-finetuned-nlvr2.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::dandelin name::vilt-b32-finetuned-nlvr2 task::unknown downloads::252 license::apache-2.0
+# labels: test_group::monthly author::dandelin name::vilt-b32-finetuned-nlvr2 task::MultiModal downloads::252 license::apache-2.0
 from transformers import ViltProcessor, ViltForImagesAndTextClassification
 import requests
 from PIL import Image
 
 image1 = Image.open(requests.get("https://lil.nlp.cornell.edu/nlvr/exs/ex0_0.jpg", stream=True).raw)
 image2 = Image.open(requests.get("https://lil.nlp.cornell.edu/nlvr/exs/ex0_1.jpg", stream=True).raw)
 text = "The left image contains twice the number of dogs as the right image."
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/dandelin_vilt-b32-mlm.py` & `mlagility-3.1.1/models/popular_on_huggingface/dandelin_vilt-b32-mlm.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::dandelin name::vilt-b32-mlm downloads::7,671 license::apache-2.0 task::Fill-Mask
+# labels: test_group::monthly author::dandelin name::vilt-b32-mlm downloads::7,671 license::apache-2.0 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import ViltProcessor, ViltForMaskedLM
 import requests
 from PIL import Image
 import re
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/dangvantuan_sentence-camembert-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/dangvantuan_sentence-camembert-base.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::dangvantuan name::sentence-camembert-base downloads::287 license::apache-2.0 task::Sentence_Similarity
+# labels: test_group::monthly author::dangvantuan name::sentence-camembert-base downloads::287 license::apache-2.0 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer
 model =  SentenceTransformer("dangvantuan/sentence-camembert-base")
 
 sentences = ["Un avion est en train de dcoller.",
           "Un homme joue d'une grande flte.",
           "Un homme tale du fromage rp sur une pizza.",
           "Une personne jette un chat au plafond.",
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/dangvantuan_sentence-camembert-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/dangvantuan_sentence-camembert-large.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::dangvantuan name::sentence-camembert-large downloads::13,347 license::apache-2.0 task::Sentence_Similarity
+# labels: test_group::monthly author::dangvantuan name::sentence-camembert-large downloads::13,347 license::apache-2.0 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer
 model =  SentenceTransformer("dangvantuan/sentence-camembert-large")
 
 sentences = ["Un avion est en train de dcoller.",
           "Un homme joue d'une grande flte.",
           "Un homme tale du fromage rp sur une pizza.",
           "Une personne jette un chat au plafond.",
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/deepset_deberta-v3-base-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/deepset_xlm-roberta-base-squad2-distilled.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,13 +1,16 @@
-# labels: test_group::monthly author::deepset name::deberta-v3-base-squad2 downloads::7,980 license::cc-by-4.0 task::Question_Answering
+# labels: test_group::monthly author::deepset name::xlm-roberta-base-squad2-distilled downloads::1,673 license::mit task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
-model_name = "deepset/deberta-v3-base-squad2"
+
+model_name = "deepset/xlm-roberta-base-squad2-distilled"
+
 # a) Get predictions
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 QA_input = {
     'question': 'Why is model conversion important?',
     'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'
 }
 res = nlp(QA_input)
+
 # b) Load model & tokenizer
 model = AutoModelForQuestionAnswering.from_pretrained(model_name)
 tokenizer = AutoTokenizer.from_pretrained(model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/deepset_deberta-v3-large-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/deepset_deberta-v3-large-squad2.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::deepset name::deberta-v3-large-squad2 downloads::20,376 license::cc-by-4.0 task::Question_Answering
+# labels: test_group::monthly author::deepset name::deberta-v3-large-squad2 downloads::20,376 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
 
 model_name = "deepset/deberta-v3-large-squad2"
 
 # a) Get predictions
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 QA_input = {
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/deepset_electra-base-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/deepset_deberta-v3-base-squad2.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,16 +1,13 @@
-# labels: test_group::monthly author::deepset name::electra-base-squad2 downloads::60,435 license::cc-by-4.0 task::Question_Answering
+# labels: test_group::monthly author::deepset name::deberta-v3-base-squad2 downloads::7,980 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
-
-model_name = "deepset/electra-base-squad2"
-
+model_name = "deepset/deberta-v3-base-squad2"
 # a) Get predictions
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 QA_input = {
     'question': 'Why is model conversion important?',
-    'context': 'The option to convert models between FARM and transformers gives freedom to the user and lets people easily switch between frameworks.'
+    'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'
 }
 res = nlp(QA_input)
-
 # b) Load model & tokenizer
 model = AutoModelForQuestionAnswering.from_pretrained(model_name)
 tokenizer = AutoTokenizer.from_pretrained(model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/deepset_roberta-base-squad2-covid.py` & `mlagility-3.1.1/models/popular_on_huggingface/deepset_roberta-base-squad2.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,12 +1,11 @@
-# labels: test_group::monthly author::deepset name::roberta-base-squad2-covid downloads::124,342 license::cc-by-4.0 task::Question_Answering
+# labels: test_group::monthly author::deepset name::roberta-base-squad2 downloads::3,159,056 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
 
-
-model_name = "deepset/roberta-base-squad2-covid"
+model_name = "deepset/roberta-base-squad2"
 
 # a) Get predictions
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 QA_input = {
     'question': 'Why is model conversion important?',
     'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'
 }
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/deepset_roberta-base-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/deepset_electra-base-squad2.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# labels: test_group::monthly author::deepset name::roberta-base-squad2 downloads::3,159,056 license::cc-by-4.0 task::Question_Answering
+# labels: test_group::monthly author::deepset name::electra-base-squad2 downloads::60,435 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
 
-model_name = "deepset/roberta-base-squad2"
+model_name = "deepset/electra-base-squad2"
 
 # a) Get predictions
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 QA_input = {
     'question': 'Why is model conversion important?',
-    'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'
+    'context': 'The option to convert models between FARM and transformers gives freedom to the user and lets people easily switch between frameworks.'
 }
 res = nlp(QA_input)
 
 # b) Load model & tokenizer
 model = AutoModelForQuestionAnswering.from_pretrained(model_name)
 tokenizer = AutoTokenizer.from_pretrained(model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/deepset_tinyroberta-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/deepset_roberta-base-squad2-covid.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,11 +1,12 @@
-# labels: test_group::monthly author::deepset name::tinyroberta-squad2 downloads::78,671 license::cc-by-4.0 task::Question_Answering
+# labels: test_group::monthly author::deepset name::roberta-base-squad2-covid downloads::124,342 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
 
-model_name = "deepset/tinyroberta-squad2"
+
+model_name = "deepset/roberta-base-squad2-covid"
 
 # a) Get predictions
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 QA_input = {
     'question': 'Why is model conversion important?',
     'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'
 }
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/deepset_xlm-roberta-base-squad2-distilled.py` & `mlagility-3.1.1/models/popular_on_huggingface/deepset_tinyroberta-squad2.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,11 +1,11 @@
-# labels: test_group::monthly author::deepset name::xlm-roberta-base-squad2-distilled downloads::1,673 license::mit task::Question_Answering
+# labels: test_group::monthly author::deepset name::tinyroberta-squad2 downloads::78,671 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
 
-model_name = "deepset/xlm-roberta-base-squad2-distilled"
+model_name = "deepset/tinyroberta-squad2"
 
 # a) Get predictions
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 QA_input = {
     'question': 'Why is model conversion important?',
     'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'
 }
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/deepset_xlm-roberta-large-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/deepset_xlm-roberta-large-squad2.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::deepset name::xlm-roberta-large-squad2 downloads::78,903 license::cc-by-4.0 task::Question_Answering
+# labels: test_group::monthly author::deepset name::xlm-roberta-large-squad2 downloads::78,903 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
 
 model_name = "deepset/xlm-roberta-large-squad2"
 
 # a) Get predictions
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 QA_input = {
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/deutsche-telekom_bert-multi-english-german-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/deutsche-telekom_bert-multi-english-german-squad2.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::deutsche-telekom name::bert-multi-english-german-squad2 downloads::1,615 license::mit task::Question_Answering
+# labels: test_group::monthly author::deutsche-telekom name::bert-multi-english-german-squad2 downloads::1,615 license::mit task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 qa_pipeline = pipeline(
     "question-answering",
     model="deutsche-telekom/bert-multi-english-german-squad2",
     tokenizer="deutsche-telekom/bert-multi-english-german-squad2"
 )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/deutsche-telekom_electra-base-de-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/deutsche-telekom_electra-base-de-squad2.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::deutsche-telekom name::electra-base-de-squad2 downloads::217 license::mit task::Question_Answering
+# labels: test_group::monthly author::deutsche-telekom name::electra-base-de-squad2 downloads::217 license::mit task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 qa_pipeline = pipeline(
     "question-answering",
     model="deutsche-telekom/electra-base-de-squad2",
     tokenizer="deutsche-telekom/electra-base-de-squad2"
 )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/digitalepidemiologylab_covid-twitter-bert-v2.py` & `mlagility-3.1.1/models/popular_on_huggingface/digitalepidemiologylab_covid-twitter-bert-v2.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::digitalepidemiologylab name::covid-twitter-bert-v2 task::unknown downloads::8,270 license::mit
+# labels: test_group::monthly author::digitalepidemiologylab name::covid-twitter-bert-v2 task::Natural_Language_Processing downloads::8,270 license::mit
 from transformers import pipeline
 import json
 
 pipe = pipeline(task='fill-mask', model='digitalepidemiologylab/covid-twitter-bert-v2')
 out = pipe(f"In places with a lot of people, it's a good idea to wear a {pipe.tokenizer.mask_token}")
 print(json.dumps(out, indent=4))
 [
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/digitalepidemiologylab_covid-twitter-bert.py` & `mlagility-3.1.1/models/popular_on_huggingface/digitalepidemiologylab_covid-twitter-bert.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::digitalepidemiologylab name::covid-twitter-bert task::unknown downloads::331,544 license::mit
+# labels: test_group::monthly author::digitalepidemiologylab name::covid-twitter-bert task::Natural_Language_Processing downloads::331,544 license::mit
 from transformers import pipeline
 import json
 
 pipe = pipeline(task='fill-mask', model='digitalepidemiologylab/covid-twitter-bert-v2')
 out = pipe(f"In places with a lot of people, it's a good idea to wear a {pipe.tokenizer.mask_token}")
 print(json.dumps(out, indent=4))
 [
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/distilbert-base-uncased-finetuned-sst-2-english.py` & `mlagility-3.1.1/models/popular_on_huggingface/distilbert-base-uncased-finetuned-sst-2-english.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::huggingface name::distilbert-base-uncased-finetuned-sst-2-english downloads::2,161,565 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::huggingface name::distilbert-base-uncased-finetuned-sst-2-english downloads::2,161,565 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 import torch
 from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
 
 tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")
 model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")
 
 inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/dkleczek_bert-base-polish-cased-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/dkleczek_bert-base-polish-uncased-v1.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::dkleczek name::bert-base-polish-cased-v1 task::unknown downloads::828
+# labels: test_group::monthly author::dkleczek name::bert-base-polish-uncased-v1 downloads::12,447 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import *
 model = BertForMaskedLM.from_pretrained("dkleczek/bert-base-polish-uncased-v1")
 tokenizer = BertTokenizer.from_pretrained("dkleczek/bert-base-polish-uncased-v1")
 nlp = pipeline('fill-mask', model=model, tokenizer=tokenizer)
 for pred in nlp(f"Adam Mickiewicz wielkim polskim {nlp.tokenizer.mask_token} by."):
   print(pred)
 # Output:
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/dkleczek_bert-base-polish-uncased-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/dkleczek_bert-base-polish-cased-v1.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::dkleczek name::bert-base-polish-uncased-v1 downloads::12,447 task::Fill-Mask
+# labels: test_group::monthly author::dkleczek name::bert-base-polish-cased-v1 task::Natural_Language_Processing downloads::828
 from transformers import *
 model = BertForMaskedLM.from_pretrained("dkleczek/bert-base-polish-uncased-v1")
 tokenizer = BertTokenizer.from_pretrained("dkleczek/bert-base-polish-uncased-v1")
 nlp = pipeline('fill-mask', model=model, tokenizer=tokenizer)
 for pred in nlp(f"Adam Mickiewicz wielkim polskim {nlp.tokenizer.mask_token} by."):
   print(pred)
 # Output:
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/doc2query_all-t5-base-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/doc2query_msmarco-t5-base-v1.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-# labels: test_group::monthly author::doc2query name::all-t5-base-v1 downloads::525 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::doc2query name::msmarco-t5-base-v1 downloads::924 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5Tokenizer, T5ForConditionalGeneration
 
-model_name = 'doc2query/all-t5-base-v1'
+model_name = 'doc2query/msmarco-t5-base-v1'
 tokenizer = T5Tokenizer.from_pretrained(model_name)
 model = T5ForConditionalGeneration.from_pretrained(model_name)
 
 text = "Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects."
 
 
-input_ids = tokenizer.encode(text, max_length=384, truncation=True, return_tensors='pt')
+input_ids = tokenizer.encode(text, max_length=320, truncation=True, return_tensors='pt')
 outputs = model.generate(
     input_ids=input_ids,
     max_length=64,
     do_sample=True,
     top_p=0.95,
     num_return_sequences=5)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/doc2query_all-with_prefix-t5-base-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/doc2query_all-with_prefix-t5-base-v1.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::doc2query name::all-with_prefix-t5-base-v1 downloads::263 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::doc2query name::all-with_prefix-t5-base-v1 downloads::263 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5Tokenizer, T5ForConditionalGeneration
 
 model_name = 'doc2query/all-with_prefix-t5-base-v1'
 tokenizer = T5Tokenizer.from_pretrained(model_name)
 model = T5ForConditionalGeneration.from_pretrained(model_name)
 
 prefix = "answer2question"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/doc2query_msmarco-t5-base-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/doc2query_all-t5-base-v1.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-# labels: test_group::monthly author::doc2query name::msmarco-t5-base-v1 downloads::924 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::doc2query name::all-t5-base-v1 downloads::525 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5Tokenizer, T5ForConditionalGeneration
 
-model_name = 'doc2query/msmarco-t5-base-v1'
+model_name = 'doc2query/all-t5-base-v1'
 tokenizer = T5Tokenizer.from_pretrained(model_name)
 model = T5ForConditionalGeneration.from_pretrained(model_name)
 
 text = "Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects."
 
 
-input_ids = tokenizer.encode(text, max_length=320, truncation=True, return_tensors='pt')
+input_ids = tokenizer.encode(text, max_length=384, truncation=True, return_tensors='pt')
 outputs = model.generate(
     input_ids=input_ids,
     max_length=64,
     do_sample=True,
     top_p=0.95,
     num_return_sequences=5)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/dslim_bert-base-NER.py` & `mlagility-3.1.1/models/popular_on_huggingface/dslim_bert-base-NER.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::dslim name::bert-base-NER downloads::412,204 license::mit task::Token_Classification
+# labels: test_group::monthly author::dslim name::bert-base-NER downloads::412,204 license::mit task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
 
 tokenizer = AutoTokenizer.from_pretrained("dslim/bert-base-NER")
 model = AutoModelForTokenClassification.from_pretrained("dslim/bert-base-NER")
 
 nlp = pipeline("ner", model=model, tokenizer=tokenizer)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/dslim_bert-large-NER.py` & `mlagility-3.1.1/models/popular_on_huggingface/dslim_bert-large-NER.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::dslim name::bert-large-NER downloads::950,542 license::mit task::Token_Classification
+# labels: test_group::monthly author::dslim name::bert-large-NER downloads::950,542 license::mit task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
 
 tokenizer = AutoTokenizer.from_pretrained("dslim/bert-base-NER")
 model = AutoModelForTokenClassification.from_pretrained("dslim/bert-base-NER")
 
 nlp = pipeline("ner", model=model, tokenizer=tokenizer)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/dumitrescustefan_bert-base-romanian-cased-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/dumitrescustefan_bert-base-romanian-cased-v1.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::dumitrescustefan name::bert-base-romanian-cased-v1 downloads::6,471 license::mit task::Fill-Mask
+# labels: test_group::monthly author::dumitrescustefan name::bert-base-romanian-cased-v1 downloads::6,471 license::mit task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import AutoTokenizer, AutoModel
 import torch
 # load tokenizer and model
 tokenizer = AutoTokenizer.from_pretrained("dumitrescustefan/bert-base-romanian-cased-v1")
 model = AutoModel.from_pretrained("dumitrescustefan/bert-base-romanian-cased-v1")
 # tokenize a sentence and run through the model
 input_ids = torch.tensor(tokenizer.encode("Acesta este un test.", add_special_tokens=True)).unsqueeze(0)  # Batch size 1
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/edumunozsala_beto_sentiment_analysis_es.py` & `mlagility-3.1.1/models/popular_on_huggingface/edumunozsala_beto_sentiment_analysis_es.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::edumunozsala name::beto_sentiment_analysis_es downloads::204 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::edumunozsala name::beto_sentiment_analysis_es downloads::204 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 import torch
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 
 tokenizer = AutoTokenizer.from_pretrained("edumunozsala/beto_sentiment_analysis_es")
 model = AutoModelForSequenceClassification.from_pretrained("edumunozsala/beto_sentiment_analysis_es")
 
 text ="Se trata de una pelcula interesante, con un solido argumento y un gran interpretacin de su actor principal"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/edumunozsala_vit_base-224-in21k-ft-cifar100.py` & `mlagility-3.1.1/models/popular_on_huggingface/edumunozsala_vit_base-224-in21k-ft-cifar100.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::edumunozsala name::vit_base-224-in21k-ft-cifar100 downloads::242 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly author::edumunozsala name::vit_base-224-in21k-ft-cifar100 downloads::242 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ViTFeatureExtractor, ViTModel
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ehdwns1516_klue-roberta-base-kornli.py` & `mlagility-3.1.1/models/popular_on_huggingface/ehdwns1516_klue-roberta-base-kornli.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ehdwns1516 name::klue-roberta-base-kornli downloads::390 task::Text_Classification
+# labels: test_group::monthly author::ehdwns1516 name::klue-roberta-base-kornli downloads::390 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoTokenizer, pipeline
 
 tokenizer = AutoTokenizer.from_pretrained("ehdwns1516/klue-roberta-base-kornli")
 
 classifier = pipeline(
     "text-classification",
     model="ehdwns1516/klue-roberta-base-kornli",
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/esiebomajeremiah_autonlp-email-classification-657119381.py` & `mlagility-3.1.1/models/popular_on_huggingface/esiebomajeremiah_autonlp-email-classification-657119381.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::esiebomajeremiah name::autonlp-email-classification-657119381 downloads::1,890 task::Text_Classification
+# labels: test_group::monthly author::esiebomajeremiah name::autonlp-email-classification-657119381 downloads::1,890 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification, AutoTokenizer
 
 model = AutoModelForSequenceClassification.from_pretrained("esiebomajeremiah/autonlp-email-classification-657119381", use_auth_token=True)
 
 tokenizer = AutoTokenizer.from_pretrained("esiebomajeremiah/autonlp-email-classification-657119381", use_auth_token=True)
 
 inputs = tokenizer("I love AutoNLP", return_tensors="pt")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/etalab-ia_dpr-ctx_encoder-fr_qa-camembert.py` & `mlagility-3.1.1/models/popular_on_huggingface/etalab-ia_dpr-ctx_encoder-fr_qa-camembert.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::etalab-ia name::dpr-ctx_encoder-fr_qa-camembert task::unknown downloads::2,213
+# labels: test_group::monthly author::etalab-ia name::dpr-ctx_encoder-fr_qa-camembert task::Natural_Language_Processing downloads::2,213
 from transformers import AutoTokenizer, AutoModel
 query = "Salut, mon chien est-il mignon ?"
 tokenizer = AutoTokenizer.from_pretrained("etalab-ia/dpr-ctx_encoder-fr_qa-camembert",  do_lower_case=True)
 input_ids = tokenizer(query, return_tensors='pt')["input_ids"]
 model = AutoModel.from_pretrained("etalab-ia/dpr-ctx_encoder-fr_qa-camembert", return_dict=True)
 embeddings = model.forward(input_ids).pooler_output
 print(embeddings)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/etalab-ia_dpr-question_encoder-fr_qa-camembert.py` & `mlagility-3.1.1/models/popular_on_huggingface/etalab-ia_dpr-question_encoder-fr_qa-camembert.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::etalab-ia name::dpr-question_encoder-fr_qa-camembert downloads::2,145 task::Feature_Extraction
+# labels: test_group::monthly author::etalab-ia name::dpr-question_encoder-fr_qa-camembert downloads::2,145 task::Multimodal sub_task::Feature_Extraction
 from transformers import AutoTokenizer, AutoModel
 query = "Salut, mon chien est-il mignon ?"
 tokenizer = AutoTokenizer.from_pretrained("etalab-ia/dpr-question_encoder-fr_qa-camembert",  do_lower_case=True)
 input_ids = tokenizer(query, return_tensors='pt')["input_ids"]
 model = AutoModel.from_pretrained("etalab-ia/dpr-question_encoder-fr_qa-camembert", return_dict=True)
 embeddings = model.forward(input_ids).pooler_output
 print(embeddings)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/fabiochiu_t5-base-tag-generation.py` & `mlagility-3.1.1/models/popular_on_huggingface/fabiochiu_t5-base-tag-generation.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::fabiochiu name::t5-base-tag-generation downloads::189 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::fabiochiu name::t5-base-tag-generation downloads::189 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 import nltk
 nltk.download('punkt')
 
 tokenizer = AutoTokenizer.from_pretrained("fabiochiu/t5-base-tag-generation")
 model = AutoModelForSeq2SeqLM.from_pretrained("fabiochiu/t5-base-tag-generation")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_contriever-msmarco.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_contriever.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-# labels: test_group::monthly,daily author::facebook name::contriever-msmarco downloads::640,510 task::Feature_Extraction
+# labels: test_group::monthly,daily author::facebook name::contriever task::Natural_Language_Processing downloads::11,989
 import torch
 from transformers import AutoTokenizer, AutoModel
 
-tokenizer = AutoTokenizer.from_pretrained('facebook/contriever-msmarco')
-model = AutoModel.from_pretrained('facebook/contriever-msmarco')
+tokenizer = AutoTokenizer.from_pretrained('facebook/contriever')
+model = AutoModel.from_pretrained('facebook/contriever')
 
 sentences = [
     "Where was Marie Curie born?",
     "Maria Sklodowska, later known as Marie Curie, was born on November 7, 1867.",
     "Born in Paris on 15 May 1859, Pierre Curie was the son of Eugne Curie, a doctor of French Catholic origin from Alsace."
 ]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_contriever.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_contriever-msmarco.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-# labels: test_group::monthly,daily author::facebook name::contriever task::unknown downloads::11,989
+# labels: test_group::monthly,daily author::facebook name::contriever-msmarco downloads::640,510 task::Multimodal sub_task::Feature_Extraction
 import torch
 from transformers import AutoTokenizer, AutoModel
 
-tokenizer = AutoTokenizer.from_pretrained('facebook/contriever')
-model = AutoModel.from_pretrained('facebook/contriever')
+tokenizer = AutoTokenizer.from_pretrained('facebook/contriever-msmarco')
+model = AutoModel.from_pretrained('facebook/contriever-msmarco')
 
 sentences = [
     "Where was Marie Curie born?",
     "Maria Sklodowska, later known as Marie Curie, was born on November 7, 1867.",
     "Born in Paris on 15 May 1859, Pierre Curie was the son of Eugne Curie, a doctor of French Catholic origin from Alsace."
 ]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-base-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-base-224.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::convnext-base-224 downloads::1,195 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::convnext-base-224 downloads::1,195 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-base-384.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-base-384.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::convnext-base-384 downloads::503 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::convnext-base-384 downloads::503 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-large-224-22k-1k.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-large-224-22k-1k.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::convnext-large-224-22k-1k downloads::532 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::convnext-large-224-22k-1k downloads::532 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-small-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-xlarge-224-22k.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# labels: test_group::monthly,daily author::facebook name::convnext-small-224 downloads::1,084 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::convnext-xlarge-224-22k downloads::950 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
 
-feature_extractor = ConvNextFeatureExtractor.from_pretrained("facebook/convnext-small-224")
-model = ConvNextForImageClassification.from_pretrained("facebook/convnext-small-224")
+feature_extractor = ConvNextFeatureExtractor.from_pretrained("facebook/convnext-xlarge-224-22k")
+model = ConvNextForImageClassification.from_pretrained("facebook/convnext-xlarge-224-22k")
 
 inputs = feature_extractor(image, return_tensors="pt")
 
 with torch.no_grad():
     logits = model(**inputs).logits
 
-# model predicts one of the 1000 ImageNet classes
+# model predicts one of the 22k ImageNet classes
 predicted_label = logits.argmax(-1).item()
 print(model.config.id2label[predicted_label]),
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-tiny-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-tiny-224.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::convnext-tiny-224 downloads::7,627 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::convnext-tiny-224 downloads::7,627 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-xlarge-224-22k.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_convnext-xlarge-384-22k-1k.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# labels: test_group::monthly,daily author::facebook name::convnext-xlarge-224-22k downloads::950 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::convnext-xlarge-384-22k-1k downloads::1,487 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
 
-feature_extractor = ConvNextFeatureExtractor.from_pretrained("facebook/convnext-xlarge-224-22k")
-model = ConvNextForImageClassification.from_pretrained("facebook/convnext-xlarge-224-22k")
+feature_extractor = ConvNextFeatureExtractor.from_pretrained("facebook/convnext-xlarge-384-22k-1k")
+model = ConvNextForImageClassification.from_pretrained("facebook/convnext-xlarge-384-22k-1k")
 
 inputs = feature_extractor(image, return_tensors="pt")
 
 with torch.no_grad():
     logits = model(**inputs).logits
 
-# model predicts one of the 22k ImageNet classes
+# model predicts one of the 1000 ImageNet classes
 predicted_label = logits.argmax(-1).item()
 print(model.config.id2label[predicted_label]),
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_convnext-xlarge-384-22k-1k.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_resnet-152.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-# labels: test_group::monthly,daily author::facebook name::convnext-xlarge-384-22k-1k downloads::1,487 license::apache-2.0 task::Image_Classification
-from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification
+# labels: test_group::monthly,daily author::microsoft name::resnet-152 downloads::303 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
+from transformers import AutoFeatureExtractor, ResNetForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
 
-feature_extractor = ConvNextFeatureExtractor.from_pretrained("facebook/convnext-xlarge-384-22k-1k")
-model = ConvNextForImageClassification.from_pretrained("facebook/convnext-xlarge-384-22k-1k")
+feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/resnet-152")
+model = ResNetForImageClassification.from_pretrained("microsoft/resnet-152")
 
 inputs = feature_extractor(image, return_tensors="pt")
 
 with torch.no_grad():
     logits = model(**inputs).logits
 
 # model predicts one of the 1000 ImageNet classes
 predicted_label = logits.argmax(-1).item()
-print(model.config.id2label[predicted_label]),
+print(model.config.id2label[predicted_label])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_data2vec-vision-base-ft1k.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_data2vec-vision-base-ft1k.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::data2vec-vision-base-ft1k downloads::896 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::data2vec-vision-base-ft1k downloads::896 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import BeitFeatureExtractor, Data2VecVisionForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = BeitFeatureExtractor.from_pretrained('facebook/data2vec-vision-base-ft1k')
 model = Data2VecVisionForImageClassification.from_pretrained('facebook/data2vec-vision-base-ft1k')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-base-distilled-patch16-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-tiny-distilled-patch16-224.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,20 +1,14 @@
-# labels: test_group::monthly,daily author::facebook name::deit-base-distilled-patch16-224 downloads::3,896 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::deit-tiny-distilled-patch16-224 downloads::554 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, DeiTForImageClassificationWithTeacher
 from PIL import Image
 import requests
-
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-
-feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-base-distilled-patch16-224')
-model = DeiTForImageClassificationWithTeacher.from_pretrained('facebook/deit-base-distilled-patch16-224')
-
+feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-tiny-distilled-patch16-224')
+model = DeiTForImageClassificationWithTeacher.from_pretrained('facebook/deit-tiny-distilled-patch16-224')
 inputs = feature_extractor(images=image, return_tensors="pt")
-
-# forward pass
 outputs = model(**inputs)
 logits = outputs.logits
-
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-base-distilled-patch16-384.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-base-distilled-patch16-224.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,20 @@
-# labels: test_group::monthly,daily author::facebook name::deit-base-distilled-patch16-384 downloads::1,089 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::deit-base-distilled-patch16-224 downloads::3,896 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, DeiTForImageClassificationWithTeacher
 from PIL import Image
 import requests
+
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-base-distilled-patch16-384')
-model = DeiTForImageClassificationWithTeacher.from_pretrained('facebook/deit-base-distilled-patch16-384')
+
+feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-base-distilled-patch16-224')
+model = DeiTForImageClassificationWithTeacher.from_pretrained('facebook/deit-base-distilled-patch16-224')
+
 inputs = feature_extractor(images=image, return_tensors="pt")
+
+# forward pass
 outputs = model(**inputs)
 logits = outputs.logits
+
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-base-patch16-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-base-patch16-224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::deit-base-patch16-224 downloads::1,627 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::deit-base-patch16-224 downloads::1,627 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, ViTForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-base-patch16-224')
 model = ViTForImageClassification.from_pretrained('facebook/deit-base-patch16-224')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-base-patch16-384.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_vit-large-patch16-224.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly,daily author::facebook name::deit-base-patch16-384 downloads::249 license::apache-2.0 task::Image_Classification
-from transformers import AutoFeatureExtractor, ViTForImageClassification
+# labels: test_group::monthly,daily author::google name::vit-large-patch16-224 downloads::607 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
+from transformers import ViTFeatureExtractor, ViTForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-base-patch16-384')
-model = ViTForImageClassification.from_pretrained('facebook/deit-base-patch16-384')
+feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch16-224')
+model = ViTForImageClassification.from_pretrained('google/vit-large-patch16-224')
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-small-distilled-patch16-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-small-patch16-224.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly,daily author::facebook name::deit-small-distilled-patch16-224 downloads::4,774 license::apache-2.0 task::Image_Classification
-from transformers import AutoFeatureExtractor, DeiTForImageClassificationWithTeacher
+# labels: test_group::monthly,daily author::facebook name::deit-small-patch16-224 downloads::2,221 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
+from transformers import AutoFeatureExtractor, ViTForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-small-distilled-patch16-224')
-model = DeiTForImageClassificationWithTeacher.from_pretrained('facebook/deit-small-distilled-patch16-224')
+feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-small-patch16-224')
+model = ViTForImageClassification.from_pretrained('facebook/deit-small-patch16-224')
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-small-patch16-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-tiny-patch16-224.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly,daily author::facebook name::deit-small-patch16-224 downloads::2,221 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::deit-tiny-patch16-224 downloads::1,605 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, ViTForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-small-patch16-224')
-model = ViTForImageClassification.from_pretrained('facebook/deit-small-patch16-224')
+feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-tiny-patch16-224')
+model = ViTForImageClassification.from_pretrained('facebook/deit-tiny-patch16-224')
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-tiny-distilled-patch16-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_deit-small-distilled-patch16-224.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly,daily author::facebook name::deit-tiny-distilled-patch16-224 downloads::554 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::deit-small-distilled-patch16-224 downloads::4,774 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, DeiTForImageClassificationWithTeacher
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-tiny-distilled-patch16-224')
-model = DeiTForImageClassificationWithTeacher.from_pretrained('facebook/deit-tiny-distilled-patch16-224')
+feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-small-distilled-patch16-224')
+model = DeiTForImageClassificationWithTeacher.from_pretrained('facebook/deit-small-distilled-patch16-224')
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_deit-tiny-patch16-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_vit-mae-base.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,14 +1,16 @@
-# labels: test_group::monthly,daily author::facebook name::deit-tiny-patch16-224 downloads::1,605 license::apache-2.0 task::Image_Classification
-from transformers import AutoFeatureExtractor, ViTForImageClassification
+# labels: test_group::monthly,daily author::facebook name::vit-mae-base task::Computer_Vision downloads::11,994 license::apache-2.0
+from transformers import AutoFeatureExtractor, ViTMAEForPreTraining
 from PIL import Image
 import requests
+
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-tiny-patch16-224')
-model = ViTForImageClassification.from_pretrained('facebook/deit-tiny-patch16-224')
+
+feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/vit-mae-base')
+model = ViTMAEForPreTraining.from_pretrained('facebook/vit-mae-base')
+
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
-logits = outputs.logits
-# model predicts one of the 1000 ImageNet classes
-predicted_class_idx = logits.argmax(-1).item()
-print("Predicted class:", model.config.id2label[predicted_class_idx])
+loss = outputs.loss
+mask = outputs.mask
+ids_restore = outputs.ids_restore
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_detr-resnet-50-panoptic.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_detr-resnet-50-panoptic.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::facebook name::detr-resnet-50-panoptic downloads::51,551 license::apache-2.0 task::Image_Segmentation
+# labels: test_group::monthly author::facebook name::detr-resnet-50-panoptic downloads::51,551 license::apache-2.0 task::Computer_Vision sub_task::Image_Segmentation
 import io
 import requests
 from PIL import Image
 import torch
 import numpy
 
 from transformers import DetrFeatureExtractor, DetrForSegmentation
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_detr-resnet-50.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_detr-resnet-50.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::facebook name::detr-resnet-50 downloads::61,308 license::apache-2.0 task::Object_Detection
+# labels: test_group::monthly author::facebook name::detr-resnet-50 downloads::61,308 license::apache-2.0 task::Computer_Vision sub_task::Object_Detection
 from transformers import DetrFeatureExtractor, DetrForObjectDetection
 import torch
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_dino-vitb16.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_dino-vitb16.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::dino-vitb16 downloads::5,486 license::apache-2.0 task::Feature_Extraction
+# labels: test_group::monthly,daily author::facebook name::dino-vitb16 downloads::5,486 license::apache-2.0 task::Multimodal sub_task::Feature_Extraction
 from transformers import ViTFeatureExtractor, ViTModel
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_dino-vitb8.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_dino-vitb8.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::dino-vitb8 downloads::631 license::apache-2.0 task::Feature_Extraction
+# labels: test_group::monthly,daily author::facebook name::dino-vitb8 downloads::631 license::apache-2.0 task::Multimodal sub_task::Feature_Extraction
 from transformers import ViTFeatureExtractor, ViTModel
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_dino-vits16.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_dino-vits16.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::dino-vits16 downloads::352 license::apache-2.0 task::Feature_Extraction
+# labels: test_group::monthly,daily author::facebook name::dino-vits16 downloads::352 license::apache-2.0 task::Multimodal sub_task::Feature_Extraction
 from transformers import ViTFeatureExtractor, ViTModel
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_dino-vits8.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_dino-vits8.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::dino-vits8 downloads::291 license::apache-2.0 task::Feature_Extraction
+# labels: test_group::monthly,daily author::facebook name::dino-vits8 downloads::291 license::apache-2.0 task::Multimodal sub_task::Feature_Extraction
 from transformers import ViTFeatureExtractor, ViTModel
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_flava-full.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_flava-full.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::flava-full task::unknown downloads::5,282 license::bsd-3-clause
+# labels: test_group::monthly,daily author::facebook name::flava-full task::MultiModal downloads::5,282 license::bsd-3-clause
 from PIL import Image
 import requests
 
 from transformers import FlavaProcessor, FlavaModel
 
 model = FlavaModel.from_pretrained("facebook/flava-full")
 processor = FlavaProcessor.from_pretrained("facebook/flava-full")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_levit-128S.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_levit-128S.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::levit-128S downloads::1,379 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::levit-128S downloads::1,379 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import LevitFeatureExtractor, LevitForImageClassificationWithTeacher
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_maskformer-swin-base-ade.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_maskformer-swin-base-coco.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::maskformer-swin-base-ade downloads::915 license::apache-2.0 task::Image_Segmentation
+# labels: test_group::monthly,daily author::facebook name::maskformer-swin-base-coco downloads::2,485 license::apache-2.0 task::Computer_Vision sub_task::Image_Segmentation
 from transformers import MaskFormerFeatureExtractor, MaskFormerForInstanceSegmentation
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = MaskFormerFeatureExtractor.from_pretrained("facebook/maskformer-swin-base-ade")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_maskformer-swin-base-coco.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_maskformer-swin-small-coco.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::maskformer-swin-base-coco downloads::2,485 license::apache-2.0 task::Image_Segmentation
+# labels: test_group::monthly,daily author::facebook name::maskformer-swin-small-coco downloads::644 license::apache-2.0 task::Computer_Vision sub_task::Image_Segmentation
 from transformers import MaskFormerFeatureExtractor, MaskFormerForInstanceSegmentation
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = MaskFormerFeatureExtractor.from_pretrained("facebook/maskformer-swin-base-ade")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_maskformer-swin-large-ade.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_maskformer-swin-tiny-ade.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::facebook name::maskformer-swin-large-ade downloads::201 license::apache-2.0 task::Image_Segmentation
+# labels: test_group::monthly,daily author::facebook name::maskformer-swin-tiny-ade downloads::957 license::apache-2.0 task::Computer_Vision sub_task::Image_Segmentation
 from transformers import MaskFormerFeatureExtractor, MaskFormerForInstanceSegmentation
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = MaskFormerFeatureExtractor.from_pretrained("facebook/maskformer-swin-base-ade")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_maskformer-swin-small-coco.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_maskformer-swin-base-ade.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::maskformer-swin-small-coco downloads::644 license::apache-2.0 task::Image_Segmentation
+# labels: test_group::monthly,daily author::facebook name::maskformer-swin-base-ade downloads::915 license::apache-2.0 task::Computer_Vision sub_task::Image_Segmentation
 from transformers import MaskFormerFeatureExtractor, MaskFormerForInstanceSegmentation
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = MaskFormerFeatureExtractor.from_pretrained("facebook/maskformer-swin-base-ade")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_maskformer-swin-tiny-ade.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_maskformer-swin-large-ade.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::maskformer-swin-tiny-ade downloads::957 license::apache-2.0 task::Image_Segmentation
+# labels: test_group::monthly author::facebook name::maskformer-swin-large-ade downloads::201 license::apache-2.0 task::Computer_Vision sub_task::Image_Segmentation
 from transformers import MaskFormerFeatureExtractor, MaskFormerForInstanceSegmentation
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = MaskFormerFeatureExtractor.from_pretrained("facebook/maskformer-swin-base-ade")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_mbart-large-50.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_mbart-large-50.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::mbart-large-50 downloads::750,716 license::mit task::Text2Text_Generation
+# labels: test_group::monthly,daily author::facebook name::mbart-large-50 downloads::750,716 license::mit task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import MBartForConditionalGeneration, MBart50TokenizerFast
 
 model = MBartForConditionalGeneration.from_pretrained("facebook/mbart-large-50")
 tokenizer = MBart50TokenizerFast.from_pretrained("facebook/mbart-large-50", src_lang="en_XX", tgt_lang="ro_RO")
 
 src_text = " UN Chief Says There Is No Military Solution in Syria"
 tgt_text =  "eful ONU declar c nu exist o soluie militar n Siria"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_regnet-y-040.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_regnet-y-040.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::facebook name::regnet-y-040 downloads::694 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::facebook name::regnet-y-040 downloads::694 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, RegNetForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_vit-mae-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/facebook_vit-mae-large.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# labels: test_group::monthly,daily author::facebook name::vit-mae-base task::unknown downloads::11,994 license::apache-2.0
+# labels: test_group::monthly,daily author::facebook name::vit-mae-large task::Computer_Vision downloads::5,655 license::apache-2.0
 from transformers import AutoFeatureExtractor, ViTMAEForPreTraining
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/vit-mae-base')
-model = ViTMAEForPreTraining.from_pretrained('facebook/vit-mae-base')
+feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/vit-mae-large')
+model = ViTMAEForPreTraining.from_pretrained('facebook/vit-mae-large')
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 loss = outputs.loss
 mask = outputs.mask
 ids_restore = outputs.ids_restore
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/facebook_vit-mae-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_vit-large-patch32-224-in21k.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,16 +1,11 @@
-# labels: test_group::monthly,daily author::facebook name::vit-mae-large task::unknown downloads::5,655 license::apache-2.0
-from transformers import AutoFeatureExtractor, ViTMAEForPreTraining
+# labels: test_group::monthly,daily author::google name::vit-large-patch32-224-in21k downloads::882 license::apache-2.0 task::Multimodal sub_task::Feature_Extraction
+from transformers import ViTFeatureExtractor, ViTModel
 from PIL import Image
 import requests
-
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-
-feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/vit-mae-large')
-model = ViTMAEForPreTraining.from_pretrained('facebook/vit-mae-large')
-
+feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')
+model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
-loss = outputs.loss
-mask = outputs.mask
-ids_restore = outputs.ids_restore
+last_hidden_state = outputs.last_hidden_state
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/flax-community_clip-rsicd-v2.py` & `mlagility-3.1.1/models/popular_on_huggingface/flax-community_clip-rsicd-v2.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::flax-community name::clip-rsicd-v2 downloads::439 task::Zero-Shot_Image_Classification
+# labels: test_group::monthly author::flax-community name::clip-rsicd-v2 downloads::439 task::Computer_Vision sub_task::Zero-Shot_Image_Classification
 from PIL import Image
 import requests
 
 from transformers import CLIPProcessor, CLIPModel
 
 model = CLIPModel.from_pretrained("flax-community/clip-rsicd-v2")
 processor = CLIPProcessor.from_pretrained("flax-community/clip-rsicd-v2")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/flax-community_t5-large-wikisplit.py` & `mlagility-3.1.1/models/popular_on_huggingface/flax-community_t5-large-wikisplit.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::flax-community name::t5-large-wikisplit downloads::5,896 task::Text2Text_Generation
+# labels: test_group::monthly author::flax-community name::t5-large-wikisplit downloads::5,896 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 tokenizer = AutoTokenizer.from_pretrained("flax-community/t5-large-wikisplit")
 model = AutoModelForSeq2SeqLM.from_pretrained("flax-community/t5-large-wikisplit")
 complex_sentence = "This comedy drama is produced by Tidy , the company she co-founded in 2008 with her husband David Peet , who is managing director ."
 sample_tokenized = tokenizer(complex_sentence, return_tensors="pt")
 answer = model.generate(sample_tokenized['input_ids'], attention_mask = sample_tokenized['attention_mask'], max_length=256, num_beams=5)
 gene_sentence = tokenizer.decode(answer[0], skip_special_tokens=True)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/flax-sentence-embeddings_all_datasets_v3_roberta-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/flax-sentence-embeddings_all_datasets_v4_MiniLM-L6.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-# labels: test_group::monthly author::flax-sentence-embeddings name::all_datasets_v3_roberta-large downloads::319 task::Sentence_Similarity
+# labels: test_group::monthly author::flax-sentence-embeddings name::all_datasets_v4_MiniLM-L6 downloads::8,563 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer
 
-model = SentenceTransformer('flax-sentence-embeddings/all_datasets_v3_roberta-large')
+model = SentenceTransformer('flax-sentence-embeddings/all_datasets_v4_MiniLM-L6')
 text = "Replace me by any text you'd like."
 text_embbedding = model.encode(text)
 # array([-0.01559514,  0.04046123,  0.1317083 ,  0.00085931,  0.04585106,
 #        -0.05607086,  0.0138078 ,  0.03569756,  0.01420381,  0.04266302 ...],
 #        dtype=float32)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/flax-sentence-embeddings_st-codesearch-distilroberta-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/flax-sentence-embeddings_st-codesearch-distilroberta-base.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::flax-sentence-embeddings name::st-codesearch-distilroberta-base downloads::853 task::Sentence_Similarity
+# labels: test_group::monthly author::flax-sentence-embeddings name::st-codesearch-distilroberta-base downloads::853 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer, util
 
 
 #This list the defines the different programm codes
 code = ["""def sort_list(x):
    return sorted(x)""",
 """def count_above_threshold(elements, threshold=0):
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/flax-sentence-embeddings_stackoverflow_mpnet-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/flax-sentence-embeddings_stackoverflow_mpnet-base.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::flax-sentence-embeddings name::stackoverflow_mpnet-base downloads::2,520 task::Sentence_Similarity
+# labels: test_group::monthly author::flax-sentence-embeddings name::stackoverflow_mpnet-base downloads::2,520 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer
 
 model = SentenceTransformer('flax-sentence-embeddings/stackoverflow_mpnet-base')
 text = "Replace me by any question / answer you'd like."
 text_embbedding = model.encode(text)
 # array([-0.01559514,  0.04046123,  0.1317083 ,  0.00085931,  0.04585106,
 #        -0.05607086,  0.0138078 ,  0.03569756,  0.01420381,  0.04266302 ...],
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/flexudy_t5-base-multi-sentence-doctor.py` & `mlagility-3.1.1/models/popular_on_huggingface/flexudy_t5-base-multi-sentence-doctor.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::flexudy name::t5-base-multi-sentence-doctor downloads::206,333 task::Text2Text_Generation
+# labels: test_group::monthly author::flexudy name::t5-base-multi-sentence-doctor downloads::206,333 task::Natural_Language_Processing sub_task::Text2Text_Generation
 
 from transformers import AutoTokenizer, AutoModelWithLMHead
 
 tokenizer = AutoTokenizer.from_pretrained("flexudy/t5-base-multi-sentence-doctor")
 
 model = AutoModelWithLMHead.from_pretrained("flexudy/t5-base-multi-sentence-doctor")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/flexudy_t5-small-wav2vec2-grammar-fixer.py` & `mlagility-3.1.1/models/popular_on_huggingface/flexudy_t5-small-wav2vec2-grammar-fixer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::flexudy name::t5-small-wav2vec2-grammar-fixer task::unknown downloads::486
+# labels: test_group::monthly author::flexudy name::t5-small-wav2vec2-grammar-fixer task::Natural_Language_Processing downloads::486
 from transformers import T5Tokenizer, T5ForConditionalGeneration
 
 model_name = "flexudy/t5-small-wav2vec2-grammar-fixer"
 
 tokenizer = T5Tokenizer.from_pretrained(model_name)
 
 model = T5ForConditionalGeneration.from_pretrained(model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/fran-martinez_scibert_scivocab_cased_ner_jnlpba.py` & `mlagility-3.1.1/models/popular_on_huggingface/fran-martinez_scibert_scivocab_cased_ner_jnlpba.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::fran-martinez name::scibert_scivocab_cased_ner_jnlpba downloads::10,836 task::Token_Classification
+# labels: test_group::monthly author::fran-martinez name::scibert_scivocab_cased_ner_jnlpba downloads::10,836 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import pipeline
 
 text = "Mouse thymus was used as a source of glucocorticoid receptor from normal CS lymphocytes."
 
 nlp_ner = pipeline("ner",
                    model='fran-martinez/scibert_scivocab_cased_ner_jnlpba',
                    tokenizer='fran-martinez/scibert_scivocab_cased_ner_jnlpba')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/gerulata_slovakbert.py` & `mlagility-3.1.1/models/popular_on_huggingface/gerulata_slovakbert.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::gerulata name::slovakbert downloads::1,284 license::mit task::Fill-Mask
+# labels: test_group::monthly author::gerulata name::slovakbert downloads::1,284 license::mit task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import pipeline
 unmasker = pipeline('fill-mask', model='gerulata/slovakbert')
 unmasker("Deti sa <mask> na ihrisku.")
 
 [{'sequence': 'Deti sa hrali na ihrisku.',
   'score': 0.6355380415916443,
   'token': 5949,
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/gilf_french-camembert-postag-model.py` & `mlagility-3.1.1/models/popular_on_huggingface/gilf_french-camembert-postag-model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::gilf name::french-camembert-postag-model downloads::459 task::Token_Classification
+# labels: test_group::monthly author::gilf name::french-camembert-postag-model downloads::459 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 
 tokenizer = AutoTokenizer.from_pretrained("gilf/french-camembert-postag-model")
 model = AutoModelForTokenClassification.from_pretrained("gilf/french-camembert-postag-model")
 
 from transformers import pipeline
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/gilf_french-postag-model.py` & `mlagility-3.1.1/models/popular_on_huggingface/gilf_french-postag-model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::gilf name::french-postag-model downloads::737 task::Token_Classification
+# labels: test_group::monthly author::gilf name::french-postag-model downloads::737 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 
 tokenizer = AutoTokenizer.from_pretrained("gilf/french-postag-model")
 model = AutoModelForTokenClassification.from_pretrained("gilf/french-postag-model")
 
 from transformers import pipeline
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_bert2bert_L-24_wmt_de_en.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_bert2bert_L-24_wmt_de_en.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::bert2bert_L-24_wmt_de_en downloads::1,524 license::apache-2.0 task::Translation
+# labels: test_group::monthly,daily author::google name::bert2bert_L-24_wmt_de_en downloads::1,524 license::apache-2.0 task::Natural_Language_Processing sub_task::Translation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 tokenizer = AutoTokenizer.from_pretrained("google/bert2bert_L-24_wmt_de_en", pad_token="<pad>", eos_token="</s>", bos_token="<s>")
 model = AutoModelForSeq2SeqLM.from_pretrained("google/bert2bert_L-24_wmt_de_en")
 
 sentence = "Willst du einen Kaffee trinken gehen mit mir?"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_byt5-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_byt5-base.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::byt5-base downloads::3,256 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly,daily author::google name::byt5-base downloads::3,256 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5ForConditionalGeneration
 import torch
 
 model = T5ForConditionalGeneration.from_pretrained('google/byt5-base')
 
 input_ids = torch.tensor([list("Life is like a box of chocolates.".encode("utf-8"))]) + 3  # add 3 for special tokens
 labels = torch.tensor([list("La vie est comme une bote de chocolat.".encode("utf-8"))]) + 3  # add 3 for special tokens
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_byt5-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_byt5-large.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::byt5-large downloads::780 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly,daily author::google name::byt5-large downloads::780 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5ForConditionalGeneration
 import torch
 
 model = T5ForConditionalGeneration.from_pretrained('google/byt5-large')
 
 input_ids = torch.tensor([list("Life is like a box of chocolates.".encode("utf-8"))]) + 3  # add 3 for special tokens
 labels = torch.tensor([list("La vie est comme une bote de chocolat.".encode("utf-8"))]) + 3  # add 3 for special tokens
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_canine-s.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_canine-s.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::canine-s downloads::10,734 license::apache-2.0 task::Feature_Extraction
+# labels: test_group::monthly,daily author::google name::canine-s downloads::10,734 license::apache-2.0 task::Multimodal sub_task::Feature_Extraction
 from transformers import CanineTokenizer, CanineModel
 
 model = CanineModel.from_pretrained('google/canine-s')
 tokenizer = CanineTokenizer.from_pretrained('google/canine-s')
 
 inputs = ["Life is like a box of chocolates.", "You never know what you gonna get."]
 encoding = tokenizer(inputs, padding="longest", truncation=True, return_tensors="pt")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_ddpm-celebahq-256.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_ddpm-cifar10-32.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,12 +1,12 @@
-# labels: test_group::monthly,daily author::google name::ddpm-celebahq-256 downloads::1,827 license::apache-2.0 task::Unconditional_Image_Generation
+# labels: test_group::monthly,daily author::google name::ddpm-cifar10-32 downloads::1,945 license::apache-2.0 task::Computer_Vision sub_task::Unconditional_Image_Generation
 # !pip install diffusers
 from diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline
 
-model_id = "google/ddpm-celebahq-256"
+model_id = "google/ddpm-cifar10-32"
 
 # load model and scheduler
 ddpm = DDPMPipeline.from_pretrained(model_id)  # you can replace DDPMPipeline with DDIMPipeline or PNDMPipeline for faster inference
 
 # run pipeline in inference (sample random noise and denoise)
 image = ddpm()["sample"]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_ddpm-cifar10-32.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_ddpm-celebahq-256.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,12 +1,12 @@
-# labels: test_group::monthly,daily author::google name::ddpm-cifar10-32 downloads::1,945 license::apache-2.0 task::Unconditional_Image_Generation
+# labels: test_group::monthly,daily author::google name::ddpm-celebahq-256 downloads::1,827 license::apache-2.0 task::Computer_Vision sub_task::Unconditional_Image_Generation
 # !pip install diffusers
 from diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline
 
-model_id = "google/ddpm-cifar10-32"
+model_id = "google/ddpm-celebahq-256"
 
 # load model and scheduler
 ddpm = DDPMPipeline.from_pretrained(model_id)  # you can replace DDPMPipeline with DDIMPipeline or PNDMPipeline for faster inference
 
 # run pipeline in inference (sample random noise and denoise)
 image = ddpm()["sample"]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_electra-base-discriminator.py` & `mlagility-3.1.1/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-# labels: test_group::monthly,daily author::google name::electra-base-discriminator task::unknown downloads::179,212 license::apache-2.0
+# labels: test_group::monthly author::kamalkraj name::bioelectra-base-discriminator-pubmed task::Natural_Language_Processing downloads::2,171
 from transformers import ElectraForPreTraining, ElectraTokenizerFast
 import torch
 
-discriminator = ElectraForPreTraining.from_pretrained("google/electra-base-discriminator")
-tokenizer = ElectraTokenizerFast.from_pretrained("google/electra-base-discriminator")
+discriminator = ElectraForPreTraining.from_pretrained("kamalkraj/bioelectra-base-discriminator-pubmed")
+tokenizer = ElectraTokenizerFast.from_pretrained("kamalkraj/bioelectra-base-discriminator-pubmed")
 
 sentence = "The quick brown fox jumps over the lazy dog"
 fake_sentence = "The quick brown fox fake over the lazy dog"
 
 fake_tokens = tokenizer.tokenize(fake_sentence)
 fake_inputs = tokenizer.encode(fake_sentence, return_tensors="pt")
 discriminator_outputs = discriminator(fake_inputs)
 predictions = torch.round((torch.sign(discriminator_outputs[0]) + 1) / 2)
 
 [print("%7s" % token, end="") for token in fake_tokens]
 
-[print("%7s" % int(prediction), end="") for prediction in predictions.tolist()]
+[print("%7s" % int(prediction), end="") for prediction in predictions[0].tolist()]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_electra-large-discriminator.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_electra-large-discriminator.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::electra-large-discriminator task::unknown downloads::46,237 license::apache-2.0
+# labels: test_group::monthly,daily author::google name::electra-large-discriminator task::Natural_Language_Processing downloads::46,237 license::apache-2.0
 from transformers import ElectraForPreTraining, ElectraTokenizerFast
 import torch
 
 discriminator = ElectraForPreTraining.from_pretrained("google/electra-large-discriminator")
 tokenizer = ElectraTokenizerFast.from_pretrained("google/electra-large-discriminator")
 
 sentence = "The quick brown fox jumps over the lazy dog"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_electra-small-discriminator.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_electra-small-discriminator.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::electra-small-discriminator task::unknown downloads::446,832 license::apache-2.0
+# labels: test_group::monthly,daily author::google name::electra-small-discriminator task::Natural_Language_Processing downloads::446,832 license::apache-2.0
 from transformers import ElectraForPreTraining, ElectraTokenizerFast
 import torch
 
 discriminator = ElectraForPreTraining.from_pretrained("google/electra-small-discriminator")
 tokenizer = ElectraTokenizerFast.from_pretrained("google/electra-small-discriminator")
 
 sentence = "The quick brown fox jumps over the lazy dog"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_owlvit-base-patch16.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_owlvit-base-patch16.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::owlvit-base-patch16 downloads::2,261 license::apache-2.0 task::Object_Detection
+# labels: test_group::monthly,daily author::google name::owlvit-base-patch16 downloads::2,261 license::apache-2.0 task::Computer_Vision sub_task::Object_Detection
 import requests
 from PIL import Image
 import torch
 
 from transformers import OwlViTProcessor, OwlViTForObjectDetection
 
 processor = OwlViTProcessor.from_pretrained("google/owlvit-base-patch16")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_owlvit-base-patch32.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_owlvit-large-patch14.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# labels: test_group::monthly,daily author::google name::owlvit-base-patch32 downloads::10,221 license::apache-2.0 task::Object_Detection
+# labels: test_group::monthly,daily author::google name::owlvit-large-patch14 downloads::2,642 license::apache-2.0 task::Computer_Vision sub_task::Object_Detection
 import requests
 from PIL import Image
 import torch
 
 from transformers import OwlViTProcessor, OwlViTForObjectDetection
 
-processor = OwlViTProcessor.from_pretrained("google/owlvit-base-patch32")
-model = OwlViTForObjectDetection.from_pretrained("google/owlvit-base-patch32")
+processor = OwlViTProcessor.from_pretrained("google/owlvit-large-patch14")
+model = OwlViTForObjectDetection.from_pretrained("google/owlvit-large-patch14")
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 texts = [["a photo of a cat", "a photo of a dog"]]
 inputs = processor(text=texts, images=image, return_tensors="pt")
 outputs = model(**inputs)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_owlvit-large-patch14.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_owlvit-base-patch32.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# labels: test_group::monthly,daily author::google name::owlvit-large-patch14 downloads::2,642 license::apache-2.0 task::Object_Detection
+# labels: test_group::monthly,daily author::google name::owlvit-base-patch32 downloads::10,221 license::apache-2.0 task::Computer_Vision sub_task::Object_Detection
 import requests
 from PIL import Image
 import torch
 
 from transformers import OwlViTProcessor, OwlViTForObjectDetection
 
-processor = OwlViTProcessor.from_pretrained("google/owlvit-large-patch14")
-model = OwlViTForObjectDetection.from_pretrained("google/owlvit-large-patch14")
+processor = OwlViTProcessor.from_pretrained("google/owlvit-base-patch32")
+model = OwlViTForObjectDetection.from_pretrained("google/owlvit-base-patch32")
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 texts = [["a photo of a cat", "a photo of a dog"]]
 inputs = processor(text=texts, images=image, return_tensors="pt")
 outputs = model(**inputs)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_roberta2roberta_L-24_bbc.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_roberta2roberta_L-24_bbc.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::google name::roberta2roberta_L-24_bbc downloads::322 license::apache-2.0 task::Summarization
+# labels: test_group::monthly author::google name::roberta2roberta_L-24_bbc downloads::322 license::apache-2.0 task::Natural_Language_Processing sub_task::Summarization
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 tokenizer = AutoTokenizer.from_pretrained("google/roberta2roberta_L-24_bbc")
 model = AutoModelForSeq2SeqLM.from_pretrained("google/roberta2roberta_L-24_bbc")
 
 article = """The problem is affecting people using the older
 versions of the PlayStation 3, called the "Fat"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_roberta2roberta_L-24_cnn_daily_mail.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_roberta2roberta_L-24_cnn_daily_mail.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::google name::roberta2roberta_L-24_cnn_daily_mail downloads::1,552 license::apache-2.0 task::Summarization
+# labels: test_group::monthly author::google name::roberta2roberta_L-24_cnn_daily_mail downloads::1,552 license::apache-2.0 task::Natural_Language_Processing sub_task::Summarization
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 tokenizer = AutoTokenizer.from_pretrained("google/roberta2roberta_L-24_cnn_daily_mail")
 model = AutoModelForSeq2SeqLM.from_pretrained("google/roberta2roberta_L-24_cnn_daily_mail")
 
 article = """	(The Hollywood Reporter)"The Rocky Horror Picture
 Show" is the latest musical getting the small-
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_roberta2roberta_L-24_discofuse.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_roberta2roberta_L-24_discofuse.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::google name::roberta2roberta_L-24_discofuse downloads::268 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::google name::roberta2roberta_L-24_discofuse downloads::268 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 tokenizer = AutoTokenizer.from_pretrained("google/roberta2roberta_L-24_discofuse")
 model = AutoModelForSeq2SeqLM.from_pretrained("google/roberta2roberta_L-24_discofuse")
 
 discofuse = """As a run-blocker, Zeitler moves relatively well. Zeitler often struggles at the point of contact in space."""
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_t5-small-ssm-nq.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_t5-small-ssm-nq.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::t5-small-ssm-nq downloads::2,505 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly,daily author::google name::t5-small-ssm-nq downloads::2,505 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
 
 t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained("google/t5-small-ssm-nq")
 t5_tok = AutoTokenizer.from_pretrained("google/t5-small-ssm-nq")
 
 input_ids = t5_tok("When was Franklin D. Roosevelt born?", return_tensors="pt").input_ids
 gen_output = t5_qa_model.generate(input_ids)[0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-base-patch16-224-in21k.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-base-patch16-224-pt22k.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly,daily author::google name::vit-base-patch16-224-in21k downloads::614,852 license::apache-2.0 task::Feature_Extraction
-from transformers import ViTFeatureExtractor, ViTModel
+# labels: test_group::monthly,daily author::microsoft name::beit-base-patch16-224-pt22k downloads::1,999 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
+from transformers import BeitFeatureExtractor, BeitForMaskedImageModeling
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')
-model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')
-inputs = feature_extractor(images=image, return_tensors="pt")
+feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224-pt22k')
+model = BeitForMaskedImageModeling.from_pretrained('microsoft/beit-base-patch16-224-pt22k')
 
+inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
-last_hidden_states = outputs.last_hidden_state
+logits = outputs.logits
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-base-patch16-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_vit-base-patch16-384.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,14 @@
-# labels: test_group::monthly,daily author::google name::vit-base-patch16-224 downloads::1,305,984 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::google name::vit-base-patch16-384 downloads::7,771 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ViTFeatureExtractor, ViTForImageClassification
 from PIL import Image
 import requests
-
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-
-feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')
-model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')
-
+feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-384')
+model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-384')
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-base-patch16-384.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-base-patch16-384.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly,daily author::google name::vit-base-patch16-384 downloads::7,771 license::apache-2.0 task::Image_Classification
-from transformers import ViTFeatureExtractor, ViTForImageClassification
+# labels: test_group::monthly,daily author::microsoft name::beit-base-patch16-384 downloads::2,193 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
+from transformers import BeitFeatureExtractor, BeitForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-384')
-model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-384')
+feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-384')
+model = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-384')
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-base-patch32-224-in21k.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_vit-base-patch32-224-in21k.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::vit-base-patch32-224-in21k downloads::3,348 license::apache-2.0 task::Feature_Extraction
+# labels: test_group::monthly,daily author::google name::vit-base-patch32-224-in21k downloads::3,348 license::apache-2.0 task::Multimodal sub_task::Feature_Extraction
 from transformers import ViTFeatureExtractor, ViTModel
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch32-224-in21k')
 model = ViTModel.from_pretrained('google/vit-base-patch32-224-in21k')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-base-patch32-384.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_vit-base-patch32-384.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::vit-base-patch32-384 downloads::1,806 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::google name::vit-base-patch32-384 downloads::1,806 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ViTFeatureExtractor, ViTForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch32-384')
 model = ViTForImageClassification.from_pretrained('google/vit-base-patch32-384')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-huge-patch14-224-in21k.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_vit-huge-patch14-224-in21k.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::vit-huge-patch14-224-in21k downloads::927 license::apache-2.0 task::Feature_Extraction
+# labels: test_group::monthly,daily author::google name::vit-huge-patch14-224-in21k downloads::927 license::apache-2.0 task::Multimodal sub_task::Feature_Extraction
 from transformers import ViTFeatureExtractor, ViTModel
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-huge-patch14-224-in21k')
 model = ViTModel.from_pretrained('google/vit-huge-patch14-224-in21k')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-large-patch16-224-in21k.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_vit-large-patch16-224-in21k.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::vit-large-patch16-224-in21k downloads::642 license::apache-2.0 task::Feature_Extraction
+# labels: test_group::monthly,daily author::google name::vit-large-patch16-224-in21k downloads::642 license::apache-2.0 task::Multimodal sub_task::Feature_Extraction
 from transformers import ViTFeatureExtractor, ViTModel
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch16-224-in21k')
 model = ViTModel.from_pretrained('google/vit-large-patch16-224-in21k')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-large-patch16-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_vit-base-patch16-224.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,17 @@
-# labels: test_group::monthly,daily author::google name::vit-large-patch16-224 downloads::607 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::google name::vit-base-patch16-224 downloads::1,305,984 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ViTFeatureExtractor, ViTForImageClassification
 from PIL import Image
 import requests
+
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch16-224')
-model = ViTForImageClassification.from_pretrained('google/vit-large-patch16-224')
+
+feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')
+model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')
+
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-large-patch16-384.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_vit-large-patch16-384.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::vit-large-patch16-384 downloads::684 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::google name::vit-large-patch16-384 downloads::684 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ViTFeatureExtractor, ViTForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch16-384')
 model = ViTForImageClassification.from_pretrained('google/vit-large-patch16-384')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-large-patch32-224-in21k.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-large-patch16-224-pt22k.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,11 +1,14 @@
-# labels: test_group::monthly,daily author::google name::vit-large-patch32-224-in21k downloads::882 license::apache-2.0 task::Feature_Extraction
-from transformers import ViTFeatureExtractor, ViTModel
+# labels: test_group::monthly,daily author::microsoft name::beit-large-patch16-224-pt22k downloads::542 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
+from transformers import BeitFeatureExtractor, BeitForMaskedImageModeling
 from PIL import Image
 import requests
+
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')
-model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')
+
+feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-large-patch16-224-pt22k')
+model = BeitForMaskedImageModeling.from_pretrained('microsoft/beit-large-patch16-224-pt22k')
+
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
-last_hidden_state = outputs.last_hidden_state
+logits = outputs.logits
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/google_vit-large-patch32-384.py` & `mlagility-3.1.1/models/popular_on_huggingface/google_vit-large-patch32-384.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::google name::vit-large-patch32-384 downloads::3,062 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::google name::vit-large-patch32-384 downloads::3,062 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ViTFeatureExtractor, ViTForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch32-384')
 model = ViTForImageClassification.from_pretrained('google/vit-large-patch32-384')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/hakurei_lit-6B.py` & `mlagility-3.1.1/models/popular_on_huggingface/hakurei_lit-6B.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::hakurei name::lit-6B downloads::2,564 license::mit task::Text_Generation
+# labels: test_group::monthly author::hakurei name::lit-6B downloads::2,564 license::mit task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelForCausalLM
 
 model = AutoModelForCausalLM.from_pretrained('hakurei/lit-6B')
 tokenizer = AutoTokenizer.from_pretrained('hakurei/lit-6B')
 
 prompt = '''[ Title: The Dunwich Horror; Author: H. P. Lovecraft; Genre: Horror ]
 ***
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/henryk_bert-base-multilingual-cased-finetuned-polish-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/henryk_bert-base-multilingual-cased-finetuned-polish-squad2.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::henryk name::bert-base-multilingual-cased-finetuned-polish-squad2 downloads::1,551 task::Question_Answering
+# labels: test_group::monthly author::henryk name::bert-base-multilingual-cased-finetuned-polish-squad2 downloads::1,551 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 qa_pipeline = pipeline(
     "question-answering",
     model="henryk/bert-base-multilingual-cased-finetuned-polish-squad2",
     tokenizer="henryk/bert-base-multilingual-cased-finetuned-polish-squad2"
 )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/hetpandya_t5-base-tapaco.py` & `mlagility-3.1.1/models/popular_on_huggingface/hetpandya_t5-base-tapaco.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::hetpandya name::t5-base-tapaco downloads::6,665 task::Text2Text_Generation
+# labels: test_group::monthly author::hetpandya name::t5-base-tapaco downloads::6,665 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5ForConditionalGeneration, T5Tokenizer
 
 tokenizer = T5Tokenizer.from_pretrained("hetpandya/t5-base-tapaco")
 model = T5ForConditionalGeneration.from_pretrained("hetpandya/t5-base-tapaco")
 
 def get_paraphrases(sentence, prefix="paraphrase: ", n_predictions=5, top_k=120, max_length=256,device="cpu"):
         text = prefix + sentence + " </s>"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/hetpandya_t5-small-tapaco.py` & `mlagility-3.1.1/models/popular_on_huggingface/hetpandya_t5-small-tapaco.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::hetpandya name::t5-small-tapaco downloads::194 task::Text2Text_Generation
+# labels: test_group::monthly author::hetpandya name::t5-small-tapaco downloads::194 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5ForConditionalGeneration, T5Tokenizer
 
 tokenizer = T5Tokenizer.from_pretrained("hetpandya/t5-small-tapaco")
 model = T5ForConditionalGeneration.from_pretrained("hetpandya/t5-small-tapaco")
 
 def get_paraphrases(sentence, prefix="paraphrase: ", n_predictions=5, top_k=120, max_length=256,device="cpu"):
         text = prefix + sentence + " </s>"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/hustvl_yolos-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/hustvl_yolos-base.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::hustvl name::yolos-base downloads::1,372 license::apache-2.0 task::Object_Detection
+# labels: test_group::monthly author::hustvl name::yolos-base downloads::1,372 license::apache-2.0 task::Computer_Vision sub_task::Object_Detection
 from transformers import YolosFeatureExtractor, YolosForObjectDetection
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/hustvl_yolos-small.py` & `mlagility-3.1.1/models/popular_on_huggingface/nickmuchi_yolos-small-rego-plates-detection.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,15 @@
-# labels: test_group::monthly author::hustvl name::yolos-small downloads::1,658 license::apache-2.0 task::Object_Detection
+# labels: test_group::monthly author::nickmuchi name::yolos-small-rego-plates-detection downloads::541 license::apache-2.0 task::Computer_Vision sub_task::Object_Detection
 from transformers import YolosFeatureExtractor, YolosForObjectDetection
 from PIL import Image
 import requests
 
-url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
+url = 'https://drive.google.com/uc?id=1p9wJIqRz3W50e2f_A0D8ftla8hoXz4T5'
 image = Image.open(requests.get(url, stream=True).raw)
-
-feature_extractor = YolosFeatureExtractor.from_pretrained('hustvl/yolos-small')
-model = YolosForObjectDetection.from_pretrained('hustvl/yolos-small')
-
+feature_extractor = YolosFeatureExtractor.from_pretrained('nickmuchi/yolos-small-rego-plates-detection')
+model = YolosForObjectDetection.from_pretrained('nickmuchi/yolos-small-rego-plates-detection')
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 
-# model predicts bounding boxes and corresponding COCO classes
+# model predicts bounding boxes and corresponding face mask detection classes
 logits = outputs.logits
 bboxes = outputs.pred_boxes
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/hustvl_yolos-tiny.py` & `mlagility-3.1.1/models/popular_on_huggingface/hustvl_yolos-tiny.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::hustvl name::yolos-tiny downloads::27,362 license::apache-2.0 task::Object_Detection
+# labels: test_group::monthly author::hustvl name::yolos-tiny downloads::27,362 license::apache-2.0 task::Computer_Vision sub_task::Object_Detection
 from transformers import YolosFeatureExtractor, YolosForObjectDetection
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/imranraad_idiom-xlm-roberta.py` & `mlagility-3.1.1/models/popular_on_huggingface/imranraad_idiom-xlm-roberta.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::imranraad name::idiom-xlm-roberta downloads::195 task::Token_Classification
+# labels: test_group::monthly author::imranraad name::idiom-xlm-roberta downloads::195 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoModelForTokenClassification, AutoTokenizer
 
 model = AutoModelForTokenClassification.from_pretrained("imranraad/autotrain-magpie-epie-combine-xlmr-metaphor-1595156286", use_auth_token=True)
 
 tokenizer = AutoTokenizer.from_pretrained("imranraad/autotrain-magpie-epie-combine-xlmr-metaphor-1595156286", use_auth_token=True)
 
 inputs = tokenizer("I love AutoTrain", return_tensors="pt")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/inkoziev_rugpt_chitchat.py` & `mlagility-3.1.1/models/popular_on_huggingface/inkoziev_rugpt_chitchat.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::inkoziev name::rugpt_chitchat downloads::434 license::unlicense task::Text_Generation
+# labels: test_group::monthly author::inkoziev name::rugpt_chitchat downloads::434 license::unlicense task::Natural_Language_Processing sub_task::Text_Generation
 import torch
 from transformers import AutoTokenizer, AutoModelForCausalLM
 
 
 device = "cuda" if torch.cuda.is_available() else "cpu"
 model_name = "inkoziev/rugpt_chitchat"
 tokenizer = AutoTokenizer.from_pretrained(model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/intfloat_simlm-msmarco-reranker.py` & `mlagility-3.1.1/models/popular_on_huggingface/intfloat_simlm-msmarco-reranker.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::intfloat name::simlm-msmarco-reranker downloads::2,245 task::Text_Classification
+# labels: test_group::monthly author::intfloat name::simlm-msmarco-reranker downloads::2,245 task::Natural_Language_Processing sub_task::Text_Classification
 import torch
 from transformers import AutoModelForSequenceClassification, AutoTokenizer, BatchEncoding, PreTrainedTokenizerFast
 from transformers.modeling_outputs import SequenceClassifierOutput
 
 def encode(tokenizer: PreTrainedTokenizerFast,
            query: str, passage: str, title: str = '-') -> BatchEncoding:
     return tokenizer(query,
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/jaehyeong_koelectra-base-v3-generalized-sentiment-analysis.py` & `mlagility-3.1.1/models/popular_on_huggingface/jaehyeong_koelectra-base-v3-generalized-sentiment-analysis.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::jaehyeong name::koelectra-base-v3-generalized-sentiment-analysis downloads::1,430 task::Text_Classification
+# labels: test_group::monthly author::jaehyeong name::koelectra-base-v3-generalized-sentiment-analysis downloads::1,430 task::Natural_Language_Processing sub_task::Text_Classification
 # import library
 import torch
 from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline
 
 # load model
 tokenizer = AutoTokenizer.from_pretrained("jaehyeong/koelectra-base-v3-generalized-sentiment-analysis")
 model = AutoModelForSequenceClassification.from_pretrained("jaehyeong/koelectra-base-v3-generalized-sentiment-analysis")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/joeddav_bart-large-mnli-yahoo-answers.py` & `mlagility-3.1.1/models/popular_on_huggingface/joeddav_bart-large-mnli-yahoo-answers.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::joeddav name::bart-large-mnli-yahoo-answers downloads::33,009 task::Zero-Shot_Classification
+# labels: test_group::monthly author::joeddav name::bart-large-mnli-yahoo-answers downloads::33,009 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import pipeline
 nlp = pipeline("zero-shot-classification", model="joeddav/bart-large-mnli-yahoo-answers")
 
 sequence_to_classify = "Who are you voting for in 2020?"
 candidate_labels = ["Europe", "public health", "politics", "elections"]
 hypothesis_template = "This text is about {}."
 nlp(sequence_to_classify, candidate_labels, multi_class=True, hypothesis_template=hypothesis_template)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/johngiorgi_declutr-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/johngiorgi_declutr-base.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::johngiorgi name::declutr-base downloads::894 license::apache-2.0 task::Sentence_Similarity
+# labels: test_group::monthly author::johngiorgi name::declutr-base downloads::894 license::apache-2.0 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from scipy.spatial.distance import cosine
 from sentence_transformers import SentenceTransformer
 
 # Load the model
 model = SentenceTransformer("johngiorgi/declutr-base")
 
 # Prepare some text to embed
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/jsylee_scibert_scivocab_uncased-finetuned-ner.py` & `mlagility-3.1.1/models/popular_on_huggingface/jsylee_scibert_scivocab_uncased-finetuned-ner.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::jsylee name::scibert_scivocab_uncased-finetuned-ner downloads::645 task::Token_Classification
+# labels: test_group::monthly author::jsylee name::scibert_scivocab_uncased-finetuned-ner downloads::645 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import (AutoModelForTokenClassification, 
                           AutoTokenizer, 
                           pipeline,
                           )
 
 model_checkpoint = "jsylee/scibert_scivocab_uncased-finetuned-ner"
 model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=5,
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_chinese_base.py` & `mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_chinese_base.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::junnyu name::roformer_chinese_base downloads::3,143 task::Fill-Mask
+# labels: test_group::monthly author::junnyu name::roformer_chinese_base downloads::3,143 task::Natural_Language_Processing sub_task::Fill-Mask
 import torch
 from transformers import RoFormerForMaskedLM, RoFormerTokenizer
 
 text = "[MASK]"
 tokenizer = RoFormerTokenizer.from_pretrained("junnyu/roformer_chinese_base")
 pt_model = RoFormerForMaskedLM.from_pretrained("junnyu/roformer_chinese_base")
 pt_inputs = tokenizer(text, return_tensors="pt")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_chinese_sim_char_base.py` & `mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_chinese_sim_char_base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::junnyu name::roformer_chinese_sim_char_base downloads::737 task::Text_Generation
+# labels: test_group::monthly author::junnyu name::roformer_chinese_sim_char_base downloads::737 task::Natural_Language_Processing sub_task::Text_Generation
 import torch
 import numpy as np
 from roformer import RoFormerForCausalLM, RoFormerConfig
 from transformers import BertTokenizer
 
 device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
 pretrained_model = "junnyu/roformer_chinese_sim_char_base"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_chinese_sim_char_ft_base.py` & `mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_chinese_sim_char_ft_base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::junnyu name::roformer_chinese_sim_char_ft_base downloads::412 task::Text_Generation
+# labels: test_group::monthly author::junnyu name::roformer_chinese_sim_char_ft_base downloads::412 task::Natural_Language_Processing sub_task::Text_Generation
 import torch
 import numpy as np
 from roformer import RoFormerForCausalLM, RoFormerConfig
 from transformers import BertTokenizer
 
 device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
 pretrained_model = "junnyu/roformer_chinese_sim_char_base"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_base.py` & `mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_large.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# labels: test_group::monthly author::junnyu name::roformer_v2_chinese_char_base downloads::1,403 task::Fill-Mask
+# labels: test_group::monthly author::junnyu name::roformer_v2_chinese_char_large downloads::2,724 task::Natural_Language_Processing sub_task::Fill-Mask
 import torch
 import tensorflow as tf
 from transformers import BertTokenizer
 from roformer import RoFormerForMaskedLM, TFRoFormerForMaskedLM
-
 text = "[MASK][MASK]"
-tokenizer = BertTokenizer.from_pretrained("junnyu/roformer_v2_chinese_char_base")
-pt_model = RoFormerForMaskedLM.from_pretrained("junnyu/roformer_v2_chinese_char_base")
+tokenizer = BertTokenizer.from_pretrained("junnyu/roformer_v2_chinese_char_large")
+pt_model = RoFormerForMaskedLM.from_pretrained("junnyu/roformer_v2_chinese_char_large")
 tf_model = TFRoFormerForMaskedLM.from_pretrained(
     "junnyu/roformer_v2_chinese_char_base", from_pt=True
 )
 pt_inputs = tokenizer(text, return_tensors="pt")
 tf_inputs = tokenizer(text, return_tensors="tf")
 # pytorch
 with torch.no_grad():
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_large.py` & `mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_small.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,16 @@
-# labels: test_group::monthly author::junnyu name::roformer_v2_chinese_char_large downloads::2,724 task::Fill-Mask
+# labels: test_group::monthly author::junnyu name::roformer_v2_chinese_char_small downloads::835 task::Natural_Language_Processing sub_task::Fill-Mask
 import torch
 import tensorflow as tf
 from transformers import BertTokenizer
 from roformer import RoFormerForMaskedLM, TFRoFormerForMaskedLM
+
 text = "[MASK][MASK]"
-tokenizer = BertTokenizer.from_pretrained("junnyu/roformer_v2_chinese_char_large")
-pt_model = RoFormerForMaskedLM.from_pretrained("junnyu/roformer_v2_chinese_char_large")
+tokenizer = BertTokenizer.from_pretrained("junnyu/roformer_v2_chinese_char_small")
+pt_model = RoFormerForMaskedLM.from_pretrained("junnyu/roformer_v2_chinese_char_small")
 tf_model = TFRoFormerForMaskedLM.from_pretrained(
     "junnyu/roformer_v2_chinese_char_base", from_pt=True
 )
 pt_inputs = tokenizer(text, return_tensors="pt")
 tf_inputs = tokenizer(text, return_tensors="tf")
 # pytorch
 with torch.no_grad():
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_small.py` & `mlagility-3.1.1/models/popular_on_huggingface/junnyu_roformer_v2_chinese_char_base.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# labels: test_group::monthly author::junnyu name::roformer_v2_chinese_char_small downloads::835 task::Fill-Mask
+# labels: test_group::monthly author::junnyu name::roformer_v2_chinese_char_base downloads::1,403 task::Natural_Language_Processing sub_task::Fill-Mask
 import torch
 import tensorflow as tf
 from transformers import BertTokenizer
 from roformer import RoFormerForMaskedLM, TFRoFormerForMaskedLM
 
 text = "[MASK][MASK]"
-tokenizer = BertTokenizer.from_pretrained("junnyu/roformer_v2_chinese_char_small")
-pt_model = RoFormerForMaskedLM.from_pretrained("junnyu/roformer_v2_chinese_char_small")
+tokenizer = BertTokenizer.from_pretrained("junnyu/roformer_v2_chinese_char_base")
+pt_model = RoFormerForMaskedLM.from_pretrained("junnyu/roformer_v2_chinese_char_base")
 tf_model = TFRoFormerForMaskedLM.from_pretrained(
     "junnyu/roformer_v2_chinese_char_base", from_pt=True
 )
 pt_inputs = tokenizer(text, return_tensors="pt")
 tf_inputs = tokenizer(text, return_tensors="tf")
 # pytorch
 with torch.no_grad():
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed-pmc-lt.py` & `mlagility-3.1.1/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed-pmc.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::kamalkraj name::bioelectra-base-discriminator-pubmed-pmc-lt task::unknown downloads::815
+# labels: test_group::monthly author::kamalkraj name::bioelectra-base-discriminator-pubmed-pmc ask::Natural_Language_Processing downloads::469
 from transformers import ElectraForPreTraining, ElectraTokenizerFast
 import torch
 
 discriminator = ElectraForPreTraining.from_pretrained("kamalkraj/bioelectra-base-discriminator-pubmed")
 tokenizer = ElectraTokenizerFast.from_pretrained("kamalkraj/bioelectra-base-discriminator-pubmed")
 
 sentence = "The quick brown fox jumps over the lazy dog"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed-pmc.py` & `mlagility-3.1.1/models/popular_on_huggingface/kamalkraj_bioelectra-base-discriminator-pubmed-pmc-lt.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::kamalkraj name::bioelectra-base-discriminator-pubmed-pmc task::unknown downloads::469
+# labels: test_group::monthly author::kamalkraj name::bioelectra-base-discriminator-pubmed-pmc-lt task::Natural_Language_Processing downloads::815
 from transformers import ElectraForPreTraining, ElectraTokenizerFast
 import torch
 
 discriminator = ElectraForPreTraining.from_pretrained("kamalkraj/bioelectra-base-discriminator-pubmed")
 tokenizer = ElectraTokenizerFast.from_pretrained("kamalkraj/bioelectra-base-discriminator-pubmed")
 
 sentence = "The quick brown fox jumps over the lazy dog"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ken11_albert-base-japanese-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/ken11_albert-base-japanese-v1.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ken11 name::albert-base-japanese-v1 downloads::3,207 license::mit task::Fill-Mask
+# labels: test_group::monthly author::ken11 name::albert-base-japanese-v1 downloads::3,207 license::mit task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import (
     AlbertForMaskedLM, AlbertTokenizerFast
 )
 import torch
 
 
 tokenizer = AlbertTokenizerFast.from_pretrained("ken11/albert-base-japanese-v1")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/kiheh85202_yolo.py` & `mlagility-3.1.1/models/popular_on_huggingface/kiheh85202_yolo.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::kiheh85202 name::yolo downloads::263 license::apache-2.0 task::Image_Segmentation
+# labels: test_group::monthly author::kiheh85202 name::yolo downloads::263 license::apache-2.0 task::Computer_Vision sub_task::Image_Segmentation
 from transformers import DPTFeatureExtractor, DPTForSemanticSegmentation
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/laituan245_molt5-large-smiles2caption.py` & `mlagility-3.1.1/models/popular_on_huggingface/laituan245_molt5-large-smiles2caption.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::laituan245 name::molt5-large-smiles2caption downloads::185 license::apache-2.0 task::Text2Text_Generation
+# labels: test_group::monthly author::laituan245 name::molt5-large-smiles2caption downloads::185 license::apache-2.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5Tokenizer, T5ForConditionalGeneration
 
 tokenizer = T5Tokenizer.from_pretrained("laituan245/molt5-large-smiles2caption", model_max_length=512)
 model = T5ForConditionalGeneration.from_pretrained('laituan245/molt5-large-smiles2caption')
 
 input_text = 'C1=CC2=C(C(=C1)[O-])NC(=CC2=O)C(=O)O'
 input_ids = tokenizer(input_text, return_tensors="pt").input_ids
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/lcw99_t5-base-korean-chit-chat.py` & `mlagility-3.1.1/models/popular_on_huggingface/lcw99_t5-base-korean-chit-chat.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::lcw99 name::t5-base-korean-chit-chat downloads::243 task::Text2Text_Generation
+# labels: test_group::monthly author::lcw99 name::t5-base-korean-chit-chat downloads::243 task::Natural_Language_Processing sub_task::Text2Text_Generation
 
 from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, MT5ForConditionalGeneration
 from transformers import AutoTokenizer, T5TokenizerFast
 import nltk
 nltk.download('punkt')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/liandarizkia_SA01-IndoBert.py` & `mlagility-3.1.1/models/popular_on_huggingface/liandarizkia_SA01-IndoBert.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::liandarizkia name::SA01-IndoBert downloads::944 task::Text_Classification
+# labels: test_group::monthly author::liandarizkia name::SA01-IndoBert downloads::944 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 
 pretrained= "liandarizkia/SA01-IndoBert"
 
 model = AutoModelForSequenceClassification.from_pretrained(pretrained)
 tokenizer = AutoTokenizer.from_pretrained(pretrained)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/malteos_scincl.py` & `mlagility-3.1.1/models/popular_on_huggingface/malteos_scincl.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::malteos name::scincl downloads::198 license::mit task::Feature_Extraction
+# labels: test_group::monthly author::malteos name::scincl downloads::198 license::mit task::Multimodal sub_task::Feature_Extraction
 from transformers import AutoTokenizer, AutoModel
 
 # load model and tokenizer
 tokenizer = AutoTokenizer.from_pretrained('malteos/scincl')
 model = AutoModel.from_pretrained('malteos/scincl')
 
 papers = [{'title': 'BERT', 'abstract': 'We introduce a new language representation model called BERT'},
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/marefa-nlp_marefa-ner.py` & `mlagility-3.1.1/models/popular_on_huggingface/marefa-nlp_marefa-ner.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::marefa-nlp name::marefa-ner downloads::548 task::Token_Classification
+# labels: test_group::monthly author::marefa-nlp name::marefa-ner downloads::548 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 import torch
 
 import numpy as np
 import nltk
 nltk.download('punkt')
 from nltk.tokenize import word_tokenize
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mdhugol_indonesia-bert-sentiment-classification.py` & `mlagility-3.1.1/models/popular_on_huggingface/mdhugol_indonesia-bert-sentiment-classification.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mdhugol name::indonesia-bert-sentiment-classification downloads::3,468 task::Text_Classification
+# labels: test_group::monthly author::mdhugol name::indonesia-bert-sentiment-classification downloads::3,468 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 
 pretrained= "mdhugol/indonesia-bert-sentiment-classification"
 
 model = AutoModelForSequenceClassification.from_pretrained(pretrained)
 tokenizer = AutoTokenizer.from_pretrained(pretrained)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/melll-uff_bertweetbr.py` & `mlagility-3.1.1/models/popular_on_huggingface/melll-uff_bertweetbr.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::melll-uff name::bertweetbr downloads::249 license::apache-2.0 task::Fill-Mask
+# labels: test_group::monthly author::melll-uff name::bertweetbr downloads::249 license::apache-2.0 task::Natural_Language_Processing sub_task::Fill-Mask
 import torch
 from transformers import AutoModel, AutoTokenizer 
 
 model = AutoModel.from_pretrained('melll-uff/bertweetbr')
 tokenizer = AutoTokenizer.from_pretrained('melll-uff/bertweetbr', normalization=False)
 
 # INPUT TWEETS ALREADY NORMALIZED!
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_BiomedVLP-CXR-BERT-specialized.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_BiomedVLP-CXR-BERT-specialized.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::microsoft name::BiomedVLP-CXR-BERT-specialized downloads::5,824 license::mit task::Fill-Mask
+# labels: test_group::monthly author::microsoft name::BiomedVLP-CXR-BERT-specialized downloads::5,824 license::mit task::Natural_Language_Processing sub_task::Fill-Mask
 import torch
 from transformers import AutoModel, AutoTokenizer
 
 # Load the model and tokenizer
 url = "microsoft/BiomedVLP-CXR-BERT-specialized"
 tokenizer = AutoTokenizer.from_pretrained(url, trust_remote_code=True)
 model = AutoModel.from_pretrained(url, trust_remote_code=True)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-base-patch16-224-pt22k-ft22k.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-large-patch16-512.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly,daily author::microsoft name::beit-base-patch16-224-pt22k-ft22k downloads::13,214 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::beit-large-patch16-512 downloads::2,832 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import BeitFeatureExtractor, BeitForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k')
-model = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k')
+feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-large-patch16-512')
+model = BeitForImageClassification.from_pretrained('microsoft/beit-large-patch16-512')
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
-# model predicts one of the 21,841 ImageNet-22k classes
+# model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-base-patch16-224-pt22k.py` & `mlagility-3.1.1/models/popular_on_huggingface/Intel_dpt-large-ade.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,14 +1,15 @@
-# labels: test_group::monthly,daily author::microsoft name::beit-base-patch16-224-pt22k downloads::1,999 license::apache-2.0 task::Image_Classification
-from transformers import BeitFeatureExtractor, BeitForMaskedImageModeling
+# labels: test_group::monthly author::Intel name::dpt-large-ade downloads::1,255 license::apache-2.0 task::Computer_Vision sub_task::Image_Segmentation
+from transformers import DPTFeatureExtractor, DPTForSemanticSegmentation
 from PIL import Image
 import requests
 
-url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
+url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224-pt22k')
-model = BeitForMaskedImageModeling.from_pretrained('microsoft/beit-base-patch16-224-pt22k')
+feature_extractor = DPTFeatureExtractor.from_pretrained("Intel/dpt-large-ade")
+model = DPTForSemanticSegmentation.from_pretrained("Intel/dpt-large-ade")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
+
 outputs = model(**inputs)
 logits = outputs.logits
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-base-patch16-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-base-patch16-224.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::beit-base-patch16-224 downloads::4,097 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::beit-base-patch16-224 downloads::4,097 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import BeitFeatureExtractor, BeitForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224')
 model = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-224')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-base-patch16-384.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-large-patch16-384.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly,daily author::microsoft name::beit-base-patch16-384 downloads::2,193 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::beit-large-patch16-384 downloads::252 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import BeitFeatureExtractor, BeitForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-384')
-model = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-384')
+feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-large-patch16-384')
+model = BeitForImageClassification.from_pretrained('microsoft/beit-large-patch16-384')
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-large-patch16-224-pt22k-ft22k.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_beit-large-patch16-224-pt22k-ft22k.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::beit-large-patch16-224-pt22k-ft22k downloads::384 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::beit-large-patch16-224-pt22k-ft22k downloads::384 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import BeitFeatureExtractor, BeitForImageClassification
 from PIL import Image
 import requests
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-large-patch16-224-pt22k-ft22k')
 model = BeitForImageClassification.from_pretrained('microsoft/beit-large-patch16-224-pt22k-ft22k')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-large-patch16-384.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-large-patch4-window7-224-in22k.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,14 +1,17 @@
-# labels: test_group::monthly,daily author::microsoft name::beit-large-patch16-384 downloads::252 license::apache-2.0 task::Image_Classification
-from transformers import BeitFeatureExtractor, BeitForImageClassification
+# labels: test_group::monthly,daily author::microsoft name::swin-large-patch4-window7-224-in22k downloads::244 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
+from transformers import AutoFeatureExtractor, SwinForImageClassification
 from PIL import Image
 import requests
-url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
+
+url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-large-patch16-384')
-model = BeitForImageClassification.from_pretrained('microsoft/beit-large-patch16-384')
+
+feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-large-patch4-window7-224-in22k")
+model = SwinForImageClassification.from_pretrained("microsoft/swin-large-patch4-window7-224-in22k")
+
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_beit-large-patch16-512.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_mit-b5.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,14 +1,17 @@
-# labels: test_group::monthly,daily author::microsoft name::beit-large-patch16-512 downloads::2,832 license::apache-2.0 task::Image_Classification
-from transformers import BeitFeatureExtractor, BeitForImageClassification
+# labels: test_group::monthly author::nvidia name::mit-b5 downloads::1,712 license::other task::Computer_Vision sub_task::Image_Classification
+from transformers import SegformerFeatureExtractor, SegformerForImageClassification
 from PIL import Image
 import requests
-url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
+
+url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
-feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-large-patch16-512')
-model = BeitForImageClassification.from_pretrained('microsoft/beit-large-patch16-512')
+
+feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/mit-b5")
+model = SegformerForImageClassification.from_pretrained("nvidia/mit-b5")
+
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_conditional-detr-resnet-50.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_conditional-detr-resnet-50.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::microsoft name::conditional-detr-resnet-50 downloads::221 license::apache-2.0 task::Object_Detection
+# labels: test_group::monthly author::microsoft name::conditional-detr-resnet-50 downloads::221 license::apache-2.0 task::Computer_Vision sub_task::Object_Detection
 from transformers import AutoFeatureExtractor, ConditionalDetrForObjectDetection
 import torch
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_cvt-13.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_cvt-13.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::cvt-13 downloads::7,775 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::cvt-13 downloads::7,775 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, CvtForImageClassification
 from PIL import Image
 import requests
 
 url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_prophetnet-large-uncased.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_prophetnet-large-uncased.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::prophetnet-large-uncased downloads::5,629 task::Text2Text_Generation
+# labels: test_group::monthly,daily author::microsoft name::prophetnet-large-uncased downloads::5,629 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import ProphetNetForConditionalGeneration, ProphetNetTokenizer
 
 model = ProphetNetForConditionalGeneration.from_pretrained("microsoft/prophetnet-large-uncased")
 tokenizer = ProphetNetTokenizer.from_pretrained("microsoft/prophetnet-large-uncased")
 
 input_str = "the us state department said wednesday it had received no formal word from bolivia that it was expelling the us ambassador there but said the charges made against him are `` baseless ."
 target_str = "us rejects charges against its ambassador in bolivia"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_resnet-101.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_resnet-101.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::resnet-101 downloads::303 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::resnet-101 downloads::303 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, ResNetForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_resnet-152.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_resnet-50.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: test_group::monthly,daily author::microsoft name::resnet-152 downloads::303 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::resnet-50 downloads::113,970 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, ResNetForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
 
-feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/resnet-152")
-model = ResNetForImageClassification.from_pretrained("microsoft/resnet-152")
+feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/resnet-50")
+model = ResNetForImageClassification.from_pretrained("microsoft/resnet-50")
 
 inputs = feature_extractor(image, return_tensors="pt")
 
 with torch.no_grad():
     logits = model(**inputs).logits
 
 # model predicts one of the 1000 ImageNet classes
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_resnet-18.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_resnet-18.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::resnet-18 downloads::677 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::resnet-18 downloads::677 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, ResNetForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_resnet-34.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_resnet-34.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::resnet-34 downloads::288 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::resnet-34 downloads::288 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, ResNetForImageClassification
 import torch
 from datasets import load_dataset
 
 dataset = load_dataset("huggingface/cats-image")
 image = dataset["test"]["image"][0]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_resnet-50.py` & `mlagility-3.1.1/models/popular_on_huggingface/sail_poolformer_s12.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,19 +1,14 @@
-# labels: test_group::monthly,daily author::microsoft name::resnet-50 downloads::113,970 license::apache-2.0 task::Image_Classification
-from transformers import AutoFeatureExtractor, ResNetForImageClassification
-import torch
-from datasets import load_dataset
-
-dataset = load_dataset("huggingface/cats-image")
-image = dataset["test"]["image"][0]
-
-feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/resnet-50")
-model = ResNetForImageClassification.from_pretrained("microsoft/resnet-50")
-
-inputs = feature_extractor(image, return_tensors="pt")
-
-with torch.no_grad():
-    logits = model(**inputs).logits
-
+# labels: test_group::monthly author::sail name::poolformer_s12 downloads::397 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
+from transformers import PoolFormerFeatureExtractor, PoolFormerForImageClassification
+from PIL import Image
+import requests
+url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
+image = Image.open(requests.get(url, stream=True).raw)
+feature_extractor = PoolFormerFeatureExtractor.from_pretrained('sail/poolformer_s12')
+model = PoolFormerForImageClassification.from_pretrained('sail/poolformer_s12')
+inputs = feature_extractor(images=image, return_tensors="pt")
+outputs = model(**inputs)
+logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
-predicted_label = logits.argmax(-1).item()
-print(model.config.id2label[predicted_label])
+predicted_class_idx = logits.argmax(-1).item()
+print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-base-patch4-window12-384-in22k.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-base-patch4-window12-384-in22k.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::swin-base-patch4-window12-384-in22k downloads::1,546 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::swin-base-patch4-window12-384-in22k downloads::1,546 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, SwinForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-base-patch4-window12-384.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-base-patch4-window12-384.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::swin-base-patch4-window12-384 downloads::381 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::swin-base-patch4-window12-384 downloads::381 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, SwinForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-base-patch4-window7-224-in22k.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-large-patch4-window7-224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: test_group::monthly,daily author::microsoft name::swin-base-patch4-window7-224-in22k downloads::6,434 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::swin-large-patch4-window7-224 downloads::8,406 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, SwinForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-base-patch4-window7-224-in22k")
-model = SwinForImageClassification.from_pretrained("microsoft/swin-base-patch4-window7-224-in22k")
+feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-large-patch4-window7-224")
+model = SwinForImageClassification.from_pretrained("microsoft/swin-large-patch4-window7-224")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-base-patch4-window7-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-base-patch4-window7-224-in22k.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: test_group::monthly,daily author::microsoft name::swin-base-patch4-window7-224 downloads::1,783 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::swin-base-patch4-window7-224-in22k downloads::6,434 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, SwinForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-base-patch4-window7-224")
-model = SwinForImageClassification.from_pretrained("microsoft/swin-base-patch4-window7-224")
+feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-base-patch4-window7-224-in22k")
+model = SwinForImageClassification.from_pretrained("microsoft/swin-base-patch4-window7-224-in22k")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-large-patch4-window12-384-in22k.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-base-patch4-window7-224.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: test_group::monthly,daily author::microsoft name::swin-large-patch4-window12-384-in22k downloads::26,264 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::swin-base-patch4-window7-224 downloads::1,783 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, SwinForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-large-patch4-window12-384-in22k")
-model = SwinForImageClassification.from_pretrained("microsoft/swin-large-patch4-window12-384-in22k")
+feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-base-patch4-window7-224")
+model = SwinForImageClassification.from_pretrained("microsoft/swin-base-patch4-window7-224")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-large-patch4-window7-224-in22k.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-small-patch4-window7-224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: test_group::monthly,daily author::microsoft name::swin-large-patch4-window7-224-in22k downloads::244 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::swin-small-patch4-window7-224 downloads::562 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, SwinForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-large-patch4-window7-224-in22k")
-model = SwinForImageClassification.from_pretrained("microsoft/swin-large-patch4-window7-224-in22k")
+feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-small-patch4-window7-224")
+model = SwinForImageClassification.from_pretrained("microsoft/swin-small-patch4-window7-224")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-large-patch4-window7-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_swinv2-tiny-patch4-window8-256.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: test_group::monthly,daily author::microsoft name::swin-large-patch4-window7-224 downloads::8,406 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::swinv2-tiny-patch4-window8-256 downloads::1,754 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, SwinForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-large-patch4-window7-224")
-model = SwinForImageClassification.from_pretrained("microsoft/swin-large-patch4-window7-224")
+feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swinv2-tiny-patch4-window8-256")
+model = SwinForImageClassification.from_pretrained("microsoft/swinv2-tiny-patch4-window8-256")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_swin-small-patch4-window7-224.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_swin-tiny-patch4-window7-224.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: test_group::monthly,daily author::microsoft name::swin-small-patch4-window7-224 downloads::562 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly,daily author::microsoft name::swin-tiny-patch4-window7-224 downloads::7,898 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import AutoFeatureExtractor, SwinForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-small-patch4-window7-224")
-model = SwinForImageClassification.from_pretrained("microsoft/swin-small-patch4-window7-224")
+feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-tiny-patch4-window7-224")
+model = SwinForImageClassification.from_pretrained("microsoft/swin-tiny-patch4-window7-224")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_swinv2-tiny-patch4-window8-256.py` & `mlagility-3.1.1/models/popular_on_huggingface/apple_mobilevit-xx-small.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,19 @@
-# labels: test_group::monthly,daily author::microsoft name::swinv2-tiny-patch4-window8-256 downloads::1,754 license::apache-2.0 task::Image_Classification
-from transformers import AutoFeatureExtractor, SwinForImageClassification
+# labels: test_group::monthly,daily author::apple name::mobilevit-xx-small downloads::347 license::other task::Computer_Vision sub_task::Image_Classification
+from transformers import MobileViTFeatureExtractor, MobileViTForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swinv2-tiny-patch4-window8-256")
-model = SwinForImageClassification.from_pretrained("microsoft/swinv2-tiny-patch4-window8-256")
+feature_extractor = MobileViTFeatureExtractor.from_pretrained("apple/mobilevit-xx-small")
+model = MobileViTForImageClassification.from_pretrained("apple/mobilevit-xx-small")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
+
 outputs = model(**inputs)
 logits = outputs.logits
+
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_tapex-large-finetuned-tabfact.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_tapex-large-finetuned-tabfact.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::microsoft name::tapex-large-finetuned-tabfact downloads::201 license::mit task::Text_Classification
+# labels: test_group::monthly author::microsoft name::tapex-large-finetuned-tabfact downloads::201 license::mit task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import TapexTokenizer, BartForSequenceClassification
 import pandas as pd
 
 tokenizer = TapexTokenizer.from_pretrained("microsoft/tapex-large-finetuned-tabfact")
 model = BartForSequenceClassification.from_pretrained("microsoft/tapex-large-finetuned-tabfact")
 
 data = {
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-base-handwritten.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-base-handwritten.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::trocr-base-handwritten task::unknown downloads::6,461
+# labels: test_group::monthly,daily author::microsoft name::trocr-base-handwritten task::MultiModal downloads::6,461
 from transformers import TrOCRProcessor, VisionEncoderDecoderModel
 from PIL import Image
 import requests
 
 # load image from the IAM database
 url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'
 image = Image.open(requests.get(url, stream=True).raw).convert("RGB")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-base-printed.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-base-printed.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::trocr-base-printed task::unknown downloads::18,133
+# labels: test_group::monthly,daily author::microsoft name::trocr-base-printed task::MultiModal downloads::18,133
 from transformers import TrOCRProcessor, VisionEncoderDecoderModel
 from PIL import Image
 import requests
 
 # load image from the IAM database (actually this model is meant to be used on printed text)
 url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'
 image = Image.open(requests.get(url, stream=True).raw).convert("RGB")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-large-handwritten.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-large-handwritten.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::trocr-large-handwritten task::unknown downloads::1,876
+# labels: test_group::monthly,daily author::microsoft name::trocr-large-handwritten task::MultiModal downloads::1,876
 from transformers import TrOCRProcessor, VisionEncoderDecoderModel
 from PIL import Image
 import requests
 
 # load image from the IAM database
 url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'
 image = Image.open(requests.get(url, stream=True).raw).convert("RGB")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-large-printed.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-large-printed.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::trocr-large-printed task::unknown downloads::2,727
+# labels: test_group::monthly,daily author::microsoft name::trocr-large-printed task::MultiModal downloads::2,727
 from transformers import TrOCRProcessor, VisionEncoderDecoderModel
 from PIL import Image
 import requests
 
 # load image from the IAM database (actually this model is meant to be used on printed text)
 url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'
 image = Image.open(requests.get(url, stream=True).raw).convert("RGB")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-large-str.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-large-str.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::trocr-large-str task::unknown downloads::229
+# labels: test_group::monthly,daily author::microsoft name::trocr-large-str task::MultiModal downloads::229
 from transformers import TrOCRProcessor, VisionEncoderDecoderModel
 from PIL import Image
 import requests
 
 # load image from the IIIT-5k dataset
 url = 'https://i.postimg.cc/ZKwLg2Gw/367-14.png'
 image = Image.open(requests.get(url, stream=True).raw).convert("RGB")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-small-handwritten.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-small-handwritten.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::trocr-small-handwritten task::unknown downloads::1,138
+# labels: test_group::monthly,daily author::microsoft name::trocr-small-handwritten task::MultiModal downloads::1,138
 from transformers import TrOCRProcessor, VisionEncoderDecoderModel
 from PIL import Image
 import requests
 
 # load image from the IAM database
 url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'
 image = Image.open(requests.get(url, stream=True).raw).convert("RGB")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_trocr-small-stage1.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_trocr-small-stage1.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::trocr-small-stage1 task::unknown downloads::585
+# labels: test_group::monthly,daily author::microsoft name::trocr-small-stage1 task::MultiModal downloads::585
 from transformers import TrOCRProcessor, VisionEncoderDecoderModel
 from PIL import Image
 import requests
 import torch
 
 # load image from the IAM database
 url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/microsoft_xprophetnet-large-wiki100-cased.py` & `mlagility-3.1.1/models/popular_on_huggingface/microsoft_xprophetnet-large-wiki100-cased.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::microsoft name::xprophetnet-large-wiki100-cased downloads::540 task::Text2Text_Generation
+# labels: test_group::monthly,daily author::microsoft name::xprophetnet-large-wiki100-cased downloads::540 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import XLMProphetNetForConditionalGeneration, XLMProphetNetTokenizer
 
 model = XLMProphetNetForConditionalGeneration.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
 tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
 
 input_str = "the us state department said wednesday it had received no formal word from bolivia that it was expelling the us ambassador there but said the charges made against him are `` baseless ."
 target_str = "us rejects charges against its ambassador in bolivia"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ml4pubmed_BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext_pub_section.py` & `mlagility-3.1.1/models/popular_on_huggingface/ml4pubmed_BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext_pub_section.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ml4pubmed name::BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext_pub_section downloads::356 task::Text_Classification
+# labels: test_group::monthly author::ml4pubmed name::BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext_pub_section downloads::356 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 
 model_tag = "ml4pubmed/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext_pub_section"
 classifier = pipeline(
               'text-classification', 
               model=model_tag, 
             )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ml6team_distilbert-base-german-cased-toxic-comments.py` & `mlagility-3.1.1/models/popular_on_huggingface/ml6team_distilbert-base-german-cased-toxic-comments.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ml6team name::distilbert-base-german-cased-toxic-comments downloads::861 task::Text_Classification
+# labels: test_group::monthly author::ml6team name::distilbert-base-german-cased-toxic-comments downloads::861 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import pipeline
 
 model_hub_url = 'https://huggingface.co/ml6team/distilbert-base-german-cased-toxic-comments'
 model_name = 'ml6team/distilbert-base-german-cased-toxic-comments'
 
 toxicity_pipeline = pipeline('text-classification', model=model_name, tokenizer=model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/monilouise_ner_news_portuguese.py` & `mlagility-3.1.1/models/popular_on_huggingface/monilouise_ner_news_portuguese.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::monilouise name::ner_news_portuguese downloads::463 task::Token_Classification
+# labels: test_group::monthly author::monilouise name::ner_news_portuguese downloads::463 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import BertForTokenClassification, DistilBertTokenizerFast, pipeline
 model = BertForTokenClassification.from_pretrained('monilouise/ner_pt_br')
 tokenizer = DistilBertTokenizerFast.from_pretrained('neuralmind/bert-base-portuguese-cased'
                                                     , model_max_length=512
                                                     , do_lower_case=False
                                                     )
 nlp = pipeline('ner', model=model, tokenizer=tokenizer, grouped_entities=True)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_TinyBERT-spanish-uncased-finetuned-ner.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_TinyBERT-spanish-uncased-finetuned-ner.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::TinyBERT-spanish-uncased-finetuned-ner downloads::1,131 task::Token_Classification
+# labels: test_group::monthly author::mrm8488 name::TinyBERT-spanish-uncased-finetuned-ner downloads::1,131 task::Natural_Language_Processing sub_task::Token_Classification
 import torch
 from transformers import AutoModelForTokenClassification, AutoTokenizer
 
 id2label = {
     "0": "B-LOC",
     "1": "B-MISC",
     "2": "B-ORG",
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-italian-finedtuned-squadv1-it-alfa.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-italian-finedtuned-squadv1-it-alfa.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::bert-italian-finedtuned-squadv1-it-alfa downloads::3,249 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::bert-italian-finedtuned-squadv1-it-alfa downloads::3,249 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 nlp_qa = pipeline(
     'question-answering',
     model='mrm8488/bert-italian-finedtuned-squadv1-it-alfa',
     tokenizer='mrm8488/bert-italian-finedtuned-squadv1-it-alfa'
 )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-medium-finetuned-squadv2.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-small-finetuned-squadv2.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::bert-medium-finetuned-squadv2 downloads::26,836 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::bert-small-finetuned-squadv2 downloads::29,466 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 qa_pipeline = pipeline(
     "question-answering",
     model="mrm8488/bert-small-finetuned-squadv2",
     tokenizer="mrm8488/bert-small-finetuned-squadv2"
 )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-multi-cased-finetuned-xquadv1.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-multi-cased-finetuned-xquadv1.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::bert-multi-cased-finetuned-xquadv1 downloads::930 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::bert-multi-cased-finetuned-xquadv1 downloads::930 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 from transformers import pipeline
 
 qa_pipeline = pipeline(
     "question-answering",
     model="mrm8488/bert-multi-cased-finetuned-xquadv1",
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-small-finetuned-squadv2.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_spanbert-finetuned-squadv2.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# labels: test_group::monthly author::mrm8488 name::bert-small-finetuned-squadv2 downloads::29,466 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::spanbert-finetuned-squadv2 downloads::1,981 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 qa_pipeline = pipeline(
     "question-answering",
-    model="mrm8488/bert-small-finetuned-squadv2",
-    tokenizer="mrm8488/bert-small-finetuned-squadv2"
+    model="mrm8488/spanbert-finetuned-squadv2",
+    tokenizer="mrm8488/spanbert-finetuned-squadv2"
 )
 
 qa_pipeline({
     'context': "Manuel Romero has been working hardly in the repository hugginface/transformers lately",
     'question': "Who has been working hard for hugginface/transformers lately?"
 
 })
 
-# Output:
+# Output: {'answer': 'Manuel Romero','end': 13,'score': 6.836378586818937e-09, 'start': 0}
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-small2bert-small-finetuned-cnn_daily_mail-summarization.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-small2bert-small-finetuned-cnn_daily_mail-summarization.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::bert-small2bert-small-finetuned-cnn_daily_mail-summarization downloads::11,465 license::apache-2.0 task::Summarization
+# labels: test_group::monthly author::mrm8488 name::bert-small2bert-small-finetuned-cnn_daily_mail-summarization downloads::11,465 license::apache-2.0 task::Natural_Language_Processing sub_task::Summarization
 from transformers import BertTokenizerFast, EncoderDecoderModel
 import torch
 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
 tokenizer = BertTokenizerFast.from_pretrained('mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization')
 model = EncoderDecoderModel.from_pretrained('mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization').to(device)
 
 def generate_summary(text):
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-spanish-cased-finetuned-ner.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-spanish-cased-finetuned-ner.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::bert-spanish-cased-finetuned-ner downloads::253,145 task::Token_Classification
+# labels: test_group::monthly author::mrm8488 name::bert-spanish-cased-finetuned-ner downloads::253,145 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import pipeline
 
 nlp_ner = pipeline(
     "ner",
     model="mrm8488/bert-spanish-cased-finetuned-ner",
     tokenizer=(
         'mrm8488/bert-spanish-cased-finetuned-ner',
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-tiny-5-finetuned-squadv2.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-tiny-5-finetuned-squadv2.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::bert-tiny-5-finetuned-squadv2 downloads::752 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::bert-tiny-5-finetuned-squadv2 downloads::752 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 qa_pipeline = pipeline(
     "question-answering",
     model="mrm8488/bert-tiny-5-finetuned-squadv2",
     tokenizer="mrm8488/bert-tiny-5-finetuned-squadv2"
 )
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert-tiny-finetuned-squadv2.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert-medium-finetuned-squadv2.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly author::mrm8488 name::bert-tiny-finetuned-squadv2 downloads::9,523 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::bert-medium-finetuned-squadv2 downloads::26,836 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 qa_pipeline = pipeline(
     "question-answering",
-    model="mrm8488/bert-tiny-finetuned-squadv2",
-    tokenizer="mrm8488/bert-tiny-finetuned-squadv2"
+    model="mrm8488/bert-small-finetuned-squadv2",
+    tokenizer="mrm8488/bert-small-finetuned-squadv2"
 )
 
 qa_pipeline({
     'context': "Manuel Romero has been working hardly in the repository hugginface/transformers lately",
     'question': "Who has been working hard for hugginface/transformers lately?"
 
 })
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert2bert_shared-german-finetuned-summarization.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert2bert_shared-german-finetuned-summarization.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::bert2bert_shared-german-finetuned-summarization downloads::948 task::Summarization
+# labels: test_group::monthly author::mrm8488 name::bert2bert_shared-german-finetuned-summarization downloads::948 task::Natural_Language_Processing sub_task::Summarization
 import torch
 from transformers import BertTokenizerFast, EncoderDecoderModel
 device = 'cuda' if torch.cuda.is_available() else 'cpu'
 ckpt = 'mrm8488/bert2bert_shared-german-finetuned-summarization'
 tokenizer = BertTokenizerFast.from_pretrained(ckpt)
 model = EncoderDecoderModel.from_pretrained(ckpt).to(device)
 def generate_summary(text):
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_bert2bert_shared-spanish-finetuned-summarization.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_bert2bert_shared-spanish-finetuned-summarization.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::bert2bert_shared-spanish-finetuned-summarization downloads::1,386 task::Summarization
+# labels: test_group::monthly author::mrm8488 name::bert2bert_shared-spanish-finetuned-summarization downloads::1,386 task::Natural_Language_Processing sub_task::Summarization
 import torch
 from transformers import BertTokenizerFast, EncoderDecoderModel
 device = 'cuda' if torch.cuda.is_available() else 'cpu'
 ckpt = 'mrm8488/bert2bert_shared-spanish-finetuned-summarization'
 tokenizer = BertTokenizerFast.from_pretrained(ckpt)
 model = EncoderDecoderModel.from_pretrained(ckpt).to(device)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_codebert-base-finetuned-detect-insecure-code.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_codebert-base-finetuned-detect-insecure-code.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::codebert-base-finetuned-detect-insecure-code downloads::4,786 task::Text_Classification
+# labels: test_group::monthly author::mrm8488 name::codebert-base-finetuned-detect-insecure-code downloads::4,786 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 import torch
 import numpy as np
 tokenizer = AutoTokenizer.from_pretrained('mrm8488/codebert-base-finetuned-detect-insecure-code')
 model = AutoModelForSequenceClassification.from_pretrained('mrm8488/codebert-base-finetuned-detect-insecure-code')
 
 inputs = tokenizer("your code here", return_tensors="pt", truncation=True, padding='max_length')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es downloads::5,415 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es downloads::5,415 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import *
 
 # Important!: By now the QA pipeline is not compatible with fast tokenizer, but they are working on it. So that pass the object to the tokenizer {"use_fast": False} as in the following example:
 
 nlp = pipeline(
     'question-answering', 
     model='mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_electra-small-finetuned-squadv2.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_electra-small-finetuned-squadv2.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::electra-small-finetuned-squadv2 downloads::9,682 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::electra-small-finetuned-squadv2 downloads::9,682 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 QnA_pipeline = pipeline('question-answering', model='mrm8488/electra-base-finetuned-squadv2')
 QnA_pipeline({
     'context': 'A new strain of flu that has the potential to become a pandemic has been identified in China by scientists.',
     'question': 'What has been discovered by scientists from China ?'
 })
 # Output:
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_electricidad-base-discriminator.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_electricidad-base-discriminator.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::electricidad-base-discriminator task::unknown downloads::656
+# labels: test_group::monthly author::mrm8488 name::electricidad-base-discriminator task::Natural_Language_Processing downloads::656
 from transformers import ElectraForPreTraining, ElectraTokenizerFast
 import torch
 
 discriminator = ElectraForPreTraining.from_pretrained("mrm8488/electricidad-base-discriminator")
 tokenizer = ElectraTokenizerFast.from_pretrained("mrm8488/electricidad-base-discriminator")
 
 sentence = "El rpido zorro marrn salta sobre el perro perezoso"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_roberta-base-1B-1-finetuned-squadv1.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_roberta-base-1B-1-finetuned-squadv1.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::roberta-base-1B-1-finetuned-squadv1 downloads::185 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::roberta-base-1B-1-finetuned-squadv1 downloads::185 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import pipeline
 
 QnA_pipeline = pipeline('question-answering', model='mrm8488/roberta-base-1B-1-finetuned-squadv1')
 
 QnA_pipeline({
     'context': 'A new strain of flu that has the potential to become a pandemic has been identified in China by scientists.',
     'question': 'What has been discovered by scientists from China ?'
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_spanbert-finetuned-squadv2.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_spanbert-large-finetuned-squadv2.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# labels: test_group::monthly author::mrm8488 name::spanbert-finetuned-squadv2 downloads::1,981 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::spanbert-large-finetuned-squadv2 task::Natural_Language_Processing downloads::389
 from transformers import pipeline
 
 qa_pipeline = pipeline(
     "question-answering",
-    model="mrm8488/spanbert-finetuned-squadv2",
-    tokenizer="mrm8488/spanbert-finetuned-squadv2"
+    model="mrm8488/spanbert-large-finetuned-squadv2",
+    tokenizer="SpanBERT/spanbert-large-cased"
 )
 
 qa_pipeline({
-    'context': "Manuel Romero has been working hardly in the repository hugginface/transformers lately",
-    'question': "Who has been working hard for hugginface/transformers lately?"
+    'context': "Manuel Romero has been working very hard in the repository hugginface/transformers lately",
+    'question': "How has been working Manuel Romero lately?"
 
 })
-
-# Output: {'answer': 'Manuel Romero','end': 13,'score': 6.836378586818937e-09, 'start': 0}
+# Output: {'answer': 'very hard', 'end': 40, 'score': 0.9052708846768347, 'start': 31}
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-common_gen.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-common_gen.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-common_gen downloads::451,087 task::Text2Text_Generation
+# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-common_gen downloads::451,087 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoModelWithLMHead, AutoTokenizer
 
 tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-common_gen")
 model = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-common_gen")
 
 def gen_sentence(words, max_length=32):
   input_text = words
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-e2m-intent.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-e2m-intent.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-e2m-intent downloads::12,729 task::Text2Text_Generation
+# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-e2m-intent downloads::12,729 task::Natural_Language_Processing sub_task::Text2Text_Generation
 # Tip: By now, install transformers from source
 
 from transformers import AutoModelWithLMHead, AutoTokenizer
 
 tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-e2m-intent")
 model = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-e2m-intent")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-imdb-sentiment.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-imdb-sentiment.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-imdb-sentiment downloads::2,670 task::Text2Text_Generation
+# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-imdb-sentiment downloads::2,670 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelWithLMHead
 
 tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-imdb-sentiment")
 
 model = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-imdb-sentiment")
 
 def get_sentiment(text):
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-quartz.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-quartz.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-quartz downloads::254 task::Question_Answering
+# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-quartz downloads::254 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelWithLMHead, AutoTokenizer
 
 tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-quartz")
 model = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-quartz")
 
 def get_response(question, fact, opts, max_length=16):
   input_text = 'question: %s context: %s options: %s' % (question, fact, opts)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-question-generation-ap.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-question-generation-ap.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-question-generation-ap downloads::882,467 task::Text2Text_Generation
+# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-question-generation-ap downloads::882,467 task::Natural_Language_Processing sub_task::Text2Text_Generation
 # Tip: By now, install transformers from source
 
 from transformers import AutoModelWithLMHead, AutoTokenizer
 
 tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-question-generation-ap")
 model = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-question-generation-ap")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-span-sentiment-extraction.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-span-sentiment-extraction.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-span-sentiment-extraction downloads::42,794 task::Text2Text_Generation
+# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-span-sentiment-extraction downloads::42,794 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoModelWithLMHead, AutoTokenizer
 
 tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-span-sentiment-extraction")
 model = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-span-sentiment-extraction")
 
 def get_sentiment_span(text):
   input_ids = tokenizer.encode(text, return_tensors="pt", add_special_tokens=True)  # Batch size 1
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-base-finetuned-squadv2.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-base-finetuned-wikiSQL.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-squadv2 downloads::215 task::Text2Text_Generation
-from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
+# labels: test_group::monthly author::mrm8488 name::t5-base-finetuned-wikiSQL downloads::5,704 task::Natural_Language_Processing sub_task::Text2Text_Generation
+from transformers import AutoModelWithLMHead, AutoTokenizer
 
-tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-squadv2")
-model = AutoModelForSeq2SeqLM.from_pretrained("mrm8488/t5-base-finetuned-squadv2")
+tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")
+model = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")
 
-def get_answer(question, context):
-  input_text = "question: %s  context: %s" % (question, context)
+def get_sql(query):
+  input_text = "translate English to SQL: %s </s>" % query
   features = tokenizer([input_text], return_tensors='pt')
 
   output = model.generate(input_ids=features['input_ids'], 
                attention_mask=features['attention_mask'])
   
   return tokenizer.decode(output[0])
 
-context = "Manuel have created RuPERTa-base with the support of HF-Transformers and Google"
-question = "Who has supported Manuel?"
+query = "How many models were finetuned using BERT as base model?"
 
-get_answer(question, context)
+get_sql(query)
 
-# output: 'HF-Transformers and Google'
+# output: 'SELECT COUNT Model fine tuned FROM table WHERE Base model = BERT'
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/mrm8488_t5-small-finetuned-quora-for-paraphrasing.py` & `mlagility-3.1.1/models/popular_on_huggingface/mrm8488_t5-small-finetuned-quora-for-paraphrasing.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::mrm8488 name::t5-small-finetuned-quora-for-paraphrasing downloads::408 task::Text2Text_Generation
+# labels: test_group::monthly author::mrm8488 name::t5-small-finetuned-quora-for-paraphrasing downloads::408 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoModelWithLMHead, AutoTokenizer
 
 tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-small-finetuned-quora-for-paraphrasing")
 model = AutoModelWithLMHead.from_pretrained("mrm8488/t5-small-finetuned-quora-for-paraphrasing")
 
 def paraphrase(text, max_length=128):
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nateraw_vit-age-classifier.py` & `mlagility-3.1.1/models/popular_on_huggingface/nateraw_vit-age-classifier.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nateraw name::vit-age-classifier downloads::3,230 task::Image_Classification
+# labels: test_group::monthly author::nateraw name::vit-age-classifier downloads::3,230 task::Computer_Vision sub_task::Image_Classification
 import requests
 from PIL import Image
 from io import BytesIO
 
 from transformers import ViTFeatureExtractor, ViTForImageClassification
 
 # Get example image from official fairface repo + read it in as an image
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nateraw_vit-base-patch16-224-cifar10.py` & `mlagility-3.1.1/models/popular_on_huggingface/nateraw_vit-base-patch16-224-cifar10.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nateraw name::vit-base-patch16-224-cifar10 downloads::738 license::apache-2.0 task::Image_Classification
+# labels: test_group::monthly author::nateraw name::vit-base-patch16-224-cifar10 downloads::738 license::apache-2.0 task::Computer_Vision sub_task::Image_Classification
 from transformers import ViTFeatureExtractor, ViTForImageClassification
 from PIL import Image
 import requests
 
 url = 'https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog10.png'
 image = Image.open(requests.get(url, stream=True).raw)
 feature_extractor = ViTFeatureExtractor.from_pretrained('nateraw/vit-base-patch16-224-cifar10')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/navteca_bart-large-mnli.py` & `mlagility-3.1.1/models/popular_on_huggingface/navteca_bart-large-mnli.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::navteca name::bart-large-mnli downloads::1,332 license::mit task::Zero-Shot_Classification
+# labels: test_group::monthly author::navteca name::bart-large-mnli downloads::1,332 license::mit task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
 
 # Load model & tokenizer
 bart_model = AutoModelForSequenceClassification.from_pretrained('navteca/bart-large-mnli')
 bart_tokenizer = AutoTokenizer.from_pretrained('navteca/bart-large-mnli')
 
 # Get predictions
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/navteca_nli-deberta-v3-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/navteca_nli-deberta-v3-large.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::navteca name::nli-deberta-v3-large downloads::218 license::apache-2.0 task::Zero-Shot_Classification
+# labels: test_group::monthly author::navteca name::nli-deberta-v3-large downloads::218 license::apache-2.0 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 from sentence_transformers import CrossEncoder
 model = CrossEncoder('cross-encoder/nli-deberta-v3-large')
 scores = model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])
 
 #Convert scores to labels
 label_mapping = ['contradiction', 'entailment', 'neutral']
 labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/navteca_roberta-base-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/navteca_roberta-base-squad2.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::navteca name::roberta-base-squad2 downloads::906 license::mit task::Question_Answering
+# labels: test_group::monthly author::navteca name::roberta-base-squad2 downloads::906 license::mit task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
 
 # Load model & tokenizer
 roberta_model = AutoModelForQuestionAnswering.from_pretrained('navteca/roberta-base-squad2')
 roberta_tokenizer = AutoTokenizer.from_pretrained('navteca/roberta-base-squad2')
 
 # Get predictions
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/navteca_roberta-large-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/navteca_roberta-large-squad2.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::navteca name::roberta-large-squad2 downloads::1,323 license::mit task::Question_Answering
+# labels: test_group::monthly author::navteca name::roberta-large-squad2 downloads::1,323 license::mit task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
 
 # Load model & tokenizer
 roberta_model = AutoModelForQuestionAnswering.from_pretrained('navteca/roberta-large-squad2')
 roberta_tokenizer = AutoTokenizer.from_pretrained('navteca/roberta-large-squad2')
 
 # Get predictions
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nbroad_mt5-base-qgen.py` & `mlagility-3.1.1/models/popular_on_huggingface/nbroad_mt5-base-qgen.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nbroad name::mt5-base-qgen downloads::216 task::Text2Text_Generation
+# labels: test_group::monthly author::nbroad name::mt5-base-qgen downloads::216 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
   
 tokenizer = AutoTokenizer.from_pretrained("nbroad/mt5-base-qgen")
 model = AutoModelForSeq2SeqLM.from_pretrained("nbroad/mt5-base-qgen")
 
 text = "Hugging Face has seen rapid growth in its \
 popularity since the get-go. It is definitely doing\
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/neuraly_bert-base-italian-cased-sentiment.py` & `mlagility-3.1.1/models/popular_on_huggingface/neuraly_bert-base-italian-cased-sentiment.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::neuraly name::bert-base-italian-cased-sentiment downloads::1,736 license::mit task::Text_Classification
+# labels: test_group::monthly author::neuraly name::bert-base-italian-cased-sentiment downloads::1,736 license::mit task::Natural_Language_Processing sub_task::Text_Classification
 import torch
 from torch import nn  
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 
 # Load the tokenizer
 tokenizer = AutoTokenizer.from_pretrained("neuraly/bert-base-italian-cased-sentiment")
 # Load the model, use .cuda() to load it on the GPU
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/neuropark_sahajBERT.py` & `mlagility-3.1.1/models/popular_on_huggingface/neuropark_sahajBERT.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::neuropark name::sahajBERT downloads::341 license::apache-2.0 task::Fill-Mask
+# labels: test_group::monthly author::neuropark name::sahajBERT downloads::341 license::apache-2.0 task::Natural_Language_Processing sub_task::Fill-Mask
 
 from transformers import AlbertForMaskedLM, FillMaskPipeline, PreTrainedTokenizerFast
 
 # Initialize tokenizer
 
 tokenizer = PreTrainedTokenizerFast.from_pretrained("neuropark/sahajBERT")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nkoh01_MSRoberta.py` & `mlagility-3.1.1/models/popular_on_huggingface/nkoh01_MSRoberta.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nkoh01 name::MSRoberta downloads::705 task::Fill-Mask
+# labels: test_group::monthly author::nkoh01 name::MSRoberta downloads::705 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import pipeline,AutoModelForMaskedLM,AutoTokenizer
 tokenizer = AutoTokenizer.from_pretrained("nkoh01/MSRoberta")
 model = AutoModelForMaskedLM.from_pretrained("nkoh01/MSRoberta")
 
 unmasker = pipeline(
     "fill-mask",
     model=model,
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_groupvit-gcc-yfcc.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_groupvit-gcc-yfcc.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nvidia name::groupvit-gcc-yfcc downloads::787 task::Feature_Extraction
+# labels: test_group::monthly author::nvidia name::groupvit-gcc-yfcc downloads::787 task::Multimodal sub_task::Feature_Extraction
 from PIL import Image
 import requests
 from transformers import AutoProcessor, GroupViTModel
 
 model = GroupViTModel.from_pretrained("nvidia/groupvit-gcc-yfcc")
 processor = AutoProcessor.from_pretrained("nvidia/groupvit-gcc-yfcc")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_mit-b1.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_mit-b1.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nvidia name::mit-b1 downloads::2,859 license::other task::Image_Classification
+# labels: test_group::monthly author::nvidia name::mit-b1 downloads::2,859 license::other task::Computer_Vision sub_task::Image_Classification
 from transformers import SegformerFeatureExtractor, SegformerForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_mit-b2.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_mit-b4.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: test_group::monthly author::nvidia name::mit-b2 downloads::50,931 license::other task::Image_Classification
+# labels: test_group::monthly author::nvidia name::mit-b4 downloads::1,215 license::other task::Computer_Vision sub_task::Image_Classification
 from transformers import SegformerFeatureExtractor, SegformerForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/mit-b2")
-model = SegformerForImageClassification.from_pretrained("nvidia/mit-b2")
+feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/mit-b4")
+model = SegformerForImageClassification.from_pretrained("nvidia/mit-b4")
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits
 # model predicts one of the 1000 ImageNet classes
 predicted_class_idx = logits.argmax(-1).item()
 print("Predicted class:", model.config.id2label[predicted_class_idx])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_mit-b3.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_mit-b3.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nvidia name::mit-b3 downloads::2,356 license::other task::Image_Classification
+# labels: test_group::monthly author::nvidia name::mit-b3 downloads::2,356 license::other task::Computer_Vision sub_task::Image_Classification
 from transformers import SegformerFeatureExtractor, SegformerForImageClassification
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_mit-b4.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b4-finetuned-ade-512-512.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,14 @@
-# labels: test_group::monthly author::nvidia name::mit-b4 downloads::1,215 license::other task::Image_Classification
-from transformers import SegformerFeatureExtractor, SegformerForImageClassification
+# labels: test_group::monthly author::nvidia name::segformer-b4-finetuned-ade-512-512 downloads::1,352 license::other task::Computer_Vision sub_task::Image_Segmentation
+from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation
 from PIL import Image
 import requests
 
+feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b4-finetuned-ade-512-512")
+model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b4-finetuned-ade-512-512")
+
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/mit-b4")
-model = SegformerForImageClassification.from_pretrained("nvidia/mit-b4")
-
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
-logits = outputs.logits
-# model predicts one of the 1000 ImageNet classes
-predicted_class_idx = logits.argmax(-1).item()
-print("Predicted class:", model.config.id2label[predicted_class_idx])
+logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_mit-b5.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b4-finetuned-cityscapes-1024-1024.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,14 @@
-# labels: test_group::monthly author::nvidia name::mit-b5 downloads::1,712 license::other task::Image_Classification
-from transformers import SegformerFeatureExtractor, SegformerForImageClassification
+# labels: test_group::monthly author::nvidia name::segformer-b4-finetuned-cityscapes-1024-1024 downloads::496 license::other task::Computer_Vision sub_task::Image_Segmentation
+from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation
 from PIL import Image
 import requests
 
+feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b4-finetuned-cityscapes-1024-1024")
+model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b4-finetuned-cityscapes-1024-1024")
+
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
-feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/mit-b5")
-model = SegformerForImageClassification.from_pretrained("nvidia/mit-b5")
-
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
-logits = outputs.logits
-# model predicts one of the 1000 ImageNet classes
-predicted_class_idx = logits.argmax(-1).item()
-print("Predicted class:", model.config.id2label[predicted_class_idx])
+logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-ade-512-512.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-ade-512-512.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nvidia name::segformer-b0-finetuned-ade-512-512 downloads::81,385 license::other task::Image_Segmentation
+# labels: test_group::monthly author::nvidia name::segformer-b0-finetuned-ade-512-512 downloads::81,385 license::other task::Computer_Vision sub_task::Image_Segmentation
 from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation
 from PIL import Image
 import requests
 
 feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b0-finetuned-ade-512-512")
 model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b0-finetuned-ade-512-512")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-1024-1024.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-768-768.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly author::nvidia name::segformer-b0-finetuned-cityscapes-1024-1024 downloads::1,046 license::other task::Image_Segmentation
+# labels: test_group::monthly author::nvidia name::segformer-b0-finetuned-cityscapes-768-768 downloads::1,216 license::other task::Computer_Vision sub_task::Image_Segmentation
 from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation
 from PIL import Image
 import requests
 
-feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b0-finetuned-cityscapes-1024-1024")
-model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b0-finetuned-cityscapes-1024-1024")
+feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b0-finetuned-cityscapes-768-768")
+model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b0-finetuned-cityscapes-768-768")
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-512-1024.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-512-1024.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nvidia name::segformer-b0-finetuned-cityscapes-512-1024 downloads::216 license::other task::Image_Segmentation
+# labels: test_group::monthly author::nvidia name::segformer-b0-finetuned-cityscapes-512-1024 downloads::216 license::other task::Computer_Vision sub_task::Image_Segmentation
 from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation
 from PIL import Image
 import requests
 
 feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b0-finetuned-cityscapes-512-1024")
 model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b0-finetuned-cityscapes-512-1024")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-768-768.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b0-finetuned-cityscapes-1024-1024.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly author::nvidia name::segformer-b0-finetuned-cityscapes-768-768 downloads::1,216 license::other task::Image_Segmentation
+# labels: test_group::monthly author::nvidia name::segformer-b0-finetuned-cityscapes-1024-1024 downloads::1,046 license::other task::Computer_Vision sub_task::Image_Segmentation
 from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation
 from PIL import Image
 import requests
 
-feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b0-finetuned-cityscapes-768-768")
-model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b0-finetuned-cityscapes-768-768")
+feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b0-finetuned-cityscapes-1024-1024")
+model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b0-finetuned-cityscapes-1024-1024")
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b1-finetuned-ade-512-512.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b1-finetuned-ade-512-512.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nvidia name::segformer-b1-finetuned-ade-512-512 downloads::1,246 license::other task::Image_Segmentation
+# labels: test_group::monthly author::nvidia name::segformer-b1-finetuned-ade-512-512 downloads::1,246 license::other task::Computer_Vision sub_task::Image_Segmentation
 from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation
 from PIL import Image
 import requests
 
 feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b1-finetuned-ade-512-512")
 model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b1-finetuned-ade-512-512")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b2-finetuned-cityscapes-1024-1024.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b3-finetuned-ade-512-512.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly author::nvidia name::segformer-b2-finetuned-cityscapes-1024-1024 downloads::372 license::other task::Image_Segmentation
+# labels: test_group::monthly author::nvidia name::segformer-b3-finetuned-ade-512-512 downloads::752 license::other task::Computer_Vision sub_task::Image_Segmentation
 from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation
 from PIL import Image
 import requests
 
-feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b2-finetuned-cityscapes-1024-1024")
-model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b2-finetuned-cityscapes-1024-1024")
+feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b3-finetuned-ade-512-512")
+model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b3-finetuned-ade-512-512")
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
 
 inputs = feature_extractor(images=image, return_tensors="pt")
 outputs = model(**inputs)
 logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b3-finetuned-cityscapes-1024-1024.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b3-finetuned-cityscapes-1024-1024.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nvidia name::segformer-b3-finetuned-cityscapes-1024-1024 downloads::2,021 license::other task::Image_Segmentation
+# labels: test_group::monthly author::nvidia name::segformer-b3-finetuned-cityscapes-1024-1024 downloads::2,021 license::other task::Computer_Vision sub_task::Image_Segmentation
 from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation
 from PIL import Image
 import requests
 
 feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b3-finetuned-cityscapes-1024-1024")
 model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b3-finetuned-cityscapes-1024-1024")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/nvidia_segformer-b5-finetuned-cityscapes-1024-1024.py` & `mlagility-3.1.1/models/popular_on_huggingface/nvidia_segformer-b5-finetuned-cityscapes-1024-1024.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::nvidia name::segformer-b5-finetuned-cityscapes-1024-1024 downloads::3,407 license::other task::Image_Segmentation
+# labels: test_group::monthly author::nvidia name::segformer-b5-finetuned-cityscapes-1024-1024 downloads::3,407 license::other task::Computer_Vision sub_task::Image_Segmentation
 from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation
 from PIL import Image
 import requests
 
 feature_extractor = SegformerFeatureExtractor.from_pretrained("nvidia/segformer-b5-finetuned-cityscapes-1024-1024")
 model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b5-finetuned-cityscapes-1024-1024")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/openai_clip-vit-base-patch16.py` & `mlagility-3.1.1/models/popular_on_huggingface/openai_clip-vit-large-patch14.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,12 +1,17 @@
-# labels: test_group::monthly,daily author::openai name::clip-vit-base-patch16 downloads::70,786 task::Zero-Shot_Image_Classification
+# labels: test_group::monthly,daily author::openai name::clip-vit-large-patch14 downloads::11,601,851 task::Computer_Vision sub_task::Zero-Shot_Image_Classification
 from PIL import Image
 import requests
+
 from transformers import CLIPProcessor, CLIPModel
-model = CLIPModel.from_pretrained("openai/clip-vit-base-patch16")
-processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch16")
+
+model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")
+processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")
+
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
+
 inputs = processor(text=["a photo of a cat", "a photo of a dog"], images=image, return_tensors="pt", padding=True)
+
 outputs = model(**inputs)
 logits_per_image = outputs.logits_per_image # this is the image-text similarity score
 probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/openai_clip-vit-base-patch32.py` & `mlagility-3.1.1/models/popular_on_huggingface/openai_clip-vit-base-patch32.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly,daily author::openai name::clip-vit-base-patch32 downloads::2,330,296 task::Zero-Shot_Image_Classification
+# labels: test_group::monthly,daily author::openai name::clip-vit-base-patch32 downloads::2,330,296 task::Computer_Vision sub_task::Zero-Shot_Image_Classification
 from PIL import Image
 import requests
 
 from transformers import CLIPProcessor, CLIPModel
 
 model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
 processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/openai_clip-vit-large-patch14.py` & `mlagility-3.1.1/models/popular_on_huggingface/openai_clip-vit-base-patch16.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,12 @@
-# labels: test_group::monthly,daily author::openai name::clip-vit-large-patch14 downloads::11,601,851 task::Zero-Shot_Image_Classification
+# labels: test_group::monthly,daily author::openai name::clip-vit-base-patch16 downloads::70,786 task::Computer_Vision sub_task::Zero-Shot_Image_Classification
 from PIL import Image
 import requests
-
 from transformers import CLIPProcessor, CLIPModel
-
-model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")
-processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")
-
+model = CLIPModel.from_pretrained("openai/clip-vit-base-patch16")
+processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch16")
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
 image = Image.open(requests.get(url, stream=True).raw)
-
 inputs = processor(text=["a photo of a cat", "a photo of a dog"], images=image, return_tensors="pt", padding=True)
-
 outputs = model(**inputs)
 logits_per_image = outputs.logits_per_image # this is the image-text similarity score
 probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/patrickvonplaten_longformer2roberta-cnn_dailymail-fp16.py` & `mlagility-3.1.1/models/popular_on_huggingface/patrickvonplaten_longformer2roberta-cnn_dailymail-fp16.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::patrickvonplaten name::longformer2roberta-cnn_dailymail-fp16 downloads::513 task::Text2Text_Generation
+# labels: test_group::monthly author::patrickvonplaten name::longformer2roberta-cnn_dailymail-fp16 downloads::513 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import LongformerTokenizer, EncoderDecoderModel
 
 model = EncoderDecoderModel.from_pretrained("patrickvonplaten/longformer2roberta-cnn_dailymail-fp16")
 tokenizer = LongformerTokenizer.from_pretrained("allenai/longformer-base-4096") 
 
 article = """(CNN)James Holmes made his introduction to the world in a Colorado cinema filled with spectators watching a midnight showing of the new Batman movie, "The Dark Knight Rises," in June 2012. The moment became one of the deadliest shootings in U.S. history. Holmes is accused of opening fire on the crowd, killing 12 people and injuring or maiming 70 others in Aurora, a suburb of Denver. Holmes appeared like a comic book character: He resembled the Joker, with red-orange hair, similar to the late actor Heath Ledger\'s portrayal of the villain in an earlier Batman movie, authorities said. But Holmes was hardly a cartoon. Authorities said he wore body armor and carried several guns, including an AR-15 rifle, with lots of ammo. He also wore a gas mask. Holmes says he was insane at the time of the shootings, and that is his legal defense and court plea: not guilty by reason of insanity. Prosecutors aren\'t swayed and will seek the death penalty. Opening statements in his trial are scheduled to begin Monday. Holmes admits to the shootings but says he was suffering "a psychotic episode" at the time,  according to court papers filed in July 2013 by the state public defenders, Daniel King and Tamara A. Brady. Evidence "revealed thus far in the case supports the defense\'s position that Mr. Holmes suffers from a severe mental illness and was in the throes of a psychotic episode when he committed the acts that resulted in the tragic loss of life and injuries sustained by moviegoers on July 20, 2012," the public defenders wrote. Holmes no longer looks like a dazed Joker, as he did in his first appearance before a judge in 2012. He appeared dramatically different in January when jury selection began for his trial: 9,000 potential jurors were summoned for duty, described as one of the nation\'s largest jury calls. Holmes now has a cleaner look, with a mustache, button-down shirt and khaki pants. In January, he had a beard and eyeglasses. If this new image sounds like one of an academician, it may be because Holmes, now 27, once was one. Just before the shooting, Holmes was a doctoral student in neuroscience, and he was studying how the brain works, with his schooling funded by a U.S. government grant. Yet for all his learning, Holmes apparently lacked the capacity to command his own mind, according to the case against him. A jury will ultimately decide Holmes\' fate. That panel is made up of 12 jurors and 12 alternates. They are 19 women and five men, and almost all are white and middle-aged. The trial could last until autumn. When jury summonses were issued in January, each potential juror stood a 0.2% chance of being selected, District Attorney George Brauchler told the final jury this month. He described the approaching trial as "four to five months of a horrible roller coaster through the worst haunted house you can imagine." The jury will have to render verdicts on each of the 165 counts against Holmes, including murder and attempted murder charges. Meanwhile, victims and their relatives are challenging all media outlets "to stop the gratuitous use of the name and likeness of mass killers, thereby depriving violent individuals the media celebrity and media spotlight they so crave," the No Notoriety group says. They are joined by victims from eight other mass shootings in recent U.S. history. Raised in central coastal California and in San Diego, James Eagan Holmes is the son of a mathematician father noted for his work at the FICO firm that provides credit scores and a registered nurse mother, according to the U-T San Diego newspaper. Holmes also has a sister, Chris, a musician, who\'s five years younger, the newspaper said. His childhood classmates remember him as a clean-cut, bespectacled boy with an "exemplary" character who "never gave any trouble, and never got in trouble himself," The Salinas Californian reported. His family then moved down the California coast, where Holmes grew up in the San Diego-area neighborhood of Rancho Peasquitos, which a neighbor described as "kind of like Mayberry," the San Diego newspaper said. Holmes attended Westview High School, which says its school district sits in "a primarily middle- to upper-middle-income residential community." There, Holmes ran cross-country, played soccer and later worked at a biotechnology internship at the Salk Institute and Miramar College, which attracts academically talented students. By then, his peers described him as standoffish and a bit of a wiseacre, the San Diego newspaper said. Holmes attended college fairly close to home, in a neighboring area known as Southern California\'s "inland empire" because it\'s more than an hour\'s drive from the coast, in a warm, low-desert climate. He entered the University of California, Riverside, in 2006 as a scholarship student. In 2008 he was a summer camp counselor for disadvantaged children, age 7 to 14, at Camp Max Straus, run by Jewish Big Brothers Big Sisters of Los Angeles. He graduated from UC Riverside in 2010 with the highest honors and a bachelor\'s degree in neuroscience. "Academically, he was at the top of the top," Chancellor Timothy P. White said. He seemed destined for even higher achievement. By 2011, he had enrolled as a doctoral student in the neuroscience program at the University of Colorado Anschutz Medical Campus in Aurora, the largest academic health center in the Rocky Mountain region. The doctoral in neuroscience program attended by Holmes focuses on how the brain works, with an emphasis on processing of information, behavior, learning and memory. Holmes was one of six pre-thesis Ph.D. students in the program who were awarded a neuroscience training grant from the National Institutes of Health. The grant rewards outstanding neuroscientists who will make major contributions to neurobiology. A syllabus that listed Holmes as a student at the medical school shows he was to have delivered a presentation about microRNA biomarkers. But Holmes struggled, and his own mental health took an ominous turn. In March 2012, he told a classmate he wanted to kill people, and that he would do so "when his life was over," court documents said. Holmes was "denied access to the school after June 12, 2012, after he made threats to a professor," according to court documents. About that time, Holmes was a patient of University of Colorado psychiatrist Lynne Fenton. Fenton was so concerned about Holmes\' behavior that she mentioned it to her colleagues, saying he could be a danger to others, CNN affiliate KMGH-TV reported, citing sources with knowledge of the investigation. Fenton\'s concerns surfaced in early June, sources told the Denver station. Holmes began to fantasize about killing "a lot of people" in early June, nearly six weeks before the shootings, the station reported, citing unidentified sources familiar with the investigation. Holmes\' psychiatrist contacted several members of a "behavioral evaluation and threat assessment" team to say Holmes could be a danger to others, the station reported. At issue was whether to order Holmes held for 72 hours to be evaluated by mental health professionals, the station reported. "Fenton made initial phone calls about engaging the BETA team" in "the first 10 days" of June, but it "never came together" because in the period Fenton was having conversations with team members, Holmes began the process of dropping out of school, a source told KMGH. Defense attorneys have rejected the prosecution\'s assertions that Holmes was barred from campus. Citing statements from the university, Holmes\' attorneys have argued that his access was revoked because that\'s normal procedure when a student drops enrollment. What caused this turn for the worse for Holmes has yet to be clearly detailed. In the months before the shooting, he bought four weapons and more than 6,000 rounds of ammunition, authorities said. Police said he also booby-trapped his third-floor apartment with explosives, but police weren\'t fooled. After Holmes was caught in the cinema parking lot immediately after the shooting, bomb technicians went to the apartment and neutralized the explosives. No one was injured at the apartment building. Nine minutes before Holmes went into the movie theater, he called a University of Colorado switchboard, public defender Brady has said in court. The number he called can be used to get in contact with faculty members during off hours, Brady said. Court documents have also revealed that investigators have obtained text messages that Holmes exchanged with someone before the shooting. That person was not named, and the content of the texts has not been made public. According to The New York Times, Holmes sent a text message to a fellow graduate student, a woman, about two weeks before the shooting. She asked if he had left Aurora yet, reported the newspaper, which didn\'t identify her. No, he had two months left on his lease, Holmes wrote back, according to the Times. He asked if she had heard of "dysphoric mania," a form of bipolar disorder marked by the highs of mania and the dark and sometimes paranoid delusions of major depression. The woman asked if the disorder could be managed with treatment. "It was," Holmes wrote her, according to the Times. But he warned she should stay away from him "because I am bad news," the newspaper reported. It was her last contact with Holmes. After the shooting, Holmes\' family issued a brief statement: "Our hearts go out to those who were involved in this tragedy and to the families and friends of those involved," they said, without giving any information about their son. Since then, prosecutors have refused to offer a plea deal to Holmes. For Holmes, "justice is death," said Brauchler, the district attorney. In December, Holmes\' parents, who will be attending the trial, issued another statement: They asked that their son\'s life be spared and that he be sent to an institution for mentally ill people for the rest of his life, if he\'s found not guilty by reason of insanity. "He is not a monster," Robert and Arlene Holmes wrote, saying the death penalty is "morally wrong, especially when the condemned is mentally ill." "He is a human being gripped by a severe mental illness," the parents said. The matter will be settled by the jury. CNN\'s Ana Cabrera and Sara Weisfeldt contributed to this report from Denver."""
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/paust_pko-t5-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/paust_pko-t5-base.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::paust name::pko-t5-base downloads::624 license::cc-by-4.0 task::Text2Text_Generation
+# labels: test_group::monthly author::paust name::pko-t5-base downloads::624 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5TokenizerFast, T5ForConditionalGeneration
 
 tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-base')
 model = T5ForConditionalGeneration.from_pretrained('paust/pko-t5-base')
 
 input_ids = tokenizer(["qa question:   ?"]).input_ids
 labels = tokenizer(["T5 ."]).input_ids
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/paust_pko-t5-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/paust_pko-t5-large.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::paust name::pko-t5-large downloads::390 license::cc-by-4.0 task::Text2Text_Generation
+# labels: test_group::monthly author::paust name::pko-t5-large downloads::390 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import T5TokenizerFast, T5ForConditionalGeneration
 
 tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-large')
 model = T5ForConditionalGeneration.from_pretrained('paust/pko-t5-large')
 
 input_ids = tokenizer(["qa question:   ?"]).input_ids
 labels = tokenizer(["T5 ."]).input_ids
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/persiannlp_mt5-large-parsinlu-arc-comqa-obqa-multiple-choice.py` & `mlagility-3.1.1/models/popular_on_huggingface/persiannlp_mt5-large-parsinlu-arc-comqa-obqa-multiple-choice.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::persiannlp name::mt5-large-parsinlu-arc-comqa-obqa-multiple-choice downloads::246 license::cc-by-nc-sa-4.0 task::Text2Text_Generation
+# labels: test_group::monthly author::persiannlp name::mt5-large-parsinlu-arc-comqa-obqa-multiple-choice downloads::246 license::cc-by-nc-sa-4.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import MT5ForConditionalGeneration, MT5Tokenizer
 
 model_size = "large"
 model_name = f"persiannlp/mt5-{model_size}-parsinlu-arc-comqa-obqa-multiple-choice"
 tokenizer = MT5Tokenizer.from_pretrained(model_name)
 model = MT5ForConditionalGeneration.from_pretrained(model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/philschmid_distilroberta-base-ner-conll2003.py` & `mlagility-3.1.1/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-pos-lince.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# labels: test_group::monthly author::philschmid name::distilroberta-base-ner-conll2003 downloads::496 license::apache-2.0 task::Token_Classification
-from transformers import AutoTokenizer, AutoModelForTokenClassification
-from transformers import pipeline
+# labels: test_group::monthly author::sagorsarker name::codeswitch-hineng-pos-lince downloads::237 license::mit task::Natural_Language_Processing sub_task::Token_Classification
 
-tokenizer = AutoTokenizer.from_pretrained("philschmid/distilroberta-base-ner-conll2003")
-model = AutoModelForTokenClassification.from_pretrained("philschmid/distilroberta-base-ner-conll2003")
+from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
 
-nlp = pipeline("ner", model=model, tokenizer=tokenizer, grouped_entities=True)
-example = "My name is Philipp and live in Germany"
+tokenizer = AutoTokenizer.from_pretrained("sagorsarker/codeswitch-hineng-pos-lince")
 
-nlp(example)
+model = AutoModelForTokenClassification.from_pretrained("sagorsarker/codeswitch-hineng-pos-lince")
+pos_model = pipeline('ner', model=model, tokenizer=tokenizer)
+
+pos_model("put any hindi english code-mixed sentence")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/philschmid_distilroberta-base-ner-wikiann-conll2003-3-class.py` & `mlagility-3.1.1/models/popular_on_huggingface/philschmid_distilroberta-base-ner-conll2003.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,11 +1,11 @@
-# labels: test_group::monthly author::philschmid name::distilroberta-base-ner-wikiann-conll2003-3-class downloads::220 license::apache-2.0 task::Token_Classification
+# labels: test_group::monthly author::philschmid name::distilroberta-base-ner-conll2003 downloads::496 license::apache-2.0 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
 
-tokenizer = AutoTokenizer.from_pretrained("philschmid/distilroberta-base-ner-wikiann-conll2003-3-class")
-model = AutoModelForTokenClassification.from_pretrained("philschmid/distilroberta-base-ner-wikiann-conll2003-3-class")
+tokenizer = AutoTokenizer.from_pretrained("philschmid/distilroberta-base-ner-conll2003")
+model = AutoModelForTokenClassification.from_pretrained("philschmid/distilroberta-base-ner-conll2003")
 
 nlp = pipeline("ner", model=model, tokenizer=tokenizer, grouped_entities=True)
 example = "My name is Philipp and live in Germany"
 
 nlp(example)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/philschmid_distilroberta-base-ner-wikiann-conll2003-4-class.py` & `mlagility-3.1.1/models/popular_on_huggingface/philschmid_distilroberta-base-ner-wikiann-conll2003-4-class.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::philschmid name::distilroberta-base-ner-wikiann-conll2003-4-class downloads::213 license::apache-2.0 task::Token_Classification
+# labels: test_group::monthly author::philschmid name::distilroberta-base-ner-wikiann-conll2003-4-class downloads::213 license::apache-2.0 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
 
 tokenizer = AutoTokenizer.from_pretrained("philschmid/distilroberta-base-ner-wikiann-conll2003-4-class")
 model = AutoModelForTokenClassification.from_pretrained("philschmid/distilroberta-base-ner-wikiann-conll2003-4-class")
 
 nlp = pipeline("ner", model=model, tokenizer=tokenizer, grouped_entities=True)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/phiyodr_bart-large-finetuned-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/phiyodr_bart-large-finetuned-squad2.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::phiyodr name::bart-large-finetuned-squad2 downloads::361 task::Question_Answering
+# labels: test_group::monthly author::phiyodr name::bart-large-finetuned-squad2 downloads::361 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers.pipelines import pipeline
 
 model_name = "phiyodr/bart-large-finetuned-squad2"
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 inputs = {
     'question': 'What discipline did Winkelmann create?',
     'context': 'Johann Joachim Winckelmann was a German art historian and archaeologist. He was a pioneering Hellenist who first articulated the difference between Greek, Greco-Roman and Roman art. "The prophet and founding hero of modern archaeology", Winckelmann was one of the founders of scientific archaeology and first applied the categories of style on a large, systematic basis to the history of art. '
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/phiyodr_bert-base-finetuned-squad2.py` & `mlagility-3.1.1/models/popular_on_huggingface/phiyodr_bert-base-finetuned-squad2.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::phiyodr name::bert-base-finetuned-squad2 downloads::2,083 task::Question_Answering
+# labels: test_group::monthly author::phiyodr name::bert-base-finetuned-squad2 downloads::2,083 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers.pipelines import pipeline
 
 model_name = "phiyodr/bert-base-finetuned-squad2"
 nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
 inputs = {
     'question': 'What discipline did Winkelmann create?',
     'context': 'Johann Joachim Winckelmann was a German art historian and archaeologist. He was a pioneering Hellenist who first articulated the difference between Greek, Greco-Roman and Roman art. "The prophet and founding hero of modern archaeology", Winckelmann was one of the founders of scientific archaeology and first applied the categories of style on a large, systematic basis to the history of art. '
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/phpaiola_ptt5-base-summ-cstnews.py` & `mlagility-3.1.1/models/popular_on_huggingface/phpaiola_ptt5-base-summ-cstnews.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::phpaiola name::ptt5-base-summ-cstnews downloads::323 license::mit task::Summarization
+# labels: test_group::monthly author::phpaiola name::ptt5-base-summ-cstnews downloads::323 license::mit task::Natural_Language_Processing sub_task::Summarization
 # Tokenizer 
 from transformers import T5Tokenizer
 
 # PyTorch model 
 from transformers import T5Model, T5ForConditionalGeneration
 
 token_name = 'unicamp-dl/ptt5-base-portuguese-vocab'
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/pierreguillou_ner-bert-large-cased-pt-lenerbr.py` & `mlagility-3.1.1/models/popular_on_huggingface/pierreguillou_ner-bert-large-cased-pt-lenerbr.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::pierreguillou name::ner-bert-large-cased-pt-lenerbr downloads::449 task::Token_Classification
+# labels: test_group::monthly author::pierreguillou name::ner-bert-large-cased-pt-lenerbr downloads::449 task::Natural_Language_Processing sub_task::Token_Classification
 # install pytorch: check https://pytorch.org/
 # !pip install transformers 
 from transformers import AutoModelForTokenClassification, AutoTokenizer
 import torch
 
 # parameters
 model_name = "pierreguillou/ner-bert-large-cased-pt-lenerbr"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/pin_senda.py` & `mlagility-3.1.1/models/popular_on_huggingface/pin_senda.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::pin name::senda downloads::27,194 license::cc-by-4.0 task::Text_Classification
+# labels: test_group::monthly author::pin name::senda downloads::27,194 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
 tokenizer = AutoTokenizer.from_pretrained("pin/senda")
 model = AutoModelForSequenceClassification.from_pretrained("pin/senda")
 
 # create 'senda' sentiment analysis pipeline 
 senda_pipeline = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/projecte-aina_roberta-base-ca-v2.py` & `mlagility-3.1.1/models/popular_on_huggingface/projecte-aina_roberta-base-ca-v2.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::projecte-aina name::roberta-base-ca-v2 downloads::229 license::apache-2.0 task::Fill-Mask
+# labels: test_group::monthly author::projecte-aina name::roberta-base-ca-v2 downloads::229 license::apache-2.0 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import AutoModelForMaskedLM
 from transformers import AutoTokenizer, FillMaskPipeline
 from pprint import pprint
 tokenizer_hf = AutoTokenizer.from_pretrained('projecte-aina/roberta-base-ca-v2')
 model = AutoModelForMaskedLM.from_pretrained('projecte-aina/roberta-base-ca-v2')
 model.eval()
 pipeline = FillMaskPipeline(model, tokenizer_hf)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/pvl_labse_bert.py` & `mlagility-3.1.1/models/popular_on_huggingface/pvl_labse_bert.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::pvl name::labse_bert task::unknown downloads::5,198 license::apache-2.0
+# labels: test_group::monthly author::pvl name::labse_bert task::Natural_Language_Processing downloads::5,198 license::apache-2.0
 from transformers import AutoTokenizer, AutoModel
 import torch
 
 # from sentence-transformers
 def mean_pooling(model_output, attention_mask):
     token_embeddings = model_output[0] #First element of model_output contains all token embeddings
     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/racai_distilbert-base-romanian-uncased.py` & `mlagility-3.1.1/models/popular_on_huggingface/racai_distilbert-base-romanian-uncased.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::racai name::distilbert-base-romanian-uncased task::unknown downloads::389 license::mit
+# labels: test_group::monthly author::racai name::distilbert-base-romanian-uncased task::Natural_Language_Processing downloads::389 license::mit
 from transformers import AutoTokenizer, AutoModel
 
 # load the tokenizer and the model
 tokenizer = AutoTokenizer.from_pretrained("racai/distilbert-base-romanian-uncased")
 model = AutoModel.from_pretrained("racai/distilbert-base-romanian-uncased")
 
 # tokenize a test sentence
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ramsrigouthamg_t5-large-paraphraser-diverse-high-quality.py` & `mlagility-3.1.1/models/popular_on_huggingface/ramsrigouthamg_t5-large-paraphraser-diverse-high-quality.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ramsrigouthamg name::t5-large-paraphraser-diverse-high-quality downloads::69,043 task::Text2Text_Generation
+# labels: test_group::monthly author::ramsrigouthamg name::t5-large-paraphraser-diverse-high-quality downloads::69,043 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
 
 model = AutoModelForSeq2SeqLM.from_pretrained("ramsrigouthamg/t5-large-paraphraser-diverse-high-quality")
 tokenizer = AutoTokenizer.from_pretrained("ramsrigouthamg/t5-large-paraphraser-diverse-high-quality")
 
 import torch
 device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ramsrigouthamg_t5_paraphraser.py` & `mlagility-3.1.1/models/popular_on_huggingface/ramsrigouthamg_t5_paraphraser.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ramsrigouthamg name::t5_paraphraser downloads::5,088 task::Text2Text_Generation
+# labels: test_group::monthly author::ramsrigouthamg name::t5_paraphraser downloads::5,088 task::Natural_Language_Processing sub_task::Text2Text_Generation
 import torch
 from transformers import T5ForConditionalGeneration,T5Tokenizer
 
 
 def set_seed(seed):
   torch.manual_seed(seed)
   if torch.cuda.is_available():
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/readerbench_RoBERT-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/readerbench_RoBERT-base.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::readerbench name::RoBERT-base task::unknown downloads::265
+# labels: test_group::monthly author::readerbench name::RoBERT-base task::Natural_Language_Processing downloads::265
 # tensorflow
 from transformers import AutoModel, AutoTokenizer, TFAutoModel
 tokenizer = AutoTokenizer.from_pretrained("readerbench/RoBERT-base")
 model = TFAutoModel.from_pretrained("readerbench/RoBERT-base")
 inputs = tokenizer("exemplu de propoziie", return_tensors="tf")
 outputs = model(inputs)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/readerbench_RoBERT-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/readerbench_RoBERT-large.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::readerbench name::RoBERT-large task::unknown downloads::368
+# labels: test_group::monthly author::readerbench name::RoBERT-large task::Natural_Language_Processing downloads::368
 # tensorflow
 from transformers import AutoModel, AutoTokenizer, TFAutoModel
 tokenizer = AutoTokenizer.from_pretrained("readerbench/RoBERT-large")
 model = TFAutoModel.from_pretrained("readerbench/RoBERT-large")
 inputs = tokenizer("exemplu de propoziie", return_tensors="tf")
 outputs = model(inputs)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/readerbench_RoGPT2-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/readerbench_RoGPT2-base.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::readerbench name::RoGPT2-base downloads::871 task::Text_Generation
+# labels: test_group::monthly author::readerbench name::RoGPT2-base downloads::871 task::Natural_Language_Processing sub_task::Text_Generation
 # TensorFlow
 from transformers import AutoTokenizer, TFAutoModelForCausalLM
 
 tokenizer = AutoTokenizer.from_pretrained('readerbench/RoGPT2-base')
 model = TFAutoModelForCausalLM.from_pretrained('readerbench/RoGPT2-base')
 inputs = tokenizer.encode("Este o zi de vara", return_tensors='tf')
 text = model.generate(inputs, max_length=1024,  no_repeat_ngram_size=2)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/readerbench_RoGPT2-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/readerbench_RoGPT2-large.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::readerbench name::RoGPT2-large downloads::372 task::Text_Generation
+# labels: test_group::monthly author::readerbench name::RoGPT2-large downloads::372 task::Natural_Language_Processing sub_task::Text_Generation
 # TensorFlow
 from transformers import AutoTokenizer, TFAutoModelForCausalLM
 
 tokenizer = AutoTokenizer.from_pretrained('readerbench/RoGPT2-large')
 model = TFAutoModelForCausalLM.from_pretrained('readerbench/RoGPT2-large')
 inputs = tokenizer.encode("Este o zi de vara", return_tensors='tf')
 text = model.generate(inputs, max_length=1024,  no_repeat_ngram_size=2)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-lid-lince.py` & `mlagility-3.1.1/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-lid-lince.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::sagorsarker name::codeswitch-hineng-lid-lince downloads::310 license::mit task::Token_Classification
+# labels: test_group::monthly author::sagorsarker name::codeswitch-hineng-lid-lince downloads::310 license::mit task::Natural_Language_Processing sub_task::Token_Classification
 
 from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
 
 tokenizer = AutoTokenizer.from_pretrained("sagorsarker/codeswitch-hineng-lid-lince")
 
 model = AutoModelForTokenClassification.from_pretrained("sagorsarker/codeswitch-hineng-lid-lince")
 lid_model = pipeline('ner', model=model, tokenizer=tokenizer)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-pos-lince.py` & `mlagility-3.1.1/models/popular_on_huggingface/sagorsarker_codeswitch-hineng-ner-lince.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,10 +1,11 @@
-# labels: test_group::monthly author::sagorsarker name::codeswitch-hineng-pos-lince downloads::237 license::mit task::Token_Classification
+# labels: test_group::monthly author::sagorsarker name::codeswitch-hineng-ner-lince downloads::7,147 license::mit task::Natural_Language_Processing sub_task::Token_Classification
 
 from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
 
-tokenizer = AutoTokenizer.from_pretrained("sagorsarker/codeswitch-hineng-pos-lince")
+tokenizer = AutoTokenizer.from_pretrained("sagorsarker/codeswitch-hineng-ner-lince")
 
-model = AutoModelForTokenClassification.from_pretrained("sagorsarker/codeswitch-hineng-pos-lince")
-pos_model = pipeline('ner', model=model, tokenizer=tokenizer)
+model = AutoModelForTokenClassification.from_pretrained("sagorsarker/codeswitch-hineng-ner-lince")
 
-pos_model("put any hindi english code-mixed sentence")
+ner_model = pipeline('ner', model=model, tokenizer=tokenizer)
+
+ner_model("put any hindi english code-mixed sentence")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sagorsarker_codeswitch-spaeng-sentiment-analysis-lince.py` & `mlagility-3.1.1/models/popular_on_huggingface/sagorsarker_codeswitch-spaeng-sentiment-analysis-lince.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::sagorsarker name::codeswitch-spaeng-sentiment-analysis-lince downloads::236 license::mit task::Text_Classification
+# labels: test_group::monthly author::sagorsarker name::codeswitch-spaeng-sentiment-analysis-lince downloads::236 license::mit task::Natural_Language_Processing sub_task::Text_Classification
 
 from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
 
 tokenizer = AutoTokenizer.from_pretrained("sagorsarker/codeswitch-spaeng-sentiment-analysis-lince")
 
 model = AutoModelForSequenceClassification.from_pretrained("sagorsarker/codeswitch-spaeng-sentiment-analysis-lince")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/salesken_natural_rephrase.py` & `mlagility-3.1.1/models/popular_on_huggingface/salesken_natural_rephrase.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::salesken name::natural_rephrase downloads::203 license::apache-2.0 task::Text_Generation
+# labels: test_group::monthly author::salesken name::natural_rephrase downloads::203 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelWithLMHead
 tokenizer = AutoTokenizer.from_pretrained("salesken/natural_rephrase")
 model = AutoModelWithLMHead.from_pretrained("salesken/natural_rephrase")
 
 
 Input_query="Hey Siri, Send message to mom to say thank you for the delicious dinner yesterday"
 query= Input_query + " ~~ "
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/salesken_paraphrase_diversity_ranker.py` & `mlagility-3.1.1/models/popular_on_huggingface/salesken_paraphrase_diversity_ranker.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::salesken name::paraphrase_diversity_ranker downloads::681 license::apache-2.0 task::Text_Classification
+# labels: test_group::monthly author::salesken name::paraphrase_diversity_ranker downloads::681 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoTokenizer, AutoModelForSequenceClassification  
 import torch
 import pandas as pd
 import numpy as np
 tokenizer = AutoTokenizer.from_pretrained("salesken/paraphrase_diversity_ranker")
 model = AutoModelForSequenceClassification.from_pretrained("salesken/paraphrase_diversity_ranker")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/salesken_paraphrase_generation.py` & `mlagility-3.1.1/models/popular_on_huggingface/salesken_paraphrase_generation.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::salesken name::paraphrase_generation downloads::302 license::apache-2.0 task::Text_Generation
+# labels: test_group::monthly author::salesken name::paraphrase_generation downloads::302 license::apache-2.0 task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelWithLMHead 
 
 import torch
 if torch.cuda.is_available():
     device = torch.device("cuda")
 else :
     device = "cpu"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/salesken_text_generate.py` & `mlagility-3.1.1/models/popular_on_huggingface/salesken_text_generate.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::salesken name::text_generate downloads::205 task::Text_Generation
+# labels: test_group::monthly author::salesken name::text_generate downloads::205 task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import AutoTokenizer, AutoModelWithLMHead
 import torch
 if torch.cuda.is_available():
     device = torch.device("cuda")
 else :
     device = "cpu"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sampathkethineedi_industry-classification.py` & `mlagility-3.1.1/models/popular_on_huggingface/sampathkethineedi_industry-classification.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::sampathkethineedi name::industry-classification downloads::7,659 task::Text_Classification
+# labels: test_group::monthly author::sampathkethineedi name::industry-classification downloads::7,659 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
 
 tokenizer = AutoTokenizer.from_pretrained("sampathkethineedi/industry-classification")  
 model = AutoModelForSequenceClassification.from_pretrained("sampathkethineedi/industry-classification")
 
 industry_tags = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)
 industry_tags("Stellar Capital Services Limited is an India-based non-banking financial company ... loan against property, management consultancy, personal loans and unsecured loans.")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/savasy_bert-base-turkish-sentiment-cased.py` & `mlagility-3.1.1/models/popular_on_huggingface/savasy_bert-base-turkish-sentiment-cased.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::savasy name::bert-base-turkish-sentiment-cased downloads::2,311 task::Text_Classification
+# labels: test_group::monthly author::savasy name::bert-base-turkish-sentiment-cased downloads::2,311 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
 
 model = AutoModelForSequenceClassification.from_pretrained("savasy/bert-base-turkish-sentiment-cased")
 tokenizer = AutoTokenizer.from_pretrained("savasy/bert-base-turkish-sentiment-cased")
 sa= pipeline("sentiment-analysis", tokenizer=tokenizer, model=model)
 
 p = sa("bu telefon modelleri ok kaliteli , her paras ok zel bence")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sberbank-ai_sbert_large_mt_nlu_ru.py` & `mlagility-3.1.1/models/popular_on_huggingface/sberbank-ai_sbert_large_mt_nlu_ru.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::sberbank-ai name::sbert_large_mt_nlu_ru downloads::1,926 task::Feature_Extraction
+# labels: test_group::monthly author::sberbank-ai name::sbert_large_mt_nlu_ru downloads::1,926 task::Multimodal sub_task::Feature_Extraction
 from transformers import AutoTokenizer, AutoModel
 import torch
 #Mean Pooling - Take attention mask into account for correct averaging
 def mean_pooling(model_output, attention_mask):
     token_embeddings = model_output[0] #First element of model_output contains all token embeddings
     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
     sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sberbank-ai_sbert_large_nlu_ru.py` & `mlagility-3.1.1/models/popular_on_huggingface/sberbank-ai_sbert_large_nlu_ru.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::sberbank-ai name::sbert_large_nlu_ru downloads::2,295 task::Feature_Extraction
+# labels: test_group::monthly author::sberbank-ai name::sbert_large_nlu_ru downloads::2,295 task::Multimodal sub_task::Feature_Extraction
 from transformers import AutoTokenizer, AutoModel
 import torch
 
 
 #Mean Pooling - Take attention mask into account for correct averaging
 def mean_pooling(model_output, attention_mask):
     token_embeddings = model_output[0] #First element of model_output contains all token embeddings
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_clip-ViT-B-32-multilingual-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_clip-ViT-B-32-multilingual-v1.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::sentence-transformers name::clip-ViT-B-32-multilingual-v1 downloads::6,920 license::apache-2.0 task::Sentence_Similarity
+# labels: test_group::monthly author::sentence-transformers name::clip-ViT-B-32-multilingual-v1 downloads::6,920 license::apache-2.0 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer, util
 from PIL import Image, ImageFile
 import requests
 import torch
 
 # We use the original clip-ViT-B-32 for encoding images
 img_model = SentenceTransformer('clip-ViT-B-32')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-MiniLM-L6-cos-v5.py` & `mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_multi-qa-MiniLM-L6-dot-v1.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# labels: test_group::monthly author::sentence-transformers name::msmarco-MiniLM-L6-cos-v5 downloads::564 task::Sentence_Similarity
+# labels: test_group::monthly author::sentence-transformers name::multi-qa-MiniLM-L6-dot-v1 downloads::15,238 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer, util
 
 query = "How many people live in London?"
 docs = ["Around 9 Million people live in London", "London is known for its financial district"]
 
 #Load the model
-model = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L6-cos-v5')
+model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-dot-v1')
 
 #Encode query and documents
 query_emb = model.encode(query)
 doc_emb = model.encode(docs)
 
 #Compute dot score between query and all document embeddings
 scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-bert-base-dot-v5.py` & `mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-MiniLM-L6-cos-v5.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# labels: test_group::monthly author::sentence-transformers name::msmarco-bert-base-dot-v5 downloads::41,358 task::Sentence_Similarity
+# labels: test_group::monthly author::sentence-transformers name::msmarco-MiniLM-L6-cos-v5 downloads::564 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer, util
 
 query = "How many people live in London?"
 docs = ["Around 9 Million people live in London", "London is known for its financial district"]
 
 #Load the model
-model = SentenceTransformer('sentence-transformers/msmarco-bert-base-dot-v5')
+model = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L6-cos-v5')
 
 #Encode query and documents
 query_emb = model.encode(query)
 doc_emb = model.encode(docs)
 
 #Compute dot score between query and all document embeddings
 scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()
@@ -17,10 +17,9 @@
 #Combine docs & scores
 doc_score_pairs = list(zip(docs, scores))
 
 #Sort by decreasing score
 doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)
 
 #Output passages & scores
-print("Query:", query)
 for doc, score in doc_score_pairs:
     print(score, doc)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-tas-b.py` & `mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-cos-v5.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# labels: test_group::monthly author::sentence-transformers name::msmarco-distilbert-base-tas-b downloads::22,475 license::apache-2.0 task::Sentence_Similarity
+# labels: test_group::monthly author::sentence-transformers name::msmarco-distilbert-cos-v5 downloads::6,386 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer, util
 
 query = "How many people live in London?"
 docs = ["Around 9 Million people live in London", "London is known for its financial district"]
 
 #Load the model
-model = SentenceTransformer('sentence-transformers/msmarco-distilbert-base-tas-b')
+model = SentenceTransformer('sentence-transformers/msmarco-distilbert-cos-v5')
 
 #Encode query and documents
 query_emb = model.encode(query)
 doc_emb = model.encode(docs)
 
 #Compute dot score between query and all document embeddings
 scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-cos-v5.py` & `mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_multi-qa-distilbert-cos-v1.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# labels: test_group::monthly author::sentence-transformers name::msmarco-distilbert-cos-v5 downloads::6,386 task::Sentence_Similarity
+# labels: test_group::monthly author::sentence-transformers name::multi-qa-distilbert-cos-v1 downloads::8,334 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer, util
 
 query = "How many people live in London?"
 docs = ["Around 9 Million people live in London", "London is known for its financial district"]
 
 #Load the model
-model = SentenceTransformer('sentence-transformers/msmarco-distilbert-cos-v5')
+model = SentenceTransformer('sentence-transformers/multi-qa-distilbert-cos-v1')
 
 #Encode query and documents
 query_emb = model.encode(query)
 doc_emb = model.encode(docs)
 
 #Compute dot score between query and all document embeddings
 scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-dot-v5.py` & `mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_msmarco-distilbert-base-tas-b.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# labels: test_group::monthly author::sentence-transformers name::msmarco-distilbert-dot-v5 downloads::4,543 license::apache-2.0 task::Sentence_Similarity
+# labels: test_group::monthly author::sentence-transformers name::msmarco-distilbert-base-tas-b downloads::22,475 license::apache-2.0 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer, util
 
 query = "How many people live in London?"
 docs = ["Around 9 Million people live in London", "London is known for its financial district"]
 
 #Load the model
-model = SentenceTransformer('sentence-transformers/msmarco-distilbert-dot-v5')
+model = SentenceTransformer('sentence-transformers/msmarco-distilbert-base-tas-b')
 
 #Encode query and documents
 query_emb = model.encode(query)
 doc_emb = model.encode(docs)
 
 #Compute dot score between query and all document embeddings
 scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()
@@ -17,10 +17,9 @@
 #Combine docs & scores
 doc_score_pairs = list(zip(docs, scores))
 
 #Sort by decreasing score
 doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)
 
 #Output passages & scores
-print("Query:", query)
 for doc, score in doc_score_pairs:
     print(score, doc)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_multi-qa-MiniLM-L6-cos-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_multi-qa-MiniLM-L6-cos-v1.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::sentence-transformers name::multi-qa-MiniLM-L6-cos-v1 downloads::316,426 task::Sentence_Similarity
+# labels: test_group::monthly author::sentence-transformers name::multi-qa-MiniLM-L6-cos-v1 downloads::316,426 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer, util
 
 query = "How many people live in London?"
 docs = ["Around 9 Million people live in London", "London is known for its financial district"]
 
 #Load the model
 model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_multi-qa-mpnet-base-cos-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_multi-qa-mpnet-base-cos-v1.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::sentence-transformers name::multi-qa-mpnet-base-cos-v1 downloads::19,496 task::Sentence_Similarity
+# labels: test_group::monthly author::sentence-transformers name::multi-qa-mpnet-base-cos-v1 downloads::19,496 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer, util
 
 query = "How many people live in London?"
 docs = ["Around 9 Million people live in London", "London is known for its financial district"]
 
 #Load the model
 model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/sentence-transformers_multi-qa-mpnet-base-dot-v1.py` & `mlagility-3.1.1/models/popular_on_huggingface/sentence-transformers_multi-qa-mpnet-base-dot-v1.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::sentence-transformers name::multi-qa-mpnet-base-dot-v1 downloads::659,591 task::Sentence_Similarity
+# labels: test_group::monthly author::sentence-transformers name::multi-qa-mpnet-base-dot-v1 downloads::659,591 task::Natural_Language_Processing sub_task::Sentence_Similarity
 from sentence_transformers import SentenceTransformer, util
 
 query = "How many people live in London?"
 docs = ["Around 9 Million people live in London", "London is known for its financial district"]
 
 #Load the model
 model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/setu4993_smaller-LaBSE.py` & `mlagility-3.1.1/models/popular_on_huggingface/setu4993_LaBSE.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-# labels: test_group::monthly author::setu4993 name::smaller-LaBSE downloads::1,111 license::apache-2.0 task::Feature_Extraction
+# labels: test_group::monthly author::setu4993 name::LaBSE downloads::5,160 license::apache-2.0 task::Multimodal sub_task::Feature_Extraction
 import torch
 from transformers import BertModel, BertTokenizerFast
 
 
-tokenizer = BertTokenizerFast.from_pretrained("setu4993/smaller-LaBSE")
-model = BertModel.from_pretrained("setu4993/smaller-LaBSE")
+tokenizer = BertTokenizerFast.from_pretrained("setu4993/LaBSE")
+model = BertModel.from_pretrained("setu4993/LaBSE")
 model = model.eval()
 
 english_sentences = [
     "dog",
     "Puppies are nice.",
     "I enjoy taking long walks along the beach with my dog.",
 ]
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/soheeyang_rdr-question_encoder-single-nq-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/soheeyang_rdr-question_encoder-single-nq-base.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::soheeyang name::rdr-question_encoder-single-nq-base downloads::1,236 task::Feature_Extraction
+# labels: test_group::monthly author::soheeyang name::rdr-question_encoder-single-nq-base downloads::1,236 task::Multimodal sub_task::Feature_Extraction
 from transformers import DPRQuestionEncoder, AutoTokenizer
 
 tokenizer = AutoTokenizer.from_pretrained("soheeyang/rdr-question_encoder-single-trivia-base")
 question_encoder = DPRQuestionEncoder.from_pretrained("soheeyang/rdr-question_encoder-single-trivia-base")
 
 data = tokenizer("question comes here", return_tensors="pt")
 question_embedding = question_encoder(**data).pooler_output  # embedding vector for question
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/squirro_albert-base-v2-squad_v2.py` & `mlagility-3.1.1/models/popular_on_huggingface/squirro_albert-base-v2-squad_v2.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::squirro name::albert-base-v2-squad_v2 downloads::199 license::apache-2.0 task::Question_Answering
+# labels: test_group::monthly author::squirro name::albert-base-v2-squad_v2 downloads::199 license::apache-2.0 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer, QuestionAnsweringPipeline
 model = AutoModelForQuestionAnswering.from_pretrained("squirro/albert-base-v2-squad_v2")
 tokenizer = AutoTokenizer.from_pretrained("squirro/albert-base-v2-squad_v2")
 qa_model = QuestionAnsweringPipeline(model, tokenizer)
 qa_model(
    question="What's your name?",
    context="My name is Clara and I live in Berkeley.",
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/strombergnlp_dant5-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/strombergnlp_dant5-large.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::strombergnlp name::dant5-large downloads::332 license::cc-by-4.0 task::Text2Text_Generation
+# labels: test_group::monthly author::strombergnlp name::dant5-large downloads::332 license::cc-by-4.0 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoTokenizer, T5ForConditionalGeneration
 
 model_name = "strombergnlp/dant5-large"
 
 tokenizer = AutoTokenizer.from_pretrained(model_name)
 model = T5ForConditionalGeneration.from_pretrained(model_name)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/svalabs_gbert-large-zeroshot-nli.py` & `mlagility-3.1.1/models/popular_on_huggingface/svalabs_gbert-large-zeroshot-nli.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::svalabs name::gbert-large-zeroshot-nli downloads::1,288 task::Zero-Shot_Classification
+# labels: test_group::monthly author::svalabs name::gbert-large-zeroshot-nli downloads::1,288 task::Natural_Language_Processing sub_task::Zero-Shot_Classification
 
 from transformers import pipeline
 
 zershot_pipeline = pipeline("zero-shot-classification",
                              model="svalabs/gbert-large-zeroshot-nli")
 
 sequence = "Ich habe ein Problem mit meinem Iphone das so schnell wie mglich gelst werden muss"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/t5-base.py` & `mlagility-3.1.1/models/popular_on_huggingface/t5-base.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::huggingface name::t5-base downloads::1,826,561 license::apache-2.0 task::Translation
+# labels: test_group::monthly author::huggingface name::t5-base downloads::1,826,561 license::apache-2.0 task::Natural_Language_Processing sub_task::Translation
 from transformers import T5Tokenizer, T5Model
 
 tokenizer = T5Tokenizer.from_pretrained("t5-base")
 model = T5Model.from_pretrained("t5-base")
 
 input_ids = tokenizer(
     "Studies have been shown that owning a dog is good for you", return_tensors="pt"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/t5-large.py` & `mlagility-3.1.1/models/popular_on_huggingface/t5-large.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::huggingface name::t5-large downloads::253,127 license::apache-2.0 task::Translation
+# labels: test_group::monthly author::huggingface name::t5-large downloads::253,127 license::apache-2.0 task::Natural_Language_Processing sub_task::Translation
 from transformers import T5Tokenizer, T5Model
 
 tokenizer = T5Tokenizer.from_pretrained("t5-large")
 model = T5Model.from_pretrained("t5-large")
 
 input_ids = tokenizer(
     "Studies have been shown that owning a dog is good for you", return_tensors="pt"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/t5-small.py` & `mlagility-3.1.1/models/popular_on_huggingface/t5-small.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::huggingface name::t5-small downloads::2,296,353 license::apache-2.0 task::Translation
+# labels: test_group::monthly author::huggingface name::t5-small downloads::2,296,353 license::apache-2.0 task::Natural_Language_Processing sub_task::Translation
 from transformers import T5Tokenizer, T5Model
 
 tokenizer = T5Tokenizer.from_pretrained("t5-small")
 model = T5Model.from_pretrained("t5-small")
 
 input_ids = tokenizer(
     "Studies have been shown that owning a dog is good for you", return_tensors="pt"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/taeminlee_kogpt2.py` & `mlagility-3.1.1/models/popular_on_huggingface/taeminlee_kogpt2.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::taeminlee name::kogpt2 downloads::1,006 task::Text_Generation
+# labels: test_group::monthly author::taeminlee name::kogpt2 downloads::1,006 task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast
 
 model = GPT2LMHeadModel.from_pretrained("taeminlee/kogpt2")
 tokenizer = PreTrainedTokenizerFast.from_pretrained("taeminlee/kogpt2")
 
 input_ids = tokenizer.encode("", add_special_tokens=False, return_tensors="pt")
 output_sequences = model.generate(input_ids=input_ids, do_sample=True, max_length=100, num_return_sequences=3)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/tdobrxl_ClinicBERT.py` & `mlagility-3.1.1/models/popular_on_huggingface/tdobrxl_ClinicBERT.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::tdobrxl name::ClinicBERT downloads::434 task::Fill-Mask
+# labels: test_group::monthly author::tdobrxl name::ClinicBERT downloads::434 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import RobertaModel, RobertaTokenizer
 model = RobertaModel.from_pretrained("tdobrxl/ClinicBERT")
 tokenizer = RobertaTokenizer.from_pretrained("tdobrxl/ClinicBERT")
 
 text = "Randomized Study of Shark Cartilage in Patients With Breast Cancer."
 last_hidden_state, pooler_output = model(tokenizer.encode(text, return_tensors="pt")).last_hidden_state, model(tokenizer.encode(text, return_tensors="pt")).pooler_output
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/thanathorn_mt5-cpe-kmutt-thai-sentence-sum.py` & `mlagility-3.1.1/models/popular_on_huggingface/thanathorn_mt5-cpe-kmutt-thai-sentence-sum.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::thanathorn name::mt5-cpe-kmutt-thai-sentence-sum downloads::744 task::Summarization
+# labels: test_group::monthly author::thanathorn name::mt5-cpe-kmutt-thai-sentence-sum downloads::744 task::Natural_Language_Processing sub_task::Summarization
 from simpletransformers.t5 import T5Model, T5Args
 from torch import cuda
 
 model = T5Model("t5", "thanathorn/mt5-cpe-kmutt-thai-sentence-sum", use_cuda=cuda.is_available())
 
 sentence = "simplify:   "
 prediction = model.predict([sentence])
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/tugstugi_bert-large-mongolian-uncased.py` & `mlagility-3.1.1/models/popular_on_huggingface/tugstugi_bert-large-mongolian-uncased.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::tugstugi name::bert-large-mongolian-uncased downloads::648 task::Fill-Mask
+# labels: test_group::monthly author::tugstugi name::bert-large-mongolian-uncased downloads::648 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import pipeline, AutoTokenizer, AutoModelForMaskedLM
 
 tokenizer = AutoTokenizer.from_pretrained('tugstugi/bert-large-mongolian-uncased', use_fast=False)
 model = AutoModelForMaskedLM.from_pretrained('tugstugi/bert-large-mongolian-uncased')
 
 ## declare task ##
 pipe = pipeline(task="fill-mask", model=model, tokenizer=tokenizer)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-chinese-extractive-qa.py` & `mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-chinese-extractive-qa.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::uer name::roberta-base-chinese-extractive-qa downloads::4,469 task::Question_Answering
+# labels: test_group::monthly author::uer name::roberta-base-chinese-extractive-qa downloads::4,469 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import AutoModelForQuestionAnswering,AutoTokenizer,pipeline
 model = AutoModelForQuestionAnswering.from_pretrained('uer/roberta-base-chinese-extractive-qa')
 tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-chinese-extractive-qa')
 QA = pipeline('question-answering', model=model, tokenizer=tokenizer)
 QA_input = {'question': "",'context': ""}
 QA(QA_input)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-finetuned-chinanews-chinese.py` & `mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-finetuned-chinanews-chinese.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::uer name::roberta-base-finetuned-chinanews-chinese downloads::3,754 task::Text_Classification
+# labels: test_group::monthly author::uer name::roberta-base-finetuned-chinanews-chinese downloads::3,754 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification,AutoTokenizer,pipeline
 model = AutoModelForSequenceClassification.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')
 tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')
 text_classification = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)
 text_classification("")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-finetuned-cluener2020-chinese.py` & `mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-finetuned-cluener2020-chinese.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::uer name::roberta-base-finetuned-cluener2020-chinese downloads::5,409 task::Token_Classification
+# labels: test_group::monthly author::uer name::roberta-base-finetuned-cluener2020-chinese downloads::5,409 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoModelForTokenClassification,AutoTokenizer,pipeline
 model = AutoModelForTokenClassification.from_pretrained('uer/roberta-base-finetuned-cluener2020-chinese')
 tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-cluener2020-chinese')
 ner = pipeline('ner', model=model, tokenizer=tokenizer)
 ner("")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-finetuned-dianping-chinese.py` & `mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-finetuned-jd-full-chinese.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::uer name::roberta-base-finetuned-dianping-chinese downloads::2,604 task::Text_Classification
+# labels: test_group::monthly author::uer name::roberta-base-finetuned-jd-full-chinese downloads::956 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification,AutoTokenizer,pipeline
 model = AutoModelForSequenceClassification.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')
 tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')
 text_classification = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)
 text_classification("")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-finetuned-jd-binary-chinese.py` & `mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-finetuned-jd-binary-chinese.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::uer name::roberta-base-finetuned-jd-binary-chinese downloads::452 task::Text_Classification
+# labels: test_group::monthly author::uer name::roberta-base-finetuned-jd-binary-chinese downloads::452 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification,AutoTokenizer,pipeline
 model = AutoModelForSequenceClassification.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')
 tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')
 text_classification = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)
 text_classification("")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/uer_roberta-base-finetuned-jd-full-chinese.py` & `mlagility-3.1.1/models/popular_on_huggingface/uer_roberta-base-finetuned-dianping-chinese.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::uer name::roberta-base-finetuned-jd-full-chinese downloads::956 task::Text_Classification
+# labels: test_group::monthly author::uer name::roberta-base-finetuned-dianping-chinese downloads::2,604 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import AutoModelForSequenceClassification,AutoTokenizer,pipeline
 model = AutoModelForSequenceClassification.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')
 tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')
 text_classification = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)
 text_classification("")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/uer_t5-base-chinese-cluecorpussmall.py` & `mlagility-3.1.1/models/popular_on_huggingface/uer_t5-base-chinese-cluecorpussmall.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::uer name::t5-base-chinese-cluecorpussmall downloads::624 task::Text2Text_Generation
+# labels: test_group::monthly author::uer name::t5-base-chinese-cluecorpussmall downloads::624 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import BertTokenizer, T5ForConditionalGeneration, Text2TextGenerationPipeline
 tokenizer = BertTokenizer.from_pretrained("uer/t5-small-chinese-cluecorpussmall")
 model = T5ForConditionalGeneration.from_pretrained("uer/t5-small-chinese-cluecorpussmall")
 text2text_generator = Text2TextGenerationPipeline(model, tokenizer)  
 text2text_generator("extra0", max_length=50, do_sample=False)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/uer_t5-small-chinese-cluecorpussmall.py` & `mlagility-3.1.1/models/popular_on_huggingface/uer_t5-small-chinese-cluecorpussmall.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::uer name::t5-small-chinese-cluecorpussmall downloads::310,636 task::Text2Text_Generation
+# labels: test_group::monthly author::uer name::t5-small-chinese-cluecorpussmall downloads::310,636 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import BertTokenizer, T5ForConditionalGeneration, Text2TextGenerationPipeline
 tokenizer = BertTokenizer.from_pretrained("uer/t5-small-chinese-cluecorpussmall")
 model = T5ForConditionalGeneration.from_pretrained("uer/t5-small-chinese-cluecorpussmall")
 text2text_generator = Text2TextGenerationPipeline(model, tokenizer)  
 text2text_generator("extra0", max_length=50, do_sample=False)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/uer_t5-v1_1-base-chinese-cluecorpussmall.py` & `mlagility-3.1.1/models/popular_on_huggingface/uer_t5-v1_1-base-chinese-cluecorpussmall.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::uer name::t5-v1_1-base-chinese-cluecorpussmall downloads::1,673 task::Text2Text_Generation
+# labels: test_group::monthly author::uer name::t5-v1_1-base-chinese-cluecorpussmall downloads::1,673 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import BertTokenizer, MT5ForConditionalGeneration, Text2TextGenerationPipeline
 tokenizer = BertTokenizer.from_pretrained("uer/t5-v1_1-small-chinese-cluecorpussmall")
 model = MT5ForConditionalGeneration.from_pretrained("uer/t5-v1_1-small-chinese-cluecorpussmall")
 text2text_generator = Text2TextGenerationPipeline(model, tokenizer)  
 text2text_generator("extra0", max_length=50, do_sample=False)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/uer_t5-v1_1-small-chinese-cluecorpussmall.py` & `mlagility-3.1.1/models/popular_on_huggingface/uer_t5-v1_1-small-chinese-cluecorpussmall.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::uer name::t5-v1_1-small-chinese-cluecorpussmall downloads::359 task::Text2Text_Generation
+# labels: test_group::monthly author::uer name::t5-v1_1-small-chinese-cluecorpussmall downloads::359 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import BertTokenizer, MT5ForConditionalGeneration, Text2TextGenerationPipeline
 tokenizer = BertTokenizer.from_pretrained("uer/t5-v1_1-small-chinese-cluecorpussmall")
 model = MT5ForConditionalGeneration.from_pretrained("uer/t5-v1_1-small-chinese-cluecorpussmall")
 text2text_generator = Text2TextGenerationPipeline(model, tokenizer)  
 text2text_generator("extra0", max_length=50, do_sample=False)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ushikado_yuyuyui-chatbot.py` & `mlagility-3.1.1/models/popular_on_huggingface/ushikado_yuyuyui-chatbot.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ushikado name::yuyuyui-chatbot downloads::483 task::Text_Generation
+# labels: test_group::monthly author::ushikado name::yuyuyui-chatbot downloads::483 task::Natural_Language_Processing sub_task::Text_Generation
 from transformers import T5Tokenizer, AutoModelForCausalLM
 
 tokenizer = T5Tokenizer.from_pretrained("ushikado/yuyuyui-chatbot")
 model = AutoModelForCausalLM.from_pretrained("ushikado/yuyuyui-chatbot")
 
 query_text = "<></s>< >"
 input_tensor = tokenizer.encode(query_text, add_special_tokens=False, return_tensors="pt")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/valhalla_bart-large-finetuned-squadv1.py` & `mlagility-3.1.1/models/popular_on_huggingface/valhalla_bart-large-finetuned-squadv1.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::valhalla name::bart-large-finetuned-squadv1 downloads::1,872 task::Question_Answering
+# labels: test_group::monthly author::valhalla name::bart-large-finetuned-squadv1 downloads::1,872 task::Natural_Language_Processing sub_task::Question_Answering
 from transformers import BartTokenizer, BartForQuestionAnswering
 import torch
 
 tokenizer = BartTokenizer.from_pretrained('valhalla/bart-large-finetuned-squadv1')
 model = BartForQuestionAnswering.from_pretrained('valhalla/bart-large-finetuned-squadv1')
 
 question, text = "Who was Jim Henson?", "Jim Henson was a nice puppet"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/valhalla_t5-base-squad.py` & `mlagility-3.1.1/models/popular_on_huggingface/valhalla_t5-base-squad.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::valhalla name::t5-base-squad downloads::99,402 task::Text2Text_Generation
+# labels: test_group::monthly author::valhalla name::t5-base-squad downloads::99,402 task::Natural_Language_Processing sub_task::Text2Text_Generation
 from transformers import AutoModelWithLMHead, AutoTokenizer
 
 tokenizer = AutoTokenizer.from_pretrained("valhalla/t5-base-squad")
 model = AutoModelWithLMHead.from_pretrained("valhalla/t5-base-squad")
 
 def get_answer(question, context):
   input_text = "question: %s  context: %s </s>" % (question, context)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/vblagoje_dpr-ctx_encoder-single-lfqa-wiki.py` & `mlagility-3.1.1/models/popular_on_huggingface/vblagoje_dpr-ctx_encoder-single-lfqa-wiki.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-# labels: test_group::monthly author::vblagoje name::dpr-ctx_encoder-single-lfqa-wiki task::unknown downloads::8,721 license::mit
+# labels: test_group::monthly author::vblagoje name::dpr-ctx_encoder-single-lfqa-wiki task::Natural_Language_Processing downloads::8,721 license::mit
 from transformers import DPRContextEncoder, DPRContextEncoderTokenizer
 
 tokenizer = DPRContextEncoderTokenizer.from_pretrained("vblagoje/dpr-ctx_encoder-single-lfqa-wiki")
 model = DPRContextEncoder.from_pretrained("vblagoje/dpr-ctx_encoder-single-lfqa-wiki")
 input_ids = tokenizer("Where an aircraft passes through a cloud, it can disperse the cloud in its path...", return_tensors="pt")["input_ids"]
 embeddings = model(input_ids).pooler_output
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/vinvino02_glpn-kitti.py` & `mlagility-3.1.1/models/popular_on_huggingface/vinvino02_glpn-kitti.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::vinvino02 name::glpn-kitti task::unknown downloads::493 license::apache-2.0
+# labels: test_group::monthly author::vinvino02 name::glpn-kitti task::Computer_Vision downloads::493 license::apache-2.0
 from transformers import GLPNFeatureExtractor, GLPNForDepthEstimation
 import torch
 import numpy as np
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/vinvino02_glpn-nyu.py` & `mlagility-3.1.1/models/popular_on_huggingface/vinvino02_glpn-nyu.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::vinvino02 name::glpn-nyu task::unknown downloads::752 license::apache-2.0
+# labels: test_group::monthly author::vinvino02 name::glpn-nyu task::Computer_Vision downloads::752 license::apache-2.0
 from transformers import GLPNFeatureExtractor, GLPNForDepthEstimation
 import torch
 import numpy as np
 from PIL import Image
 import requests
 
 url = "http://images.cocodataset.org/val2017/000000039769.jpg"
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/voidful_albert_chinese_base.py` & `mlagility-3.1.1/models/popular_on_huggingface/voidful_albert_chinese_base.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::voidful name::albert_chinese_base downloads::945 task::Fill-Mask
+# labels: test_group::monthly author::voidful name::albert_chinese_base downloads::945 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import AutoTokenizer, AlbertForMaskedLM
 import torch
 from torch.nn.functional import softmax
 
 pretrained = 'voidful/albert_chinese_base'
 tokenizer = AutoTokenizer.from_pretrained(pretrained)
 model = AlbertForMaskedLM.from_pretrained(pretrained)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/voidful_albert_chinese_large.py` & `mlagility-3.1.1/models/popular_on_huggingface/voidful_albert_chinese_large.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::voidful name::albert_chinese_large downloads::185 task::Fill-Mask
+# labels: test_group::monthly author::voidful name::albert_chinese_large downloads::185 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import AutoTokenizer, AlbertForMaskedLM
 import torch
 from torch.nn.functional import softmax
 
 pretrained = 'voidful/albert_chinese_large'
 tokenizer = AutoTokenizer.from_pretrained(pretrained)
 model = AlbertForMaskedLM.from_pretrained(pretrained)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/voidful_albert_chinese_small.py` & `mlagility-3.1.1/models/popular_on_huggingface/voidful_albert_chinese_small.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::voidful name::albert_chinese_small downloads::1,489 task::Fill-Mask
+# labels: test_group::monthly author::voidful name::albert_chinese_small downloads::1,489 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import AutoTokenizer, AlbertForMaskedLM
 import torch
 from torch.nn.functional import softmax
 
 pretrained = 'voidful/albert_chinese_small'
 tokenizer = AutoTokenizer.from_pretrained(pretrained)
 model = AlbertForMaskedLM.from_pretrained(pretrained)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/voidful_albert_chinese_tiny.py` & `mlagility-3.1.1/models/popular_on_huggingface/voidful_albert_chinese_tiny.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::voidful name::albert_chinese_tiny downloads::1,127 task::Fill-Mask
+# labels: test_group::monthly author::voidful name::albert_chinese_tiny downloads::1,127 task::Natural_Language_Processing sub_task::Fill-Mask
 from transformers import AutoTokenizer, AlbertForMaskedLM
 import torch
 from torch.nn.functional import softmax
 
 pretrained = 'voidful/albert_chinese_tiny'
 tokenizer = AutoTokenizer.from_pretrained(pretrained)
 model = AlbertForMaskedLM.from_pretrained(pretrained)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/voidful_dpr-question_encoder-bert-base-multilingual.py` & `mlagility-3.1.1/models/popular_on_huggingface/voidful_dpr-question_encoder-bert-base-multilingual.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,6 +1,6 @@
-# labels: test_group::monthly author::voidful name::dpr-question_encoder-bert-base-multilingual downloads::1,963 task::Feature_Extraction
+# labels: test_group::monthly author::voidful name::dpr-question_encoder-bert-base-multilingual downloads::1,963 task::Multimodal sub_task::Feature_Extraction
 from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer
 tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('voidful/dpr-question_encoder-bert-base-multilingual')
 model = DPRQuestionEncoder.from_pretrained('voidful/dpr-question_encoder-bert-base-multilingual')
 input_ids = tokenizer("Hello, is my dog cute ?", return_tensors='pt')["input_ids"]
 embeddings = model(input_ids).pooler_output
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/wanyu_IteraTeR-ROBERTA-Intention-Classifier.py` & `mlagility-3.1.1/models/popular_on_huggingface/wanyu_IteraTeR-ROBERTA-Intention-Classifier.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::wanyu name::IteraTeR-ROBERTA-Intention-Classifier downloads::290 task::Text_Classification
+# labels: test_group::monthly author::wanyu name::IteraTeR-ROBERTA-Intention-Classifier downloads::290 task::Natural_Language_Processing sub_task::Text_Classification
 import torch
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 
 tokenizer = AutoTokenizer.from_pretrained("wanyu/IteraTeR-ROBERTA-Intention-Classifier")
 model = AutoModelForSequenceClassification.from_pretrained("wanyu/IteraTeR-ROBERTA-Intention-Classifier")
 
 id2label = {0: "clarity", 1: "fluency", 2: "coherence", 3: "style", 4: "meaning-changed"}
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/wonrax_phobert-base-vietnamese-sentiment.py` & `mlagility-3.1.1/models/popular_on_huggingface/wonrax_phobert-base-vietnamese-sentiment.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::wonrax name::phobert-base-vietnamese-sentiment downloads::281 license::mit task::Text_Classification
+# labels: test_group::monthly author::wonrax name::phobert-base-vietnamese-sentiment downloads::281 license::mit task::Natural_Language_Processing sub_task::Text_Classification
 import torch
 from transformers import RobertaForSequenceClassification, AutoTokenizer
 
 model = RobertaForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment")
 
 tokenizer = AutoTokenizer.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", use_fast=False)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/xlm-clm-ende-1024.py` & `mlagility-3.1.1/models/popular_on_huggingface/xlm-clm-enfr-1024.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-# labels: test_group::monthly author::huggingface name::xlm-clm-ende-1024 downloads::42,051 task::Fill-Mask
+# labels: test_group::monthly author::huggingface name::xlm-clm-enfr-1024 downloads::247 task::Natural_Language_Processing sub_task::Fill-Mask
 import torch
 from transformers import XLMTokenizer, XLMWithLMHeadModel
 
-tokenizer = XLMTokenizer.from_pretrained("xlm-clm-ende-1024")
-model = XLMWithLMHeadModel.from_pretrained("xlm-clm-ende-1024")
+tokenizer = XLMTokenizer.from_pretrained("xlm-clm-enfr-1024")
+model = XLMWithLMHeadModel.from_pretrained("xlm-clm-enfr-1024")
 
 input_ids = torch.tensor([tokenizer.encode("Wikipedia was used to")])  # batch size of 1
 
 language_id = tokenizer.lang2id["en"]  # 0
 langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])
 
 # We reshape it to be of size (batch_size, sequence_length)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/xlm-clm-enfr-1024.py` & `mlagility-3.1.1/models/popular_on_huggingface/xlm-clm-ende-1024.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-# labels: test_group::monthly author::huggingface name::xlm-clm-enfr-1024 downloads::247 task::Fill-Mask
+# labels: test_group::monthly author::huggingface name::xlm-clm-ende-1024 downloads::42,051 task::Natural_Language_Processing sub_task::Fill-Mask
 import torch
 from transformers import XLMTokenizer, XLMWithLMHeadModel
 
-tokenizer = XLMTokenizer.from_pretrained("xlm-clm-enfr-1024")
-model = XLMWithLMHeadModel.from_pretrained("xlm-clm-enfr-1024")
+tokenizer = XLMTokenizer.from_pretrained("xlm-clm-ende-1024")
+model = XLMWithLMHeadModel.from_pretrained("xlm-clm-ende-1024")
 
 input_ids = torch.tensor([tokenizer.encode("Wikipedia was used to")])  # batch size of 1
 
 language_id = tokenizer.lang2id["en"]  # 0
 langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])
 
 # We reshape it to be of size (batch_size, sequence_length)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/xlm-roberta-large-finetuned-conll03-german.py` & `mlagility-3.1.1/models/popular_on_huggingface/xlm-roberta-large-finetuned-conll03-german.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::huggingface name::xlm-roberta-large-finetuned-conll03-german downloads::9,448 task::Token_Classification
+# labels: test_group::monthly author::huggingface name::xlm-roberta-large-finetuned-conll03-german downloads::9,448 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 from transformers import pipeline
 tokenizer = AutoTokenizer.from_pretrained("xlm-roberta-large-finetuned-conll03-german")
 model = AutoModelForTokenClassification.from_pretrained("xlm-roberta-large-finetuned-conll03-german")
 classifier = pipeline("ner", model=model, tokenizer=tokenizer)
 classifier("Bayern Mnchen ist wieder alleiniger Top-Favorit auf den Gewinn der deutschen Fuball-Meisterschaft.")
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ybelkada_japanese-roberta-question-answering.py` & `mlagility-3.1.1/models/popular_on_huggingface/ybelkada_japanese-roberta-question-answering.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ybelkada name::japanese-roberta-question-answering task::unknown downloads::337 license::cc-by-sa-3.0
+# labels: test_group::monthly author::ybelkada name::japanese-roberta-question-answering task::Natural_Language_Processing downloads::337 license::cc-by-sa-3.0
 from transformers import AutoModelForQuestionAnswering, AutoTokenizer
 question = '?'
 context = '>'
 model = AutoModelForQuestionAnswering.from_pretrained(
     'ybelkada/japanese-roberta-question-answering')
 tokenizer = AutoTokenizer.from_pretrained(
     'ybelkada/japanese-roberta-question-answering')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ydshieh_roberta-large-ner-english.py` & `mlagility-3.1.1/models/popular_on_huggingface/ydshieh_roberta-large-ner-english.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ydshieh name::roberta-large-ner-english downloads::486 task::Token_Classification
+# labels: test_group::monthly author::ydshieh name::roberta-large-ner-english downloads::486 task::Natural_Language_Processing sub_task::Token_Classification
 from transformers import AutoTokenizer, AutoModelForTokenClassification
 
 tokenizer = AutoTokenizer.from_pretrained("Jean-Baptiste/roberta-large-ner-english")
 model = AutoModelForTokenClassification.from_pretrained("Jean-Baptiste/roberta-large-ner-english")
 
 
 ##### Process text sample (from wikipedia)
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/ydshieh_vit-gpt2-coco-en.py` & `mlagility-3.1.1/models/popular_on_huggingface/ydshieh_vit-gpt2-coco-en.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::ydshieh name::vit-gpt2-coco-en task::unknown downloads::2,903
+# labels: test_group::monthly author::ydshieh name::vit-gpt2-coco-en task::Computer_Vision downloads::2,903
 
 import torch
 import requests
 from PIL import Image
 from transformers import ViTFeatureExtractor, AutoTokenizer, VisionEncoderDecoderModel
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/yiyanghkust_finbert-esg.py` & `mlagility-3.1.1/models/popular_on_huggingface/yiyanghkust_finbert-esg.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::monthly author::yiyanghkust name::finbert-esg downloads::2,795 task::Text_Classification
+# labels: test_group::monthly author::yiyanghkust name::finbert-esg downloads::2,795 task::Natural_Language_Processing sub_task::Text_Classification
 # tested in transformers==4.18.0 
 from transformers import BertTokenizer, BertForSequenceClassification, pipeline
 
 finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-esg',num_labels=4)
 tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-esg')
 nlp = pipeline("text-classification", model=finbert, tokenizer=tokenizer)
 results = nlp('Rhonda has been volunteering for several years for a variety of charitable community programs.')
```

### Comparing `mlagility-3.0.2/models/popular_on_huggingface/yiyanghkust_finbert-tone.py` & `mlagility-3.1.1/models/popular_on_huggingface/yiyanghkust_finbert-tone.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: author::yiyanghkust name::finbert-tone downloads::22,877 task::Text_Classification
+# labels: author::yiyanghkust name::finbert-tone downloads::22,877 task::Natural_Language_Processing sub_task::Text_Classification
 from transformers import BertTokenizer, BertForSequenceClassification
 from transformers import pipeline
 
 finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)
 tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')
 
 nlp = pipeline("sentiment-analysis", model=finbert, tokenizer=tokenizer)
```

### Comparing `mlagility-3.0.2/models/readme.md` & `mlagility-3.1.1/models/readme.md`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/models/selftest/linear.py` & `mlagility-3.1.1/models/selftest/linear.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/models/selftest/twolayer.py` & `mlagility-3.1.1/models/selftest/twolayer.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/models/timm/beit_base_patch16_224.py` & `mlagility-3.1.1/models/timm/beit_base_patch16_224.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::beit_base_patch16_224 author::timm task::computer_vision
+# labels: name::beit_base_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/beit_base_patch16_224_in22k.py` & `mlagility-3.1.1/models/timm/beit_base_patch16_224_in22k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::beit_base_patch16_224_in22k author::timm task::computer_vision
+# labels: name::beit_base_patch16_224_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/beit_base_patch16_384.py` & `mlagility-3.1.1/models/timm/vit_base_patch16_224_miil.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::beit_base_patch16_384 author::timm task::computer_vision
+# labels: name::vit_base_patch16_224_miil author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("beit_base_patch16_384", pretrained = False)
+model = timm.create_model("vit_base_patch16_224_miil", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/beit_large_patch16_224.py` & `mlagility-3.1.1/models/timm/pit_s_distilled_224.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::beit_large_patch16_224 author::timm task::computer_vision
+# labels: name::pit_s_distilled_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("beit_large_patch16_224", pretrained = False)
+model = timm.create_model("pit_s_distilled_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/beit_large_patch16_224_in22k.py` & `mlagility-3.1.1/models/timm/deit3_large_patch16_224.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::beit_large_patch16_224_in22k author::timm task::computer_vision
+# labels: name::deit3_large_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("beit_large_patch16_224_in22k", pretrained = False)
+model = timm.create_model("deit3_large_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/beit_large_patch16_384.py` & `mlagility-3.1.1/models/timm/beit_large_patch16_384.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::beit_large_patch16_384 author::timm task::computer_vision
+# labels: name::beit_large_patch16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/beit_large_patch16_512.py` & `mlagility-3.1.1/models/timm/pit_ti_distilled_224.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::beit_large_patch16_512 author::timm task::computer_vision
+# labels: name::pit_ti_distilled_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("beit_large_patch16_512", pretrained = False)
+model = timm.create_model("pit_ti_distilled_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/convmixer_1024_20_ks9_p14.py` & `mlagility-3.1.1/models/timm/convmixer_1024_20_ks9_p14.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::convmixer_1024_20_ks9_p14 author::timm task::computer_vision
+# labels: name::convmixer_1024_20_ks9_p14 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/convmixer_1536_20.py` & `mlagility-3.1.1/models/timm/convmixer_1536_20.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::convmixer_1536_20 author::timm task::computer_vision
+# labels: name::convmixer_1536_20 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/convnext_base_384_in22ft1k.py` & `mlagility-3.1.1/models/timm/convnext_base_384_in22ft1k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::convnext_base_384_in22ft1k author::timm task::computer_vision
+# labels: name::convnext_base_384_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/convnext_base_in22ft1k.py` & `mlagility-3.1.1/models/timm/convnext_base_in22ft1k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::convnext_base_in22ft1k author::timm task::computer_vision
+# labels: name::convnext_base_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/convnext_base_in22k.py` & `mlagility-3.1.1/models/timm/convnext_base_in22k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::convnext_base_in22k author::timm task::computer_vision
+# labels: name::convnext_base_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/convnext_large_384_in22ft1k.py` & `mlagility-3.1.1/models/timm/convnext_xlarge_in22ft1k.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::convnext_large_384_in22ft1k author::timm task::computer_vision
+# labels: name::convnext_xlarge_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("convnext_large_384_in22ft1k", pretrained = False)
+model = timm.create_model("convnext_xlarge_in22ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/convnext_large_in22ft1k.py` & `mlagility-3.1.1/models/timm/convnext_large_in22ft1k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::convnext_large_in22ft1k author::timm task::computer_vision
+# labels: name::convnext_large_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/convnext_large_in22k.py` & `mlagility-3.1.1/models/timm/convnext_large_in22k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::convnext_large_in22k author::timm task::computer_vision
+# labels: name::convnext_large_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/convnext_nano_hnf.py` & `mlagility-3.1.1/models/timm/convnext_nano_hnf.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::convnext_nano_hnf author::timm task::computer_vision
+# labels: name::convnext_nano_hnf author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/convnext_nano_ols.py` & `mlagility-3.1.1/models/timm/convnext_nano_ols.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::convnext_nano_ols author::timm task::computer_vision
+# labels: name::convnext_nano_ols author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/convnext_small_384_in22ft1k.py` & `mlagility-3.1.1/models/timm/convnext_small_in22ft1k.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::convnext_small_384_in22ft1k author::timm task::computer_vision
+# labels: name::convnext_small_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("convnext_small_384_in22ft1k", pretrained = False)
+model = timm.create_model("convnext_small_in22ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/convnext_small_in22ft1k.py` & `mlagility-3.1.1/models/timm/convnext_small_in22k.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::convnext_small_in22ft1k author::timm task::computer_vision
+# labels: name::convnext_small_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("convnext_small_in22ft1k", pretrained = False)
+model = timm.create_model("convnext_small_in22k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/convnext_small_in22k.py` & `mlagility-3.1.1/models/timm/convnext_tiny_in22k.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::convnext_small_in22k author::timm task::computer_vision
+# labels: name::convnext_tiny_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("convnext_small_in22k", pretrained = False)
+model = timm.create_model("convnext_tiny_in22k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/convnext_tiny_384_in22ft1k.py` & `mlagility-3.1.1/models/timm/xcit_tiny_24_p8_384_dist.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::convnext_tiny_384_in22ft1k author::timm task::computer_vision
+# labels: name::xcit_tiny_24_p8_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("convnext_tiny_384_in22ft1k", pretrained = False)
+model = timm.create_model("xcit_tiny_24_p8_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/convnext_tiny_hnf.py` & `mlagility-3.1.1/models/timm/convnext_tiny_hnf.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::convnext_tiny_hnf author::timm task::computer_vision
+# labels: name::convnext_tiny_hnf author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/convnext_tiny_in22ft1k.py` & `mlagility-3.1.1/models/timm/convnext_xlarge_in22k.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::convnext_tiny_in22ft1k author::timm task::computer_vision
+# labels: name::convnext_xlarge_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("convnext_tiny_in22ft1k", pretrained = False)
+model = timm.create_model("convnext_xlarge_in22k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/convnext_tiny_in22k.py` & `mlagility-3.1.1/models/timm/vit_large_patch14_224.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::convnext_tiny_in22k author::timm task::computer_vision
+# labels: name::vit_large_patch14_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("convnext_tiny_in22k", pretrained = False)
+model = timm.create_model("vit_large_patch14_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/convnext_xlarge_384_in22ft1k.py` & `mlagility-3.1.1/models/timm/crossvit_18_dagger_240.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::convnext_xlarge_384_in22ft1k author::timm task::computer_vision
+# labels: name::crossvit_18_dagger_240 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("convnext_xlarge_384_in22ft1k", pretrained = False)
+model = timm.create_model("crossvit_18_dagger_240", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/convnext_xlarge_in22ft1k.py` & `mlagility-3.1.1/models/timm/mobilenetv3_large_100.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::convnext_xlarge_in22ft1k author::timm task::computer_vision
+# labels: name::mobilenetv3_large_100 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("convnext_xlarge_in22ft1k", pretrained = False)
+model = timm.create_model("mobilenetv3_large_100", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/convnext_xlarge_in22k.py` & `mlagility-3.1.1/models/timm/twins_pcpvt_large.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::convnext_xlarge_in22k author::timm task::computer_vision
+# labels: name::twins_pcpvt_large author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("convnext_xlarge_in22k", pretrained = False)
+model = timm.create_model("twins_pcpvt_large", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/crossvit_15_dagger_240.py` & `mlagility-3.1.1/models/timm/crossvit_15_dagger_240.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::crossvit_15_dagger_240 author::timm task::computer_vision
+# labels: name::crossvit_15_dagger_240 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/crossvit_15_dagger_408.py` & `mlagility-3.1.1/models/timm/crossvit_15_dagger_408.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::crossvit_15_dagger_408 author::timm task::computer_vision
+# labels: name::crossvit_15_dagger_408 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/crossvit_18_dagger_240.py` & `mlagility-3.1.1/models/timm/crossvit_9_dagger_240.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::crossvit_18_dagger_240 author::timm task::computer_vision
+# labels: name::crossvit_9_dagger_240 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("crossvit_18_dagger_240", pretrained = False)
+model = timm.create_model("crossvit_9_dagger_240", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/crossvit_18_dagger_408.py` & `mlagility-3.1.1/models/timm/crossvit_18_dagger_408.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::crossvit_18_dagger_408 author::timm task::computer_vision
+# labels: name::crossvit_18_dagger_408 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/crossvit_9_dagger_240.py` & `mlagility-3.1.1/models/timm/crossvit_base_240.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::crossvit_9_dagger_240 author::timm task::computer_vision
+# labels: name::crossvit_base_240 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("crossvit_9_dagger_240", pretrained = False)
+model = timm.create_model("crossvit_base_240", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/crossvit_base_240.py` & `mlagility-3.1.1/models/timm/vit_base_r50_s16_384.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::crossvit_base_240 author::timm task::computer_vision
+# labels: name::vit_base_r50_s16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("crossvit_base_240", pretrained = False)
+model = timm.create_model("vit_base_r50_s16_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/crossvit_small_240.py` & `mlagility-3.1.1/models/timm/crossvit_small_240.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::crossvit_small_240 author::timm task::computer_vision
+# labels: name::crossvit_small_240 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/crossvit_tiny_240.py` & `mlagility-3.1.1/models/timm/crossvit_tiny_240.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::crossvit_tiny_240 author::timm task::computer_vision
+# labels: name::crossvit_tiny_240 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/cs3darknet_focus_l.py` & `mlagility-3.1.1/models/timm/cs3darknet_focus_s.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::cs3darknet_focus_l author::timm task::computer_vision
+# labels: name::cs3darknet_focus_s author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("cs3darknet_focus_l", pretrained = False)
+model = timm.create_model("cs3darknet_focus_s", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/cs3darknet_focus_m.py` & `mlagility-3.1.1/models/timm/tnt_s_patch16_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::cs3darknet_focus_m author::timm task::computer_vision
+# labels: name::tnt_s_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("cs3darknet_focus_m", pretrained = False)
+model = timm.create_model("tnt_s_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/cs3darknet_focus_s.py` & `mlagility-3.1.1/models/timm/resmlp_12_224_dino.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::cs3darknet_focus_s author::timm task::computer_vision
+# labels: name::resmlp_12_224_dino author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("cs3darknet_focus_s", pretrained = False)
+model = timm.create_model("resmlp_12_224_dino", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/cs3darknet_focus_x.py` & `mlagility-3.1.1/models/timm/seresnext26d_32x4d.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::cs3darknet_focus_x author::timm task::computer_vision
+# labels: name::seresnext26d_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("cs3darknet_focus_x", pretrained = False)
+model = timm.create_model("seresnext26d_32x4d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_base_patch16_224.py` & `mlagility-3.1.1/models/timm/vit_base_patch32_224.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_base_patch16_224 author::timm task::computer_vision
+# labels: name::vit_base_patch32_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_base_patch16_224", pretrained = False)
+model = timm.create_model("vit_base_patch32_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_base_patch16_224_in21ft1k.py` & `mlagility-3.1.1/models/timm/deit3_base_patch16_384_in21ft1k.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_base_patch16_224_in21ft1k author::timm task::computer_vision
+# labels: name::deit3_base_patch16_384_in21ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_base_patch16_224_in21ft1k", pretrained = False)
+model = timm.create_model("deit3_base_patch16_384_in21ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_base_patch16_384.py` & `mlagility-3.1.1/models/timm/vit_small_patch32_384.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_base_patch16_384 author::timm task::computer_vision
+# labels: name::vit_small_patch32_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_base_patch16_384", pretrained = False)
+model = timm.create_model("vit_small_patch32_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_base_patch16_384_in21ft1k.py` & `mlagility-3.1.1/models/timm/deit3_large_patch16_384_in21ft1k.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_base_patch16_384_in21ft1k author::timm task::computer_vision
+# labels: name::deit3_large_patch16_384_in21ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_base_patch16_384_in21ft1k", pretrained = False)
+model = timm.create_model("deit3_large_patch16_384_in21ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_huge_patch14_224.py` & `mlagility-3.1.1/models/timm/swin_base_patch4_window7_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_huge_patch14_224 author::timm task::computer_vision
+# labels: name::swin_base_patch4_window7_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_huge_patch14_224", pretrained = False)
+model = timm.create_model("swin_base_patch4_window7_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_huge_patch14_224_in21ft1k.py` & `mlagility-3.1.1/models/timm/deit3_small_patch16_224_in21ft1k.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_huge_patch14_224_in21ft1k author::timm task::computer_vision
+# labels: name::deit3_small_patch16_224_in21ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_huge_patch14_224_in21ft1k", pretrained = False)
+model = timm.create_model("deit3_small_patch16_224_in21ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_large_patch16_224.py` & `mlagility-3.1.1/models/timm/resmlp_big_24_distilled_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_large_patch16_224 author::timm task::computer_vision
+# labels: name::resmlp_big_24_distilled_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_large_patch16_224", pretrained = False)
+model = timm.create_model("resmlp_big_24_distilled_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_large_patch16_224_in21ft1k.py` & `mlagility-3.1.1/models/timm/deit3_small_patch16_384_in21ft1k.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_large_patch16_224_in21ft1k author::timm task::computer_vision
+# labels: name::deit3_small_patch16_384_in21ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_large_patch16_224_in21ft1k", pretrained = False)
+model = timm.create_model("deit3_small_patch16_384_in21ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_large_patch16_384.py` & `mlagility-3.1.1/models/timm/swin_large_patch4_window7_224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_large_patch16_384 author::timm task::computer_vision
+# labels: name::swin_large_patch4_window7_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_large_patch16_384", pretrained = False)
+model = timm.create_model("swin_large_patch4_window7_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_large_patch16_384_in21ft1k.py` & `mlagility-3.1.1/models/timm/convnext_xlarge_384_in22ft1k.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_large_patch16_384_in21ft1k author::timm task::computer_vision
+# labels: name::convnext_xlarge_384_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_large_patch16_384_in21ft1k", pretrained = False)
+model = timm.create_model("convnext_xlarge_384_in22ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_small_patch16_224.py` & `mlagility-3.1.1/models/timm/mobilenetv3_small_100.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_small_patch16_224 author::timm task::computer_vision
+# labels: name::mobilenetv3_small_100 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_small_patch16_224", pretrained = False)
+model = timm.create_model("mobilenetv3_small_100", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_small_patch16_224_in21ft1k.py` & `mlagility-3.1.1/models/timm/deit3_small_patch16_384.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_small_patch16_224_in21ft1k author::timm task::computer_vision
+# labels: name::deit3_small_patch16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_small_patch16_224_in21ft1k", pretrained = False)
+model = timm.create_model("deit3_small_patch16_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_small_patch16_384.py` & `mlagility-3.1.1/models/timm/convnext_tiny_in22ft1k.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_small_patch16_384 author::timm task::computer_vision
+# labels: name::convnext_tiny_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_small_patch16_384", pretrained = False)
+model = timm.create_model("convnext_tiny_in22ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit3_small_patch16_384_in21ft1k.py` & `mlagility-3.1.1/models/timm/vit_relpos_small_patch16_rpn_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit3_small_patch16_384_in21ft1k author::timm task::computer_vision
+# labels: name::vit_relpos_small_patch16_rpn_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit3_small_patch16_384_in21ft1k", pretrained = False)
+model = timm.create_model("vit_relpos_small_patch16_rpn_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit_base_distilled_patch16_224.py` & `mlagility-3.1.1/models/timm/deit_base_distilled_patch16_224.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::deit_base_distilled_patch16_224 author::timm task::computer_vision
+# labels: name::deit_base_distilled_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/deit_base_distilled_patch16_384.py` & `mlagility-3.1.1/models/timm/deit_base_distilled_patch16_384.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::deit_base_distilled_patch16_384 author::timm task::computer_vision
+# labels: name::deit_base_distilled_patch16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/deit_base_patch16_224.py` & `mlagility-3.1.1/models/timm/deit_base_patch16_224.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::deit_base_patch16_224 author::timm task::computer_vision
+# labels: name::deit_base_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/deit_base_patch16_384.py` & `mlagility-3.1.1/models/timm/deit_base_patch16_384.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::deit_base_patch16_384 author::timm task::computer_vision
+# labels: name::deit_base_patch16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/deit_small_distilled_patch16_224.py` & `mlagility-3.1.1/models/timm/deit_small_distilled_patch16_224.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::deit_small_distilled_patch16_224 author::timm task::computer_vision
+# labels: name::deit_small_distilled_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/deit_small_patch16_224.py` & `mlagility-3.1.1/models/timm/swin_small_patch4_window7_224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit_small_patch16_224 author::timm task::computer_vision
+# labels: name::swin_small_patch4_window7_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit_small_patch16_224", pretrained = False)
+model = timm.create_model("swin_small_patch4_window7_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit_tiny_distilled_patch16_224.py` & `mlagility-3.1.1/models/timm/resmlp_36_distilled_224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit_tiny_distilled_patch16_224 author::timm task::computer_vision
+# labels: name::resmlp_36_distilled_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit_tiny_distilled_patch16_224", pretrained = False)
+model = timm.create_model("resmlp_36_distilled_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/deit_tiny_patch16_224.py` & `mlagility-3.1.1/models/timm/resmlp_24_distilled_224.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::deit_tiny_patch16_224 author::timm task::computer_vision
+# labels: name::resmlp_24_distilled_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("deit_tiny_patch16_224", pretrained = False)
+model = timm.create_model("resmlp_24_distilled_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/eca_botnext26ts_256.py` & `mlagility-3.1.1/models/timm/eca_botnext26ts_256.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::eca_botnext26ts_256 author::timm task::computer_vision
+# labels: name::eca_botnext26ts_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/ecaresnext26t_32x4d.py` & `mlagility-3.1.1/models/timm/ecaresnext26t_32x4d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::ecaresnext26t_32x4d author::timm task::computer_vision
+# labels: name::ecaresnext26t_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/ecaresnext50t_32x4d.py` & `mlagility-3.1.1/models/timm/legacy_seresnext50_32x4d.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::ecaresnext50t_32x4d author::timm task::computer_vision
+# labels: name::legacy_seresnext50_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("ecaresnext50t_32x4d", pretrained = False)
+model = timm.create_model("legacy_seresnext50_32x4d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/edgenext_small_rw.py` & `mlagility-3.1.1/models/timm/edgenext_small_rw.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::edgenext_small_rw author::timm task::computer_vision
+# labels: name::edgenext_small_rw author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/edgenext_xx_small.py` & `mlagility-3.1.1/models/timm/edgenext_xx_small.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::edgenext_xx_small author::timm task::computer_vision
+# labels: name::edgenext_xx_small author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_b0_g16_evos.py` & `mlagility-3.1.1/models/timm/efficientnet_b0_g16_evos.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::efficientnet_b0_g16_evos author::timm task::computer_vision
+# labels: name::efficientnet_b0_g16_evos author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_b0_g8_gn.py` & `mlagility-3.1.1/models/timm/vit_base_r50_s16_224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_b0_g8_gn author::timm task::computer_vision
+# labels: name::vit_base_r50_s16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_b0_g8_gn", pretrained = False)
+model = timm.create_model("vit_base_r50_s16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_b0_gn.py` & `mlagility-3.1.1/models/timm/efficientnet_cc_b0_4e.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_b0_gn author::timm task::computer_vision
+# labels: name::efficientnet_cc_b0_4e author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_b0_gn", pretrained = False)
+model = timm.create_model("efficientnet_cc_b0_4e", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_b3_g8_gn.py` & `mlagility-3.1.1/models/timm/efficientnet_b3_g8_gn.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::efficientnet_b3_g8_gn author::timm task::computer_vision
+# labels: name::efficientnet_b3_g8_gn author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_b3_gn.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b0.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_b3_gn author::timm task::computer_vision
+# labels: name::tf_efficientnet_b0 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_b3_gn", pretrained = False)
+model = timm.create_model("tf_efficientnet_b0", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_cc_b0_4e.py` & `mlagility-3.1.1/models/timm/efficientnet_el_pruned.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_cc_b0_4e author::timm task::computer_vision
+# labels: name::efficientnet_el_pruned author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_cc_b0_4e", pretrained = False)
+model = timm.create_model("efficientnet_el_pruned", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_cc_b0_8e.py` & `mlagility-3.1.1/models/timm/efficientnet_lite0.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_cc_b0_8e author::timm task::computer_vision
+# labels: name::efficientnet_lite0 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_cc_b0_8e", pretrained = False)
+model = timm.create_model("efficientnet_lite0", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_cc_b1_8e.py` & `mlagility-3.1.1/models/timm/efficientnet_lite2.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_cc_b1_8e author::timm task::computer_vision
+# labels: name::efficientnet_lite2 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_cc_b1_8e", pretrained = False)
+model = timm.create_model("efficientnet_lite2", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_el_pruned.py` & `mlagility-3.1.1/models/timm/efficientnet_lite3.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_el_pruned author::timm task::computer_vision
+# labels: name::efficientnet_lite3 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_el_pruned", pretrained = False)
+model = timm.create_model("efficientnet_lite3", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_es_pruned.py` & `mlagility-3.1.1/models/timm/efficientnet_lite4.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_es_pruned author::timm task::computer_vision
+# labels: name::efficientnet_lite4 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_es_pruned", pretrained = False)
+model = timm.create_model("efficientnet_lite4", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_lite0.py` & `mlagility-3.1.1/models/timm/efficientnet_lite1.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_lite0 author::timm task::computer_vision
+# labels: name::efficientnet_lite1 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_lite0", pretrained = False)
+model = timm.create_model("efficientnet_lite1", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_lite1.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_lite2.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_lite1 author::timm task::computer_vision
+# labels: name::tf_efficientnet_lite2 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_lite1", pretrained = False)
+model = timm.create_model("tf_efficientnet_lite2", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_lite2.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_lite0.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_lite2 author::timm task::computer_vision
+# labels: name::tf_efficientnet_lite0 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_lite2", pretrained = False)
+model = timm.create_model("tf_efficientnet_lite0", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_lite3.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_lite3.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_lite3 author::timm task::computer_vision
+# labels: name::tf_efficientnet_lite3 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_lite3", pretrained = False)
+model = timm.create_model("tf_efficientnet_lite3", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnet_lite4.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_lite4.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnet_lite4 author::timm task::computer_vision
+# labels: name::tf_efficientnet_lite4 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnet_lite4", pretrained = False)
+model = timm.create_model("tf_efficientnet_lite4", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/efficientnetv2_rw_m.py` & `mlagility-3.1.1/models/timm/efficientnetv2_rw_m.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::efficientnetv2_rw_m author::timm task::computer_vision
+# labels: name::efficientnetv2_rw_m author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/efficientnetv2_rw_s.py` & `mlagility-3.1.1/models/timm/efficientnetv2_rw_s.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::efficientnetv2_rw_s author::timm task::computer_vision
+# labels: name::efficientnetv2_rw_s author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/efficientnetv2_rw_t.py` & `mlagility-3.1.1/models/timm/efficientnetv2_rw_t.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::efficientnetv2_rw_t author::timm task::computer_vision
+# labels: name::efficientnetv2_rw_t author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/efficientnetv2_xl.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_b0.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::efficientnetv2_xl author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_b0 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("efficientnetv2_xl", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_b0", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/ens_adv_inception_resnet_v2.py` & `mlagility-3.1.1/models/timm/gluon_seresnext101_64x4d.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::ens_adv_inception_resnet_v2 author::timm task::computer_vision
+# labels: name::gluon_seresnext101_64x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("ens_adv_inception_resnet_v2", pretrained = False)
+model = timm.create_model("gluon_seresnext101_64x4d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/ese_vovnet19b_slim.py` & `mlagility-3.1.1/models/timm/ese_vovnet19b_slim.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::ese_vovnet19b_slim author::timm task::computer_vision
+# labels: name::ese_vovnet19b_slim author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/ese_vovnet19b_slim_dw.py` & `mlagility-3.1.1/models/timm/ese_vovnet19b_slim_dw.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::ese_vovnet19b_slim_dw author::timm task::computer_vision
+# labels: name::ese_vovnet19b_slim_dw author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/ese_vovnet39b_evos.py` & `mlagility-3.1.1/models/timm/ese_vovnet39b_evos.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::ese_vovnet39b_evos author::timm task::computer_vision
+# labels: name::ese_vovnet39b_evos author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/gc_efficientnetv2_rw_t.py` & `mlagility-3.1.1/models/timm/gluon_resnext101_64x4d.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gc_efficientnetv2_rw_t author::timm task::computer_vision
+# labels: name::gluon_resnext101_64x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gc_efficientnetv2_rw_t", pretrained = False)
+model = timm.create_model("gluon_resnext101_64x4d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_inception_v3.py` & `mlagility-3.1.1/models/timm/gluon_inception_v3.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::gluon_inception_v3 author::timm task::computer_vision
+# labels: name::gluon_inception_v3 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet101_v1b.py` & `mlagility-3.1.1/models/timm/gluon_resnet101_v1d.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet101_v1b author::timm task::computer_vision
+# labels: name::gluon_resnet101_v1d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet101_v1b", pretrained = False)
+model = timm.create_model("gluon_resnet101_v1d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet101_v1c.py` & `mlagility-3.1.1/models/timm/gluon_resnet101_v1s.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet101_v1c author::timm task::computer_vision
+# labels: name::gluon_resnet101_v1s author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet101_v1c", pretrained = False)
+model = timm.create_model("gluon_resnet101_v1s", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet101_v1d.py` & `mlagility-3.1.1/models/timm/gluon_resnet152_v1d.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet101_v1d author::timm task::computer_vision
+# labels: name::gluon_resnet152_v1d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet101_v1d", pretrained = False)
+model = timm.create_model("gluon_resnet152_v1d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet101_v1s.py` & `mlagility-3.1.1/models/timm/gluon_resnet152_v1s.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet101_v1s author::timm task::computer_vision
+# labels: name::gluon_resnet152_v1s author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet101_v1s", pretrained = False)
+model = timm.create_model("gluon_resnet152_v1s", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet152_v1b.py` & `mlagility-3.1.1/models/timm/gluon_resnet152_v1b.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::gluon_resnet152_v1b author::timm task::computer_vision
+# labels: name::gluon_resnet152_v1b author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet152_v1c.py` & `mlagility-3.1.1/models/timm/gluon_resnet18_v1b.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet152_v1c author::timm task::computer_vision
+# labels: name::gluon_resnet18_v1b author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet152_v1c", pretrained = False)
+model = timm.create_model("gluon_resnet18_v1b", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet152_v1d.py` & `mlagility-3.1.1/models/timm/gluon_resnet50_v1d.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet152_v1d author::timm task::computer_vision
+# labels: name::gluon_resnet50_v1d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet152_v1d", pretrained = False)
+model = timm.create_model("gluon_resnet50_v1d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet152_v1s.py` & `mlagility-3.1.1/models/timm/gluon_resnet50_v1s.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet152_v1s author::timm task::computer_vision
+# labels: name::gluon_resnet50_v1s author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet152_v1s", pretrained = False)
+model = timm.create_model("gluon_resnet50_v1s", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet18_v1b.py` & `mlagility-3.1.1/models/timm/gluon_resnet34_v1b.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet18_v1b author::timm task::computer_vision
+# labels: name::gluon_resnet34_v1b author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet18_v1b", pretrained = False)
+model = timm.create_model("gluon_resnet34_v1b", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet34_v1b.py` & `mlagility-3.1.1/models/timm/inception_resnet_v2.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet34_v1b author::timm task::computer_vision
+# labels: name::inception_resnet_v2 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet34_v1b", pretrained = False)
+model = timm.create_model("inception_resnet_v2", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet50_v1b.py` & `mlagility-3.1.1/models/timm/legacy_seresnet18.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet50_v1b author::timm task::computer_vision
+# labels: name::legacy_seresnet18 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet50_v1b", pretrained = False)
+model = timm.create_model("legacy_seresnet18", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet50_v1c.py` & `mlagility-3.1.1/models/timm/resnetv2_50x3_bitm.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet50_v1c author::timm task::computer_vision
+# labels: name::resnetv2_50x3_bitm author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet50_v1c", pretrained = False)
+model = timm.create_model("resnetv2_50x3_bitm", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet50_v1d.py` & `mlagility-3.1.1/models/timm/ssl_resnext101_32x16d.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet50_v1d author::timm task::computer_vision
+# labels: name::ssl_resnext101_32x16d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet50_v1d", pretrained = False)
+model = timm.create_model("ssl_resnext101_32x16d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnet50_v1s.py` & `mlagility-3.1.1/models/timm/resnetv2_101x3_bitm.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnet50_v1s author::timm task::computer_vision
+# labels: name::resnetv2_101x3_bitm author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnet50_v1s", pretrained = False)
+model = timm.create_model("resnetv2_101x3_bitm", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnext101_32x4d.py` & `mlagility-3.1.1/models/timm/swinv2_small_window8_256.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnext101_32x4d author::timm task::computer_vision
+# labels: name::swinv2_small_window8_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnext101_32x4d", pretrained = False)
+model = timm.create_model("swinv2_small_window8_256", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnext101_64x4d.py` & `mlagility-3.1.1/models/timm/mobilenetv3_large_100_miil_in21k.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnext101_64x4d author::timm task::computer_vision
+# labels: name::mobilenetv3_large_100_miil_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnext101_64x4d", pretrained = False)
+model = timm.create_model("mobilenetv3_large_100_miil_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_resnext50_32x4d.py` & `mlagility-3.1.1/models/timm/swinv2_small_window16_256.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_resnext50_32x4d author::timm task::computer_vision
+# labels: name::swinv2_small_window16_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_resnext50_32x4d", pretrained = False)
+model = timm.create_model("swinv2_small_window16_256", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_seresnext101_32x4d.py` & `mlagility-3.1.1/models/timm/resnetv2_152x2_bit_teacher_384.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_seresnext101_32x4d author::timm task::computer_vision
+# labels: name::resnetv2_152x2_bit_teacher_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_seresnext101_32x4d", pretrained = False)
+model = timm.create_model("resnetv2_152x2_bit_teacher_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_seresnext101_64x4d.py` & `mlagility-3.1.1/models/timm/vit_large_patch32_224_in21k.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_seresnext101_64x4d author::timm task::computer_vision
+# labels: name::vit_large_patch32_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_seresnext101_64x4d", pretrained = False)
+model = timm.create_model("vit_large_patch32_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/gluon_seresnext50_32x4d.py` & `mlagility-3.1.1/models/timm/resnetv2_152x2_bit_teacher.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::gluon_seresnext50_32x4d author::timm task::computer_vision
+# labels: name::resnetv2_152x2_bit_teacher author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("gluon_seresnext50_32x4d", pretrained = False)
+model = timm.create_model("resnetv2_152x2_bit_teacher", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/halo2botnet50ts_256.py` & `mlagility-3.1.1/models/timm/halo2botnet50ts_256.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::halo2botnet50ts_256 author::timm task::computer_vision
+# labels: name::halo2botnet50ts_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/hrnet_w18_small_v2.py` & `mlagility-3.1.1/models/timm/hrnet_w18_small_v2.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::hrnet_w18_small_v2 author::timm task::computer_vision
+# labels: name::hrnet_w18_small_v2 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/ig_resnext101_32x16d.py` & `mlagility-3.1.1/models/timm/ig_resnext101_32x16d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::ig_resnext101_32x16d author::timm task::computer_vision
+# labels: name::ig_resnext101_32x16d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/ig_resnext101_32x32d.py` & `mlagility-3.1.1/models/timm/ig_resnext101_32x32d.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::ig_resnext101_32x32d author::timm task::computer_vision
+# labels: name::ig_resnext101_32x32d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/ig_resnext101_32x48d.py` & `mlagility-3.1.1/models/timm/ig_resnext101_32x48d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::ig_resnext101_32x48d author::timm task::computer_vision
+# labels: name::ig_resnext101_32x48d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/ig_resnext101_32x8d.py` & `mlagility-3.1.1/models/timm/ig_resnext101_32x8d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::ig_resnext101_32x8d author::timm task::computer_vision
+# labels: name::ig_resnext101_32x8d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/inception_resnet_v2.py` & `mlagility-3.1.1/models/timm/xcit_large_24_p16_224_dist.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::inception_resnet_v2 author::timm task::computer_vision
+# labels: name::xcit_large_24_p16_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("inception_resnet_v2", pretrained = False)
+model = timm.create_model("xcit_large_24_p16_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/lambda_resnet26rpt_256.py` & `mlagility-3.1.1/models/timm/legacy_seresnet152.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::lambda_resnet26rpt_256 author::timm task::computer_vision
+# labels: name::legacy_seresnet152 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("lambda_resnet26rpt_256", pretrained = False)
+model = timm.create_model("legacy_seresnet152", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/lambda_resnet50ts.py` & `mlagility-3.1.1/models/timm/lambda_resnet50ts.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::lambda_resnet50ts author::timm task::computer_vision
+# labels: name::lambda_resnet50ts author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/lamhalobotnet50ts_256.py` & `mlagility-3.1.1/models/timm/lamhalobotnet50ts_256.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::lamhalobotnet50ts_256 author::timm task::computer_vision
+# labels: name::lamhalobotnet50ts_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/legacy_seresnet101.py` & `mlagility-3.1.1/models/timm/legacy_seresnet101.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::legacy_seresnet101 author::timm task::computer_vision
+# labels: name::legacy_seresnet101 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/legacy_seresnet152.py` & `mlagility-3.1.1/models/timm/seresnext26t_32x4d.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::legacy_seresnet152 author::timm task::computer_vision
+# labels: name::seresnext26t_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("legacy_seresnet152", pretrained = False)
+model = timm.create_model("seresnext26t_32x4d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/legacy_seresnet18.py` & `mlagility-3.1.1/models/timm/resnetv2_50d_evob.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::legacy_seresnet18 author::timm task::computer_vision
+# labels: name::resnetv2_50d_evob author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("legacy_seresnet18", pretrained = False)
+model = timm.create_model("resnetv2_50d_evob", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/legacy_seresnet34.py` & `mlagility-3.1.1/models/timm/resnetv2_50d_evos.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::legacy_seresnet34 author::timm task::computer_vision
+# labels: name::resnetv2_50d_evos author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("legacy_seresnet34", pretrained = False)
+model = timm.create_model("resnetv2_50d_evos", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/legacy_seresnet50.py` & `mlagility-3.1.1/models/timm/twins_pcpvt_small.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::legacy_seresnet50 author::timm task::computer_vision
+# labels: name::twins_pcpvt_small author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("legacy_seresnet50", pretrained = False)
+model = timm.create_model("twins_pcpvt_small", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/legacy_seresnext101_32x4d.py` & `mlagility-3.1.1/models/timm/legacy_seresnext101_32x4d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::legacy_seresnext101_32x4d author::timm task::computer_vision
+# labels: name::legacy_seresnext101_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/legacy_seresnext26_32x4d.py` & `mlagility-3.1.1/models/timm/legacy_seresnext26_32x4d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::legacy_seresnext26_32x4d author::timm task::computer_vision
+# labels: name::legacy_seresnext26_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/legacy_seresnext50_32x4d.py` & `mlagility-3.1.1/models/timm/xcit_medium_24_p16_224.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::legacy_seresnext50_32x4d author::timm task::computer_vision
+# labels: name::xcit_medium_24_p16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("legacy_seresnext50_32x4d", pretrained = False)
+model = timm.create_model("xcit_medium_24_p16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/mixer_b16_224_in21k.py` & `mlagility-3.1.1/models/timm/mixer_b16_224_in21k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::mixer_b16_224_in21k author::timm task::computer_vision
+# labels: name::mixer_b16_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/mixer_b16_224_miil.py` & `mlagility-3.1.1/models/timm/mixer_b16_224_miil.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::mixer_b16_224_miil author::timm task::computer_vision
+# labels: name::mixer_b16_224_miil author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/mixer_b16_224_miil_in21k.py` & `mlagility-3.1.1/models/timm/mixer_b16_224_miil_in21k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::mixer_b16_224_miil_in21k author::timm task::computer_vision
+# labels: name::mixer_b16_224_miil_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/mixer_l16_224_in21k.py` & `mlagility-3.1.1/models/timm/mixer_l16_224_in21k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::mixer_l16_224_in21k author::timm task::computer_vision
+# labels: name::mixer_l16_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/mobilenetv3_large_075.py` & `mlagility-3.1.1/models/timm/mobilenetv3_large_075.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::mobilenetv3_large_075 author::timm task::computer_vision
+# labels: name::mobilenetv3_large_075 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/mobilenetv3_large_100.py` & `mlagility-3.1.1/models/timm/tf_mobilenetv3_large_075.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::mobilenetv3_large_100 author::timm task::computer_vision
+# labels: name::tf_mobilenetv3_large_075 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("mobilenetv3_large_100", pretrained = False)
+model = timm.create_model("tf_mobilenetv3_large_075", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/mobilenetv3_large_100_miil.py` & `mlagility-3.1.1/models/timm/tf_mobilenetv3_small_minimal_100.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::mobilenetv3_large_100_miil author::timm task::computer_vision
+# labels: name::tf_mobilenetv3_small_minimal_100 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("mobilenetv3_large_100_miil", pretrained = False)
+model = timm.create_model("tf_mobilenetv3_small_minimal_100", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/mobilenetv3_large_100_miil_in21k.py` & `mlagility-3.1.1/models/timm/xcit_large_24_p8_384_dist.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::mobilenetv3_large_100_miil_in21k author::timm task::computer_vision
+# labels: name::xcit_large_24_p8_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("mobilenetv3_large_100_miil_in21k", pretrained = False)
+model = timm.create_model("xcit_large_24_p8_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/mobilenetv3_small_050.py` & `mlagility-3.1.1/models/timm/mobilenetv3_small_050.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::mobilenetv3_small_050 author::timm task::computer_vision
+# labels: name::mobilenetv3_small_050 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/mobilenetv3_small_075.py` & `mlagility-3.1.1/models/timm/mobilenetv3_small_075.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::mobilenetv3_small_075 author::timm task::computer_vision
+# labels: name::mobilenetv3_small_075 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/mobilenetv3_small_100.py` & `mlagility-3.1.1/models/timm/tf_mobilenetv3_small_100.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::mobilenetv3_small_100 author::timm task::computer_vision
+# labels: name::tf_mobilenetv3_small_100 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("mobilenetv3_small_100", pretrained = False)
+model = timm.create_model("tf_mobilenetv3_small_100", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/mobilevitv2_150_384_in22ft1k.py` & `mlagility-3.1.1/models/timm/mobilevitv2_150_384_in22ft1k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::mobilevitv2_150_384_in22ft1k author::timm task::computer_vision
+# labels: name::mobilevitv2_150_384_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/mobilevitv2_150_in22ft1k.py` & `mlagility-3.1.1/models/timm/vit_small_patch16_224_dino.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::mobilevitv2_150_in22ft1k author::timm task::computer_vision
+# labels: name::vit_small_patch16_224_dino author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("mobilevitv2_150_in22ft1k", pretrained = False)
+model = timm.create_model("vit_small_patch16_224_dino", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/mobilevitv2_175_384_in22ft1k.py` & `mlagility-3.1.1/models/timm/mobilevitv2_175_384_in22ft1k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::mobilevitv2_175_384_in22ft1k author::timm task::computer_vision
+# labels: name::mobilevitv2_175_384_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/mobilevitv2_175_in22ft1k.py` & `mlagility-3.1.1/models/timm/pit_xs_distilled_224.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::mobilevitv2_175_in22ft1k author::timm task::computer_vision
+# labels: name::pit_xs_distilled_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("mobilevitv2_175_in22ft1k", pretrained = False)
+model = timm.create_model("pit_xs_distilled_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/mobilevitv2_200_384_in22ft1k.py` & `mlagility-3.1.1/models/timm/mobilevitv2_200_384_in22ft1k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::mobilevitv2_200_384_in22ft1k author::timm task::computer_vision
+# labels: name::mobilevitv2_200_384_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/mobilevitv2_200_in22ft1k.py` & `mlagility-3.1.1/models/timm/xcit_small_24_p16_224_dist.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::mobilevitv2_200_in22ft1k author::timm task::computer_vision
+# labels: name::xcit_small_24_p16_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("mobilevitv2_200_in22ft1k", pretrained = False)
+model = timm.create_model("xcit_small_24_p16_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/pit_b_distilled_224.py` & `mlagility-3.1.1/models/timm/swinv2_tiny_window16_256.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::pit_b_distilled_224 author::timm task::computer_vision
+# labels: name::swinv2_tiny_window16_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("pit_b_distilled_224", pretrained = False)
+model = timm.create_model("swinv2_tiny_window16_256", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/pit_s_distilled_224.py` & `mlagility-3.1.1/models/timm/ens_adv_inception_resnet_v2.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::pit_s_distilled_224 author::timm task::computer_vision
+# labels: name::ens_adv_inception_resnet_v2 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("pit_s_distilled_224", pretrained = False)
+model = timm.create_model("ens_adv_inception_resnet_v2", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/pit_ti_distilled_224.py` & `mlagility-3.1.1/models/timm/efficientnet_es_pruned.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::pit_ti_distilled_224 author::timm task::computer_vision
+# labels: name::efficientnet_es_pruned author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("pit_ti_distilled_224", pretrained = False)
+model = timm.create_model("efficientnet_es_pruned", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/pit_xs_distilled_224.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_s_in21k.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::pit_xs_distilled_224 author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_s_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("pit_xs_distilled_224", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_s_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/res2net101_26w_4s.py` & `mlagility-3.1.1/models/timm/res2net101_26w_4s.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::res2net101_26w_4s author::timm task::computer_vision
+# labels: name::res2net101_26w_4s author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/resmlp_12_224_dino.py` & `mlagility-3.1.1/models/timm/resmlp_24_224_dino.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resmlp_12_224_dino author::timm task::computer_vision
+# labels: name::resmlp_24_224_dino author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resmlp_12_224_dino", pretrained = False)
+model = timm.create_model("resmlp_24_224_dino", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resmlp_12_distilled_224.py` & `mlagility-3.1.1/models/timm/resmlp_12_distilled_224.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::resmlp_12_distilled_224 author::timm task::computer_vision
+# labels: name::resmlp_12_distilled_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/resmlp_24_224_dino.py` & `mlagility-3.1.1/models/timm/resmlp_big_24_224.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resmlp_24_224_dino author::timm task::computer_vision
+# labels: name::resmlp_big_24_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resmlp_24_224_dino", pretrained = False)
+model = timm.create_model("resmlp_big_24_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resmlp_24_distilled_224.py` & `mlagility-3.1.1/models/timm/seresnext101d_32x8d.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resmlp_24_distilled_224 author::timm task::computer_vision
+# labels: name::seresnext101d_32x8d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resmlp_24_distilled_224", pretrained = False)
+model = timm.create_model("seresnext101d_32x8d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resmlp_36_distilled_224.py` & `mlagility-3.1.1/models/timm/cs3darknet_focus_l.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resmlp_36_distilled_224 author::timm task::computer_vision
+# labels: name::cs3darknet_focus_l author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resmlp_36_distilled_224", pretrained = False)
+model = timm.create_model("cs3darknet_focus_l", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resmlp_big_24_224.py` & `mlagility-3.1.1/models/timm/xcit_tiny_24_p8_224.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resmlp_big_24_224 author::timm task::computer_vision
+# labels: name::xcit_tiny_24_p8_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resmlp_big_24_224", pretrained = False)
+model = timm.create_model("xcit_tiny_24_p8_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resmlp_big_24_224_in22ft1k.py` & `mlagility-3.1.1/models/timm/resmlp_big_24_224_in22ft1k.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::resmlp_big_24_224_in22ft1k author::timm task::computer_vision
+# labels: name::resmlp_big_24_224_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/resmlp_big_24_distilled_224.py` & `mlagility-3.1.1/models/timm/swinv2_cr_small_224.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resmlp_big_24_distilled_224 author::timm task::computer_vision
+# labels: name::swinv2_cr_small_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resmlp_big_24_distilled_224", pretrained = False)
+model = timm.create_model("swinv2_cr_small_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnest50d_1s4x24d.py` & `mlagility-3.1.1/models/timm/resnest50d_1s4x24d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::resnest50d_1s4x24d author::timm task::computer_vision
+# labels: name::resnest50d_1s4x24d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/resnest50d_4s2x40d.py` & `mlagility-3.1.1/models/timm/resnest50d_4s2x40d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::resnest50d_4s2x40d author::timm task::computer_vision
+# labels: name::resnest50d_4s2x40d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_101x1_bitm.py` & `mlagility-3.1.1/models/timm/resnetv2_101x1_bitm.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::resnetv2_101x1_bitm author::timm task::computer_vision
+# labels: name::resnetv2_101x1_bitm author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_101x1_bitm_in21k.py` & `mlagility-3.1.1/models/timm/convnext_small_384_in22ft1k.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_101x1_bitm_in21k author::timm task::computer_vision
+# labels: name::convnext_small_384_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_101x1_bitm_in21k", pretrained = False)
+model = timm.create_model("convnext_small_384_in22ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_101x3_bitm.py` & `mlagility-3.1.1/models/timm/resnetv2_152x2_bitm.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_101x3_bitm author::timm task::computer_vision
+# labels: name::resnetv2_152x2_bitm author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_101x3_bitm", pretrained = False)
+model = timm.create_model("resnetv2_152x2_bitm", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_101x3_bitm_in21k.py` & `mlagility-3.1.1/models/timm/xcit_small_12_p8_384_dist.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_101x3_bitm_in21k author::timm task::computer_vision
+# labels: name::xcit_small_12_p8_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_101x3_bitm_in21k", pretrained = False)
+model = timm.create_model("xcit_small_12_p8_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_152x2_bit_teacher.py` & `mlagility-3.1.1/models/timm/resnetv2_152x2_bitm_in21k.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_152x2_bit_teacher author::timm task::computer_vision
+# labels: name::resnetv2_152x2_bitm_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_152x2_bit_teacher", pretrained = False)
+model = timm.create_model("resnetv2_152x2_bitm_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_152x2_bit_teacher_384.py` & `mlagility-3.1.1/models/timm/resnetv2_152x4_bitm_in21k.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_152x2_bit_teacher_384 author::timm task::computer_vision
+# labels: name::resnetv2_152x4_bitm_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_152x2_bit_teacher_384", pretrained = False)
+model = timm.create_model("resnetv2_152x4_bitm_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_152x2_bitm.py` & `mlagility-3.1.1/models/timm/resnetv2_152x4_bitm.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_152x2_bitm author::timm task::computer_vision
+# labels: name::resnetv2_152x4_bitm author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_152x2_bitm", pretrained = False)
+model = timm.create_model("resnetv2_152x4_bitm", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_152x2_bitm_in21k.py` & `mlagility-3.1.1/models/timm/resnetv2_50x1_bitm.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_152x2_bitm_in21k author::timm task::computer_vision
+# labels: name::resnetv2_50x1_bitm author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_152x2_bitm_in21k", pretrained = False)
+model = timm.create_model("resnetv2_50x1_bitm", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_152x4_bitm.py` & `mlagility-3.1.1/models/timm/gc_efficientnetv2_rw_t.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_152x4_bitm author::timm task::computer_vision
+# labels: name::gc_efficientnetv2_rw_t author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_152x4_bitm", pretrained = False)
+model = timm.create_model("gc_efficientnetv2_rw_t", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_152x4_bitm_in21k.py` & `mlagility-3.1.1/models/timm/resnetv2_50x1_bitm_in21k.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_152x4_bitm_in21k author::timm task::computer_vision
+# labels: name::resnetv2_50x1_bitm_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_152x4_bitm_in21k", pretrained = False)
+model = timm.create_model("resnetv2_50x1_bitm_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_50d_evob.py` & `mlagility-3.1.1/models/timm/resnetv2_50x1_bit_distilled.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_50d_evob author::timm task::computer_vision
+# labels: name::resnetv2_50x1_bit_distilled author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_50d_evob", pretrained = False)
+model = timm.create_model("resnetv2_50x1_bit_distilled", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_50d_evos.py` & `mlagility-3.1.1/models/timm/beit_large_patch16_512.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_50d_evos author::timm task::computer_vision
+# labels: name::beit_large_patch16_512 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_50d_evos", pretrained = False)
+model = timm.create_model("beit_large_patch16_512", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_50x1_bit_distilled.py` & `mlagility-3.1.1/models/timm/vit_large_patch32_384.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_50x1_bit_distilled author::timm task::computer_vision
+# labels: name::vit_large_patch32_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_50x1_bit_distilled", pretrained = False)
+model = timm.create_model("vit_large_patch32_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_50x1_bitm.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_l.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_50x1_bitm author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_l author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_50x1_bitm", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_l", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_50x1_bitm_in21k.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_l_in21k.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_50x1_bitm_in21k author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_l_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_50x1_bitm_in21k", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_l_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_50x3_bitm.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_b3.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::resnetv2_50x3_bitm author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_b3 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("resnetv2_50x3_bitm", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_b3", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/resnetv2_50x3_bitm_in21k.py` & `mlagility-3.1.1/models/timm/resnetv2_50x3_bitm_in21k.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::resnetv2_50x3_bitm_in21k author::timm task::computer_vision
+# labels: name::resnetv2_50x3_bitm_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/seresnext101_32x4d.py` & `mlagility-3.1.1/models/timm/seresnext50_32x4d.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::seresnext101_32x4d author::timm task::computer_vision
+# labels: name::seresnext50_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("seresnext101_32x4d", pretrained = False)
+model = timm.create_model("seresnext50_32x4d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/seresnext101_32x8d.py` & `mlagility-3.1.1/models/timm/seresnext101_32x8d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::seresnext101_32x8d author::timm task::computer_vision
+# labels: name::seresnext101_32x8d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/seresnext101d_32x8d.py` & `mlagility-3.1.1/models/timm/swsl_resnext101_32x16d.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::seresnext101d_32x8d author::timm task::computer_vision
+# labels: name::swsl_resnext101_32x16d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("seresnext101d_32x8d", pretrained = False)
+model = timm.create_model("swsl_resnext101_32x16d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/seresnext26d_32x4d.py` & `mlagility-3.1.1/models/timm/seresnext26tn_32x4d.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::seresnext26d_32x4d author::timm task::computer_vision
+# labels: name::seresnext26tn_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("seresnext26d_32x4d", pretrained = False)
+model = timm.create_model("seresnext26tn_32x4d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/seresnext26t_32x4d.py` & `mlagility-3.1.1/models/timm/ssl_resnext50_32x4d.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::seresnext26t_32x4d author::timm task::computer_vision
+# labels: name::ssl_resnext50_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("seresnext26t_32x4d", pretrained = False)
+model = timm.create_model("ssl_resnext50_32x4d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/seresnext26tn_32x4d.py` & `mlagility-3.1.1/models/timm/swinv2_base_window8_256.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::seresnext26tn_32x4d author::timm task::computer_vision
+# labels: name::swinv2_base_window8_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("seresnext26tn_32x4d", pretrained = False)
+model = timm.create_model("swinv2_base_window8_256", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/seresnext50_32x4d.py` & `mlagility-3.1.1/models/timm/swinv2_base_window16_256.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::seresnext50_32x4d author::timm task::computer_vision
+# labels: name::swinv2_base_window16_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("seresnext50_32x4d", pretrained = False)
+model = timm.create_model("swinv2_base_window16_256", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/seresnextaa101d_32x8d.py` & `mlagility-3.1.1/models/timm/seresnextaa101d_32x8d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::seresnextaa101d_32x8d author::timm task::computer_vision
+# labels: name::seresnextaa101d_32x8d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/skresnext50_32x4d.py` & `mlagility-3.1.1/models/timm/vit_base_r26_s32_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::skresnext50_32x4d author::timm task::computer_vision
+# labels: name::vit_base_r26_s32_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("skresnext50_32x4d", pretrained = False)
+model = timm.create_model("vit_base_r26_s32_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/ssl_resnext101_32x16d.py` & `mlagility-3.1.1/models/timm/swinv2_cr_huge_224.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::ssl_resnext101_32x16d author::timm task::computer_vision
+# labels: name::swinv2_cr_huge_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("ssl_resnext101_32x16d", pretrained = False)
+model = timm.create_model("swinv2_cr_huge_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/ssl_resnext101_32x4d.py` & `mlagility-3.1.1/models/timm/swinv2_cr_small_384.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::ssl_resnext101_32x4d author::timm task::computer_vision
+# labels: name::swinv2_cr_small_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("ssl_resnext101_32x4d", pretrained = False)
+model = timm.create_model("swinv2_cr_small_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/ssl_resnext101_32x8d.py` & `mlagility-3.1.1/models/timm/ssl_resnext101_32x8d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::ssl_resnext101_32x8d author::timm task::computer_vision
+# labels: name::ssl_resnext101_32x8d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/ssl_resnext50_32x4d.py` & `mlagility-3.1.1/models/timm/swinv2_tiny_window8_256.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::ssl_resnext50_32x4d author::timm task::computer_vision
+# labels: name::swinv2_tiny_window8_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("ssl_resnext50_32x4d", pretrained = False)
+model = timm.create_model("swinv2_tiny_window8_256", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swin_base_patch4_window12_384.py` & `mlagility-3.1.1/models/timm/swin_base_patch4_window12_384.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swin_base_patch4_window12_384 author::timm task::computer_vision
+# labels: name::swin_base_patch4_window12_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swin_base_patch4_window12_384_in22k.py` & `mlagility-3.1.1/models/timm/swin_base_patch4_window12_384_in22k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swin_base_patch4_window12_384_in22k author::timm task::computer_vision
+# labels: name::swin_base_patch4_window12_384_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swin_base_patch4_window7_224.py` & `mlagility-3.1.1/models/timm/swin_base_patch4_window7_224_in22k.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swin_base_patch4_window7_224 author::timm task::computer_vision
+# labels: name::swin_base_patch4_window7_224_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swin_base_patch4_window7_224", pretrained = False)
+model = timm.create_model("swin_base_patch4_window7_224_in22k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swin_base_patch4_window7_224_in22k.py` & `mlagility-3.1.1/models/timm/vit_small_r26_s32_224_in21k.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swin_base_patch4_window7_224_in22k author::timm task::computer_vision
+# labels: name::vit_small_r26_s32_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swin_base_patch4_window7_224_in22k", pretrained = False)
+model = timm.create_model("vit_small_r26_s32_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swin_large_patch4_window12_384.py` & `mlagility-3.1.1/models/timm/swin_large_patch4_window12_384.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swin_large_patch4_window12_384 author::timm task::computer_vision
+# labels: name::swin_large_patch4_window12_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swin_large_patch4_window12_384_in22k.py` & `mlagility-3.1.1/models/timm/swin_large_patch4_window12_384_in22k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swin_large_patch4_window12_384_in22k author::timm task::computer_vision
+# labels: name::swin_large_patch4_window12_384_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swin_large_patch4_window7_224.py` & `mlagility-3.1.1/models/timm/swin_large_patch4_window7_224_in22k.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swin_large_patch4_window7_224 author::timm task::computer_vision
+# labels: name::swin_large_patch4_window7_224_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swin_large_patch4_window7_224", pretrained = False)
+model = timm.create_model("swin_large_patch4_window7_224_in22k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swin_large_patch4_window7_224_in22k.py` & `mlagility-3.1.1/models/timm/beit_large_patch16_224_in22k.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swin_large_patch4_window7_224_in22k author::timm task::computer_vision
+# labels: name::beit_large_patch16_224_in22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swin_large_patch4_window7_224_in22k", pretrained = False)
+model = timm.create_model("beit_large_patch16_224_in22k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swin_s3_small_224.py` & `mlagility-3.1.1/models/timm/vit_large_patch16_384.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swin_s3_small_224 author::timm task::computer_vision
+# labels: name::vit_large_patch16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swin_s3_small_224", pretrained = False)
+model = timm.create_model("vit_large_patch16_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swin_small_patch4_window7_224.py` & `mlagility-3.1.1/models/timm/swin_s3_small_224.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swin_small_patch4_window7_224 author::timm task::computer_vision
+# labels: name::swin_s3_small_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swin_small_patch4_window7_224", pretrained = False)
+model = timm.create_model("swin_s3_small_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swin_tiny_patch4_window7_224.py` & `mlagility-3.1.1/models/timm/swin_tiny_patch4_window7_224.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swin_tiny_patch4_window7_224 author::timm task::computer_vision
+# labels: name::swin_tiny_patch4_window7_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_base_window12_192_22k.py` & `mlagility-3.1.1/models/timm/swinv2_base_window12_192_22k.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swinv2_base_window12_192_22k author::timm task::computer_vision
+# labels: name::swinv2_base_window12_192_22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_base_window12to16_192to256_22kft1k.py` & `mlagility-3.1.1/models/timm/swinv2_base_window12to16_192to256_22kft1k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swinv2_base_window12to16_192to256_22kft1k author::timm task::computer_vision
+# labels: name::swinv2_base_window12to16_192to256_22kft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_base_window12to24_192to384_22kft1k.py` & `mlagility-3.1.1/models/timm/swinv2_base_window12to24_192to384_22kft1k.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swinv2_base_window12to24_192to384_22kft1k author::timm task::computer_vision
+# labels: name::swinv2_base_window12to24_192to384_22kft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_base_window16_256.py` & `mlagility-3.1.1/models/timm/swinv2_cr_base_224.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_base_window16_256 author::timm task::computer_vision
+# labels: name::swinv2_cr_base_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_base_window16_256", pretrained = False)
+model = timm.create_model("swinv2_cr_base_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_base_window8_256.py` & `mlagility-3.1.1/models/timm/swinv2_cr_large_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_base_window8_256 author::timm task::computer_vision
+# labels: name::swinv2_cr_large_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_base_window8_256", pretrained = False)
+model = timm.create_model("swinv2_cr_large_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_base_224.py` & `mlagility-3.1.1/models/timm/beit_large_patch16_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_base_224 author::timm task::computer_vision
+# labels: name::beit_large_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_base_224", pretrained = False)
+model = timm.create_model("beit_large_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_base_384.py` & `mlagility-3.1.1/models/timm/vit_large_r50_s32_384.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_base_384 author::timm task::computer_vision
+# labels: name::vit_large_r50_s32_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_base_384", pretrained = False)
+model = timm.create_model("vit_large_r50_s32_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_base_ns_224.py` & `mlagility-3.1.1/models/timm/swinv2_cr_base_ns_224.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swinv2_cr_base_ns_224 author::timm task::computer_vision
+# labels: name::swinv2_cr_base_ns_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_giant_224.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b2.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_giant_224 author::timm task::computer_vision
+# labels: name::tf_efficientnet_b2 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_giant_224", pretrained = False)
+model = timm.create_model("tf_efficientnet_b2", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_giant_384.py` & `mlagility-3.1.1/models/timm/xcit_large_24_p8_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_giant_384 author::timm task::computer_vision
+# labels: name::xcit_large_24_p8_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_giant_384", pretrained = False)
+model = timm.create_model("xcit_large_24_p8_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_huge_224.py` & `mlagility-3.1.1/models/timm/vit_large_patch16_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_huge_224 author::timm task::computer_vision
+# labels: name::vit_large_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_huge_224", pretrained = False)
+model = timm.create_model("vit_large_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_huge_384.py` & `mlagility-3.1.1/models/timm/tnt_b_patch16_224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_huge_384 author::timm task::computer_vision
+# labels: name::tnt_b_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_huge_384", pretrained = False)
+model = timm.create_model("tnt_b_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_large_224.py` & `mlagility-3.1.1/models/timm/vit_large_patch32_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_large_224 author::timm task::computer_vision
+# labels: name::vit_large_patch32_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_large_224", pretrained = False)
+model = timm.create_model("vit_large_patch32_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_large_384.py` & `mlagility-3.1.1/models/timm/vit_large_r50_s32_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_large_384 author::timm task::computer_vision
+# labels: name::vit_large_r50_s32_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_large_384", pretrained = False)
+model = timm.create_model("vit_large_r50_s32_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_small_224.py` & `mlagility-3.1.1/models/timm/pit_b_distilled_224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_small_224 author::timm task::computer_vision
+# labels: name::pit_b_distilled_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_small_224", pretrained = False)
+model = timm.create_model("pit_b_distilled_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_small_384.py` & `mlagility-3.1.1/models/timm/xcit_small_24_p8_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_small_384 author::timm task::computer_vision
+# labels: name::xcit_small_24_p8_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_small_384", pretrained = False)
+model = timm.create_model("xcit_small_24_p8_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_small_ns_224.py` & `mlagility-3.1.1/models/timm/swinv2_cr_tiny_ns_224.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_small_ns_224 author::timm task::computer_vision
+# labels: name::swinv2_cr_tiny_ns_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_small_ns_224", pretrained = False)
+model = timm.create_model("swinv2_cr_tiny_ns_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_tiny_224.py` & `mlagility-3.1.1/models/timm/vit_small_r26_s32_224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_tiny_224 author::timm task::computer_vision
+# labels: name::vit_small_r26_s32_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_tiny_224", pretrained = False)
+model = timm.create_model("vit_small_r26_s32_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_tiny_384.py` & `mlagility-3.1.1/models/timm/xcit_large_24_p16_224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_tiny_384 author::timm task::computer_vision
+# labels: name::xcit_large_24_p16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_tiny_384", pretrained = False)
+model = timm.create_model("xcit_large_24_p16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_cr_tiny_ns_224.py` & `mlagility-3.1.1/models/timm/swinv2_cr_tiny_384.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_cr_tiny_ns_224 author::timm task::computer_vision
+# labels: name::swinv2_cr_tiny_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_cr_tiny_ns_224", pretrained = False)
+model = timm.create_model("swinv2_cr_tiny_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_large_window12_192_22k.py` & `mlagility-3.1.1/models/timm/swinv2_large_window12_192_22k.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swinv2_large_window12_192_22k author::timm task::computer_vision
+# labels: name::swinv2_large_window12_192_22k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_large_window12to16_192to256_22kft1k.py` & `mlagility-3.1.1/models/timm/swinv2_large_window12to16_192to256_22kft1k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swinv2_large_window12to16_192to256_22kft1k author::timm task::computer_vision
+# labels: name::swinv2_large_window12to16_192to256_22kft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_large_window12to24_192to384_22kft1k.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b6_ap.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_large_window12to24_192to384_22kft1k author::timm task::computer_vision
+# labels: name::tf_efficientnet_b6_ap author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_large_window12to24_192to384_22kft1k", pretrained = False)
+model = timm.create_model("tf_efficientnet_b6_ap", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_small_window16_256.py` & `mlagility-3.1.1/models/timm/swinv2_cr_small_ns_224.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_small_window16_256 author::timm task::computer_vision
+# labels: name::swinv2_cr_small_ns_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_small_window16_256", pretrained = False)
+model = timm.create_model("swinv2_cr_small_ns_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_small_window8_256.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b3.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_small_window8_256 author::timm task::computer_vision
+# labels: name::tf_efficientnet_b3 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_small_window8_256", pretrained = False)
+model = timm.create_model("tf_efficientnet_b3", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_tiny_window16_256.py` & `mlagility-3.1.1/models/timm/swinv2_cr_tiny_224.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_tiny_window16_256 author::timm task::computer_vision
+# labels: name::swinv2_cr_tiny_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_tiny_window16_256", pretrained = False)
+model = timm.create_model("swinv2_cr_tiny_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swinv2_tiny_window8_256.py` & `mlagility-3.1.1/models/timm/vit_large_r50_s32_224_in21k.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swinv2_tiny_window8_256 author::timm task::computer_vision
+# labels: name::vit_large_r50_s32_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swinv2_tiny_window8_256", pretrained = False)
+model = timm.create_model("vit_large_r50_s32_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swsl_resnext101_32x16d.py` & `mlagility-3.1.1/models/timm/xcit_tiny_12_p16_224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swsl_resnext101_32x16d author::timm task::computer_vision
+# labels: name::xcit_tiny_12_p16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swsl_resnext101_32x16d", pretrained = False)
+model = timm.create_model("xcit_tiny_12_p16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swsl_resnext101_32x4d.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b6.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swsl_resnext101_32x4d author::timm task::computer_vision
+# labels: name::tf_efficientnet_b6 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swsl_resnext101_32x4d", pretrained = False)
+model = timm.create_model("tf_efficientnet_b6", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/swsl_resnext101_32x8d.py` & `mlagility-3.1.1/models/timm/swsl_resnext101_32x8d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::swsl_resnext101_32x8d author::timm task::computer_vision
+# labels: name::swsl_resnext101_32x8d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/swsl_resnext50_32x4d.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b8.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::swsl_resnext50_32x4d author::timm task::computer_vision
+# labels: name::tf_efficientnet_b8 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("swsl_resnext50_32x4d", pretrained = False)
+model = timm.create_model("tf_efficientnet_b8", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b0.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b5.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b0 author::timm task::computer_vision
+# labels: name::tf_efficientnet_b5 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b0", pretrained = False)
+model = timm.create_model("tf_efficientnet_b5", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b0_ap.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b1.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b0_ap author::timm task::computer_vision
+# labels: name::tf_efficientnet_b1 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b0_ap", pretrained = False)
+model = timm.create_model("tf_efficientnet_b1", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b0_ns.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_es.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b0_ns author::timm task::computer_vision
+# labels: name::tf_efficientnet_es author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b0_ns", pretrained = False)
+model = timm.create_model("tf_efficientnet_es", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b1.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_em.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b1 author::timm task::computer_vision
+# labels: name::tf_efficientnet_em author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b1", pretrained = False)
+model = timm.create_model("tf_efficientnet_em", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b1_ap.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_b1.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b1_ap author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_b1 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b1_ap", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_b1", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b1_ns.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_el.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b1_ns author::timm task::computer_vision
+# labels: name::tf_efficientnet_el author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b1_ns", pretrained = False)
+model = timm.create_model("tf_efficientnet_el", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b2.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_b2.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b2 author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_b2 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b2", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_b2", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b2_ap.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_m.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b2_ap author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_m author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b2_ap", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_m", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b2_ns.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_s.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b2_ns author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_s author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b2_ns", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_s", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b3.py` & `mlagility-3.1.1/models/timm/vit_small_patch32_224.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b3 author::timm task::computer_vision
+# labels: name::vit_small_patch32_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b3", pretrained = False)
+model = timm.create_model("vit_small_patch32_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b3_ap.py` & `mlagility-3.1.1/models/timm/xcit_small_12_p8_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b3_ap author::timm task::computer_vision
+# labels: name::xcit_small_12_p8_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b3_ap", pretrained = False)
+model = timm.create_model("xcit_small_12_p8_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b3_ns.py` & `mlagility-3.1.1/models/timm/vit_small_patch32_224_in21k.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b3_ns author::timm task::computer_vision
+# labels: name::vit_small_patch32_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b3_ns", pretrained = False)
+model = timm.create_model("vit_small_patch32_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b4.py` & `mlagility-3.1.1/models/timm/xcit_tiny_12_p8_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b4 author::timm task::computer_vision
+# labels: name::xcit_tiny_12_p8_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b4", pretrained = False)
+model = timm.create_model("xcit_tiny_12_p8_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b4_ap.py` & `mlagility-3.1.1/models/timm/xcit_small_12_p16_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b4_ap author::timm task::computer_vision
+# labels: name::xcit_small_12_p16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b4_ap", pretrained = False)
+model = timm.create_model("xcit_small_12_p16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b4_ns.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b4_ns.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::tf_efficientnet_b4_ns author::timm task::computer_vision
+# labels: name::tf_efficientnet_b4_ns author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b5.py` & `mlagility-3.1.1/models/timm/vit_small_patch8_224_dino.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b5 author::timm task::computer_vision
+# labels: name::vit_small_patch8_224_dino author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b5", pretrained = False)
+model = timm.create_model("vit_small_patch8_224_dino", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b5_ap.py` & `mlagility-3.1.1/models/timm/xcit_small_24_p16_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b5_ap author::timm task::computer_vision
+# labels: name::xcit_small_24_p16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b5_ap", pretrained = False)
+model = timm.create_model("xcit_small_24_p16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b5_ns.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b5_ns.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::tf_efficientnet_b5_ns author::timm task::computer_vision
+# labels: name::tf_efficientnet_b5_ns author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b6.py` & `mlagility-3.1.1/models/timm/xcit_small_24_p8_224_dist.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b6 author::timm task::computer_vision
+# labels: name::xcit_small_24_p8_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b6", pretrained = False)
+model = timm.create_model("xcit_small_24_p8_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b6_ap.py` & `mlagility-3.1.1/models/timm/xcit_large_24_p8_224_dist.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b6_ap author::timm task::computer_vision
+# labels: name::xcit_large_24_p8_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b6_ap", pretrained = False)
+model = timm.create_model("xcit_large_24_p8_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b6_ns.py` & `mlagility-3.1.1/models/timm/xcit_tiny_24_p8_224_dist.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b6_ns author::timm task::computer_vision
+# labels: name::xcit_tiny_24_p8_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b6_ns", pretrained = False)
+model = timm.create_model("xcit_tiny_24_p8_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b7.py` & `mlagility-3.1.1/models/timm/xcit_tiny_24_p16_224.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b7 author::timm task::computer_vision
+# labels: name::xcit_tiny_24_p16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b7", pretrained = False)
+model = timm.create_model("xcit_tiny_24_p16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b7_ap.py` & `mlagility-3.1.1/models/timm/xcit_tiny_24_p16_224_dist.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b7_ap author::timm task::computer_vision
+# labels: name::xcit_tiny_24_p16_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b7_ap", pretrained = False)
+model = timm.create_model("xcit_tiny_24_p16_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b7_ns.py` & `mlagility-3.1.1/models/timm/xcit_large_24_p16_384_dist.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b7_ns author::timm task::computer_vision
+# labels: name::xcit_large_24_p16_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b7_ns", pretrained = False)
+model = timm.create_model("xcit_large_24_p16_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b8.py` & `mlagility-3.1.1/models/timm/vit_small_resnet26d_224.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b8 author::timm task::computer_vision
+# labels: name::vit_small_resnet26d_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b8", pretrained = False)
+model = timm.create_model("vit_small_resnet26d_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_b8_ap.py` & `mlagility-3.1.1/models/timm/xcit_small_24_p8_384_dist.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_b8_ap author::timm task::computer_vision
+# labels: name::xcit_small_24_p8_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_b8_ap", pretrained = False)
+model = timm.create_model("xcit_small_24_p8_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_cc_b0_4e.py` & `mlagility-3.1.1/models/timm/vit_tiny_r_s16_p8_224_in21k.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_cc_b0_4e author::timm task::computer_vision
+# labels: name::vit_tiny_r_s16_p8_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_cc_b0_4e", pretrained = False)
+model = timm.create_model("vit_tiny_r_s16_p8_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_cc_b0_8e.py` & `mlagility-3.1.1/models/timm/vit_tiny_r_s16_p8_224.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_cc_b0_8e author::timm task::computer_vision
+# labels: name::vit_tiny_r_s16_p8_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_cc_b0_8e", pretrained = False)
+model = timm.create_model("vit_tiny_r_s16_p8_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_cc_b1_8e.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_cc_b1_8e.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::tf_efficientnet_cc_b1_8e author::timm task::computer_vision
+# labels: name::tf_efficientnet_cc_b1_8e author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_el.py` & `mlagility-3.1.1/models/timm/vit_base_patch32_224_sam.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_el author::timm task::computer_vision
+# labels: name::vit_base_patch32_224_sam author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_el", pretrained = False)
+model = timm.create_model("vit_base_patch32_224_sam", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_em.py` & `mlagility-3.1.1/models/timm/vit_small_patch16_36x1_224.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_em author::timm task::computer_vision
+# labels: name::vit_small_patch16_36x1_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_em", pretrained = False)
+model = timm.create_model("vit_small_patch16_36x1_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_es.py` & `mlagility-3.1.1/models/timm/deit3_small_patch16_224.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_es author::timm task::computer_vision
+# labels: name::deit3_small_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_es", pretrained = False)
+model = timm.create_model("deit3_small_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_l2_ns.py` & `mlagility-3.1.1/models/timm/convnext_large_384_in22ft1k.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_l2_ns author::timm task::computer_vision
+# labels: name::convnext_large_384_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_l2_ns", pretrained = False)
+model = timm.create_model("convnext_large_384_in22ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_l2_ns_475.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_l2_ns_475.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::tf_efficientnet_l2_ns_475 author::timm task::computer_vision
+# labels: name::tf_efficientnet_l2_ns_475 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_lite0.py` & `mlagility-3.1.1/models/timm/vit_base_resnet26d_224.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_lite0 author::timm task::computer_vision
+# labels: name::vit_base_resnet26d_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_lite0", pretrained = False)
+model = timm.create_model("vit_base_resnet26d_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_lite1.py` & `mlagility-3.1.1/models/timm/xcit_medium_24_p16_384_dist.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_lite1 author::timm task::computer_vision
+# labels: name::xcit_medium_24_p16_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_lite1", pretrained = False)
+model = timm.create_model("xcit_medium_24_p16_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_lite2.py` & `mlagility-3.1.1/models/timm/deit3_base_patch16_224.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_lite2 author::timm task::computer_vision
+# labels: name::deit3_base_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_lite2", pretrained = False)
+model = timm.create_model("deit3_base_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_lite3.py` & `mlagility-3.1.1/models/timm/deit3_base_patch16_384.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_lite3 author::timm task::computer_vision
+# labels: name::deit3_base_patch16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_lite3", pretrained = False)
+model = timm.create_model("deit3_base_patch16_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnet_lite4.py` & `mlagility-3.1.1/models/timm/deit_small_patch16_224.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnet_lite4 author::timm task::computer_vision
+# labels: name::deit_small_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnet_lite4", pretrained = False)
+model = timm.create_model("deit_small_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_b0.py` & `mlagility-3.1.1/models/timm/xcit_small_12_p16_384_dist.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_b0 author::timm task::computer_vision
+# labels: name::xcit_small_12_p16_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_b0", pretrained = False)
+model = timm.create_model("xcit_small_12_p16_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_b1.py` & `mlagility-3.1.1/models/timm/xcit_tiny_24_p16_384_dist.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_b1 author::timm task::computer_vision
+# labels: name::xcit_tiny_24_p16_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_b1", pretrained = False)
+model = timm.create_model("xcit_tiny_24_p16_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_b2.py` & `mlagility-3.1.1/models/timm/deit3_huge_patch14_224.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_b2 author::timm task::computer_vision
+# labels: name::deit3_huge_patch14_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_b2", pretrained = False)
+model = timm.create_model("deit3_huge_patch14_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_b3.py` & `mlagility-3.1.1/models/timm/vit_base_patch8_224_dino.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_b3 author::timm task::computer_vision
+# labels: name::vit_base_patch8_224_dino author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_b3", pretrained = False)
+model = timm.create_model("vit_base_patch8_224_dino", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_l.py` & `mlagility-3.1.1/models/timm/mobilevitv2_150_in22ft1k.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_l author::timm task::computer_vision
+# labels: name::mobilevitv2_150_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_l", pretrained = False)
+model = timm.create_model("mobilevitv2_150_in22ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_l_in21ft1k.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_l_in21ft1k.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::tf_efficientnetv2_l_in21ft1k author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_l_in21ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_l_in21k.py` & `mlagility-3.1.1/models/timm/vit_base_patch32_224_in21k.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_l_in21k author::timm task::computer_vision
+# labels: name::vit_base_patch32_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_l_in21k", pretrained = False)
+model = timm.create_model("vit_base_patch32_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_m.py` & `mlagility-3.1.1/models/timm/deit_tiny_patch16_224.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_m author::timm task::computer_vision
+# labels: name::deit_tiny_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_m", pretrained = False)
+model = timm.create_model("deit_tiny_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_m_in21ft1k.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_m_in21ft1k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::tf_efficientnetv2_m_in21ft1k author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_m_in21ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_m_in21k.py` & `mlagility-3.1.1/models/timm/vit_base_r50_s16_224_in21k.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_m_in21k author::timm task::computer_vision
+# labels: name::vit_base_r50_s16_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_m_in21k", pretrained = False)
+model = timm.create_model("vit_base_r50_s16_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_s.py` & `mlagility-3.1.1/models/timm/mobilevitv2_175_in22ft1k.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_s author::timm task::computer_vision
+# labels: name::mobilevitv2_175_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_s", pretrained = False)
+model = timm.create_model("mobilevitv2_175_in22ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_s_in21ft1k.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_s_in21ft1k.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::tf_efficientnetv2_s_in21ft1k author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_s_in21ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_s_in21k.py` & `mlagility-3.1.1/models/timm/vit_base_patch8_224_in21k.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_s_in21k author::timm task::computer_vision
+# labels: name::vit_base_patch8_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_s_in21k", pretrained = False)
+model = timm.create_model("vit_base_patch8_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_xl_in21ft1k.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_xl_in21ft1k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::tf_efficientnetv2_xl_in21ft1k author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_xl_in21ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/tf_efficientnetv2_xl_in21k.py` & `mlagility-3.1.1/models/timm/vit_base_patch32_plus_256.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_efficientnetv2_xl_in21k author::timm task::computer_vision
+# labels: name::vit_base_patch32_plus_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_efficientnetv2_xl_in21k", pretrained = False)
+model = timm.create_model("vit_base_patch32_plus_256", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_mobilenetv3_large_075.py` & `mlagility-3.1.1/models/timm/xcit_medium_24_p8_224.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_mobilenetv3_large_075 author::timm task::computer_vision
+# labels: name::xcit_medium_24_p8_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_mobilenetv3_large_075", pretrained = False)
+model = timm.create_model("xcit_medium_24_p8_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_mobilenetv3_large_100.py` & `mlagility-3.1.1/models/timm/xcit_medium_24_p16_224_dist.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_mobilenetv3_large_100 author::timm task::computer_vision
+# labels: name::xcit_medium_24_p16_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_mobilenetv3_large_100", pretrained = False)
+model = timm.create_model("xcit_medium_24_p16_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_mobilenetv3_large_minimal_100.py` & `mlagility-3.1.1/models/timm/tf_mobilenetv3_large_minimal_100.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::tf_mobilenetv3_large_minimal_100 author::timm task::computer_vision
+# labels: name::tf_mobilenetv3_large_minimal_100 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/tf_mobilenetv3_small_075.py` & `mlagility-3.1.1/models/timm/vit_gigantic_patch14_224.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_mobilenetv3_small_075 author::timm task::computer_vision
+# labels: name::vit_gigantic_patch14_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_mobilenetv3_small_075", pretrained = False)
+model = timm.create_model("vit_gigantic_patch14_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_mobilenetv3_small_100.py` & `mlagility-3.1.1/models/timm/vit_relpos_base_patch16_cls_224.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_mobilenetv3_small_100 author::timm task::computer_vision
+# labels: name::vit_relpos_base_patch16_cls_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_mobilenetv3_small_100", pretrained = False)
+model = timm.create_model("vit_relpos_base_patch16_cls_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tf_mobilenetv3_small_minimal_100.py` & `mlagility-3.1.1/models/timm/mobilenetv3_large_100_miil.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tf_mobilenetv3_small_minimal_100 author::timm task::computer_vision
+# labels: name::mobilenetv3_large_100_miil author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tf_mobilenetv3_small_minimal_100", pretrained = False)
+model = timm.create_model("mobilenetv3_large_100_miil", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tnt_b_patch16_224.py` & `mlagility-3.1.1/models/timm/vit_base_patch16_224.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tnt_b_patch16_224 author::timm task::computer_vision
+# labels: name::vit_base_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tnt_b_patch16_224", pretrained = False)
+model = timm.create_model("vit_base_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tnt_s_patch16_224.py` & `mlagility-3.1.1/models/timm/vit_small_patch16_224.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::tnt_s_patch16_224 author::timm task::computer_vision
+# labels: name::vit_small_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("tnt_s_patch16_224", pretrained = False)
+model = timm.create_model("vit_small_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/tv_resnext50_32x4d.py` & `mlagility-3.1.1/models/timm/tv_resnext50_32x4d.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::tv_resnext50_32x4d author::timm task::computer_vision
+# labels: name::tv_resnext50_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/twins_pcpvt_large.py` & `mlagility-3.1.1/models/timm/vit_base_patch8_224.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::twins_pcpvt_large author::timm task::computer_vision
+# labels: name::vit_base_patch8_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("twins_pcpvt_large", pretrained = False)
+model = timm.create_model("vit_base_patch8_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/twins_pcpvt_small.py` & `mlagility-3.1.1/models/timm/vit_base_patch16_224_dino.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::twins_pcpvt_small author::timm task::computer_vision
+# labels: name::vit_base_patch16_224_dino author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("twins_pcpvt_small", pretrained = False)
+model = timm.create_model("vit_base_patch16_224_dino", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch16_18x2_224.py` & `mlagility-3.1.1/models/timm/vit_base_patch16_18x2_224.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::vit_base_patch16_18x2_224 author::timm task::computer_vision
+# labels: name::vit_base_patch16_18x2_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch16_224.py` & `mlagility-3.1.1/models/timm/vit_base_patch16_384.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch16_224 author::timm task::computer_vision
+# labels: name::vit_base_patch16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch16_224", pretrained = False)
+model = timm.create_model("vit_base_patch16_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch16_224_dino.py` & `mlagility-3.1.1/models/timm/vit_base_resnet50_384.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch16_224_dino author::timm task::computer_vision
+# labels: name::vit_base_resnet50_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch16_224_dino", pretrained = False)
+model = timm.create_model("vit_base_resnet50_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch16_224_in21k.py` & `mlagility-3.1.1/models/timm/vit_large_patch16_224_in21k.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch16_224_in21k author::timm task::computer_vision
+# labels: name::vit_large_patch16_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch16_224_in21k", pretrained = False)
+model = timm.create_model("vit_large_patch16_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch16_224_miil.py` & `mlagility-3.1.1/models/timm/vit_tiny_patch16_384.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch16_224_miil author::timm task::computer_vision
+# labels: name::vit_tiny_patch16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch16_224_miil", pretrained = False)
+model = timm.create_model("vit_tiny_patch16_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch16_224_miil_in21k.py` & `mlagility-3.1.1/models/timm/vit_base_patch16_224_miil_in21k.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::vit_base_patch16_224_miil_in21k author::timm task::computer_vision
+# labels: name::vit_base_patch16_224_miil_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch16_224_sam.py` & `mlagility-3.1.1/models/timm/vit_small_patch16_384.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch16_224_sam author::timm task::computer_vision
+# labels: name::vit_small_patch16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch16_224_sam", pretrained = False)
+model = timm.create_model("vit_small_patch16_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch16_384.py` & `mlagility-3.1.1/models/timm/swinv2_cr_base_384.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch16_384 author::timm task::computer_vision
+# labels: name::swinv2_cr_base_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch16_384", pretrained = False)
+model = timm.create_model("swinv2_cr_base_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch16_plus_240.py` & `mlagility-3.1.1/models/timm/vit_giant_patch14_224.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch16_plus_240 author::timm task::computer_vision
+# labels: name::vit_giant_patch14_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch16_plus_240", pretrained = False)
+model = timm.create_model("vit_giant_patch14_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch16_rpn_224.py` & `mlagility-3.1.1/models/timm/vit_huge_patch14_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch16_rpn_224 author::timm task::computer_vision
+# labels: name::vit_huge_patch14_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch16_rpn_224", pretrained = False)
+model = timm.create_model("vit_huge_patch14_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch32_224.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_m_in21k.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch32_224 author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_m_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch32_224", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_m_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch32_224_in21k.py` & `mlagility-3.1.1/models/timm/vit_small_patch16_224_in21k.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch32_224_in21k author::timm task::computer_vision
+# labels: name::vit_small_patch16_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch32_224_in21k", pretrained = False)
+model = timm.create_model("vit_small_patch16_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch32_224_sam.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b7.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch32_224_sam author::timm task::computer_vision
+# labels: name::tf_efficientnet_b7 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch32_224_sam", pretrained = False)
+model = timm.create_model("tf_efficientnet_b7", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch32_384.py` & `mlagility-3.1.1/models/timm/vit_small_r26_s32_384.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch32_384 author::timm task::computer_vision
+# labels: name::vit_small_r26_s32_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch32_384", pretrained = False)
+model = timm.create_model("vit_small_r26_s32_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch32_plus_256.py` & `mlagility-3.1.1/models/timm/vit_base_patch32_384.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch32_plus_256 author::timm task::computer_vision
+# labels: name::vit_base_patch32_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch32_plus_256", pretrained = False)
+model = timm.create_model("vit_base_patch32_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch8_224.py` & `mlagility-3.1.1/models/timm/xcit_small_24_p16_384_dist.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch8_224 author::timm task::computer_vision
+# labels: name::xcit_small_24_p16_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch8_224", pretrained = False)
+model = timm.create_model("xcit_small_24_p16_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch8_224_dino.py` & `mlagility-3.1.1/models/timm/vit_base_patch16_224_in21k.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch8_224_dino author::timm task::computer_vision
+# labels: name::vit_base_patch16_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch8_224_dino", pretrained = False)
+model = timm.create_model("vit_base_patch16_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_patch8_224_in21k.py` & `mlagility-3.1.1/models/timm/beit_base_patch16_384.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_patch8_224_in21k author::timm task::computer_vision
+# labels: name::beit_base_patch16_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_patch8_224_in21k", pretrained = False)
+model = timm.create_model("beit_base_patch16_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_r26_s32_224.py` & `mlagility-3.1.1/models/timm/vit_base_patch16_rpn_224.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_r26_s32_224 author::timm task::computer_vision
+# labels: name::vit_base_patch16_rpn_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_r26_s32_224", pretrained = False)
+model = timm.create_model("vit_base_patch16_rpn_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_r50_s16_224.py` & `mlagility-3.1.1/models/timm/vit_base_resnet50d_224.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_r50_s16_224 author::timm task::computer_vision
+# labels: name::vit_base_resnet50d_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_r50_s16_224", pretrained = False)
+model = timm.create_model("vit_base_resnet50d_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_r50_s16_224_in21k.py` & `mlagility-3.1.1/models/timm/cs3darknet_focus_x.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_r50_s16_224_in21k author::timm task::computer_vision
+# labels: name::cs3darknet_focus_x author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_r50_s16_224_in21k", pretrained = False)
+model = timm.create_model("cs3darknet_focus_x", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_r50_s16_384.py` & `mlagility-3.1.1/models/timm/vit_base_patch16_224_sam.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_r50_s16_384 author::timm task::computer_vision
+# labels: name::vit_base_patch16_224_sam author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_r50_s16_384", pretrained = False)
+model = timm.create_model("vit_base_patch16_224_sam", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_resnet26d_224.py` & `mlagility-3.1.1/models/timm/vit_base_resnet50_224_in21k.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_resnet26d_224 author::timm task::computer_vision
+# labels: name::vit_base_resnet50_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_resnet26d_224", pretrained = False)
+model = timm.create_model("vit_base_resnet50_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_resnet50_224_in21k.py` & `mlagility-3.1.1/models/timm/vit_base_patch16_plus_240.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_resnet50_224_in21k author::timm task::computer_vision
+# labels: name::vit_base_patch16_plus_240 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_resnet50_224_in21k", pretrained = False)
+model = timm.create_model("vit_base_patch16_plus_240", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_resnet50_384.py` & `mlagility-3.1.1/models/timm/vit_relpos_base_patch16_plus_240.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_resnet50_384 author::timm task::computer_vision
+# labels: name::vit_relpos_base_patch16_plus_240 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_resnet50_384", pretrained = False)
+model = timm.create_model("vit_relpos_base_patch16_plus_240", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_base_resnet50d_224.py` & `mlagility-3.1.1/models/timm/vit_relpos_base_patch16_224.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_base_resnet50d_224 author::timm task::computer_vision
+# labels: name::vit_relpos_base_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_base_resnet50d_224", pretrained = False)
+model = timm.create_model("vit_relpos_base_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_giant_patch14_224.py` & `mlagility-3.1.1/models/timm/vit_small_patch16_18x2_224.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_giant_patch14_224 author::timm task::computer_vision
+# labels: name::vit_small_patch16_18x2_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_giant_patch14_224", pretrained = False)
+model = timm.create_model("vit_small_patch16_18x2_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_gigantic_patch14_224.py` & `mlagility-3.1.1/models/timm/vit_tiny_patch16_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_gigantic_patch14_224 author::timm task::computer_vision
+# labels: name::vit_tiny_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_gigantic_patch14_224", pretrained = False)
+model = timm.create_model("vit_tiny_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_huge_patch14_224.py` & `mlagility-3.1.1/models/timm/vit_huge_patch14_224_in21k.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_huge_patch14_224 author::timm task::computer_vision
+# labels: name::vit_huge_patch14_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_huge_patch14_224", pretrained = False)
+model = timm.create_model("vit_huge_patch14_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_huge_patch14_224_in21k.py` & `mlagility-3.1.1/models/timm/vit_tiny_patch16_224_in21k.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_huge_patch14_224_in21k author::timm task::computer_vision
+# labels: name::vit_tiny_patch16_224_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_huge_patch14_224_in21k", pretrained = False)
+model = timm.create_model("vit_tiny_patch16_224_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_large_patch14_224.py` & `mlagility-3.1.1/models/timm/deit_tiny_distilled_patch16_224.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_large_patch14_224 author::timm task::computer_vision
+# labels: name::deit_tiny_distilled_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_large_patch14_224", pretrained = False)
+model = timm.create_model("deit_tiny_distilled_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_large_patch16_224.py` & `mlagility-3.1.1/models/timm/vit_relpos_medium_patch16_224.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_large_patch16_224 author::timm task::computer_vision
+# labels: name::vit_relpos_medium_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_large_patch16_224", pretrained = False)
+model = timm.create_model("vit_relpos_medium_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_large_patch16_224_in21k.py` & `mlagility-3.1.1/models/timm/vit_relpos_medium_patch16_cls_224.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_large_patch16_224_in21k author::timm task::computer_vision
+# labels: name::vit_relpos_medium_patch16_cls_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_large_patch16_224_in21k", pretrained = False)
+model = timm.create_model("vit_relpos_medium_patch16_cls_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_large_patch16_384.py` & `mlagility-3.1.1/models/timm/vit_relpos_base_patch32_plus_rpn_256.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_large_patch16_384 author::timm task::computer_vision
+# labels: name::vit_relpos_base_patch32_plus_rpn_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_large_patch16_384", pretrained = False)
+model = timm.create_model("vit_relpos_base_patch32_plus_rpn_256", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_large_patch32_224.py` & `mlagility-3.1.1/models/timm/vit_srelpos_medium_patch16_224.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_large_patch32_224 author::timm task::computer_vision
+# labels: name::vit_srelpos_medium_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_large_patch32_224", pretrained = False)
+model = timm.create_model("vit_srelpos_medium_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_large_patch32_224_in21k.py` & `mlagility-3.1.1/models/timm/xcit_tiny_12_p16_384_dist.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_large_patch32_224_in21k author::timm task::computer_vision
+# labels: name::xcit_tiny_12_p16_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_large_patch32_224_in21k", pretrained = False)
+model = timm.create_model("xcit_tiny_12_p16_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_large_patch32_384.py` & `mlagility-3.1.1/models/timm/xcit_medium_24_p8_384_dist.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_large_patch32_384 author::timm task::computer_vision
+# labels: name::xcit_medium_24_p8_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_large_patch32_384", pretrained = False)
+model = timm.create_model("xcit_medium_24_p8_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_large_r50_s32_224.py` & `mlagility-3.1.1/models/timm/vit_relpos_base_patch16_rpn_224.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_large_r50_s32_224 author::timm task::computer_vision
+# labels: name::vit_relpos_base_patch16_rpn_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_large_r50_s32_224", pretrained = False)
+model = timm.create_model("vit_relpos_base_patch16_rpn_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_large_r50_s32_224_in21k.py` & `mlagility-3.1.1/models/timm/vit_relpos_base_patch16_clsgap_224.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_large_r50_s32_224_in21k author::timm task::computer_vision
+# labels: name::vit_relpos_base_patch16_clsgap_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_large_r50_s32_224_in21k", pretrained = False)
+model = timm.create_model("vit_relpos_base_patch16_clsgap_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_large_r50_s32_384.py` & `mlagility-3.1.1/models/timm/xcit_medium_24_p8_224_dist.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_large_r50_s32_384 author::timm task::computer_vision
+# labels: name::xcit_medium_24_p8_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_large_r50_s32_384", pretrained = False)
+model = timm.create_model("xcit_medium_24_p8_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_relpos_base_patch16_224.py` & `mlagility-3.1.1/models/timm/vit_relpos_medium_patch16_rpn_224.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_relpos_base_patch16_224 author::timm task::computer_vision
+# labels: name::vit_relpos_medium_patch16_rpn_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_relpos_base_patch16_224", pretrained = False)
+model = timm.create_model("vit_relpos_medium_patch16_rpn_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_relpos_base_patch16_cls_224.py` & `mlagility-3.1.1/models/timm/xcit_nano_12_p16_384_dist.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_relpos_base_patch16_cls_224 author::timm task::computer_vision
+# labels: name::xcit_nano_12_p16_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_relpos_base_patch16_cls_224", pretrained = False)
+model = timm.create_model("xcit_nano_12_p16_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_relpos_base_patch16_clsgap_224.py` & `mlagility-3.1.1/models/timm/vit_srelpos_small_patch16_224.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_relpos_base_patch16_clsgap_224 author::timm task::computer_vision
+# labels: name::vit_srelpos_small_patch16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_relpos_base_patch16_clsgap_224", pretrained = False)
+model = timm.create_model("vit_srelpos_small_patch16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_relpos_medium_patch16_cls_224.py` & `mlagility-3.1.1/models/timm/xcit_nano_12_p8_384_dist.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_relpos_medium_patch16_cls_224 author::timm task::computer_vision
+# labels: name::xcit_nano_12_p8_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_relpos_medium_patch16_cls_224", pretrained = False)
+model = timm.create_model("xcit_nano_12_p8_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_relpos_small_patch16_224.py` & `mlagility-3.1.1/models/timm/xcit_small_12_p16_224_dist.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_relpos_small_patch16_224 author::timm task::computer_vision
+# labels: name::xcit_small_12_p16_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_relpos_small_patch16_224", pretrained = False)
+model = timm.create_model("xcit_small_12_p16_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_relpos_small_patch16_rpn_224.py` & `mlagility-3.1.1/models/timm/efficientnet_cc_b0_8e.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_relpos_small_patch16_rpn_224 author::timm task::computer_vision
+# labels: name::efficientnet_cc_b0_8e author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_relpos_small_patch16_rpn_224", pretrained = False)
+model = timm.create_model("efficientnet_cc_b0_8e", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_patch16_18x2_224.py` & `mlagility-3.1.1/models/timm/vit_small_resnet50d_s16_224.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_patch16_18x2_224 author::timm task::computer_vision
+# labels: name::vit_small_resnet50d_s16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_patch16_18x2_224", pretrained = False)
+model = timm.create_model("vit_small_resnet50d_s16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_patch16_224.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b4.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_patch16_224 author::timm task::computer_vision
+# labels: name::tf_efficientnet_b4 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_patch16_224", pretrained = False)
+model = timm.create_model("tf_efficientnet_b4", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_patch16_224_dino.py` & `mlagility-3.1.1/models/timm/cs3darknet_focus_m.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_patch16_224_dino author::timm task::computer_vision
+# labels: name::cs3darknet_focus_m author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_patch16_224_dino", pretrained = False)
+model = timm.create_model("cs3darknet_focus_m", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_patch16_224_in21k.py` & `mlagility-3.1.1/models/timm/tf_efficientnetv2_xl_in21k.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_patch16_224_in21k author::timm task::computer_vision
+# labels: name::tf_efficientnetv2_xl_in21k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_patch16_224_in21k", pretrained = False)
+model = timm.create_model("tf_efficientnetv2_xl_in21k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_patch16_36x1_224.py` & `mlagility-3.1.1/models/timm/gluon_resnet101_v1b.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_patch16_36x1_224 author::timm task::computer_vision
+# labels: name::gluon_resnet101_v1b author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_patch16_36x1_224", pretrained = False)
+model = timm.create_model("gluon_resnet101_v1b", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_patch16_384.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b0_ap.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_patch16_384 author::timm task::computer_vision
+# labels: name::tf_efficientnet_b0_ap author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_patch16_384", pretrained = False)
+model = timm.create_model("tf_efficientnet_b0_ap", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_patch32_224.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b7_ap.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_patch32_224 author::timm task::computer_vision
+# labels: name::tf_efficientnet_b7_ap author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_patch32_224", pretrained = False)
+model = timm.create_model("tf_efficientnet_b7_ap", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_patch32_224_in21k.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b5_ap.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_patch32_224_in21k author::timm task::computer_vision
+# labels: name::tf_efficientnet_b5_ap author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_patch32_224_in21k", pretrained = False)
+model = timm.create_model("tf_efficientnet_b5_ap", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_patch32_384.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b1_ns.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_patch32_384 author::timm task::computer_vision
+# labels: name::tf_efficientnet_b1_ns author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_patch32_384", pretrained = False)
+model = timm.create_model("tf_efficientnet_b1_ns", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_patch8_224_dino.py` & `mlagility-3.1.1/models/timm/tf_mobilenetv3_small_075.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_patch8_224_dino author::timm task::computer_vision
+# labels: name::tf_mobilenetv3_small_075 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_patch8_224_dino", pretrained = False)
+model = timm.create_model("tf_mobilenetv3_small_075", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_r26_s32_224.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b2_ap.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_r26_s32_224 author::timm task::computer_vision
+# labels: name::tf_efficientnet_b2_ap author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_r26_s32_224", pretrained = False)
+model = timm.create_model("tf_efficientnet_b2_ap", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_r26_s32_224_in21k.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_cc_b0_4e.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_r26_s32_224_in21k author::timm task::computer_vision
+# labels: name::tf_efficientnet_cc_b0_4e author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_r26_s32_224_in21k", pretrained = False)
+model = timm.create_model("tf_efficientnet_cc_b0_4e", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_r26_s32_384.py` & `mlagility-3.1.1/models/torchvision/fasterrcnn_resnet50_fpn.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,19 +1,26 @@
-# labels: name::vit_small_r26_s32_384 author::timm task::computer_vision
-import torch
-import timm
+# labels: test_group::mlagility name::fasterrcnn_resnet50_fpn author::torchvision task::Computer_Vision
+"""
+https://pytorch.org/vision/stable/models/faster_rcnn.html
+"""
+
 from mlagility.parser import parse
+import torch
+from torchvision.models.detection import fasterrcnn_resnet50_fpn
+
+
+torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size = parse(["batch_size"])
+batch_size, num_channels, width, height = parse(
+    ["batch_size", "num_channels", "width", "height"]
+)
+
 
-# Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_r26_s32_384", pretrained = False)
+# Model and input configurations
+model = fasterrcnn_resnet50_fpn()
 model.eval()
+inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
 
-# Creating inputs
-input_size = model.default_cfg["input_size"]
-batched_input_size = tuple(batch_size) + input_size
-inputs = torch.rand(batched_input_size)
 
-# Calling model
-model(inputs)
+# Call model
+model(**inputs)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_resnet26d_224.py` & `mlagility-3.1.1/models/timm/legacy_seresnet50.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_resnet26d_224 author::timm task::computer_vision
+# labels: name::legacy_seresnet50 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_resnet26d_224", pretrained = False)
+model = timm.create_model("legacy_seresnet50", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_small_resnet50d_s16_224.py` & `mlagility-3.1.1/models/timm/gluon_resnet101_v1c.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_small_resnet50d_s16_224 author::timm task::computer_vision
+# labels: name::gluon_resnet101_v1c author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_small_resnet50d_s16_224", pretrained = False)
+model = timm.create_model("gluon_resnet101_v1c", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_srelpos_small_patch16_224.py` & `mlagility-3.1.1/models/timm/xcit_nano_12_p16_224.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_srelpos_small_patch16_224 author::timm task::computer_vision
+# labels: name::xcit_nano_12_p16_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_srelpos_small_patch16_224", pretrained = False)
+model = timm.create_model("xcit_nano_12_p16_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_tiny_patch16_384.py` & `mlagility-3.1.1/models/timm/vit_tiny_r_s16_p8_384.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_tiny_patch16_384 author::timm task::computer_vision
+# labels: name::vit_tiny_r_s16_p8_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_tiny_patch16_384", pretrained = False)
+model = timm.create_model("vit_tiny_r_s16_p8_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_tiny_r_s16_p8_224.py` & `mlagility-3.1.1/models/timm/lambda_resnet26rpt_256.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_tiny_r_s16_p8_224 author::timm task::computer_vision
+# labels: name::lambda_resnet26rpt_256 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_tiny_r_s16_p8_224", pretrained = False)
+model = timm.create_model("lambda_resnet26rpt_256", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_tiny_r_s16_p8_224_in21k.py` & `mlagility-3.1.1/models/timm/swinv2_cr_giant_224.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::vit_tiny_r_s16_p8_224_in21k author::timm task::computer_vision
+# labels: name::swinv2_cr_giant_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("vit_tiny_r_s16_p8_224_in21k", pretrained = False)
+model = timm.create_model("swinv2_cr_giant_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/vit_tiny_r_s16_p8_384.py` & `mlagility-3.1.1/models/torch_hub/convnext_tiny.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,19 +1,24 @@
-# labels: name::vit_tiny_r_s16_p8_384 author::timm task::computer_vision
-import torch
-import timm
+# labels: test_group::mlagility name::convnext_tiny author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
+import torch
+
+torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size = parse(["batch_size"])
+batch_size, num_channels, width, height = parse(
+    ["batch_size", "num_channels", "width", "height"]
+)
+
 
-# Creating model and set it to evaluation mode
-model = timm.create_model("vit_tiny_r_s16_p8_384", pretrained = False)
+# Model and input configurations
+model = torch.hub.load(
+    "pytorch/vision:v0.13.1",
+    "convnext_tiny",
+    weights=None,
+)
 model.eval()
+inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
-# Creating inputs
-input_size = model.default_cfg["input_size"]
-batched_input_size = tuple(batch_size) + input_size
-inputs = torch.rand(batched_input_size)
 
-# Calling model
-model(inputs)
+# Call model
+model(**inputs)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_large_24_p16_224.py` & `mlagility-3.1.1/models/timm/tf_mobilenetv3_large_100.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_large_24_p16_224 author::timm task::computer_vision
+# labels: name::tf_mobilenetv3_large_100 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_large_24_p16_224", pretrained = False)
+model = timm.create_model("tf_mobilenetv3_large_100", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_large_24_p16_224_dist.py` & `mlagility-3.1.1/models/timm/xcit_nano_12_p16_224_dist.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_large_24_p16_224_dist author::timm task::computer_vision
+# labels: name::xcit_nano_12_p16_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_large_24_p16_224_dist", pretrained = False)
+model = timm.create_model("xcit_nano_12_p16_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_large_24_p8_224.py` & `mlagility-3.1.1/models/timm/xcit_nano_12_p8_224.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_large_24_p8_224 author::timm task::computer_vision
+# labels: name::xcit_nano_12_p8_224 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_large_24_p8_224", pretrained = False)
+model = timm.create_model("xcit_nano_12_p8_224", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_large_24_p8_224_dist.py` & `mlagility-3.1.1/models/timm/xcit_nano_12_p8_224_dist.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_large_24_p8_224_dist author::timm task::computer_vision
+# labels: name::xcit_nano_12_p8_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_large_24_p8_224_dist", pretrained = False)
+model = timm.create_model("xcit_nano_12_p8_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_large_24_p8_384_dist.py` & `mlagility-3.1.1/models/timm/xcit_tiny_12_p8_384_dist.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_large_24_p8_384_dist author::timm task::computer_vision
+# labels: name::xcit_tiny_12_p8_384_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_large_24_p8_384_dist", pretrained = False)
+model = timm.create_model("xcit_tiny_12_p8_384_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_medium_24_p16_224.py` & `mlagility-3.1.1/models/timm/seresnext101_32x4d.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_medium_24_p16_224 author::timm task::computer_vision
+# labels: name::seresnext101_32x4d author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_medium_24_p16_224", pretrained = False)
+model = timm.create_model("seresnext101_32x4d", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_medium_24_p16_384_dist.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b7_ns.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_medium_24_p16_384_dist author::timm task::computer_vision
+# labels: name::tf_efficientnet_b7_ns author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_medium_24_p16_384_dist", pretrained = False)
+model = timm.create_model("tf_efficientnet_b7_ns", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_medium_24_p8_224.py` & `mlagility-3.1.1/models/timm/swinv2_cr_giant_384.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_medium_24_p8_224 author::timm task::computer_vision
+# labels: name::swinv2_cr_giant_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_medium_24_p8_224", pretrained = False)
+model = timm.create_model("swinv2_cr_giant_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_medium_24_p8_384_dist.py` & `mlagility-3.1.1/models/torch_hub/swin_b.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,19 +1,24 @@
-# labels: name::xcit_medium_24_p8_384_dist author::timm task::computer_vision
-import torch
-import timm
+# labels: test_group::mlagility name::swin_b author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
+import torch
+
+torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size = parse(["batch_size"])
+batch_size, num_channels, width, height = parse(
+    ["batch_size", "num_channels", "width", "height"]
+)
+
 
-# Creating model and set it to evaluation mode
-model = timm.create_model("xcit_medium_24_p8_384_dist", pretrained = False)
+# Model and input configurations
+model = torch.hub.load(
+    "pytorch/vision:v0.13.1",
+    "swin_b",
+    weights=None,
+)
 model.eval()
+inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
-# Creating inputs
-input_size = model.default_cfg["input_size"]
-batched_input_size = tuple(batch_size) + input_size
-inputs = torch.rand(batched_input_size)
 
-# Calling model
-model(inputs)
+# Call model
+model(**inputs)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_small_12_p16_224.py` & `mlagility-3.1.1/models/timm/efficientnet_cc_b1_8e.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_small_12_p16_224 author::timm task::computer_vision
+# labels: name::efficientnet_cc_b1_8e author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_small_12_p16_224", pretrained = False)
+model = timm.create_model("efficientnet_cc_b1_8e", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_small_12_p8_224.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b1_ap.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_small_12_p8_224 author::timm task::computer_vision
+# labels: name::tf_efficientnet_b1_ap author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_small_12_p8_224", pretrained = False)
+model = timm.create_model("tf_efficientnet_b1_ap", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_small_12_p8_224_dist.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b3_ap.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_small_12_p8_224_dist author::timm task::computer_vision
+# labels: name::tf_efficientnet_b3_ap author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_small_12_p8_224_dist", pretrained = False)
+model = timm.create_model("tf_efficientnet_b3_ap", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_small_12_p8_384_dist.py` & `mlagility-3.1.1/models/timm/xcit_small_12_p8_224_dist.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_small_12_p8_384_dist author::timm task::computer_vision
+# labels: name::xcit_small_12_p8_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_small_12_p8_384_dist", pretrained = False)
+model = timm.create_model("xcit_small_12_p8_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_small_24_p16_224.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_l2_ns.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_small_24_p16_224 author::timm task::computer_vision
+# labels: name::tf_efficientnet_l2_ns author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_small_24_p16_224", pretrained = False)
+model = timm.create_model("tf_efficientnet_l2_ns", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_small_24_p16_224_dist.py` & `mlagility-3.1.1/models/timm/gluon_resnet50_v1b.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_small_24_p16_224_dist author::timm task::computer_vision
+# labels: name::gluon_resnet50_v1b author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_small_24_p16_224_dist", pretrained = False)
+model = timm.create_model("gluon_resnet50_v1b", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_small_24_p16_384_dist.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_b0_ns.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_small_24_p16_384_dist author::timm task::computer_vision
+# labels: name::tf_efficientnet_b0_ns author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_small_24_p16_384_dist", pretrained = False)
+model = timm.create_model("tf_efficientnet_b0_ns", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_small_24_p8_384_dist.py` & `mlagility-3.1.1/models/timm/efficientnet_b0_gn.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_small_24_p8_384_dist author::timm task::computer_vision
+# labels: name::efficientnet_b0_gn author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_small_24_p8_384_dist", pretrained = False)
+model = timm.create_model("efficientnet_b0_gn", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_tiny_12_p16_224_dist.py` & `mlagility-3.1.1/models/timm/xcit_tiny_12_p16_224_dist.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: name::xcit_tiny_12_p16_224_dist author::timm task::computer_vision
+# labels: name::xcit_tiny_12_p16_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
```

### Comparing `mlagility-3.0.2/models/timm/xcit_tiny_12_p16_384_dist.py` & `mlagility-3.1.1/models/timm/xcit_tiny_12_p8_224_dist.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_tiny_12_p16_384_dist author::timm task::computer_vision
+# labels: name::xcit_tiny_12_p8_224_dist author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_tiny_12_p16_384_dist", pretrained = False)
+model = timm.create_model("xcit_tiny_12_p8_224_dist", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_tiny_12_p8_224_dist.py` & `mlagility-3.1.1/models/timm/mobilevitv2_200_in22ft1k.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_tiny_12_p8_224_dist author::timm task::computer_vision
+# labels: name::mobilevitv2_200_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_tiny_12_p8_224_dist", pretrained = False)
+model = timm.create_model("mobilevitv2_200_in22ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_tiny_12_p8_384_dist.py` & `mlagility-3.1.1/models/timm/convnext_tiny_384_in22ft1k.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_tiny_12_p8_384_dist author::timm task::computer_vision
+# labels: name::convnext_tiny_384_in22ft1k author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_tiny_12_p8_384_dist", pretrained = False)
+model = timm.create_model("convnext_tiny_384_in22ft1k", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_tiny_24_p16_224.py` & `mlagility-3.1.1/models/timm/tf_efficientnet_lite1.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_tiny_24_p16_224 author::timm task::computer_vision
+# labels: name::tf_efficientnet_lite1 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_tiny_24_p16_224", pretrained = False)
+model = timm.create_model("tf_efficientnet_lite1", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_tiny_24_p16_224_dist.py` & `mlagility-3.1.1/models/timm/swinv2_cr_large_384.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_tiny_24_p16_224_dist author::timm task::computer_vision
+# labels: name::swinv2_cr_large_384 author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_tiny_24_p16_224_dist", pretrained = False)
+model = timm.create_model("swinv2_cr_large_384", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/timm/xcit_tiny_24_p8_224.py` & `mlagility-3.1.1/models/timm/gluon_resnet152_v1c.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# labels: name::xcit_tiny_24_p8_224 author::timm task::computer_vision
+# labels: name::gluon_resnet152_v1c author::timm task::Computer_Vision
 import torch
 import timm
 from mlagility.parser import parse
 
 # Parsing command-line arguments
 batch_size = parse(["batch_size"])
 
 # Creating model and set it to evaluation mode
-model = timm.create_model("xcit_tiny_24_p8_224", pretrained = False)
+model = timm.create_model("gluon_resnet152_v1c", pretrained = False)
 model.eval()
 
 # Creating inputs
 input_size = model.default_cfg["input_size"]
 batched_input_size = tuple(batch_size) + input_size
 inputs = torch.rand(batched_input_size)
```

### Comparing `mlagility-3.0.2/models/torch_hub/alexnet.py` & `mlagility-3.1.1/models/torch_hub/alexnet.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::alexnet author::torch_hub
+# labels: test_group::mlagility name::alexnet author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_alexnet.md
 """
 
 from mlagility.parser import parse
 import torch
```

### Comparing `mlagility-3.0.2/models/torch_hub/convnext_base.py` & `mlagility-3.1.1/models/torch_hub/vit_l_16.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# labels: test_group::mlagility name::convnext_base author::torch_hub
+# labels: test_group::mlagility name::vit_l_16 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "convnext_base",
+    "vit_l_16",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/convnext_large.py` & `mlagility-3.1.1/models/torch_hub/densenet161.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::convnext_large author::torch_hub
+# labels: test_group::mlagility name::densenet161 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_densenet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "convnext_large",
+    "densenet161",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/convnext_small.py` & `mlagility-3.1.1/models/torch_hub/vgg19.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::convnext_small author::torch_hub
+# labels: test_group::mlagility name::vgg19 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "convnext_small",
+    "vgg19",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/convnext_tiny.py` & `mlagility-3.1.1/models/torch_hub/vgg13_bn.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::convnext_tiny author::torch_hub
+# labels: test_group::mlagility name::vgg13_bn author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "convnext_tiny",
+    "vgg13_bn",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/densenet121.py` & `mlagility-3.1.1/models/torch_hub/vgg13.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::densenet121 author::torch_hub
+# labels: test_group::mlagility name::vgg13 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_densenet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "densenet121",
+    "vgg13",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/densenet161.py` & `mlagility-3.1.1/models/torch_hub/densenet169.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::densenet161 author::torch_hub
+# labels: test_group::mlagility name::densenet169 author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_densenet.md
 """
 
 from mlagility.parser import parse
 import torch
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "densenet161",
+    "densenet169",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/densenet169.py` & `mlagility-3.1.1/models/torch_hub/densenet201.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::densenet169 author::torch_hub
+# labels: test_group::mlagility name::densenet201 author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_densenet.md
 """
 
 from mlagility.parser import parse
 import torch
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "densenet169",
+    "densenet201",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/densenet201.py` & `mlagility-3.1.1/models/torch_hub/densenet121.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::densenet201 author::torch_hub
+# labels: test_group::mlagility name::densenet121 author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_densenet.md
 """
 
 from mlagility.parser import parse
 import torch
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "densenet201",
+    "densenet121",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_b0.py` & `mlagility-3.1.1/models/torch_hub/vgg11_bn.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::efficientnet_b0 author::torch_hub
+# labels: test_group::mlagility name::vgg11_bn author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "efficientnet_b0",
+    "vgg11_bn",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_b1.py` & `mlagility-3.1.1/models/torch_hub/resnet34.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::efficientnet_b1 author::torch_hub
+# labels: test_group::mlagility name::resnet34 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "efficientnet_b1",
+    "resnet34",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_b2.py` & `mlagility-3.1.1/models/torch_hub/proxyless_cpu.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::efficientnet_b2 author::torch_hub
+# labels: test_group::mlagility name::proxyless_cpu author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_proxylessnas.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "efficientnet_b2",
+    "mit-han-lab/ProxylessNAS",
+    "proxyless_cpu",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_b3.py` & `mlagility-3.1.1/models/torch_hub/vgg16_bn.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::efficientnet_b3 author::torch_hub
+# labels: test_group::mlagility name::vgg16_bn author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "efficientnet_b3",
+    "vgg16_bn",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_b4.py` & `mlagility-3.1.1/models/torch_hub/resnet50.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::efficientnet_b4 author::torch_hub
+# labels: test_group::mlagility name::resnet50 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "efficientnet_b4",
+    "resnet50",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_b5.py` & `mlagility-3.1.1/models/torch_hub/googlenet.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::efficientnet_b5 author::torch_hub
+# labels: test_group::mlagility name::googlenet author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_googlenet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "efficientnet_b5",
+    "googlenet",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_b6.py` & `mlagility-3.1.1/models/torch_hub/squeezenet1_0.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::efficientnet_b6 author::torch_hub
+# labels: test_group::mlagility name::squeezenet1_0 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_squeezenet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "efficientnet_b6",
+    "squeezenet1_0",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_b7.py` & `mlagility-3.1.1/models/torch_hub/resnet152.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::efficientnet_b7 author::torch_hub
+# labels: test_group::mlagility name::resnet152 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "efficientnet_b7",
+    "resnet152",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_v2_l.py` & `mlagility-3.1.1/models/torch_hub/resnet18.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::efficientnet_v2_l author::torch_hub
+# labels: test_group::mlagility name::resnet18 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "efficientnet_v2_l",
+    "resnet18",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_v2_m.py` & `mlagility-3.1.1/models/torch_hub/mealv2_mobilenetv3_small_100.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,23 +1,28 @@
-# labels: test_group::mlagility name::efficientnet_v2_m author::torch_hub
+# labels: test_group::mlagility name::mealv2_mobilenetv3_small_100 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "efficientnet_v2_m",
+    "szq0214/MEAL-V2",
+    "meal_v2",
+    "mealv2_mobilenetv3_small_100",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/efficientnet_v2_s.py` & `mlagility-3.1.1/models/torch_hub/vit_b_16.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# labels: test_group::mlagility name::efficientnet_v2_s author::torch_hub
+# labels: test_group::mlagility name::vit_b_16 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "efficientnet_v2_s",
+    "vit_b_16",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/ghostnet.py` & `mlagility-3.1.1/models/torch_hub/hardnet68.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::ghostnet author::torch_hub
+# labels: test_group::mlagility name::hardnet68 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ghostnet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_hardnet.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "huawei-noah/ghostnet",
-    "ghostnet",
+    "PingoLH/Pytorch-HarDNet",
+    "hardnet68",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/ghostnet_1x.py` & `mlagility-3.1.1/models/torch_hub/hardnet39ds.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::ghostnet_1x author::torch_hub
+# labels: test_group::mlagility name::hardnet39ds author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ghostnet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_hardnet.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "huawei-noah/ghostnet",
-    "ghostnet_1x",
+    "PingoLH/Pytorch-HarDNet",
+    "hardnet39ds",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/googlenet.py` & `mlagility-3.1.1/models/torch_hub/inception_v3.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::googlenet author::torch_hub
+# labels: test_group::mlagility name::inception_v3 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_googlenet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_inception_v3.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "googlenet",
+    "inception_v3",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/hardnet39ds.py` & `mlagility-3.1.1/models/torch_hub/mealv2_efficientnet_b0.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::hardnet39ds author::torch_hub
+# labels: test_group::mlagility name::mealv2_efficientnet_b0 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_hardnet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,17 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "PingoLH/Pytorch-HarDNet",
-    "hardnet39ds",
+    "szq0214/MEAL-V2",
+    "meal_v2",
+    "mealv2_efficientnet_b0",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/hardnet68.py` & `mlagility-3.1.1/models/transformers/deit.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# labels: test_group::mlagility name::hardnet68 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_hardnet.md
-"""
-
+# labels: test_group::mlagility name::deit author::transformers task::Computer_Vision
 from mlagility.parser import parse
+import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "PingoLH/Pytorch-HarDNet",
-    "hardnet68",
-    weights=None,
-)
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+config = transformers.DeiTConfig()
+model = transformers.DeiTModel(config)
+inputs = {
+    "pixel_values": torch.ones(
+        batch_size, num_channels, height, width, dtype=torch.float
+    ),
+}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/hardnet68ds.py` & `mlagility-3.1.1/models/transformers/beit.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# labels: test_group::mlagility name::hardnet68ds author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_hardnet.md
-"""
-
+# labels: test_group::mlagility name::beit author::transformers task::Computer_Vision
 from mlagility.parser import parse
+import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "PingoLH/Pytorch-HarDNet",
-    "hardnet68ds",
-    weights=None,
-)
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+config = transformers.BeitConfig()
+model = transformers.BeitModel(config)
+inputs = {
+    "pixel_values": torch.ones(
+        batch_size, num_channels, height, width, dtype=torch.float
+    ),
+}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/hardnet85.py` & `mlagility-3.1.1/models/torch_hub/ghostnet_1x.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::hardnet85 author::torch_hub
+# labels: test_group::mlagility name::ghostnet_1x author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_hardnet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ghostnet.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "PingoLH/Pytorch-HarDNet",
-    "hardnet85",
+    "huawei-noah/ghostnet",
+    "ghostnet_1x",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/inception_v3.py` & `mlagility-3.1.1/models/torch_hub/vgg19_bn.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::inception_v3 author::torch_hub
+# labels: test_group::mlagility name::vgg19_bn author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_inception_v3.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "inception_v3",
+    "vgg19_bn",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/mealv1_resnest50.py` & `mlagility-3.1.1/models/torch_hub/mealv1_resnest50.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::mealv1_resnest50 author::torch_hub
+# labels: test_group::mlagility name::mealv1_resnest50 author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
 """
 
 from mlagility.parser import parse
 import torch
```

### Comparing `mlagility-3.0.2/models/torch_hub/mealv2_efficientnet_b0.py` & `mlagility-3.1.1/models/torch_hub/wide_resnet50_2.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::mealv2_efficientnet_b0 author::torch_hub
+# labels: test_group::mlagility name::wide_resnet50_2 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_wide_resnet.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,17 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "szq0214/MEAL-V2",
-    "meal_v2",
-    "mealv2_efficientnet_b0",
+    "pytorch/vision:v0.13.1",
+    "wide_resnet50_2",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/mealv2_mobilenet_v3_large_100.py` & `mlagility-3.1.1/models/torch_hub/ghostnet.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::mealv2_mobilenet_v3_large_100 author::torch_hub
+# labels: test_group::mlagility name::ghostnet author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ghostnet.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,17 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "szq0214/MEAL-V2",
-    "meal_v2",
-    "mealv2_mobilenet_v3_large_100",
+    "huawei-noah/ghostnet",
+    "ghostnet",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/mealv2_mobilenetv3_small_075.py` & `mlagility-3.1.1/models/torch_hub/midas_v3_large.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,29 +1,21 @@
-# labels: test_group::mlagility name::mealv2_mobilenetv3_small_075 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
-"""
-
+# labels: test_group::mlagility name::midas_v3_large author::torch_hub task::Computer_Vision
+"""https://pytorch.org/hub/intelisl_midas_v2/"""
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "szq0214/MEAL-V2",
-    "meal_v2",
-    "mealv2_mobilenetv3_small_075",
-    weights=None,
-)
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+model = torch.hub.load("intel-isl/MiDaS", "DPT_Large")
+
+inputs = {"x": torch.ones(batch_size, num_channels, height, width, dtype=torch.float)}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/mealv2_mobilenetv3_small_100.py` & `mlagility-3.1.1/models/torch_hub/unet.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,29 +1,26 @@
-# labels: test_group::mlagility name::mealv2_mobilenetv3_small_100 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
-"""
-
+# labels: test_group::mlagility name::unet author::torch_hub task::Computer_Vision
+"""https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/"""
 from mlagility.parser import parse
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "szq0214/MEAL-V2",
-    "meal_v2",
-    "mealv2_mobilenetv3_small_100",
-    weights=None,
+    "mateuszbuda/brain-segmentation-pytorch",
+    "unet",
+    in_channels=3,
+    out_channels=1,
+    init_features=32,
+    pretrained=True,
 )
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+
+inputs = {"x": torch.ones(batch_size, num_channels, height, width, dtype=torch.float)}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/mealv2_resnest50.py` & `mlagility-3.1.1/models/torch_hub/resnest50.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::mealv2_resnest50 author::torch_hub
+# labels: test_group::mlagility name::resnest50 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,17 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "szq0214/MEAL-V2",
-    "meal_v2",
-    "mealv2_resnest50",
+    "zhanghang1989/ResNeSt",
+    "resnest50",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/mealv2_resnest50_380x380.py` & `mlagility-3.1.1/models/torch_hub/resnet50_ibn_a.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::mealv2_resnest50_380x380 author::torch_hub
+# labels: test_group::mlagility name::resnet50_ibn_a author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,17 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "szq0214/MEAL-V2",
-    "meal_v2",
-    "mealv2_resnest50_380x380",
+    "XingangPan/IBN-Net",
+    "resnet50_ibn_a",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/mealv2_resnest50_cutmix.py` & `mlagility-3.1.1/models/torch_hub/mobilenet_v3_small.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,28 +1,23 @@
-# labels: test_group::mlagility name::mealv2_resnest50_cutmix author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
-"""
-
+# labels: test_group::mlagility name::mobilenet_v3_small author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "szq0214/MEAL-V2",
-    "meal_v2",
-    "mealv2_resnest50_cutmix",
+    "pytorch/vision:v0.13.1",
+    "mobilenet_v3_small",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/midas_v2.1_small.py` & `mlagility-3.1.1/models/torch_hub/regnet_x_1_6gf.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,21 +1,24 @@
-# labels: test_group::mlagility name::midas_v2.1_small author::torch_hub
-"""https://pytorch.org/hub/intelisl_midas_v2/"""
+# labels: test_group::mlagility name::regnet_x_1_6gf author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, height, num_channels, width = parse(
-    ["batch_size", "height", "num_channels", "width"]
+batch_size, num_channels, width, height = parse(
+    ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load("intel-isl/MiDaS", "MiDaS_small")
-
-inputs = {"x": torch.ones(batch_size, num_channels, height, width, dtype=torch.float)}
+model = torch.hub.load(
+    "pytorch/vision:v0.13.1",
+    "regnet_x_1_6gf",
+    weights=None,
+)
+model.eval()
+inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/midas_v3_hybrid.py` & `mlagility-3.1.1/models/torch_hub/midas_v3_hybrid.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::midas_v3_hybrid author::torch_hub
+# labels: test_group::mlagility name::midas_v3_hybrid author::torch_hub task::Computer_Vision
 """https://pytorch.org/hub/intelisl_midas_v2/"""
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/torch_hub/midas_v3_large.py` & `mlagility-3.1.1/models/torch_hub/regnet_y_1_6gf.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,21 +1,24 @@
-# labels: test_group::mlagility name::midas_v3_large author::torch_hub
-"""https://pytorch.org/hub/intelisl_midas_v2/"""
+# labels: test_group::mlagility name::regnet_y_1_6gf author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, height, num_channels, width = parse(
-    ["batch_size", "height", "num_channels", "width"]
+batch_size, num_channels, width, height = parse(
+    ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load("intel-isl/MiDaS", "DPT_Large")
-
-inputs = {"x": torch.ones(batch_size, num_channels, height, width, dtype=torch.float)}
+model = torch.hub.load(
+    "pytorch/vision:v0.13.1",
+    "regnet_y_1_6gf",
+    weights=None,
+)
+model.eval()
+inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/mnasnet0_5.py` & `mlagility-3.1.1/models/torch_hub/mnasnet0_5.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::mnasnet0_5 author::torch_hub
+# labels: test_group::mlagility name::mnasnet0_5 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
```

### Comparing `mlagility-3.0.2/models/torch_hub/mnasnet0_75.py` & `mlagility-3.1.1/models/torch_hub/mnasnet0_75.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::mnasnet0_75 author::torch_hub
+# labels: test_group::mlagility name::mnasnet0_75 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
```

### Comparing `mlagility-3.0.2/models/torch_hub/mnasnet1_0.py` & `mlagility-3.1.1/models/torch_hub/convnext_small.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# labels: test_group::mlagility name::mnasnet1_0 author::torch_hub
+# labels: test_group::mlagility name::convnext_small author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "mnasnet1_0",
+    "convnext_small",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/mnasnet1_3.py` & `mlagility-3.1.1/models/torch_hub/mealv2_resnest50_cutmix.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,23 +1,28 @@
-# labels: test_group::mlagility name::mnasnet1_3 author::torch_hub
+# labels: test_group::mlagility name::mealv2_resnest50_cutmix author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "mnasnet1_3",
+    "szq0214/MEAL-V2",
+    "meal_v2",
+    "mealv2_resnest50_cutmix",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/mobilenet_v2.py` & `mlagility-3.1.1/models/torch_hub/shufflenet_v2_x0_5.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::mobilenet_v2 author::torch_hub
+# labels: test_group::mlagility name::shufflenet_v2_x0_5 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_mobilenet_v2.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_shufflenet_v2.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "mobilenet_v2",
+    "shufflenet_v2_x0_5",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/mobilenet_v3_large.py` & `mlagility-3.1.1/models/torch_hub/convnext_large.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# labels: test_group::mlagility name::mobilenet_v3_large author::torch_hub
+# labels: test_group::mlagility name::convnext_large author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "mobilenet_v3_large",
+    "convnext_large",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/mobilenet_v3_small.py` & `mlagility-3.1.1/models/torch_hub/regnet_y_800mf.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# labels: test_group::mlagility name::mobilenet_v3_small author::torch_hub
+# labels: test_group::mlagility name::regnet_y_800mf author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "mobilenet_v3_small",
+    "regnet_y_800mf",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/proxyless_cpu.py` & `mlagility-3.1.1/models/torch_hub/vgg16.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::proxyless_cpu author::torch_hub
+# labels: test_group::mlagility name::vgg16 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_proxylessnas.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "mit-han-lab/ProxylessNAS",
-    "proxyless_cpu",
+    "pytorch/vision:v0.13.1",
+    "vgg16",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/proxyless_gpu.py` & `mlagility-3.1.1/models/torch_hub/vgg11.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::proxyless_gpu author::torch_hub
+# labels: test_group::mlagility name::vgg11 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_proxylessnas.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "mit-han-lab/ProxylessNAS",
-    "proxyless_gpu",
+    "pytorch/vision:v0.13.1",
+    "vgg11",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/proxyless_mobile.py` & `mlagility-3.1.1/models/torch_hub/proxyless_mobile_14.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::proxyless_mobile author::torch_hub
+# labels: test_group::mlagility name::proxyless_mobile_14 author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_proxylessnas.md
 """
 
 from mlagility.parser import parse
 import torch
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "mit-han-lab/ProxylessNAS",
-    "proxyless_mobile",
+    "proxyless_mobile_14",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/proxyless_mobile_14.py` & `mlagility-3.1.1/models/torch_hub/proxyless_gpu.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::proxyless_mobile_14 author::torch_hub
+# labels: test_group::mlagility name::proxyless_gpu author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_proxylessnas.md
 """
 
 from mlagility.parser import parse
 import torch
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "mit-han-lab/ProxylessNAS",
-    "proxyless_mobile_14",
+    "proxyless_gpu",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_x_16gf.py` & `mlagility-3.1.1/models/torch_hub/resnet50_ibn_b.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_x_16gf author::torch_hub
+# labels: test_group::mlagility name::resnet50_ibn_b author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "regnet_x_16gf",
+    "XingangPan/IBN-Net",
+    "resnet50_ibn_b",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_x_1_6gf.py` & `mlagility-3.1.1/models/torch_hub/resnet101.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_x_1_6gf author::torch_hub
+# labels: test_group::mlagility name::resnet101 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "regnet_x_1_6gf",
+    "resnet101",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_x_32gf.py` & `mlagility-3.1.1/models/torch_hub/hardnet68ds.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_x_32gf author::torch_hub
+# labels: test_group::mlagility name::hardnet68ds author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_hardnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "regnet_x_32gf",
+    "PingoLH/Pytorch-HarDNet",
+    "hardnet68ds",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_x_3_2gf.py` & `mlagility-3.1.1/models/torch_hub/resnet34_ibn_b.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_x_3_2gf author::torch_hub
+# labels: test_group::mlagility name::resnet34_ibn_b author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "regnet_x_3_2gf",
+    "XingangPan/IBN-Net",
+    "resnet34_ibn_b",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_x_400mf.py` & `mlagility-3.1.1/models/torch_hub/resnet18_ibn_b.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_x_400mf author::torch_hub
+# labels: test_group::mlagility name::resnet18_ibn_b author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "regnet_x_400mf",
+    "XingangPan/IBN-Net",
+    "resnet18_ibn_b",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_x_800mf.py` & `mlagility-3.1.1/models/torch_hub/resnet101_ibn_b.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_x_800mf author::torch_hub
+# labels: test_group::mlagility name::resnet101_ibn_b author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "regnet_x_800mf",
+    "XingangPan/IBN-Net",
+    "resnet101_ibn_b",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_x_8gf.py` & `mlagility-3.1.1/models/torch_hub/hardnet85.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_x_8gf author::torch_hub
+# labels: test_group::mlagility name::hardnet85 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_hardnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "regnet_x_8gf",
+    "PingoLH/Pytorch-HarDNet",
+    "hardnet85",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_y_128gf.py` & `mlagility-3.1.1/models/torch_hub/resnet34_ibn_a.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_y_128gf author::torch_hub
+# labels: test_group::mlagility name::resnet34_ibn_a author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "regnet_y_128gf",
+    "XingangPan/IBN-Net",
+    "resnet34_ibn_a",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_y_16gf.py` & `mlagility-3.1.1/models/torch_hub/mobilenet_v2.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_y_16gf author::torch_hub
+# labels: test_group::mlagility name::mobilenet_v2 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_mobilenet_v2.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "regnet_y_16gf",
+    "mobilenet_v2",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_y_1_6gf.py` & `mlagility-3.1.1/models/torchvision/fcos_resnet50_fpn.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,24 +1,26 @@
-# labels: test_group::mlagility name::regnet_y_1_6gf author::torch_hub
+# labels: test_group::mlagility name::fcos_resnet50_fpn author::torchvision task::Computer_Vision
+"""
+https://pytorch.org/vision/stable/models/fcos.html
+"""
+
 from mlagility.parser import parse
 import torch
+from torchvision.models.detection import fcos_resnet50_fpn
+
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "regnet_y_1_6gf",
-    weights=None,
-)
+model = fcos_resnet50_fpn()
 model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_y_32gf.py` & `mlagility-3.1.1/models/torch_hub/resnet18_ibn_a.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_y_32gf author::torch_hub
+# labels: test_group::mlagility name::resnet18_ibn_a author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "regnet_y_32gf",
+    "XingangPan/IBN-Net",
+    "resnet18_ibn_a",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_y_3_2gf.py` & `mlagility-3.1.1/models/torch_hub/shufflenet_v2_x2_0.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_y_3_2gf author::torch_hub
+# labels: test_group::mlagility name::shufflenet_v2_x2_0 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_shufflenet_v2.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "regnet_y_3_2gf",
+    "shufflenet_v2_x2_0",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_y_400mf.py` & `mlagility-3.1.1/models/torch_hub/shufflenet_v2_x1_0.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_y_400mf author::torch_hub
+# labels: test_group::mlagility name::shufflenet_v2_x1_0 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_shufflenet_v2.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "regnet_y_400mf",
+    "shufflenet_v2_x1_0",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_y_800mf.py` & `mlagility-3.1.1/models/torch_hub/squeezenet1_1.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_y_800mf author::torch_hub
+# labels: test_group::mlagility name::squeezenet1_1 author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_squeezenet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "regnet_y_800mf",
+    "squeezenet1_1",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/regnet_y_8gf.py` & `mlagility-3.1.1/models/torch_hub/resnet101_ibn_a.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-# labels: test_group::mlagility name::regnet_y_8gf author::torch_hub
+# labels: test_group::mlagility name::resnet101_ibn_a author::torch_hub task::Computer_Vision
+"""
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+"""
+
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "regnet_y_8gf",
+    "XingangPan/IBN-Net",
+    "resnet101_ibn_a",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnest101.py` & `mlagility-3.1.1/models/torch_hub/resnest50_fast_1s4x24d.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::resnest101 author::torch_hub
+# labels: test_group::mlagility name::resnest50_fast_1s4x24d author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "zhanghang1989/ResNeSt",
-    "resnest101",
+    "resnest50_fast_1s4x24d",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnest200.py` & `mlagility-3.1.1/models/torch_hub/resnest50_fast_1s1x64d.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::resnest200 author::torch_hub
+# labels: test_group::mlagility name::resnest50_fast_1s1x64d author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "zhanghang1989/ResNeSt",
-    "resnest200",
+    "resnest50_fast_1s1x64d",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnest269.py` & `mlagility-3.1.1/models/torch_hub/se_resnet101_ibn_a.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::resnest269 author::torch_hub
+# labels: test_group::mlagility name::se_resnet101_ibn_a author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "zhanghang1989/ResNeSt",
-    "resnest269",
+    "XingangPan/IBN-Net",
+    "se_resnet101_ibn_a",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnest50_fast_1s1x64d.py` & `mlagility-3.1.1/models/torch_hub/resnest50_fast_2s1x64d.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::resnest50_fast_1s1x64d author::torch_hub
+# labels: test_group::mlagility name::resnest50_fast_2s1x64d author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "zhanghang1989/ResNeSt",
-    "resnest50_fast_1s1x64d",
+    "resnest50_fast_2s1x64d",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnest50_fast_1s2x40d.py` & `mlagility-3.1.1/models/torch_hub/wide_resnet101_2.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::resnest50_fast_1s2x40d author::torch_hub
+# labels: test_group::mlagility name::wide_resnet101_2 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_wide_resnet.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "zhanghang1989/ResNeSt",
-    "resnest50_fast_1s2x40d",
+    "pytorch/vision:v0.13.1",
+    "wide_resnet101_2",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnest50_fast_1s4x24d.py` & `mlagility-3.1.1/models/torch_hub/resnest50_fast_2s2x40d.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::resnest50_fast_1s4x24d author::torch_hub
+# labels: test_group::mlagility name::resnest50_fast_2s2x40d author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "zhanghang1989/ResNeSt",
-    "resnest50_fast_1s4x24d",
+    "resnest50_fast_2s2x40d",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnest50_fast_2s1x64d.py` & `mlagility-3.1.1/models/torch_hub/mealv2_resnest50_380x380.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::resnest50_fast_2s1x64d author::torch_hub
+# labels: test_group::mlagility name::mealv2_resnest50_380x380 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,17 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "zhanghang1989/ResNeSt",
-    "resnest50_fast_2s1x64d",
+    "szq0214/MEAL-V2",
+    "meal_v2",
+    "mealv2_resnest50_380x380",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnest50_fast_2s2x40d.py` & `mlagility-3.1.1/models/torchvision/maskrcnn_resnet50_fpn.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# labels: test_group::mlagility name::resnest50_fast_2s2x40d author::torch_hub
+# labels: test_group::mlagility name::maskrcnn_resnet50_fpn author::torchvision task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
+https://pytorch.org/vision/stable/models/mask_rcnn.html
 """
 
 from mlagility.parser import parse
 import torch
+from torchvision.models.detection import maskrcnn_resnet50_fpn
+
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "zhanghang1989/ResNeSt",
-    "resnest50_fast_2s2x40d",
-    weights=None,
-)
+model = maskrcnn_resnet50_fpn()
 model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnest50_fast_4s1x64d.py` & `mlagility-3.1.1/models/torch_hub/resnest50_fast_4s1x64d.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::resnest50_fast_4s1x64d author::torch_hub
+# labels: test_group::mlagility name::resnest50_fast_4s1x64d author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnest50_fast_4s2x40d.py` & `mlagility-3.1.1/models/torch_hub/resnest50_fast_4s2x40d.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::resnest50_fast_4s2x40d author::torch_hub
+# labels: test_group::mlagility name::resnest50_fast_4s2x40d author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet101.py` & `mlagility-3.1.1/models/torch_hub/resnext50_32x4d.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::resnet101 author::torch_hub
+# labels: test_group::mlagility name::resnext50_32x4d author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_resnet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnext.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "resnet101",
+    "resnext50_32x4d",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet101_ibn_a.py` & `mlagility-3.1.1/models/torch_hub/resnest50_fast_1s2x40d.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::resnet101_ibn_a author::torch_hub
+# labels: test_group::mlagility name::resnest50_fast_1s2x40d author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "XingangPan/IBN-Net",
-    "resnet101_ibn_a",
+    "zhanghang1989/ResNeSt",
+    "resnest50_fast_1s2x40d",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet101_ibn_b.py` & `mlagility-3.1.1/models/torch_hub/mealv2_resnest50.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::resnet101_ibn_b author::torch_hub
+# labels: test_group::mlagility name::mealv2_resnest50 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,17 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "XingangPan/IBN-Net",
-    "resnet101_ibn_b",
+    "szq0214/MEAL-V2",
+    "meal_v2",
+    "mealv2_resnest50",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet152.py` & `mlagility-3.1.1/models/torchvision/fasterrcnn_resnet50_fpn_v2.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# labels: test_group::mlagility name::resnet152 author::torch_hub
+# labels: test_group::mlagility name::fasterrcnn_resnet50_fpn_v2 author::torchvision task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_resnet.md
+https://pytorch.org/vision/stable/models/faster_rcnn.html
 """
 
 from mlagility.parser import parse
 import torch
+from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2
+
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "resnet152",
-    weights=None,
-)
+model = fasterrcnn_resnet50_fpn_v2()
 model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet18.py` & `mlagility-3.1.1/models/torchvision/maskrcnn_resnet50_fpn_v2.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# labels: test_group::mlagility name::resnet18 author::torch_hub
+# labels: test_group::mlagility name::maskrcnn_resnet50_fpn_v2 author::torchvision task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_resnet.md
+https://pytorch.org/vision/stable/models/mask_rcnn.html
 """
 
 from mlagility.parser import parse
 import torch
+from torchvision.models.detection import maskrcnn_resnet50_fpn_v2
+
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "resnet18",
-    weights=None,
-)
+model = maskrcnn_resnet50_fpn_v2()
 model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet18_ibn_a.py` & `mlagility-3.1.1/models/torch_hub/shufflenet_v2_x1_5.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::resnet18_ibn_a author::torch_hub
+# labels: test_group::mlagility name::shufflenet_v2_x1_5 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_shufflenet_v2.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "XingangPan/IBN-Net",
-    "resnet18_ibn_a",
+    "pytorch/vision:v0.13.1",
+    "shufflenet_v2_x1_5",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet18_ibn_b.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_v2_l.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::resnet18_ibn_b author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
-"""
-
+# labels: test_group::mlagility name::efficientnet_v2_l author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "XingangPan/IBN-Net",
-    "resnet18_ibn_b",
+    "pytorch/vision:v0.13.1",
+    "efficientnet_v2_l",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet34.py` & `mlagility-3.1.1/models/transformers/vit.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# labels: test_group::mlagility name::resnet34 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_resnet.md
-"""
-
+# labels: test_group::mlagility name::vit author::huggingface_pytorch task::Computer_Vision
 from mlagility.parser import parse
+import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "resnet34",
-    weights=None,
-)
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+config = transformers.ViTConfig()
+model = transformers.ViTModel(config)
+inputs = {
+    "pixel_values": torch.ones(
+        batch_size, num_channels, height, width, dtype=torch.float
+    ),
+}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet34_ibn_a.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_b1.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::resnet34_ibn_a author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
-"""
-
+# labels: test_group::mlagility name::efficientnet_b1 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "XingangPan/IBN-Net",
-    "resnet34_ibn_a",
+    "pytorch/vision:v0.13.1",
+    "efficientnet_b1",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet34_ibn_b.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_b0.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::resnet34_ibn_b author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
-"""
-
+# labels: test_group::mlagility name::efficientnet_b0 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "XingangPan/IBN-Net",
-    "resnet34_ibn_b",
+    "pytorch/vision:v0.13.1",
+    "efficientnet_b0",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet50.py` & `mlagility-3.1.1/models/transformers/segformer.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# labels: test_group::mlagility name::resnet50 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_resnet.md
-"""
-
+# labels: test_group::mlagility name::segformer author::huggingface_pytorch task::Computer_Vision
 from mlagility.parser import parse
+import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "resnet50",
-    weights=None,
-)
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+config = transformers.SegformerConfig()
+model = transformers.SegformerModel(config)
+inputs = {
+    "pixel_values": torch.ones(
+        batch_size, num_channels, height, width, dtype=torch.float
+    ),
+}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet50_ibn_a.py` & `mlagility-3.1.1/models/torch_hub/resnext101_ibn_a.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::resnet50_ibn_a author::torch_hub
+# labels: test_group::mlagility name::resnext101_ibn_a author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
 """
 
 from mlagility.parser import parse
 import torch
 
@@ -13,15 +13,15 @@
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "XingangPan/IBN-Net",
-    "resnet50_ibn_a",
+    "resnext101_ibn_a",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnet50_ibn_b.py` & `mlagility-3.1.1/models/torch_hub/resnest101.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::resnet50_ibn_b author::torch_hub
+# labels: test_group::mlagility name::resnest101 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "XingangPan/IBN-Net",
-    "resnet50_ibn_b",
+    "zhanghang1989/ResNeSt",
+    "resnest101",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnext101_32x8d.py` & `mlagility-3.1.1/models/torch_hub/resnext101_32x8d.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::resnext101_32x8d author::torch_hub
+# labels: test_group::mlagility name::resnext101_32x8d author::torch_hub task::Computer_Vision
 """
 https://github.com/pytorch/hub/blob/master/pytorch_vision_resnext.md
 """
 
 from mlagility.parser import parse
 import torch
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnext101_ibn_a.py` & `mlagility-3.1.1/models/transformers/unispeech.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,28 +1,22 @@
-# labels: test_group::mlagility name::resnext101_ibn_a author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
-"""
-
+# labels: test_group::mlagility name::unispeech author::huggingface_pytorch task::Audio
 from mlagility.parser import parse
+import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
-)
+batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "XingangPan/IBN-Net",
-    "resnext101_ibn_a",
-    weights=None,
-)
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+config = transformers.UniSpeechConfig()
+model = transformers.UniSpeechModel(config)
+inputs = {
+    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "input_values": torch.ones(batch_size, 10000, dtype=torch.float),
+}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/resnext50_32x4d.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_b2.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::resnext50_32x4d author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_resnext.md
-"""
-
+# labels: test_group::mlagility name::efficientnet_b2 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "resnext50_32x4d",
+    "efficientnet_b2",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/se_resnet101_ibn_a.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_v2_m.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::se_resnet101_ibn_a author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_ibnnet.md
-"""
-
+# labels: test_group::mlagility name::efficientnet_v2_m author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "XingangPan/IBN-Net",
-    "se_resnet101_ibn_a",
+    "pytorch/vision:v0.13.1",
+    "efficientnet_v2_m",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/shufflenet_v2_x0_5.py` & `mlagility-3.1.1/models/torchvision/retinanet_resnet50_fpn.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# labels: test_group::mlagility name::shufflenet_v2_x0_5 author::torch_hub
+# labels: test_group::mlagility name::retinanet_resnet50_fpn author::torchvision task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_shufflenet_v2.md
+https://pytorch.org/vision/stable/models/retinanet.html
 """
 
 from mlagility.parser import parse
 import torch
+from torchvision.models.detection import retinanet_resnet50_fpn
+
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "shufflenet_v2_x0_5",
-    weights=None,
-)
+model = retinanet_resnet50_fpn()
 model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/shufflenet_v2_x1_0.py` & `mlagility-3.1.1/models/torchvision/retinanet_resnet50_fpn_v2.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# labels: test_group::mlagility name::shufflenet_v2_x1_0 author::torch_hub
+# labels: test_group::mlagility name::retinanet_resnet50_fpn_v2 author::torchvision task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_shufflenet_v2.md
+https://pytorch.org/vision/stable/models/retinanet.html
 """
 
 from mlagility.parser import parse
 import torch
+from torchvision.models.detection import retinanet_resnet50_fpn_v2
+
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "shufflenet_v2_x1_0",
-    weights=None,
-)
+model = retinanet_resnet50_fpn_v2()
 model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/shufflenet_v2_x1_5.py` & `mlagility-3.1.1/models/torch_hub/mobilenet_v3_large.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::shufflenet_v2_x1_5 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_shufflenet_v2.md
-"""
-
+# labels: test_group::mlagility name::mobilenet_v3_large author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "shufflenet_v2_x1_5",
+    "mobilenet_v3_large",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/shufflenet_v2_x2_0.py` & `mlagility-3.1.1/models/torch_hub/resnest200.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::shufflenet_v2_x2_0 author::torch_hub
+# labels: test_group::mlagility name::resnest200 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_shufflenet_v2.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "shufflenet_v2_x2_0",
+    "zhanghang1989/ResNeSt",
+    "resnest200",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/squeezenet1_1.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_b3.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::squeezenet1_1 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_squeezenet.md
-"""
-
+# labels: test_group::mlagility name::efficientnet_b3 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "squeezenet1_1",
+    "efficientnet_b3",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/vgg11.py` & `mlagility-3.1.1/models/torchvision/ssdlite320_mobilenet_v3_large.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# labels: test_group::mlagility name::vgg11 author::torch_hub
+# labels: test_group::mlagility name::ssdlite320_mobilenet_v3_large author::torchvision task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
+https://pytorch.org/vision/stable/models/ssdlite.html
 """
 
 from mlagility.parser import parse
 import torch
+from torchvision.models.detection import ssdlite320_mobilenet_v3_large
+
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "vgg11",
-    weights=None,
-)
+model = ssdlite320_mobilenet_v3_large()
 model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/vgg11_bn.py` & `mlagility-3.1.1/models/transformers/detr.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# labels: test_group::mlagility name::vgg11_bn author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
-"""
-
+# labels: test_group::mlagility name::detr author::transformers task::Computer_Vision
 from mlagility.parser import parse
+import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "vgg11_bn",
-    weights=None,
-)
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+config = transformers.DetrConfig()
+model = transformers.DetrModel(config)
+inputs = {
+    "pixel_values": torch.ones(
+        batch_size, num_channels, height, width, dtype=torch.float
+    ),
+}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/vgg13.py` & `mlagility-3.1.1/models/transformers/convnext.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# labels: test_group::mlagility name::vgg13 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
-"""
-
+# labels: test_group::mlagility name::convnext author::transformers task::Computer_Vision
 from mlagility.parser import parse
+import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "vgg13",
-    weights=None,
-)
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+config = transformers.ConvNextConfig()
+model = transformers.ConvNextModel(config)
+inputs = {
+    "pixel_values": torch.ones(
+        batch_size, num_channels, height, width, dtype=torch.float
+    ),
+}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/vgg13_bn.py` & `mlagility-3.1.1/models/transformers/mobilevit_small_for_semantic_segmentation.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# labels: test_group::mlagility name::vgg13_bn author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
-"""
-
+# labels: test_group::mlagility name::mobilevit_small_for_semantic_segmentation author::transformers task::Computer_Vision
+"""https://huggingface.co/apple/mobilevit-small"""
 from mlagility.parser import parse
+import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "vgg13_bn",
-    weights=None,
+model = transformers.MobileViTForSemanticSegmentation.from_pretrained(
+    "apple/deeplabv3-mobilevit-small"
 )
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+
+inputs = {
+    "pixel_values": torch.ones(
+        batch_size, num_channels, height, width, dtype=torch.float
+    ),
+}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/vgg16.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_b6.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::vgg16 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
-"""
-
+# labels: test_group::mlagility name::efficientnet_b6 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "vgg16",
+    "efficientnet_b6",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/vgg16_bn.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_b7.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::vgg16_bn author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
-"""
-
+# labels: test_group::mlagility name::efficientnet_b7 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "vgg16_bn",
+    "efficientnet_b7",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/vgg19.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_b5.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::vgg19 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
-"""
-
+# labels: test_group::mlagility name::efficientnet_b5 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "vgg19",
+    "efficientnet_b5",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/vgg19_bn.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_b4.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,27 +1,23 @@
-# labels: test_group::mlagility name::vgg19_bn author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_vgg.md
-"""
-
+# labels: test_group::mlagility name::efficientnet_b4 author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "vgg19_bn",
+    "efficientnet_b4",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/vit_b_16.py` & `mlagility-3.1.1/models/torch_hub/convnext_base.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# labels: test_group::mlagility name::vit_b_16 author::torch_hub
+# labels: test_group::mlagility name::convnext_base author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "vit_b_16",
+    "convnext_base",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/vit_b_32.py` & `mlagility-3.1.1/models/torch_hub/efficientnet_v2_s.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# labels: test_group::mlagility name::vit_b_32 author::torch_hub
+# labels: test_group::mlagility name::efficientnet_v2_s author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
     "pytorch/vision:v0.13.1",
-    "vit_b_32",
+    "efficientnet_v2_s",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/vit_h_14.py` & `mlagility-3.1.1/models/torchvision/ssd300_vgg16.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,24 +1,26 @@
-# labels: test_group::mlagility name::vit_h_14 author::torch_hub
+# labels: test_group::mlagility name::ssd300_vgg16 author::torchvision task::Computer_Vision
+"""
+https://pytorch.org/vision/stable/models/ssd.html
+"""
+
 from mlagility.parser import parse
 import torch
+from torchvision.models.detection import ssd300_vgg16
+
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "vit_h_14",
-    weights=None,
-)
+model = ssd300_vgg16()
 model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torch_hub/wide_resnet101_2.py` & `mlagility-3.1.1/models/torch_hub/resnest269.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-# labels: test_group::mlagility name::wide_resnet101_2 author::torch_hub
+# labels: test_group::mlagility name::resnest269 author::torch_hub task::Computer_Vision
 """
-https://github.com/pytorch/hub/blob/master/pytorch_vision_wide_resnet.md
+https://github.com/pytorch/hub/blob/master/pytorch_vision_resnest.md
 """
 
 from mlagility.parser import parse
 import torch
 
 torch.manual_seed(0)
 
@@ -12,16 +12,16 @@
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
 model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "wide_resnet101_2",
+    "zhanghang1989/ResNeSt",
+    "resnest269",
     weights=None,
 )
 model.eval()
 inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/torch_hub/wide_resnet50_2.py` & `mlagility-3.1.1/models/transformers/data2vecaudio.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,28 +1,22 @@
-# labels: test_group::mlagility name::wide_resnet50_2 author::torch_hub
-"""
-https://github.com/pytorch/hub/blob/master/pytorch_vision_wide_resnet.md
-"""
-
+# labels: test_group::mlagility name::data2vecaudio author::transformers task::Audio
 from mlagility.parser import parse
+import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
-)
+batch_size = parse(["batch_size"])
 
 
 # Model and input configurations
-model = torch.hub.load(
-    "pytorch/vision:v0.13.1",
-    "wide_resnet50_2",
-    weights=None,
-)
-model.eval()
-inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
+config = transformers.Data2VecAudioConfig()
+model = transformers.Data2VecAudioModel(config)
+inputs = {
+    "input_values": torch.ones(batch_size, 10000, dtype=torch.float),
+    "attention_mask": torch.ones(batch_size, 10000, dtype=torch.int32),
+}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torchvision/fasterrcnn_mobilenet_v3_large_320_fpn.py` & `mlagility-3.1.1/models/torchvision/fasterrcnn_mobilenet_v3_large_320_fpn.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::fasterrcnn_mobilenet_v3_large_320_fpn author::torchvision
+# labels: test_group::mlagility name::fasterrcnn_mobilenet_v3_large_320_fpn author::torchvision task::Computer_Vision
 """
 https://pytorch.org/vision/stable/models/faster_rcnn.html
 """
 
 from mlagility.parser import parse
 import torch
 from torchvision.models.detection import fasterrcnn_mobilenet_v3_large_320_fpn
```

### Comparing `mlagility-3.0.2/models/torchvision/fasterrcnn_mobilenet_v3_large_fpn.py` & `mlagility-3.1.1/models/torchvision/fasterrcnn_mobilenet_v3_large_fpn.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::fasterrcnn_mobilenet_v3_large_fpn author::torchvision
+# labels: test_group::mlagility name::fasterrcnn_mobilenet_v3_large_fpn author::torchvision task::Computer_Vision
 """
 https://pytorch.org/vision/stable/models/faster_rcnn.html
 """
 
 from mlagility.parser import parse
 import torch
 from torchvision.models.detection import fasterrcnn_mobilenet_v3_large_fpn
```

### Comparing `mlagility-3.0.2/models/torchvision/fasterrcnn_resnet50_fpn_v2.py` & `mlagility-3.1.1/models/torch_hub/mealv2_mobilenet_v3_large_100.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,26 +1,29 @@
-# labels: test_group::mlagility name::fasterrcnn_resnet50_fpn_v2 author::torchvision
+# labels: test_group::mlagility name::mealv2_mobilenet_v3_large_100 author::torch_hub task::Computer_Vision
 """
-https://pytorch.org/vision/stable/models/faster_rcnn.html
+https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
 """
 
 from mlagility.parser import parse
 import torch
-from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2
-
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = fasterrcnn_resnet50_fpn_v2()
+model = torch.hub.load(
+    "szq0214/MEAL-V2",
+    "meal_v2",
+    "mealv2_mobilenet_v3_large_100",
+    weights=None,
+)
 model.eval()
-inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torchvision/fcos_resnet50_fpn.py` & `mlagility-3.1.1/models/transformers/poolformer.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,26 +1,25 @@
-# labels: test_group::mlagility name::fcos_resnet50_fpn author::torchvision
-"""
-https://pytorch.org/vision/stable/models/fcos.html
-"""
-
+# labels: test_group::mlagility name::poolformer author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
+import transformers
 import torch
-from torchvision.models.detection import fcos_resnet50_fpn
-
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-model = fcos_resnet50_fpn()
-model.eval()
-inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
+config = transformers.PoolFormerConfig()
+model = transformers.PoolFormerModel(config)
+inputs = {
+    "pixel_values": torch.ones(
+        batch_size, num_channels, height, width, dtype=torch.float
+    ),
+}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torchvision/keypointrcnn_resnet50_fpn.py` & `mlagility-3.1.1/models/torchvision/keypointrcnn_resnet50_fpn.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::keypointrcnn_resnet50_fpn author::torchvision
+# labels: test_group::mlagility name::keypointrcnn_resnet50_fpn author::torchvision task::Computer_Vision
 """
 https://pytorch.org/vision/stable/models/keypoint_rcnn.html
 """
 
 from mlagility.parser import parse
 import torch
 from torchvision.models.detection import keypointrcnn_resnet50_fpn
```

### Comparing `mlagility-3.0.2/models/torchvision/maskrcnn_resnet50_fpn.py` & `mlagility-3.1.1/models/torch_hub/proxyless_mobile.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,26 +1,28 @@
-# labels: test_group::mlagility name::maskrcnn_resnet50_fpn author::torchvision
+# labels: test_group::mlagility name::proxyless_mobile author::torch_hub task::Computer_Vision
 """
-https://pytorch.org/vision/stable/models/mask_rcnn.html
+https://github.com/pytorch/hub/blob/master/pytorch_vision_proxylessnas.md
 """
 
 from mlagility.parser import parse
 import torch
-from torchvision.models.detection import maskrcnn_resnet50_fpn
-
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = maskrcnn_resnet50_fpn()
+model = torch.hub.load(
+    "mit-han-lab/ProxylessNAS",
+    "proxyless_mobile",
+    weights=None,
+)
 model.eval()
-inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torchvision/maskrcnn_resnet50_fpn_v2.py` & `mlagility-3.1.1/models/torch_hub/mealv2_mobilenetv3_small_075.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,26 +1,29 @@
-# labels: test_group::mlagility name::maskrcnn_resnet50_fpn_v2 author::torchvision
+# labels: test_group::mlagility name::mealv2_mobilenetv3_small_075 author::torch_hub task::Computer_Vision
 """
-https://pytorch.org/vision/stable/models/mask_rcnn.html
+https://github.com/pytorch/hub/blob/master/pytorch_vision_meal_v2.md
 """
 
 from mlagility.parser import parse
 import torch
-from torchvision.models.detection import maskrcnn_resnet50_fpn_v2
-
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = maskrcnn_resnet50_fpn_v2()
+model = torch.hub.load(
+    "szq0214/MEAL-V2",
+    "meal_v2",
+    "mealv2_mobilenetv3_small_075",
+    weights=None,
+)
 model.eval()
-inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torchvision/retinanet_resnet50_fpn_v2.py` & `mlagility-3.1.1/models/torch_hub/regnet_x_8gf.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-# labels: test_group::mlagility name::retinanet_resnet50_fpn_v2 author::torchvision
-"""
-https://pytorch.org/vision/stable/models/retinanet.html
-"""
-
+# labels: test_group::mlagility name::regnet_x_8gf author::torch_hub task::Computer_Vision
 from mlagility.parser import parse
 import torch
-from torchvision.models.detection import retinanet_resnet50_fpn_v2
-
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, num_channels, width, height = parse(
     ["batch_size", "num_channels", "width", "height"]
 )
 
 
 # Model and input configurations
-model = retinanet_resnet50_fpn_v2()
+model = torch.hub.load(
+    "pytorch/vision:v0.13.1",
+    "regnet_x_8gf",
+    weights=None,
+)
 model.eval()
-inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
+inputs = {"x": torch.ones([batch_size, num_channels, width, height])}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/torchvision/ssd300_vgg16.py` & `mlagility-3.1.1/models/torch_hub/midas_v2.1_small.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,26 +1,21 @@
-# labels: test_group::mlagility name::ssd300_vgg16 author::torchvision
-"""
-https://pytorch.org/vision/stable/models/ssd.html
-"""
-
+# labels: test_group::mlagility name::midas_v2.1_small author::torch_hub task::Computer_Vision
+"""https://pytorch.org/hub/intelisl_midas_v2/"""
 from mlagility.parser import parse
 import torch
-from torchvision.models.detection import ssd300_vgg16
-
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, num_channels, width, height = parse(
-    ["batch_size", "num_channels", "width", "height"]
+batch_size, height, num_channels, width = parse(
+    ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-model = ssd300_vgg16()
-model.eval()
-inputs = {"images": torch.ones([batch_size, num_channels, width, height])}
+model = torch.hub.load("intel-isl/MiDaS", "MiDaS_small")
+
+inputs = {"x": torch.ones(batch_size, num_channels, height, width, dtype=torch.float)}
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/bart.py` & `mlagility-3.1.1/models/transformers/bart.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::bart author::transformers
+# labels: test_group::mlagility name::bart author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/beit.py` & `mlagility-3.1.1/models/transformers/yolos_tiny_for_object_detection.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# labels: test_group::mlagility name::beit author::transformers
+# labels: test_group::mlagility name::yolos_tiny_for_object_detection author::huggingface_pytorch task::Computer_Vision
+"""https://huggingface.co/hustvl/yolos-tiny"""
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, height, num_channels, width = parse(
     ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-config = transformers.BeitConfig()
-model = transformers.BeitModel(config)
+model = transformers.YolosForObjectDetection.from_pretrained("hustvl/yolos-tiny")
+
 inputs = {
     "pixel_values": torch.ones(
-        batch_size, num_channels, height, width, dtype=torch.float
-    ),
+        [batch_size, num_channels, height, width], dtype=torch.float
+    )
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/bert.py` & `mlagility-3.1.1/models/llm/gptj.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# labels: test_group::mlagility name::bert author::transformers
-"""
-https://huggingface.co/docs/transformers/v4.26.1/en/model_doc/bert#overview
-"""
+# labels: name::gptj author::transformers task::Generative_AI
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.BertConfig()
-model = transformers.BertModel(config)
+config = transformers.GPTJConfig()
+model = transformers.GPTJModel(config)
+
+# Make sure the user's sequence length fits within the model's maximum
+assert max_seq_length <= config.n_positions
+
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/bert_for_question_answering.py` & `mlagility-3.1.1/models/transformers/layoutlm.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,25 +1,26 @@
-# labels: test_group::mlagility name::bert_for_question_answering author::transformers
+# labels: test_group::mlagility name::layoutlm author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
+torch.manual_seed(0)
+
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
-# This version of BERT performs question answering,
-# while the default model outputs raw hidden states.
-
 # Model and input configurations
-model = transformers.BertForQuestionAnswering.from_pretrained(
-    "bert-large-uncased-whole-word-masking-finetuned-squad"
-)
+config = transformers.LayoutLMConfig()
+model = transformers.LayoutLMModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
-    "token_type_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "bbox": torch.zeros(
+        tuple(list(torch.Size([batch_size, max_seq_length])) + [4]),
+        dtype=torch.long,
+    ),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/bert_generation.py` & `mlagility-3.1.1/models/transformers/bert_generation.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::bert_generation author::transformers
+# labels: test_group::mlagility name::bert_generation author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
```

### Comparing `mlagility-3.0.2/models/transformers/bert_tiny_for_sequence_classification.py` & `mlagility-3.1.1/models/transformers/minilmv2.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# labels: test_group::mlagility name::bert_tiny_for_sequence_classification author::transformers
+# labels: test_group::mlagility name::minilmv2 author::transformers task::Natural_Language_Processing
+"""https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"""
 from mlagility.parser import parse
-import transformers
 import torch
+from transformers import AutoModel
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
-# This version of TinyBERT performs sequence classification,
-# while the default model outputs raw hidden states.
+# This version of MiniLM generates token embeddings
 
 # Model and input configurations
-model = transformers.AutoModelForSequenceClassification.from_pretrained(
-    "mrm8488/bert-tiny-finetuned-sms-spam-detection"
-)
+model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
 inputs = {
-    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.bool),
+    "input_ids": torch.ones((2 * batch_size, max_seq_length), dtype=torch.long),
+    "token_type_ids": torch.ones((2 * batch_size, max_seq_length), dtype=torch.long),
+    "attention_mask": torch.ones((2 * batch_size, max_seq_length), dtype=torch.bool),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/bigbird_pegasus.py` & `mlagility-3.1.1/models/transformers/bigbird_pegasus.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::bigbird_pegasus author::transformers
+# labels: test_group::mlagility name::bigbird_pegasus author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/biggan.py` & `mlagility-3.1.1/models/transformers/biggan.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::biggan author::transformers
+# labels: test_group::mlagility name::biggan author::transformers task::Generative_AI
 """https://github.com/huggingface/pytorch-pretrained-BigGAN/blob/master/README.md"""
 from mlagility.parser import parse
 import torch
 
 from pytorch_pretrained_biggan import BigGAN
```

### Comparing `mlagility-3.0.2/models/transformers/blenderbot_small.py` & `mlagility-3.1.1/models/transformers/blenderbot_small.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::blenderbot_small author::transformers
+# labels: test_group::mlagility name::blenderbot_small author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/camembert.py` & `mlagility-3.1.1/models/transformers/camembert.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::camembert author::transformers
+# labels: test_group::mlagility name::camembert author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/convbert.py` & `mlagility-3.1.1/models/transformers/convbert.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::convbert author::transformers
+# labels: test_group::mlagility name::convbert author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/convnext.py` & `mlagility-3.1.1/models/transformers/xlnet-512.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,25 +1,22 @@
-# labels: test_group::mlagility name::convnext author::transformers
+# labels: test_group::mlagility name::xlnet-512 author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, height, num_channels, width = parse(
-    ["batch_size", "height", "num_channels", "width"]
-)
+batch_size = parse(["batch_size"])
 
 
 # Model and input configurations
-config = transformers.ConvNextConfig()
-model = transformers.ConvNextModel(config)
+config = transformers.XLNetConfig()
+model = transformers.XLNetModel(config)
 inputs = {
-    "pixel_values": torch.ones(
-        batch_size, num_channels, height, width, dtype=torch.float
-    ),
+    "input_ids": torch.ones(batch_size, 512, dtype=torch.long),
+    "attention_mask": torch.ones(batch_size, 512, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/data2vecaudio.py` & `mlagility-3.1.1/models/transformers/speech_encoder_decoder.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,22 +1,24 @@
-# labels: test_group::mlagility name::data2vecaudio author::transformers
+# labels: test_group::mlagility name::speech_encoder_decoder author::huggingface_pytorch task::Audio
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size = parse(["batch_size"])
+batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.Data2VecAudioConfig()
-model = transformers.Data2VecAudioModel(config)
+config = transformers.SpeechEncoderDecoderConfig.from_encoder_decoder_configs(
+    transformers.Wav2Vec2Config(), transformers.BertConfig()
+)
+model = transformers.SpeechEncoderDecoderModel(config)
 inputs = {
+    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "input_values": torch.ones(batch_size, 10000, dtype=torch.float),
-    "attention_mask": torch.ones(batch_size, 10000, dtype=torch.int32),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/data2vectext.py` & `mlagility-3.1.1/models/transformers/data2vectext.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::data2vectext author::transformers
+# labels: test_group::mlagility name::data2vectext author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/deberta.py` & `mlagility-3.1.1/models/transformers/mt5_encoder.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# labels: test_group::mlagility name::deberta author::transformers
+# labels: test_group::mlagility name::mt5_encoder author::transformers task::MultiModal
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.DebertaConfig()
-model = transformers.DebertaModel(config)
+config = transformers.MT5Config()
+model = transformers.MT5EncoderModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/deit.py` & `mlagility-3.1.1/models/transformers/mobilevit.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,23 +1,25 @@
-# labels: test_group::mlagility name::deit author::transformers
+# labels: test_group::mlagility name::mobilevit author::transformers task::Computer_Vision
+"""https://huggingface.co/docs/transformers/model_doc/mobilevit"""
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, height, num_channels, width = parse(
     ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
-config = transformers.DeiTConfig()
-model = transformers.DeiTModel(config)
+config = transformers.MobileViTConfig()
+model = transformers.MobileViTModel(config)
+
 inputs = {
     "pixel_values": torch.ones(
         batch_size, num_channels, height, width, dtype=torch.float
     ),
 }
```

### Comparing `mlagility-3.0.2/models/transformers/deit_base_for_image_classification.py` & `mlagility-3.1.1/models/transformers/deit_tiny_for_image_classification.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-# labels: test_group::mlagility name::deit_base_for_image_classification author::transformers
-"""https://huggingface.co/facebook/deit-base-patch16-224"""
+# labels: test_group::mlagility name::deit_tiny_for_image_classification author::transformers task::Computer_Vision
+"""https://huggingface.co/facebook/deit-tiny-patch16-224"""
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, height, num_channels, width = parse(
     ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
 model = transformers.ViTForImageClassification.from_pretrained(
-    "facebook/deit-base-patch16-224"
+    "facebook/deit-tiny-patch16-224"
 )
 inputs = {
     "pixel_values": torch.ones(
         batch_size, num_channels, height, width, dtype=torch.float
     ),
 }
```

### Comparing `mlagility-3.0.2/models/transformers/deit_tiny_for_image_classification.py` & `mlagility-3.1.1/models/transformers/deit_base_for_image_classification.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-# labels: test_group::mlagility name::deit_tiny_for_image_classification author::transformers
-"""https://huggingface.co/facebook/deit-tiny-patch16-224"""
+# labels: test_group::mlagility name::deit_base_for_image_classification author::transformers task::Computer_Vision
+"""https://huggingface.co/facebook/deit-base-patch16-224"""
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, height, num_channels, width = parse(
     ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
 model = transformers.ViTForImageClassification.from_pretrained(
-    "facebook/deit-tiny-patch16-224"
+    "facebook/deit-base-patch16-224"
 )
 inputs = {
     "pixel_values": torch.ones(
         batch_size, num_channels, height, width, dtype=torch.float
     ),
 }
```

### Comparing `mlagility-3.0.2/models/transformers/detr.py` & `mlagility-3.1.1/models/transformers/gpt2_doublehead.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,25 +1,22 @@
-# labels: test_group::mlagility name::detr author::transformers
+# labels: test_group::mlagility name::gpt2_doublehead author::transformers task::Generative_AI
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, height, num_channels, width = parse(
-    ["batch_size", "height", "num_channels", "width"]
-)
+batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.DetrConfig()
-model = transformers.DetrModel(config)
+config = transformers.GPT2Config()
+model = transformers.GPT2DoubleHeadsModel(config)
 inputs = {
-    "pixel_values": torch.ones(
-        batch_size, num_channels, height, width, dtype=torch.float
-    ),
+    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/detr_for_object_detection.py` & `mlagility-3.1.1/models/transformers/detr_for_object_detection.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::detr_for_object_detection author::transformers
+# labels: test_group::mlagility name::detr_for_object_detection author::transformers task::Computer_Vision
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, height, num_channels, width = parse(
     ["batch_size", "height", "num_channels", "width"]
```

### Comparing `mlagility-3.0.2/models/transformers/distil_wav2vec2_for_audio_classification.py` & `mlagility-3.1.1/models/transformers/distil_wav2vec2_for_audio_classification.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::distil_wav2vec2_for_audio_classification author::transformers
+# labels: test_group::mlagility name::distil_wav2vec2_for_audio_classification author::transformers task::Audio
 """https://huggingface.co/bookbot/distil-wav2vec2-xls-r-adult-child-cls-89m"""
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, max_audio_seq_length = parse(
```

### Comparing `mlagility-3.0.2/models/transformers/distilbert.py` & `mlagility-3.1.1/models/transformers/marian.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,23 +1,19 @@
-# labels: test_group::mlagility name::distilbert author::transformers
+# labels: test_group::mlagility name::marian author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-model = transformers.DistilBertModel.from_pretrained(
-    "distilbert-base-uncased-distilled-squad"
-)
+model = transformers.MarianModel.from_pretrained("Helsinki-NLP/opus-mt-en-de")
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
+    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/distilbert_for_question_answering.py` & `mlagility-3.1.1/models/transformers/distilbert_for_question_answering.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::distilbert_for_question_answering author::transformers
+# labels: test_group::mlagility name::distilbert_for_question_answering author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
```

### Comparing `mlagility-3.0.2/models/transformers/distilhubert_for_audio_classification.py` & `mlagility-3.1.1/models/transformers/distilhubert_for_audio_classification.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::distilhubert_for_audio_classification author::transformers
+# labels: test_group::mlagility name::distilhubert_for_audio_classification author::transformers task::Audio
 """https://huggingface.co/anton-l/distilhubert-ft-common-language"""
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, max_audio_seq_length = parse(
```

### Comparing `mlagility-3.0.2/models/transformers/electra.py` & `mlagility-3.1.1/models/transformers/electra.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::electra author::transformers
+# labels: test_group::mlagility name::electra author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/electra_for_sequence_classification.py` & `mlagility-3.1.1/models/transformers/electra_for_sequence_classification.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::electra_for_sequence_classification author::transformers
+# labels: test_group::mlagility name::electra_for_sequence_classification author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
```

### Comparing `mlagility-3.0.2/models/transformers/encoder_decoder.py` & `mlagility-3.1.1/models/transformers/encoder_decoder.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::encoder_decoder author::transformers
+# labels: test_group::mlagility name::encoder_decoder author::transformers task::MultiModal
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/flaubert.py` & `mlagility-3.1.1/models/transformers/funnel_base.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::flaubert author::transformers
+# labels: test_group::mlagility name::funnel_base author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.FlaubertConfig()
-model = transformers.FlaubertModel(config)
+config = transformers.FunnelConfig()
+model = transformers.FunnelBaseModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/funnel.py` & `mlagility-3.1.1/models/transformers/squeezebert.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::funnel author::transformers
+# labels: test_group::mlagility name::squeezebert author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.FunnelConfig()
-model = transformers.FunnelModel(config)
+config = transformers.SqueezeBertConfig()
+model = transformers.SqueezeBertModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/funnel_base.py` & `mlagility-3.1.1/models/transformers/rag.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-# labels: test_group::mlagility name::funnel_base author::transformers
+# labels: test_group::mlagility name::rag author::huggingface_pytorch task::MultiModal
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.FunnelConfig()
-model = transformers.FunnelBaseModel(config)
+model = transformers.RagModel.from_pretrained("facebook/rag-token-base")
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "context_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
+    "context_attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
+    "doc_scores": torch.ones(batch_size, 5, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/gpt1.py` & `mlagility-3.1.1/models/transformers/gpt2.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::gpt1 author::transformers
+# labels: test_group::mlagility name::gpt2 author::transformers task::Generative_AI
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.OpenAIGPTConfig()
-model = transformers.OpenAIGPTModel(config)
+config = transformers.GPT2Config()
+model = transformers.GPT2Model(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/gpt2.py` & `mlagility-3.1.1/models/transformers/ibert.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::gpt2 author::transformers
+# labels: test_group::mlagility name::ibert author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.GPT2Config()
-model = transformers.GPT2Model(config)
+config = transformers.IBertConfig()
+model = transformers.IBertModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/gpt2_doublehead.py` & `mlagility-3.1.1/models/transformers/mobilebert.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::gpt2_doublehead author::transformers
+# labels: test_group::mlagility name::mobilebert author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.GPT2Config()
-model = transformers.GPT2DoubleHeadsModel(config)
+config = transformers.MobileBertConfig()
+model = transformers.MobileBertModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/hubert.py` & `mlagility-3.1.1/models/llm_layer/gpt_neo_layer.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,22 +1,27 @@
-# labels: test_group::mlagility name::hubert author::transformers
+# labels: name::gpt_neo_layer author::transformers task::Generative_AI
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
-batch_size = parse(["batch_size"])
+batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.HubertConfig()
-model = transformers.HubertModel(config)
+config = transformers.GPTNeoConfig()
+model = transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoBlock(config, layer_id=0)
+
+# Make sure the user's sequence length fits within the model's maximum
+assert max_seq_length <= config.max_position_embeddings
+
+
 inputs = {
-    "input_values": torch.ones(batch_size, 10000, dtype=torch.float),
-    "attention_mask": torch.ones(batch_size, 10000, dtype=torch.int32),
+    "hidden_states": torch.ones(
+        batch_size, max_seq_length, config.hidden_size, dtype=torch.float
+    ),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/ibert.py` & `mlagility-3.1.1/models/transformers/mpnet.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::ibert author::transformers
+# labels: test_group::mlagility name::mpnet author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.IBertConfig()
-model = transformers.IBertModel(config)
+config = transformers.MPNetConfig()
+model = transformers.MPNetModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/layoutlm.py` & `mlagility-3.1.1/models/transformers/mt5_small.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,26 +1,19 @@
-# labels: test_group::mlagility name::layoutlm author::transformers
+# labels: test_group::mlagility name::mt5_small author::transformers task::MultiModal
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.LayoutLMConfig()
-model = transformers.LayoutLMModel(config)
+model = transformers.MT5Model.from_pretrained("google/mt5-small")
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
-    "bbox": torch.zeros(
-        tuple(list(torch.Size([batch_size, max_seq_length])) + [4]),
-        dtype=torch.long,
-    ),
+    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/luke.py` & `mlagility-3.1.1/models/transformers/deberta.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::luke author::transformers
+# labels: test_group::mlagility name::deberta author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.LukeConfig()
-model = transformers.LukeModel(config)
+config = transformers.DebertaConfig()
+model = transformers.DebertaModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/m2m_100.py` & `mlagility-3.1.1/models/transformers/mt5_base.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-# labels: test_group::mlagility name::m2m_100 author::transformers
+# labels: test_group::mlagility name::mt5_base author::transformers task::MultiModal
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.M2M100Config()
-model = transformers.M2M100Model(config)
+model = transformers.MT5Model.from_pretrained("google/mt5-base")
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/marian.py` & `mlagility-3.1.1/models/transformers/distilbert.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,19 +1,23 @@
-# labels: test_group::mlagility name::marian author::transformers
+# labels: test_group::mlagility name::distilbert author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
+torch.manual_seed(0)
+
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-model = transformers.MarianModel.from_pretrained("Helsinki-NLP/opus-mt-en-de")
+model = transformers.DistilBertModel.from_pretrained(
+    "distilbert-base-uncased-distilled-squad"
+)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/marianmt.py` & `mlagility-3.1.1/models/transformers/m2m_100.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,18 +1,21 @@
-# labels: test_group::mlagility name::marianmt author::transformers
+# labels: test_group::mlagility name::m2m_100 author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
+torch.manual_seed(0)
+
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-model = transformers.MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-fr-en")
+config = transformers.M2M100Config()
+model = transformers.M2M100Model(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/megatron_bert.py` & `mlagility-3.1.1/models/transformers/luke.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::megatron_bert author::transformers
+# labels: test_group::mlagility name::luke author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.MegatronBertConfig()
-model = transformers.MegatronBertModel(config)
+config = transformers.LukeConfig()
+model = transformers.LukeModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/mobilebert.py` & `mlagility-3.1.1/models/transformers/bert.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,21 +1,24 @@
-# labels: test_group::mlagility name::mobilebert author::transformers
+# labels: test_group::mlagility name::bert author::transformers task::Natural_Language_Processing
+"""
+https://huggingface.co/docs/transformers/v4.26.1/en/model_doc/bert#overview
+"""
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.MobileBertConfig()
-model = transformers.MobileBertModel(config)
+config = transformers.BertConfig()
+model = transformers.BertModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/mobilebert_for_sequence_classification.py` & `mlagility-3.1.1/models/transformers/mobilebert_for_sequence_classification.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::mobilebert_for_sequence_classification author::transformers
+# labels: test_group::mlagility name::mobilebert_for_sequence_classification author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
```

### Comparing `mlagility-3.0.2/models/transformers/mobilevit.py` & `mlagility-3.1.1/models/transformers/unispeech_sat.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,27 +1,22 @@
-# labels: test_group::mlagility name::mobilevit author::transformers
-"""https://huggingface.co/docs/transformers/model_doc/mobilevit"""
+# labels: test_group::mlagility name::unispeech_sat author::huggingface_pytorch task::Audio
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, height, num_channels, width = parse(
-    ["batch_size", "height", "num_channels", "width"]
-)
+batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.MobileViTConfig()
-model = transformers.MobileViTModel(config)
-
+config = transformers.UniSpeechSatConfig()
+model = transformers.UniSpeechSatModel(config)
 inputs = {
-    "pixel_values": torch.ones(
-        batch_size, num_channels, height, width, dtype=torch.float
-    ),
+    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "input_values": torch.ones(batch_size, 10000, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/mobilevit_small_for_semantic_segmentation.py` & `mlagility-3.1.1/models/transformers/mobilevit_xx_small_for_semantic_segmentation.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-# labels: test_group::mlagility name::mobilevit_small_for_semantic_segmentation author::transformers
-"""https://huggingface.co/apple/mobilevit-small"""
+# labels: test_group::mlagility name::mobilevit_xx_small_for_semantic_segmentation author::transformers task::Computer_Vision
+"""https://huggingface.co/apple/mobilevit-xx-small"""
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, height, num_channels, width = parse(
     ["batch_size", "height", "num_channels", "width"]
 )
 
 
 # Model and input configurations
 model = transformers.MobileViTForSemanticSegmentation.from_pretrained(
-    "apple/deeplabv3-mobilevit-small"
+    "apple/deeplabv3-mobilevit-xx-small"
 )
 
 inputs = {
     "pixel_values": torch.ones(
         batch_size, num_channels, height, width, dtype=torch.float
     ),
 }
```

### Comparing `mlagility-3.0.2/models/transformers/mobilevit_x_small_for_semantic_segmentation.py` & `mlagility-3.1.1/models/transformers/mobilevit_x_small_for_semantic_segmentation.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::mobilevit_x_small_for_semantic_segmentation author::transformers
+# labels: test_group::mlagility name::mobilevit_x_small_for_semantic_segmentation author::transformers task::Computer_Vision
 """https://huggingface.co/apple/deeplabv3-mobilevit-x-small"""
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, height, num_channels, width = parse(
```

### Comparing `mlagility-3.0.2/models/transformers/mobilevit_xx_small_for_semantic_segmentation.py` & `mlagility-3.1.1/models/transformers/speech_to_text.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,26 +1,22 @@
-# labels: test_group::mlagility name::mobilevit_xx_small_for_semantic_segmentation author::transformers
-"""https://huggingface.co/apple/mobilevit-xx-small"""
+# labels: test_group::mlagility name::speech_to_text author::huggingface_pytorch task::Audio
 from mlagility.parser import parse
 import transformers
 import torch
 
+torch.manual_seed(0)
+
 # Parsing command-line arguments
-batch_size, height, num_channels, width = parse(
-    ["batch_size", "height", "num_channels", "width"]
-)
+batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-model = transformers.MobileViTForSemanticSegmentation.from_pretrained(
-    "apple/deeplabv3-mobilevit-xx-small"
-)
-
+config = transformers.Speech2TextConfig(feature_size=80)
+model = transformers.Speech2TextModel(config)
 inputs = {
-    "pixel_values": torch.ones(
-        batch_size, num_channels, height, width, dtype=torch.float
-    ),
+    "input_features": torch.ones(batch_size, max_seq_length, 80, dtype=torch.float),
+    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/mpnet.py` & `mlagility-3.1.1/models/transformers/flaubert.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::mpnet author::transformers
+# labels: test_group::mlagility name::flaubert author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.MPNetConfig()
-model = transformers.MPNetModel(config)
+config = transformers.FlaubertConfig()
+model = transformers.FlaubertModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/mt5_base.py` & `mlagility-3.1.1/models/transformers/t5_base.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-# labels: test_group::mlagility name::mt5_base author::transformers
+# labels: test_group::mlagility name::t5_base author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-model = transformers.MT5Model.from_pretrained("google/mt5-base")
+model = transformers.T5ForConditionalGeneration.from_pretrained("t5-base")
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/mt5_small.py` & `mlagility-3.1.1/models/transformers/t5_encoder.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,19 +1,21 @@
-# labels: test_group::mlagility name::mt5_small author::transformers
+# labels: test_group::mlagility name::t5_encoder author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
+torch.manual_seed(0)
+
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-model = transformers.MT5Model.from_pretrained("google/mt5-small")
+config = transformers.T5Config()
+model = transformers.T5EncoderModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/openai_doublehead.py` & `mlagility-3.1.1/models/transformers/funnel.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::openai_doublehead author::transformers
+# labels: test_group::mlagility name::funnel author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.OpenAIGPTConfig()
-model = transformers.OpenAIGPTDoubleHeadsModel(config)
+config = transformers.FunnelConfig()
+model = transformers.FunnelModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/pegasus.py` & `mlagility-3.1.1/models/transformers/t5_large.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-# labels: test_group::mlagility name::pegasus author::transformers
+# labels: test_group::mlagility name::t5_large author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.PegasusConfig()
-model = transformers.PegasusModel(config)
+model = transformers.T5ForConditionalGeneration.from_pretrained("t5-large")
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/perceiver.py` & `mlagility-3.1.1/models/transformers/imagegpt.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,21 +1,22 @@
-# labels: test_group::mlagility name::perceiver author::transformers
+# labels: test_group::mlagility name::imagegpt author::transformers task::Generative_AI
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.PerceiverConfig(d_model=max_seq_length)
-model = transformers.PerceiverModel(config)
+config = transformers.ImageGPTConfig()
+model = transformers.ImageGPTModel(config)
 inputs = {
-    "inputs": torch.ones(1, batch_size, max_seq_length, dtype=torch.float),
+    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/poolformer.py` & `mlagility-3.1.1/models/transformers/pegasus.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,25 +1,22 @@
-# labels: test_group::mlagility name::poolformer author::transformers
+# labels: test_group::mlagility name::pegasus author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, height, num_channels, width = parse(
-    ["batch_size", "height", "num_channels", "width"]
-)
+batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.PoolFormerConfig()
-model = transformers.PoolFormerModel(config)
+config = transformers.PegasusConfig()
+model = transformers.PegasusModel(config)
 inputs = {
-    "pixel_values": torch.ones(
-        batch_size, num_channels, height, width, dtype=torch.float
-    ),
+    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/realm.py` & `mlagility-3.1.1/models/transformers/realm.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::realm author::huggingface_pytorch
+# labels: test_group::mlagility name::realm author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/rembert.py` & `mlagility-3.1.1/models/transformers/megatron_bert.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::rembert author::huggingface_pytorch
+# labels: test_group::mlagility name::megatron_bert author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.RemBertConfig()
-model = transformers.RemBertModel(config)
+config = transformers.MegatronBertConfig()
+model = transformers.MegatronBertModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/retribert.py` & `mlagility-3.1.1/models/transformers/retribert.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::retribert author::huggingface_pytorch
+# labels: test_group::mlagility name::retribert author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/roberta.py` & `mlagility-3.1.1/models/transformers/roberta.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::roberta author::huggingface_pytorch
+# labels: test_group::mlagility name::roberta author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/roformer.py` & `mlagility-3.1.1/models/transformers/roformer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::roformer author::huggingface_pytorch
+# labels: test_group::mlagility name::roformer author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
```

### Comparing `mlagility-3.0.2/models/transformers/segformer.py` & `mlagility-3.1.1/models/llm_layer/gptj_layer.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,25 +1,27 @@
-# labels: test_group::mlagility name::segformer author::huggingface_pytorch
+# labels: name::gptj_layer author::transformers task::Generative_AI
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
-batch_size, height, num_channels, width = parse(
-    ["batch_size", "height", "num_channels", "width"]
-)
+batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.SegformerConfig()
-model = transformers.SegformerModel(config)
+config = transformers.GPTJConfig()
+model = transformers.models.gptj.modeling_gptj.GPTJBlock(config)
+
+# Make sure the user's sequence length fits within the model's maximum
+assert max_seq_length <= config.n_positions
+
+
 inputs = {
-    "pixel_values": torch.ones(
-        batch_size, num_channels, height, width, dtype=torch.float
+    "hidden_states": torch.ones(
+        batch_size, max_seq_length, config.n_embd, dtype=torch.float
     ),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
-# Call model
+# Call layer
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/speech_encoder_decoder.py` & `mlagility-3.1.1/models/transformers/vision_encoder_decoder.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,24 +1,27 @@
-# labels: test_group::mlagility name::speech_encoder_decoder author::huggingface_pytorch
+# labels: test_group::mlagility name::vision_encoder_decoder author::huggingface_pytorch task::Computer_Vision
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
-
+batch_size, height, max_seq_length, width = parse(
+    ["batch_size", "height", "max_seq_length", "width"]
+)
 
 # Model and input configurations
-config = transformers.SpeechEncoderDecoderConfig.from_encoder_decoder_configs(
-    transformers.Wav2Vec2Config(), transformers.BertConfig()
+config = transformers.VisionEncoderDecoderConfig.from_encoder_decoder_configs(
+    transformers.ViTConfig(), transformers.BertConfig()
 )
-model = transformers.SpeechEncoderDecoderModel(config)
+model = transformers.VisionEncoderDecoderModel(config)
 inputs = {
+    "pixel_values": torch.ones(
+        batch_size, num_channels, height, width, dtype=torch.float
+    ),
     "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "input_values": torch.ones(batch_size, 10000, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/speech_encoder_decoder_pretrained.py` & `mlagility-3.1.1/models/transformers/speech_encoder_decoder_pretrained.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# labels: test_group::mlagility name::speech_encoder_decoder_pretrained author::huggingface_pytorch
+# labels: test_group::mlagility name::speech_encoder_decoder_pretrained author::huggingface_pytorch task::Audio
 from mlagility.parser import parse
 import transformers
 import torch
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
```

### Comparing `mlagility-3.0.2/models/transformers/speech_to_text.py` & `mlagility-3.1.1/models/transformers/t5_small.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,22 +1,19 @@
-# labels: test_group::mlagility name::speech_to_text author::huggingface_pytorch
+# labels: test_group::mlagility name::t5_small author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.Speech2TextConfig(feature_size=80)
-model = transformers.Speech2TextModel(config)
+model = transformers.T5ForConditionalGeneration.from_pretrained("t5-small")
 inputs = {
-    "input_features": torch.ones(batch_size, max_seq_length, 80, dtype=torch.float),
+    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/splinter.py` & `mlagility-3.1.1/models/transformers/bert_tiny_for_sequence_classification.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,22 +1,24 @@
-# labels: test_group::mlagility name::splinter author::huggingface_pytorch
+# labels: test_group::mlagility name::bert_tiny_for_sequence_classification author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
+# This version of TinyBERT performs sequence classification,
+# while the default model outputs raw hidden states.
+
 # Model and input configurations
-config = transformers.SplinterConfig()
-model = transformers.SplinterModel(config)
+model = transformers.AutoModelForSequenceClassification.from_pretrained(
+    "mrm8488/bert-tiny-finetuned-sms-spam-detection"
+)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.bool),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/squeezebert.py` & `mlagility-3.1.1/models/transformers/marianmt.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,22 +1,19 @@
-# labels: test_group::mlagility name::squeezebert author::huggingface_pytorch
+# labels: test_group::mlagility name::marianmt author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.SqueezeBertConfig()
-model = transformers.SqueezeBertModel(config)
+model = transformers.MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-fr-en")
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
+    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/t5_base.py` & `mlagility-3.1.1/models/transformers/splinter.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,19 +1,22 @@
-# labels: test_group::mlagility name::t5_base author::huggingface_pytorch
+# labels: test_group::mlagility name::splinter author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
+torch.manual_seed(0)
+
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-model = transformers.T5ForConditionalGeneration.from_pretrained("t5-base")
+config = transformers.SplinterConfig()
+model = transformers.SplinterModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/t5_large.py` & `mlagility-3.1.1/models/transformers/hubert.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,19 +1,22 @@
-# labels: test_group::mlagility name::t5_large author::huggingface_pytorch
+# labels: test_group::mlagility name::hubert author::transformers task::Audio
 from mlagility.parser import parse
 import transformers
 import torch
 
+torch.manual_seed(0)
+
 # Parsing command-line arguments
-batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
+batch_size = parse(["batch_size"])
 
 
 # Model and input configurations
-model = transformers.T5ForConditionalGeneration.from_pretrained("t5-large")
+config = transformers.HubertConfig()
+model = transformers.HubertModel(config)
 inputs = {
-    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "input_values": torch.ones(batch_size, 10000, dtype=torch.float),
+    "attention_mask": torch.ones(batch_size, 10000, dtype=torch.int32),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/t5_small.py` & `mlagility-3.1.1/models/transformers/xglm.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,19 +1,22 @@
-# labels: test_group::mlagility name::t5_small author::huggingface_pytorch
+# labels: test_group::mlagility name::xglm author::huggingface_pytorch task::Graph_Machine_Learning
 from mlagility.parser import parse
 import transformers
 import torch
 
+torch.manual_seed(0)
+
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-model = transformers.T5ForConditionalGeneration.from_pretrained("t5-small")
+config = transformers.XGLMConfig()
+model = transformers.XGLMModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/unispeech.py` & `mlagility-3.1.1/models/transformers/xlm.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-# labels: test_group::mlagility name::unispeech author::huggingface_pytorch
+# labels: test_group::mlagility name::xlm author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.UniSpeechConfig()
-model = transformers.UniSpeechModel(config)
+config = transformers.XLMConfig()
+model = transformers.XLMModel(config)
 inputs = {
-    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "input_values": torch.ones(batch_size, 10000, dtype=torch.float),
+    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/unispeech_sat.py` & `mlagility-3.1.1/models/transformers/gpt1.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-# labels: test_group::mlagility name::unispeech_sat author::huggingface_pytorch
+# labels: test_group::mlagility name::gpt1 author::transformers task::Generative_AI
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.UniSpeechSatConfig()
-model = transformers.UniSpeechSatModel(config)
+config = transformers.OpenAIGPTConfig()
+model = transformers.OpenAIGPTModel(config)
 inputs = {
-    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
-    "input_values": torch.ones(batch_size, 10000, dtype=torch.float),
+    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/vision_encoder_decoder.py` & `mlagility-3.1.1/models/transformers/rembert.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,27 +1,22 @@
-# labels: test_group::mlagility name::vision_encoder_decoder author::huggingface_pytorch
+# labels: test_group::mlagility name::rembert author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, height, max_seq_length, width = parse(
-    ["batch_size", "height", "max_seq_length", "width"]
-)
+batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
+
 
 # Model and input configurations
-config = transformers.VisionEncoderDecoderConfig.from_encoder_decoder_configs(
-    transformers.ViTConfig(), transformers.BertConfig()
-)
-model = transformers.VisionEncoderDecoderModel(config)
+config = transformers.RemBertConfig()
+model = transformers.RemBertModel(config)
 inputs = {
-    "pixel_values": torch.ones(
-        batch_size, num_channels, height, width, dtype=torch.float
-    ),
-    "decoder_input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/vit.py` & `mlagility-3.1.1/models/transformers/openai_doublehead.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,25 +1,22 @@
-# labels: test_group::mlagility name::vit author::huggingface_pytorch
+# labels: test_group::mlagility name::openai_doublehead author::transformers task::Generative_AI
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
-batch_size, height, num_channels, width = parse(
-    ["batch_size", "height", "num_channels", "width"]
-)
+batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.ViTConfig()
-model = transformers.ViTModel(config)
+config = transformers.OpenAIGPTConfig()
+model = transformers.OpenAIGPTDoubleHeadsModel(config)
 inputs = {
-    "pixel_values": torch.ones(
-        batch_size, num_channels, height, width, dtype=torch.float
-    ),
+    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/xglm.py` & `mlagility-3.1.1/models/transformers/xlnet.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::xglm author::huggingface_pytorch
+# labels: test_group::mlagility name::xlnet author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.XGLMConfig()
-model = transformers.XGLMModel(config)
+config = transformers.XLNetConfig()
+model = transformers.XLNetModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/xlm.py` & `mlagility-3.1.1/models/transformers/xlm_roberta.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# labels: test_group::mlagility name::xlm author::huggingface_pytorch
+# labels: test_group::mlagility name::xlm_roberta author::huggingface_pytorch task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
 torch.manual_seed(0)
 
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.XLMConfig()
-model = transformers.XLMModel(config)
+config = transformers.XLMRobertaConfig()
+model = transformers.XLMRobertaModel(config)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
```

### Comparing `mlagility-3.0.2/models/transformers/xlm_roberta.py` & `mlagility-3.1.1/models/transformers/bert_for_question_answering.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,22 +1,25 @@
-# labels: test_group::mlagility name::xlm_roberta author::huggingface_pytorch
+# labels: test_group::mlagility name::bert_for_question_answering author::transformers task::Natural_Language_Processing
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
+# This version of BERT performs question answering,
+# while the default model outputs raw hidden states.
+
 # Model and input configurations
-config = transformers.XLMRobertaConfig()
-model = transformers.XLMRobertaModel(config)
+model = transformers.BertForQuestionAnswering.from_pretrained(
+    "bert-large-uncased-whole-word-masking-finetuned-squad"
+)
 inputs = {
     "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
+    "token_type_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/models/transformers/xlnet.py` & `mlagility-3.1.1/models/llm/gpt_neox.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,22 +1,27 @@
-# labels: test_group::mlagility name::xlnet author::huggingface_pytorch
+# labels: name::gpt_neox author::transformers task::Generative_AI
 from mlagility.parser import parse
 import transformers
 import torch
 
-torch.manual_seed(0)
-
 # Parsing command-line arguments
 batch_size, max_seq_length = parse(["batch_size", "max_seq_length"])
 
 
 # Model and input configurations
-config = transformers.XLNetConfig()
-model = transformers.XLNetModel(config)
+config = transformers.GPTNeoXConfig()
+model = transformers.GPTNeoXModel(config)
+
+# Make sure the user's sequence length fits within the model's maximum
+assert max_seq_length <= config.max_position_embeddings
+
+
 inputs = {
-    "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
+    "hidden_states": torch.ones(
+        batch_size, max_seq_length, config.hidden_size, dtype=torch.float
+    ),
     "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.float),
 }
 
 
 # Call model
 model(**inputs)
```

### Comparing `mlagility-3.0.2/setup.py` & `mlagility-3.1.1/setup.py`

 * *Files 3% similar despite different names*

```diff
@@ -21,43 +21,46 @@
         "onnxflow",
         "onnxflow.common",
         "onnxflow.justbuildit",
         "onnxflow.model",
         "mlagility_models",
         "mlagility_models.diffusers",
         "mlagility_models.graph_convolutions",
+        "mlagility_models.llm",
+        "mlagility_models.llm_layer",
         "mlagility_models.popular_on_huggingface",
         "mlagility_models.selftest",
         "mlagility_models.timm",
         "mlagility_models.torch_hub",
         "mlagility_models.torchvision",
         "mlagility_models.transformers",
     ],
     install_requires=[
         "invoke>=2.0.0",
         "onnx>=1.11.0",
         "onnxmltools==1.10.0",
         "hummingbird-ml==0.4.4",
         "scikit-learn==1.1.1",
         "xgboost==1.6.1",
-        "onnxruntime>=1.10.0",
+        "onnxruntime>=1.10.0,<1.15.0",
         "paramiko==2.11.0",
         "torch>=1.12.1",
-        "protobuf>=3.17.3",
+        "protobuf>=3.17.3,<3.21",
         "pyyaml>=5.4",
         "typeguard>=2.3.13",
-        "packaging>=21.3",
+        "packaging>=20.9",
+        "pandas>=1.5.3",
     ],
     extras_require={
         "tensorflow": [
             "tensorflow-cpu>=2.8.1,<2.12",
             "tf2onnx>=1.12.0",
         ],
         "groq": [
-            "groqflow==2.5.2",
+            "groqflow==3.1.0",
         ],
     },
     classifiers=[],
     entry_points={
         "console_scripts": [
             "benchit=mlagility:benchitcli",
         ]
```

### Comparing `mlagility-3.0.2/src/mlagility/analysis/analysis.py` & `mlagility-3.1.1/src/mlagility/analysis/analysis.py`

 * *Files 3% similar despite different names*

```diff
@@ -22,14 +22,15 @@
 import mlagility.common.labels as labels
 from mlagility.api.model_api import benchmark_model
 import mlagility.common.filesystem as filesystem
 
 
 class Action(Enum):
     ANALYZE = "analyze"
+    EXPORT = "export"
     BUILD = "build"
     BENCHMARK = "benchmark"
 
 
 @dataclasses.dataclass
 class TracerArgs:
     input: str
@@ -93,15 +94,18 @@
         if torch.is_tensor(kwargs[k]):
             inputs[k] = torch.tensor(kwargs[k].detach().numpy())
         else:
             inputs[k] = copy.deepcopy(kwargs[k])
 
     # Convert all positional arguments into keyword arguments
     if args != ():
-        if model_info.model_type == build.ModelType.PYTORCH:
+        if model_info.model_type in [
+            build.ModelType.PYTORCH,
+            build.ModelType.PYTORCH_COMPILED,
+        ]:
             forward_function = model_info.model.forward
         elif model_info.model_type == build.ModelType.KERAS:
             forward_function = model_info.model.call
         all_args = list(inspect.signature(forward_function).parameters.keys())
         for i in range(len(args)):
             if torch.is_tensor(args[i]):
                 inputs[all_args[i]] = torch.tensor(args[i].detach().numpy())
@@ -115,38 +119,47 @@
 
     # Save model labels
     tracer_args.labels["class"] = [f"{type(model_info.model).__name__}"]
     labels.save_to_cache(tracer_args.cache_dir, build_name, tracer_args.labels)
 
     perf = None
     try:
-        perf = benchmark_model(
-            model_info.model,
-            inputs,
-            device=tracer_args.device,
-            backend=tracer_args.backend,
-            runtime=tracer_args.runtime,
-            build_name=build_name,
-            cache_dir=tracer_args.cache_dir,
-            build_only=Action.BENCHMARK not in tracer_args.actions,
-            lean_cache=tracer_args.lean_cache,
-            groq_num_chips=tracer_args.groq_num_chips,
-            groq_compiler_flags=tracer_args.groq_compiler_flags,
-            groq_assembler_flags=tracer_args.groq_assembler_flags,
-            groqview=tracer_args.groqview,
-            sequence=tracer_args.sequence,
-            onnx_opset=tracer_args.onnx_opset,
-        )
-
-        if Action.BENCHMARK in tracer_args.actions:
-            model_info.status_message = "Model successfully benchmarked!"
-            model_info.performance = perf
+        if model_info.model_type == build.ModelType.PYTORCH_COMPILED:
+            model_info.status_message = (
+                "Skipping model compiled using torch.compile(). "
+                "benchit requires models to be in eager mode "
+                "(regardless of what runtime you have selected)."
+            )
+            model_info.status_message_color = printing.Colors.WARNING
         else:
-            model_info.status_message = "Model successfully built!"
-        model_info.status_message_color = printing.Colors.OKGREEN
+            perf = benchmark_model(
+                model_info.model,
+                inputs,
+                device=tracer_args.device,
+                backend=tracer_args.backend,
+                runtime=tracer_args.runtime,
+                build_name=build_name,
+                cache_dir=tracer_args.cache_dir,
+                build_only=Action.BENCHMARK not in tracer_args.actions,
+                export_only=Action.EXPORT in tracer_args.actions,
+                lean_cache=tracer_args.lean_cache,
+                groq_num_chips=tracer_args.groq_num_chips,
+                groq_compiler_flags=tracer_args.groq_compiler_flags,
+                groq_assembler_flags=tracer_args.groq_assembler_flags,
+                groqview=tracer_args.groqview,
+                sequence=tracer_args.sequence,
+                onnx_opset=tracer_args.onnx_opset,
+            )
+            if Action.BENCHMARK in tracer_args.actions:
+                model_info.status_message = "Model successfully benchmarked!"
+                model_info.performance = perf
+                model_info.status_message_color = printing.Colors.OKGREEN
+            else:
+                model_info.status_message = "Model successfully built!"
+                model_info.status_message_color = printing.Colors.OKGREEN
 
     except exp.StageError:
         build_state = build.load_state(
             cache_dir=tracer_args.cache_dir, build_name=build_name
         )
         model_info.status_message = "Build Error: see log files for details."
         model_info.status_message_color = printing.Colors.WARNING
@@ -169,16 +182,28 @@
         _store_traceback(model_info)
     finally:
         # Ensure that stdout is not being forwarded before updating status
         if hasattr(sys.stdout, "terminal"):
             sys.stdout = sys.stdout.terminal
         status.update(tracer_args.models_found)
 
+        if tracer_args.device == "groq":
+            import groqflow.common.build as groq_build
+
+            state_type = groq_build.State
+        else:
+            state_type = build.State
+
+        if model_info.model_type == build.ModelType.PYTORCH_COMPILED:
+            return
+
         build_state = build.load_state(
-            cache_dir=tracer_args.cache_dir, build_name=build_name
+            cache_dir=tracer_args.cache_dir,
+            build_name=build_name,
+            state_type=state_type,
         )
 
         # ONNX stats that we want to save into the build's mlagility_stats.yaml file
         # so that they can be easily accessed by the report command later
         if tracer_args.runtime not in ["torch-eager", "torch-compiled"]:
             onnx_ops_counter = util.get_onnx_ops_list(build_state.converted_onnx_file)
             onnx_model_info = util.populate_onnx_model_info(
@@ -218,15 +243,15 @@
                 value=vars(perf),
             )
 
 
 def get_model_hash(
     model: Union[torch.nn.Module, "tf.keras.Model"], model_type: build.ModelType
 ):
-    return build.hash_model(model, model_type, hash_params=False)[:8]
+    return build.hash_model(model, model_type, hash_params=True)[:8]
 
 
 def store_model_info(
     model: Union[torch.nn.Module, "tf.keras.Model"],
     model_name: str,
     model_type: build.ModelType,
     frame: FrameType,
@@ -252,24 +277,27 @@
     identifier = f"{model_hash}_{tracer_args.script_name}"
     model_already_found = False
     for model_info in tracer_args.models_found.values():
         if identifier == f"{model_info.hash}_{model_info.script_name}":
             model_already_found = True
 
     if not model_already_found:
+        build_model = (Action.BUILD in tracer_args.actions) or (
+            Action.EXPORT in tracer_args.actions
+        )
         tracer_args.models_found[model_hash] = util.ModelInfo(
             model=model,
             name=model_name,
             file=file,
             line=line,
             depth=depth,
             hash=model_hash,
             parent_hash=parent_hash,
             is_target=model_hash in tracer_args.targets or tracer_args.targets == [],
-            build_model=Action.BUILD in tracer_args.actions,
+            build_model=build_model,
             model_type=model_type,
             script_name=tracer_args.script_name,
         )
 
 
 def explore_frame(
     frame,
@@ -282,21 +310,28 @@
 ):
     """
     This function checks whether local_var is a torch or keras model.
     If it is, we will modify its forward function to know when it
     is called.
     """
 
+    # Exit frame exploration if Python is shutting down
+    if not bool(sys.modules):
+        return
+
     # Skip all variables that are not a subclass of torch.nn.Module/tf.keras.Model
     # Note: try block used since dead weakreferences fail when checking subclass
     try:
         if issubclass(type(local_var), torch.nn.Module):
             if type(local_var) in tracer_args.torch_activations:
                 return
-            model_type = build.ModelType.PYTORCH
+            if "dynamo_ctx" in local_var.__dict__:
+                model_type = build.ModelType.PYTORCH_COMPILED
+            else:
+                model_type = build.ModelType.PYTORCH
         elif tf_helpers.is_keras_subclass(type(local_var)):
             model_type = build.ModelType.KERAS
         else:
             return
     except AttributeError:
         return
 
@@ -316,32 +351,40 @@
     if "self" in frame.f_locals:
         self_var = frame.f_locals["self"]
         inside_class = type(self_var)
         inside_nn_subclass = issubclass(
             inside_class, torch.nn.Module
         ) or tf_helpers.is_keras_subclass(inside_class)
 
-    if not hasattr(local_var, "forward_instrumented") and not inside_nn_subclass:
+    if not inside_nn_subclass:
+        if hasattr(local_var, "forward_instrumented"):
+            # A previously-found model might have been compiled
+            # Update that information if needed
+            if model_type == build.ModelType.PYTORCH_COMPILED:
+                tracer_args.models_found[
+                    local_var.benchit_hash
+                ].model_type = build.ModelType.PYTORCH_COMPILED
+            return
 
         if model_type == build.ModelType.PYTORCH:
-
             # Avoid instrumenting models before they have been fully loaded
             if util.count_parameters(local_var, model_type) == 0:
                 return
 
             # Mark this model as instrumented
             local_var.forward_instrumented = True
 
             # Create a copy of the old forward function
             old_forward = local_var.forward
 
             # Recursively look for sub-models within the found model
             # This is only possible on Pytorch, since each layer of a torch.nn.module
             # is also a torch.nn.module.
             model_hash = get_model_hash(local_var, model_type)
+            local_var.benchit_hash = model_hash
             if depth < tracer_args.max_depth:
                 recursive_search(
                     frame, event, local_var, depth, model_hash, tracer_args
                 )
 
             # We can keep track of Pytorch models even before they are executed
             store_model_info(
@@ -363,15 +406,14 @@
 
             # Raise exception if user tries to use max_depth!=0 for a keras model
             if tracer_args.max_depth != 0:
                 raise exp.Error("max_depth is not supported for Keras models")
         local_var.old_forward = old_forward
 
         def forward_spy(*args, **kwargs):
-
             tracer = sys.getprofile()
             if tracer is not None:
                 # Turn tracing off while the model is being executed for speed
                 sys.setprofile(None)
             elif depth == 0:
                 # If this model is being executed and the tracing is already off
                 # we are calling a module within a parent module. We only run
```

### Comparing `mlagility-3.0.2/src/mlagility/analysis/status.py` & `mlagility-3.1.1/src/mlagility/analysis/status.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility/analysis/tf_helpers.py` & `mlagility-3.1.1/src/mlagility/analysis/tf_helpers.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility/analysis/util.py` & `mlagility-3.1.1/src/mlagility/analysis/util.py`

 * *Files 6% similar despite different names*

```diff
@@ -87,19 +87,29 @@
         result_dict.update({"error": "ONNX model analysis failed"})
         return result_dict
     # pylint: disable=E1101
     result_dict.update(
         {
             "ir_version": getattr(model, "ir_version", None),
             "opset": getattr(model.opset_import[0], "version", None),
-            "size on disk (KiB)": round(
-                model.SerializeToString().__sizeof__() / 1024, 4
-            ),
         }
     )
+    try:
+        result_dict.update(
+            {
+                "size on disk (KiB)": round(
+                    model.SerializeToString().__sizeof__() / 1024, 4
+                ),
+            }
+        )
+    except ValueError:
+        # Models >2GB on disk cannot have their model size measured this
+        # way and will throw a ValueError https://github.com/groq/mlagility/issues/318
+        pass
+
     return result_dict
 
 
 def onnx_input_dimensions(onnx_model) -> Dict:
     """
     Read model input dimensions
     """
```

### Comparing `mlagility-3.0.2/src/mlagility/api/devices.py` & `mlagility-3.1.1/src/mlagility/api/devices.py`

 * *Files 0% similar despite different names*

```diff
@@ -221,15 +221,15 @@
         stdout, exit_code = exec_command(client, "lspci | grep -i nvidia")
         if stdout == "" or exit_code == 1:
             msg = "No NVIDIA GPUs available on the remote machine"
             raise exp.ModelRuntimeError(msg)
         files_to_transfer = [TRT_BENCHMARKING_SCRIPT]
     elif device_type == "x86":
         # Check if x86_64 CPU is available remotely
-        stdout, exit_code = exec_command(client, "uname -i")
+        stdout, exit_code = exec_command(client, "uname -m")
         if stdout != "x86_64" or exit_code == 1:
             msg = "Only x86_64 CPUs are supported at this time for benchmarking"
             raise exp.ModelRuntimeError(msg)
         files_to_transfer = [
             ORT_BENCHMARKING_SCRIPT,
             "Dockerfile",
             ORT_EXECUTION_SCRIPT,
@@ -268,15 +268,15 @@
             s.put(f"{dir_path}/{file}", f"{output_dir}/{file}")
 
 
 def setup_local_host(device_type: str, output_dir: str) -> None:
     if device_type == "x86":
         # Check if x86_64 CPU is available locally
         check_device = subprocess.run(
-            ["uname", "-i"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=False
+            ["uname", "-m"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=False
         )
         stdout = check_device.stdout.decode().strip()
         if stdout != "x86_64" or check_device.returncode == 1:
             msg = "Only x86_64 CPUs are supported at this time for competitive benchmarking"
             raise exp.ModelRuntimeError(msg)
         files_to_transfer = [
             ORT_BENCHMARKING_SCRIPT,
```

### Comparing `mlagility-3.0.2/src/mlagility/api/model_api.py` & `mlagility-3.1.1/src/mlagility/api/model_api.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,14 +28,15 @@
     build_name: str,
     script_name: str = None,
     cache_dir: str = filesystem.DEFAULT_CACHE_DIR,
     device: str = "x86",
     runtime: str = "ort",
     backend: str = "local",
     build_only: bool = False,
+    export_only: bool = False,
     lean_cache: bool = False,
     rebuild: str = MLAGILITY_DEFAULT_REBUILD_POLICY,
     onnx_opset: int = build.DEFAULT_ONNX_OPSET,
     groq_compiler_flags: Optional[List[str]] = None,
     groq_assembler_flags: Optional[List[str]] = None,
     groq_num_chips: Optional[int] = None,
     groqview: bool = False,
@@ -130,14 +131,15 @@
                 model=model,
                 inputs=inputs,
                 build_name=build_name,
                 cache_dir=cache_dir,
                 rebuild=rebuild,
                 sequence=sequence,
                 onnx_opset=onnx_opset,
+                export_only=export_only,
             )
 
             if not build_only:
                 printing.log_info(f"Benchmarking on {backend} {device}...")
                 gpu_model = trtmodel.TRTModel(
                     cache_dir=omodel.state.cache_dir,
                     build_name=omodel.state.config.build_name,
@@ -149,14 +151,15 @@
                 model=model,
                 inputs=inputs,
                 build_name=build_name,
                 cache_dir=cache_dir,
                 rebuild=rebuild,
                 sequence=sequence,
                 onnx_opset=onnx_opset,
+                export_only=export_only,
             )
 
             if not build_only:
                 printing.log_info(f"Benchmarking on {backend} {device}...")
                 cpu_model = ortmodel.ORTModel(
                     build_name=omodel.state.config.build_name,
                     cache_dir=omodel.state.cache_dir,
```

### Comparing `mlagility-3.0.2/src/mlagility/api/ortmodel.py` & `mlagility-3.1.1/src/mlagility/api/ortmodel.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility/api/performance.py` & `mlagility-3.1.1/src/mlagility/api/performance.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility/api/run_ort_model.py` & `mlagility-3.1.1/src/mlagility/api/run_ort_model.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility/api/script_api.py` & `mlagility-3.1.1/src/mlagility/api/script_api.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 import importlib.machinery
 from typing import Tuple, List, Dict, Optional, Union
 import onnxflow.common.printing as printing
 import onnxflow.common.build as build
 import onnxflow.common.exceptions as exceptions
 import onnxflow.justbuildit.stage as stage
 import onnxflow.justbuildit.export as export
-import mlagility.cli.slurm as slurm
+import mlagility.cli.spawn as spawn
 import mlagility.common.filesystem as filesystem
 import mlagility.common.labels as labels_library
 from mlagility.api.model_api import benchmark_model
 from mlagility.api.devices import SUPPORTED_DEVICES, DEFAULT_RUNTIME
 from mlagility.analysis.analysis import (
     evaluate_script,
     TracerArgs,
@@ -39,28 +39,32 @@
             "Each script input to benchit should have either 0 or 1 '::' in it."
             f"However, {script_path} was received."
         )
 
     return script_path, targets, encoded_input
 
 
-def load_sequence_from_file(sequence: Union[str, stage.Sequence], use_slurm: bool):
+def load_sequence_from_file(
+    sequence: Union[str, stage.Sequence],
+    use_slurm: bool,
+    process_isolation: bool,
+):
     """
     Import the sequence file to get a custom sequence, if the user provided
     one. Sequence instances are passed through this function as long as
-    the user is not in Slurm mode.
+    the user is not going to spawn a new process (indicated by `use_slurm` or `process_isolation`).
     """
 
     if sequence is not None:
-        if use_slurm:
-            # The slurm node will need to load a sequence file
+        if use_slurm or process_isolation:
+            # The spawned process will need to load a sequence file
             if not isinstance(sequence, str):
                 raise ValueError(
                     "The 'sequence' arg must be a str (path to a sequence file) "
-                    "when use_slurm=True."
+                    "when use_slurm=True or process_isolation=True."
                 )
             custom_sequence = sequence
         elif isinstance(sequence, str):
             loader = importlib.machinery.SourceFileLoader("a_b", sequence)
             mod = types.ModuleType(loader.name)
             loader.exec_module(mod)
             # pylint: disable = no-member
@@ -77,38 +81,40 @@
 
     return custom_sequence
 
 
 def benchmark_script(
     input_scripts: List[str],
     use_slurm: bool = False,
+    process_isolation: bool = False,
     lean_cache: bool = False,
     cache_dir: str = filesystem.DEFAULT_CACHE_DIR,
     labels: List[str] = None,
     rebuild: Optional[str] = None,
     device: str = None,
     backend: str = "local",
     runtimes: List[str] = None,
     analyze_only: bool = False,
     build_only: bool = False,
+    export_only: bool = False,
     resume: bool = False,
     script_args: Optional[str] = None,
     max_depth: int = 0,
     onnx_opset: int = build.DEFAULT_ONNX_OPSET,
     sequence: Union[str, stage.Sequence] = None,
     groq_compiler_flags: Optional[List[str]] = None,
     groq_assembler_flags: Optional[List[str]] = None,
     groq_num_chips: Optional[int] = None,
     groqview: bool = False,
 ):
 
     # Make sure the cache directory exists
     filesystem.make_cache_dir(cache_dir)
 
-    custom_sequence = load_sequence_from_file(sequence, use_slurm)
+    custom_sequence = load_sequence_from_file(sequence, use_slurm, process_isolation)
 
     if device is None:
         device = "x86"
     if runtimes is None:
         runtimes = [SUPPORTED_DEVICES[device][DEFAULT_RUNTIME]]
 
     # Force the user to specify a legal cache dir in NFS if they are using slurm
@@ -141,14 +147,19 @@
             raise exceptions.ArgError(f"Script must end with .py (got {script})")
 
     # Decode benchit args into TracerArgs flags
     if analyze_only:
         actions = [
             Action.ANALYZE,
         ]
+    elif export_only:
+        actions = [
+            Action.ANALYZE,
+            Action.EXPORT,
+        ]
     elif build_only:
         actions = [
             Action.ANALYZE,
             Action.BUILD,
         ]
     else:
         actions = [
@@ -159,15 +170,15 @@
 
     if use_slurm:
         if backend != "local":
             raise ValueError(
                 "Slurm only works with local benchmarking, set the `backend` "
                 "argument to 'local'."
             )
-        jobs = slurm.jobs_in_queue()
+        jobs = spawn.slurm_jobs_in_queue()
         if len(jobs) > 0:
             printing.log_warning(f"There are already slurm jobs in your queue: {jobs}")
             printing.log_info(
                 "Suggest quitting benchit, running 'scancel -u $USER' and trying again."
             )
 
     # Use this data structure to keep a running index of all models
@@ -192,30 +203,47 @@
 
         # Add the script to the database
         # Skip this if we are in Slurm mode; it has already been done in the main process
         if os.environ.get("USING_SLURM") != "TRUE":
             db.add_script(filesystem.clean_script_name(script))
 
         for runtime in runtimes:
-            if use_slurm:
-                slurm.run_benchit(
+            if use_slurm or process_isolation:
+                # Decode args into spawn.Target
+                if use_slurm and process_isolation:
+                    raise ValueError(
+                        "use_slurm and process_isolation are mutually exclusive, but both are True"
+                    )
+                elif use_slurm:
+                    target = spawn.Target.SLURM
+                elif process_isolation:
+                    target = spawn.Target.LOCAL_PROCESS
+                else:
+                    raise ValueError(
+                        "This code path requires use_slurm or use_process to be True, "
+                        "but both are False"
+                    )
+
+                spawn.run_benchit(
                     op="benchmark",
                     script=encoded_input,
                     cache_dir=cache_dir,
                     rebuild=rebuild,
+                    target=target,
                     groq_compiler_flags=groq_compiler_flags,
                     groq_assembler_flags=groq_assembler_flags,
                     groq_num_chips=groq_num_chips,
                     groqview=groqview,
                     device=device,
                     runtimes=[runtime],
                     max_depth=max_depth,
                     onnx_opset=onnx_opset,
                     analyze_only=analyze_only,
                     build_only=build_only,
+                    export_only=export_only,
                     lean_cache=lean_cache,
                 )
 
             else:
 
                 # Instantiate an object that holds all of the arguments
                 # for analysis, build, and benchmarking
@@ -241,38 +269,40 @@
 
                 # Run analysis, build, and benchmarking on every model
                 # in the script
                 models_found = evaluate_script(tracer_args, script_args)
 
     # Wait until all the Slurm jobs are done
     if use_slurm:
-        while len(slurm.jobs_in_queue()) != 0:
+        while len(spawn.slurm_jobs_in_queue()) != 0:
             print(
-                f"Waiting: {len(slurm.jobs_in_queue())} "
-                f"jobs left in queue: {slurm.jobs_in_queue()}"
+                f"Waiting: {len(spawn.slurm_jobs_in_queue())} "
+                f"jobs left in queue: {spawn.slurm_jobs_in_queue()}"
             )
             time.sleep(5)
 
-        slurm.update_database_builds(cache_dir, input_scripts)
+        spawn.update_database_builds(cache_dir, input_scripts)
 
     printing.log_success("The 'benchmark' command is complete.")
 
 
 def benchmark_files(
     input_files: str = None,
     use_slurm: bool = False,
+    process_isolation: bool = False,
     lean_cache: bool = False,
     cache_dir: str = filesystem.DEFAULT_CACHE_DIR,
     labels: List[str] = None,
     rebuild: Optional[str] = None,
     device: str = None,
     backend: str = "local",
     runtimes: List[str] = None,
     analyze_only: bool = False,
     build_only: bool = False,
+    export_only: bool = False,
     resume: bool = False,
     script_args: Optional[str] = None,
     max_depth: int = 0,
     onnx_opset: int = build.DEFAULT_ONNX_OPSET,
     sequence: Union[str, stage.Sequence] = None,
     groq_compiler_flags: Optional[List[str]] = None,
     groq_assembler_flags: Optional[List[str]] = None,
@@ -296,23 +326,25 @@
 
     if len(python_scripts):
         # Pass the args straight into benchmark_script(), which knows how
         # to iterate over python scripts
         benchmark_script(
             input_scripts=python_scripts,
             use_slurm=use_slurm,
+            process_isolation=process_isolation,
             lean_cache=lean_cache,
             cache_dir=cache_dir,
             labels=labels,
             rebuild=rebuild,
             device=device,
             backend=backend,
             runtimes=runtimes,
             analyze_only=analyze_only,
             build_only=build_only,
+            export_only=export_only,
             resume=resume,
             script_args=script_args,
             max_depth=max_depth,
             onnx_opset=onnx_opset,
             sequence=sequence,
             groq_compiler_flags=groq_compiler_flags,
             groq_assembler_flags=groq_assembler_flags,
@@ -329,26 +361,29 @@
             onnx_sequence = stage.Sequence(
                 unique_name="onnx_passthrough",
                 monitor_message="Pass through ONNX file",
                 stages=[export.ReceiveOnnxModel(), export.SuccessStage()],
                 enable_model_validation=True,
             )
         else:
-            onnx_sequence = load_sequence_from_file(sequence, use_slurm)
+            onnx_sequence = load_sequence_from_file(
+                sequence, use_slurm, process_isolation
+            )
 
         for runtime in runtimes:
             benchmark_model(
                 model=onnx_file,
                 inputs=None,
                 build_name=build_name,
                 cache_dir=cache_dir,
                 device=device,
                 backend=backend,
                 runtime=runtime,
                 build_only=build_only,
+                export_only=export_only,
                 lean_cache=lean_cache,
                 rebuild=rebuild,
                 onnx_opset=onnx_opset,
                 groq_compiler_flags=groq_compiler_flags,
                 groq_assembler_flags=groq_assembler_flags,
                 groq_num_chips=groq_num_chips,
                 groqview=groqview,
```

### Comparing `mlagility-3.0.2/src/mlagility/api/setup_ort.py` & `mlagility-3.1.1/src/mlagility/api/setup_ort.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility/api/trtmodel.py` & `mlagility-3.1.1/src/mlagility/api/trtmodel.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility/cli/cli.py` & `mlagility-3.1.1/src/mlagility/cli/cli.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 import argparse
 import os
 import sys
+from difflib import get_close_matches
 import onnxflow.common.build as build
+import onnxflow.common.exceptions as exceptions
 import mlagility.common.filesystem as filesystem
 import mlagility.cli.report as report
 from mlagility.api.script_api import benchmark_files
 from mlagility.version import __version__ as mlagility_version
 from mlagility.api.devices import SUPPORTED_DEVICES, DEFAULT_RUNTIME
 
 
@@ -41,23 +43,25 @@
     """
     Map the argparse args into benchmark_files() arguments
     """
 
     benchmark_files(
         input_files=args.input_files,
         use_slurm=args.use_slurm,
+        process_isolation=args.process_isolation,
         lean_cache=args.lean_cache,
         cache_dir=args.cache_dir,
         labels=args.labels,
         rebuild=args.rebuild,
         device=args.device,
         backend=args.backend,
         runtimes=args.runtimes,
         analyze_only=args.analyze_only,
         build_only=args.build_only,
+        export_only=args.export_only,
         resume=args.resume,
         script_args=args.script_args,
         max_depth=args.max_depth,
         onnx_opset=args.onnx_opset,
         sequence=args.sequence_file,
         groq_compiler_flags=args.groq_compiler_flags,
         groq_assembler_flags=args.groq_assembler_flags,
@@ -88,32 +92,50 @@
         required=True,
     )
 
     #######################################
     # Parser for the "benchmark" command
     #######################################
 
+    def check_extension(choices, file_name):
+        _, extension = os.path.splitext(file_name.split("::")[0])
+        if extension[1:].lower() not in choices:
+            raise exceptions.ArgError(
+                f"input_files must end with .py or .onnx (got '{file_name}')"
+            )
+        return file_name
+
     benchmark_parser = subparsers.add_parser(
         "benchmark", help="Benchmark the performance of one or more models"
     )
     benchmark_parser.set_defaults(func=benchmark_command)
 
     benchmark_parser.add_argument(
         "input_files",
         nargs="+",
         help="One or more script (.py) or ONNX (.onnx) files to be benchmarked",
+        type=lambda file: check_extension(("py", "onnx"), file),
     )
 
-    benchmark_parser.add_argument(
+    slurm_or_processes_group = benchmark_parser.add_mutually_exclusive_group()
+
+    slurm_or_processes_group.add_argument(
         "--use-slurm",
         dest="use_slurm",
         help="Execute on Slurm instead of using local compute resources",
         action="store_true",
     )
 
+    slurm_or_processes_group.add_argument(
+        "--process-isolation",
+        dest="process_isolation",
+        help="Isolate evaluating each input into a separate process",
+        action="store_true",
+    )
+
     benchmark_parser.add_argument(
         "--lean-cache",
         dest="lean_cache",
         help="Delete all build artifacts except for log files when the command completes",
         action="store_true",
     )
 
@@ -201,17 +223,24 @@
         "--build-only",
         dest="build_only",
         help="Stop this command after the build phase",
         action="store_true",
     )
 
     benchmark_parser.add_argument(
+        "--export-only",
+        dest="export_only",
+        help="Stop this command after the ONNX export in the build phase",
+        action="store_true",
+    )
+
+    benchmark_parser.add_argument(
         "--resume",
         dest="resume",
-        help="Resume a benchit run by skipping any input scripts that have already been visted",
+        help="Resume a benchit run by skipping any input scripts that have already been visited",
         action="store_true",
     )
 
     benchmark_parser.add_argument(
         "--script-args",
         dest="script_args",
         type=str,
@@ -488,16 +517,33 @@
     #######################################
 
     # The default behavior of this CLI is to run the build command
     # on a target script. If the user doesn't provide a command,
     # we alter argv to insert the command for them.
 
     if len(sys.argv) > 1:
-        if sys.argv[1] not in subparsers.choices.keys() and "-h" not in sys.argv[1]:
-            sys.argv.insert(1, "benchmark")
+        first_arg = sys.argv[1]
+        if first_arg not in subparsers.choices.keys() and "-h" not in first_arg:
+            if "." in first_arg:
+                sys.argv.insert(1, "benchmark")
+            else:
+                # Check how close we are from each of the valid options
+                valid_options = list(subparsers.choices.keys())
+                close_matches = get_close_matches(first_arg, valid_options)
+
+                error_msg = f"Unexpected positional argument `benchit {first_arg}`. "
+                if close_matches:
+                    error_msg += f"Did you mean `benchit {close_matches[0]}`?"
+                else:
+                    error_msg += (
+                        "The first positional argument must either be "
+                        "an input file with the .py or .onnx file extension or "
+                        f"one of the following commands: {valid_options}."
+                    )
+                raise exceptions.ArgError(error_msg)
 
     args = parser.parse_args()
     if args.func == benchmark_command:
         # Validate runtimes arg
         if args.runtimes:
             for runtime in args.runtimes:
                 if runtime not in SUPPORTED_DEVICES[args.device]:
```

### Comparing `mlagility-3.0.2/src/mlagility/cli/login.py` & `mlagility-3.1.1/src/mlagility/cli/login.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility/cli/report.py` & `mlagility-3.1.1/src/mlagility/cli/report.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility/common/filesystem.py` & `mlagility-3.1.1/src/mlagility/common/filesystem.py`

 * *Files 1% similar despite different names*

```diff
@@ -227,15 +227,15 @@
 
     return builds
 
 
 def print_available_builds(args):
     printing.log_info(f"Builds available in cache {args.cache_dir}:")
     builds = get_available_builds(args.cache_dir)
-    printing.list_table(builds)
+    printing.list_table(builds, num_cols=1)
     print()
 
 
 def delete_builds(args):
 
     check_cache_dir(args.cache_dir)
```

### Comparing `mlagility-3.0.2/src/mlagility/common/labels.py` & `mlagility-3.1.1/src/mlagility/common/labels.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility/parser.py` & `mlagility-3.1.1/src/mlagility/parser.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/mlagility.egg-info/PKG-INFO` & `mlagility-3.1.1/src/mlagility.egg-info/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mlagility
-Version: 3.0.2
+Version: 3.1.1
 Summary: MLAgility Benchmark and Tools
 Home-page: https://github.com/groq/mlagility
 Author: Jeremy Fowers, Daniel Holanda, Ramakrishnan Sivakumar, Victoria Godsoe
 Author-email: jfowers@groq.com, dhnoronha@groq.com, rsivakumar@groq.com, vgodsoe@groq.com
 License: MIT
 Requires-Python: >=3.8, <3.11
 Description-Content-Type: text/markdown
@@ -12,14 +12,15 @@
 Provides-Extra: groq
 License-File: LICENSE
 
 # The MLAgility Project
 
 [![MLAgility tests](https://github.com/groq/mlagility/actions/workflows/test_mlagility.yml/badge.svg)](https://github.com/groq/mlagility/tree/main/test "Check out our tests")
 [![onnxflow tests](https://github.com/groq/mlagility/actions/workflows/test_onnxflow.yml/badge.svg)](https://github.com/groq/mlagility/tree/main/test "Check out our tests")
+[![MLAgility GPU tests](https://github.com/groq/mlagility/actions/workflows/test_gpu_mlagility.yml/badge.svg)](https://github.com/groq/mlagility/tree/main/test "Check out our tests")
 [![OS - Linux](https://img.shields.io/badge/OS-Linux-blue?logo=linux&logoColor=white)](https://github.com/groq/mlagility/blob/main/docs/install.md "Check out our instructions")
 [![Made with Python](https://img.shields.io/badge/Python-3.8,3.10-blue?logo=python&logoColor=white)](https://github.com/groq/mlagility/blob/main/docs/install.md "Check out our instructions")
 [![License](https://img.shields.io/badge/License-MIT-blue)](https://github.com/groq/mlagility/blob/main/LICENSE "Check out our license")
 
 
 MLAgility offers a complementary approach to MLPerf by examining the capability of vendors to provide turnkey solutions to a corpus of hundreds of off-the-shelf models. All of the model scripts and benchmarking code are published as open source software. The performance data is available at our [Huggingface Space](https://huggingface.co/spaces/Groq/mlagility).
```

### Comparing `mlagility-3.0.2/src/mlagility.egg-info/SOURCES.txt` & `mlagility-3.1.1/src/mlagility.egg-info/SOURCES.txt`

 * *Files 0% similar despite different names*

```diff
@@ -18,14 +18,29 @@
 models/graph_convolutions/gatedgraphconv.py
 models/graph_convolutions/generalconv.py
 models/graph_convolutions/leconv.py
 models/graph_convolutions/pnaconv.py
 models/graph_convolutions/resgatedgraphconv.py
 models/graph_convolutions/sageconv.py
 models/graph_convolutions/tagconv.py
+models/llm/gpt_neo.py
+models/llm/gpt_neox.py
+models/llm/gptj.py
+models/llm_layer/gpt_neo_layer.py
+models/llm_layer/gpt_neox_layer.py
+models/llm_layer/gptj_layer.py
+models/llm_layer/llama_13b_cache_layer.py
+models/llm_layer/llama_13b_layer.py
+models/llm_layer/llama_33b_cache_layer.py
+models/llm_layer/llama_33b_layer.py
+models/llm_layer/llama_65b_cache_layer.py
+models/llm_layer/llama_65b_layer.py
+models/llm_layer/llama_7b_cache_layer.py
+models/llm_layer/llama_7b_layer.py
+models/llm_layer/llama_layer_prototype.py
 models/popular_on_huggingface/0x7194633_keyt5-large.py
 models/popular_on_huggingface/AI-Growth-Lab_PatentSBERTa.py
 models/popular_on_huggingface/AmazonScience_qanlu.py
 models/popular_on_huggingface/BM-K_KoSimCSE-roberta.py
 models/popular_on_huggingface/Babelscape_wikineural-multilingual-ner.py
 models/popular_on_huggingface/Bhuvana_t5-base-spellchecker.py
 models/popular_on_huggingface/CAMeL-Lab_bert-base-arabic-camelbert-ca-pos-egy.py
@@ -723,17 +738,14 @@
 models/popular_on_huggingface/uer_roberta-base-finetuned-jd-full-chinese.py
 models/popular_on_huggingface/uer_roberta-base-word-chinese-cluecorpussmall.py
 models/popular_on_huggingface/uer_t5-base-chinese-cluecorpussmall.py
 models/popular_on_huggingface/uer_t5-small-chinese-cluecorpussmall.py
 models/popular_on_huggingface/uer_t5-v1_1-base-chinese-cluecorpussmall.py
 models/popular_on_huggingface/uer_t5-v1_1-small-chinese-cluecorpussmall.py
 models/popular_on_huggingface/unicamp-dl_translation-pt-en-t5.py
-models/popular_on_huggingface/unitary_multilingual-toxic-xlm-roberta.py
-models/popular_on_huggingface/unitary_toxic-bert.py
-models/popular_on_huggingface/unitary_unbiased-toxic-roberta.py
 models/popular_on_huggingface/ushikado_yuyuyui-chatbot.py
 models/popular_on_huggingface/uw-madison_nystromformer-512.py
 models/popular_on_huggingface/valhalla_bart-large-finetuned-squadv1.py
 models/popular_on_huggingface/valhalla_t5-base-squad.py
 models/popular_on_huggingface/vblagoje_dpr-ctx_encoder-single-lfqa-wiki.py
 models/popular_on_huggingface/vinvino02_glpn-kitti.py
 models/popular_on_huggingface/vinvino02_glpn-nyu.py
@@ -1874,22 +1886,23 @@
 src/mlagility/analysis/util.py
 src/mlagility/api/Dockerfile
 src/mlagility/api/devices.py
 src/mlagility/api/execute_trt.py
 src/mlagility/api/model_api.py
 src/mlagility/api/ortmodel.py
 src/mlagility/api/performance.py
+src/mlagility/api/report.py
 src/mlagility/api/run_ort_model.py
 src/mlagility/api/script_api.py
 src/mlagility/api/setup_ort.py
 src/mlagility/api/trtmodel.py
 src/mlagility/cli/cli.py
 src/mlagility/cli/login.py
 src/mlagility/cli/report.py
-src/mlagility/cli/slurm.py
+src/mlagility/cli/spawn.py
 src/mlagility/common/filesystem.py
 src/mlagility/common/labels.py
 src/onnxflow/__init__.py
 src/onnxflow/version.py
 src/onnxflow/common/__init__.py
 src/onnxflow/common/build.py
 src/onnxflow/common/cache.py
```

### Comparing `mlagility-3.0.2/src/onnxflow/common/build.py` & `mlagility-3.1.1/src/onnxflow/common/build.py`

 * *Files 1% similar despite different names*

```diff
@@ -42,14 +42,15 @@
     LOCAL = "local"
     CLOUD = "cloud"
     REMOTE = "remote"
 
 
 class ModelType(enum.Enum):
     PYTORCH = "pytorch"
+    PYTORCH_COMPILED = "pytorch_compiled"
     KERAS = "keras"
     ONNX_FILE = "onnx_file"
     HUMMINGBIRD = "hummingbird"
     UNKNOWN = "unknown"
 
 
 def load_yaml(file_path):
@@ -71,15 +72,14 @@
 def state_file(cache_dir, build_name):
     state_file_name = f"{build_name}_state.yaml"
     path = os.path.join(output_dir(cache_dir, build_name), state_file_name)
     return path
 
 
 def hash_model(model, model_type: ModelType, hash_params: bool = True):
-
     # If the model is a path to a file, hash the file
     if model_type == ModelType.ONNX_FILE:
         # TODO: Implement a way of hashing the models but not the parameters
         # of ONNX inputs.
         if not hash_params:
             msg = "hash_params must be True for model_type ONNX_FILE"
             raise ValueError(msg)
@@ -88,15 +88,15 @@
                 file_content = f.read()
             return hashlib.sha256(file_content).hexdigest()
         else:
             raise ValueError(
                 "hash_model received str model that doesn't correspond to a file"
             )
 
-    elif model_type == ModelType.PYTORCH:
+    elif model_type in [ModelType.PYTORCH, ModelType.PYTORCH_COMPILED]:
         # Convert model parameters and topology to string
         hashable_params = {}
         for name, param in model.named_parameters():
             hashable_params[name] = param.data
         if hash_params:
             hashable_model = (str(model) + str(hashable_params)).encode()
         else:
@@ -156,22 +156,23 @@
     """
     Return the shape and data type of each value in the inputs dict
     """
     shapes = {}
     dtypes = {}
     for key in sorted(inputs):
         value = inputs[key]
-        if (
-            isinstance(
-                value,
-                (list, tuple),
-            )
-            or torch.is_tensor(value)
-            or tf_helpers.is_keras_tensor(value)
+        if isinstance(
+            value,
+            (list, tuple),
         ):
+            for v, i in zip(value, range(len(value))):
+                subkey = f"{key}[{i}]"
+                shapes[subkey] = np.array(v).shape
+                dtypes[subkey] = np.array(v).dtype.name
+        elif torch.is_tensor(value) or tf_helpers.is_keras_tensor(value):
             shapes[key] = np.array(value).shape
             dtypes[key] = np.array(value).dtype.name
         elif isinstance(value, np.ndarray):
             shapes[key] = value.shape
             dtypes[key] = value.dtype.name
         elif isinstance(value, (bool, int, float)):
             shapes[key] = (1,)
```

### Comparing `mlagility-3.0.2/src/onnxflow/common/cache.py` & `mlagility-3.1.1/src/onnxflow/common/cache.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/onnxflow/common/exceptions.py` & `mlagility-3.1.1/src/onnxflow/common/exceptions.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/onnxflow/common/onnx_helpers.py` & `mlagility-3.1.1/src/onnxflow/common/onnx_helpers.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/onnxflow/common/printing.py` & `mlagility-3.1.1/src/onnxflow/common/printing.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/onnxflow/common/quantization_helpers.py` & `mlagility-3.1.1/src/onnxflow/common/quantization_helpers.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/onnxflow/common/tensor_helpers.py` & `mlagility-3.1.1/src/onnxflow/common/tensor_helpers.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/onnxflow/common/tf_helpers.py` & `mlagility-3.1.1/src/onnxflow/common/tf_helpers.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/onnxflow/justbuildit/buildit.py` & `mlagility-3.1.1/src/onnxflow/justbuildit/buildit.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,14 +14,15 @@
     build_name: Optional[str] = None,
     cache_dir: str = build.DEFAULT_CACHE_DIR,
     monitor: bool = True,
     rebuild: Optional[str] = None,
     sequence: Optional[List[stage.Stage]] = None,
     quantization_samples: Collection = None,
     onnx_opset: int = build.DEFAULT_ONNX_OPSET,
+    export_only: bool = False,
 ) -> omodel.BaseModel:
 
     """Use build a model instance into an optimized ONNX file.
 
     Args:
         model: Model to be mapped to an optimized ONNX file, which can be a PyTorch
             model instance, Keras model instance, Hummingbird model instance,
@@ -47,14 +48,16 @@
             users only.
         quantization_samples: If set, performs post-training quantization
             on the ONNX model using the provided samplesIf the previous build used samples
             that are different to the samples used in current build, the "rebuild"
             argument needs to be manually set to "always" in the current build
             in order to create a new ONNX file.
         onnx_opset: ONNX opset to use during ONNX export.
+        export_only: Export the model to ONNX but do not apply any optimizations to the
+            resulting ONNX file.
     """
 
     # Support "~" in the cache_dir argument
     parsed_cache_dir = os.path.expanduser(cache_dir)
 
     # Validate and lock in the config (user arguments that
     # configure the build) that will be used by the rest of the toolchain
@@ -67,14 +70,15 @@
     # Analyze the user's model argument and lock in the model, inputs,
     # and sequence that will be used by the rest of the toolchain
     (model_locked, inputs_locked, sequence_locked, model_type,) = ignition.model_intake(
         model,
         inputs,
         sequence,
         user_quantization_samples=quantization_samples,
+        export_only=export_only,
     )
 
     # Get the state of the model from the cache if a valid build is available
     state = ignition.load_or_make_state(
         config=config,
         cache_dir=parsed_cache_dir,
         rebuild=rebuild or build.DEFAULT_REBUILD_POLICY,
```

### Comparing `mlagility-3.0.2/src/onnxflow/justbuildit/export.py` & `mlagility-3.1.1/src/onnxflow/justbuildit/export.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/onnxflow/justbuildit/hummingbird.py` & `mlagility-3.1.1/src/onnxflow/justbuildit/hummingbird.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/onnxflow/justbuildit/ignition.py` & `mlagility-3.1.1/src/onnxflow/justbuildit/ignition.py`

 * *Files 3% similar despite different names*

```diff
@@ -20,14 +20,23 @@
     [
         export.OptimizeOnnxModel(),
         export.ConvertOnnxToFp16(),
         export.SuccessStage(),
     ],
 )
 
+default_pytorch_export_sequence = stage.Sequence(
+    "default_pytorch_export_sequence",
+    "Exporting PyTorch Model",
+    [
+        export.ExportPytorchModel(),
+        export.SuccessStage(),
+    ],
+)
+
 default_pytorch_sequence = stage.Sequence(
     "default_pytorch_export_sequence",
     "Exporting PyTorch Model",
     [export.ExportPytorchModel(), polish_onnx_sequence],
 )
 
 pytorch_sequence_with_quantization = stage.Sequence(
@@ -37,33 +46,60 @@
         export.ExportPytorchModel(),
         export.OptimizeOnnxModel(),
         export.QuantizeONNXModel(),
         export.SuccessStage(),
     ],
 )
 
+default_keras_export_sequence = stage.Sequence(
+    "default_keras_export_sequence",
+    "Building Keras Model",
+    [
+        export.ExportKerasModel(),
+        export.SuccessStage(),
+    ],
+)
+
 default_keras_sequence = stage.Sequence(
     "default_keras_sequence",
     "Building Keras Model",
     [
         export.ExportKerasModel(),
         polish_onnx_sequence,
     ],
 )
 
+default_onnx_export_sequence = stage.Sequence(
+    "default_onnx_export_sequence",
+    "Building ONNX Model",
+    [
+        export.ReceiveOnnxModel(),
+        export.SuccessStage(),
+    ],
+)
+
 
 default_onnx_sequence = stage.Sequence(
     "default_onnx_sequence",
     "Building ONNX Model",
     [
         export.ReceiveOnnxModel(),
         polish_onnx_sequence,
     ],
 )
 
+default_hummingbird_export_sequence = stage.Sequence(
+    "default_hummingbird_export_sequence",
+    "Building Hummingbird Model",
+    [
+        hummingbird.ConvertHummingbirdModel(),
+        export.SuccessStage(),
+    ],
+)
+
 default_hummingbird_sequence = stage.Sequence(
     "default_hummingbird_sequence",
     "Building Hummingbird Model",
     [
         hummingbird.ConvertHummingbirdModel(),
         export.OptimizeOnnxModel(),
         export.SuccessStage(),
@@ -443,14 +479,21 @@
 model_type_to_sequence = {
     build.ModelType.PYTORCH: default_pytorch_sequence,
     build.ModelType.KERAS: default_keras_sequence,
     build.ModelType.ONNX_FILE: default_onnx_sequence,
     build.ModelType.HUMMINGBIRD: default_hummingbird_sequence,
 }
 
+model_type_to_export_sequence = {
+    build.ModelType.PYTORCH: default_pytorch_export_sequence,
+    build.ModelType.KERAS: default_keras_export_sequence,
+    build.ModelType.ONNX_FILE: default_onnx_export_sequence,
+    build.ModelType.HUMMINGBIRD: default_hummingbird_export_sequence,
+}
+
 model_type_to_sequence_with_quantization = {
     build.ModelType.PYTORCH: pytorch_sequence_with_quantization,
 }
 
 
 def validate_inputs(inputs: Dict):
     """
@@ -512,14 +555,15 @@
     user_inputs,
     user_sequence: Optional[stage.Sequence],
     user_quantization_samples: Optional[Collection] = None,
     override_quantization_sequence_map: Optional[
         Dict[build.ModelType, stage.Sequence]
     ] = None,
     override_sequence_map: Dict[build.ModelType, stage.Sequence] = None,
+    export_only: bool = False,
 ) -> Tuple[Any, Any, stage.Sequence, build.ModelType, str]:
 
     # Model intake structure options:
     # user_model
     #    |
     #    |------- path to onnx model file
     #    |
@@ -531,15 +575,18 @@
 
     if override_quantization_sequence_map is None:
         quantization_sequence_map = model_type_to_sequence_with_quantization
     else:
         quantization_sequence_map = override_quantization_sequence_map
 
     if override_sequence_map is None:
-        sequence_map = model_type_to_sequence
+        if export_only:
+            sequence_map = model_type_to_export_sequence
+        else:
+            sequence_map = model_type_to_sequence
     else:
         sequence_map = override_sequence_map
 
     if user_sequence is None or user_sequence.enable_model_validation:
 
         if user_model is None and user_inputs is None:
             msg = """
```

### Comparing `mlagility-3.0.2/src/onnxflow/justbuildit/stage.py` & `mlagility-3.1.1/src/onnxflow/justbuildit/stage.py`

 * *Files identical despite different names*

### Comparing `mlagility-3.0.2/src/onnxflow/model/model.py` & `mlagility-3.1.1/src/onnxflow/model/model.py`

 * *Files identical despite different names*

